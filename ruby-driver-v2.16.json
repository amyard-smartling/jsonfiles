{
    "url": "http://mongodb.com/docs/ruby-driver/v2.16",
    "includeInGlobalSearch": false,
    "documents": [
        {
            "slug": "nesting-levels",
            "title": "Page Title",
            "headings": [
                "First Level Heading",
                "Second Level Heading",
                "Third Level Heading"
            ],
            "paragraphs": "This file is not part of Ruby driver documentation proper, it is an internal\nreference for the nesting levels that other files should be using. Ruby driver documentation nesting levels:",
            "code": [],
            "preview": null,
            "tags": null,
            "facets": null
        },
        {
            "slug": "getting-started",
            "title": "Getting Started",
            "headings": [],
            "paragraphs": "This section describes how to install the driver, installation prerequisites\nand compatibility considerations.",
            "code": [],
            "preview": "This section describes how to install the driver, installation prerequisites\nand compatibility considerations.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "support",
            "title": "Support",
            "headings": [],
            "paragraphs": "Commercial support for the Ruby driver is available through the\n MongoDB Support Portal . For questions, discussions or general technical support, please visit the\n MongoDB Community Forum . Please see  Technical Support  page\nin the documentation for other support resources.",
            "code": [],
            "preview": "Commercial support for the Ruby driver is available through the\nMongoDB Support Portal.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "tutorials",
            "title": "Tutorials",
            "headings": [],
            "paragraphs": "The tutorials in this section provide examples of some frequently used\noperations. This section is not meant to be an exhaustive list of all\noperations available in the Ruby driver.",
            "code": [],
            "preview": "The tutorials in this section provide examples of some frequently used\noperations. This section is not meant to be an exhaustive list of all\noperations available in the Ruby driver.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "",
            "title": "Ruby MongoDB Driver",
            "headings": [
                "Get Started",
                "BSON",
                "Object Mappers"
            ],
            "paragraphs": "The MongoDB Ruby driver is the officially supported Ruby driver for MongoDB.\nIt can be used on its own, but it also serves as the basis of several\nobject mapping libraries. To get started with the Ruby driver, see  Installation  and\n Quick Start . Continue to  Tutorials \nfor high level documentation for common operations. The Ruby BSON implementation is packaged in a separate gem with C and\nJava extensions for speed depending on the runtime enviroment. For reference on the Ruby BSON gem, see the  . Because MongoDB is so easy to use, the basic Ruby driver can be the\nbest solution for many applications. But if you need validations,\nassociations, and other high-level data modeling functions, then you\nmay need Object Document Mapper. In the context of a Rails application, an Object Document Mapper\nprovides functionality equivalent to, but distinct from, ActiveRecord.\nBecause MongoDB is a document-based database, these mappers are called\nObject Document Mappers (ODM) as opposed to Object Relational Mappers\n(ORM). The ODM officially supported by MongoDB is Mongoid, originally written\nby Durran Jordan. For tutorials on Mongoid, see the  Mongoid Manual .",
            "code": [],
            "preview": "The MongoDB Ruby driver is the officially supported Ruby driver for MongoDB.\nIt can be used on its own, but it also serves as the basis of several\nobject mapping libraries.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "installation",
            "title": "Installation",
            "headings": [
                "Prerequisites",
                "Install the Gem",
                "What's New"
            ],
            "paragraphs": "The Ruby driver is released as a gem hosted on  Rubygems . Please see the  compatibility  page for the list of\nRuby versions and MongoDB server versions that this release of the Ruby\ndriver is compatible with. The driver itself is written entirely in Ruby, however it depends on the\n bson library  which includes a C extension\nfor MRI and a compiled Java extension for JRuby. A working C compiler and Ruby\ndevelopment headers and libraries are required when installing on MRI.\nWhen installing on JRuby, JRE is sufficient because the  bson  gem includes\nthe compiled extension. Connecting to TLS-enabled MongoDB servers, using SCRAM authentication\n(both SCRAM-SHA-1 and SCRAM-SHA-256) and using X.509 authentication (which\nis performed over a TLS connection) requires the Ruby  openssl  extension\nto be present and working. The  TLS compatibility \nsection provides further details on usage of newer TLS protocols like TLS 1.1. Add  mongo  to your  Gemfile : To install the driver manually: Please see the  release notes  for the major changes\nin each driver release and the  releases page on GitHub  for the complete\nlist of changes for each release of the driver.",
            "code": [
                {
                    "lang": "ruby",
                    "value": "gem \"mongo\", \"~> 2\""
                },
                {
                    "lang": "sh",
                    "value": "gem install mongo -v '~> 2'"
                }
            ],
            "preview": "The Ruby driver is released as a gem hosted on Rubygems.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "tutorials/quick-start",
            "title": "Quick Start",
            "headings": [
                "Prerequisites",
                "Make a Connection",
                "Access a Database and a Collection",
                "Insert a Document",
                "Query the Collection",
                "Update Documents",
                "Delete Documents",
                "Create Indexes",
                "Complete Sample App"
            ],
            "paragraphs": "A running MongoDB instance on localhost using the default port, 27017. The Ruby MongoDB driver. See  installation \nfor instructions on how to install the MongoDB driver. The following statement at the top of your code: Use  Mongo::Client  to establish a connection to a running MongoDB\ninstance. You can also use a URI connection string: The following examples demonstrate how to access a particular database\nand show its collections: To access a collection, refer to it by name. If the collection does not exist, the server will create it the first\ntime you put data into it. To insert a single document into a collection, use the\n insert_one  method. To insert multiple documents into a collection, use the\n insert_many  method. Use the  find  method to create collection queries. An empty query filter returns all documents in the collection. Use a query filter to find only matching documents. The example should print the following: Query nested documents by specifying the keys and values you want\nto match. The example should print the following: Query Options ,  Read Preference There are several update methods, including  update_one  and\n update_many .  update_one  updates a single document, while\n update_many  updates multiple documents at once. Both methods take as arguments a query filter document and a second\ndocument with the update data. Use  $set  to add or update a\nparticular field or fields. Without  $set , the entire existing\ndocument is replaced with the update data. The example should print the following: The following example uses  update_many  with a blank query filter\nto update all the documents in the collection. Other update options Use the  delete_one  or  delete_many  methods to delete documents\nfrom a collection (either singly or several at once). The following example inserts two more records into the collection,\nthen deletes all the documents with a  name  field which\nmatches a regular expression to find a string which begins with \"S\". Use the  create_one  or  create_many  methods to create indexes\nsingly or several at once. Use the  create_many  method to create several indexes with one\nstatement. Note that when using  create_many , the syntax is\ndifferent from  create_one . Index options A sample app using the Ruby driver for several common use cases\nis available for download from\n GitHub .",
            "code": [
                {
                    "lang": "ruby",
                    "value": "require 'mongo'"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test')"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new('mongodb://127.0.0.1:27017/test')"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test')\ndb = client.database\n\ndb.collections # returns a list of collection objects\ndb.collection_names # returns a list of collection names"
                },
                {
                    "lang": "ruby",
                    "value": "collection = client[:restaurants]"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new('mongodb://127.0.0.1:27017/test')\n\ncollection = client[:people]\n\ndoc = {\n  name: 'Steve',\n  hobbies: [ 'hiking', 'tennis', 'fly fishing' ],\n  siblings: {\n    brothers: 0,\n    sisters: 1\n  }\n}\n\nresult = collection.insert_one(doc)\nresult.n # returns 1, because one document was inserted"
                },
                {
                    "lang": "ruby",
                    "value": "docs = [ { _id: 1, name: 'Steve',\n           hobbies: [ 'hiking', 'tennis', 'fly fishing' ],\n           siblings: { brothers: 0, sisters: 1 } },\n         { _id: 2, name: 'Sally',\n                 hobbies: ['skiing', 'stamp collecting' ],\n                 siblings: { brothers: 1, sisters: 0 } } ]\n\nresult = collection.insert_many(docs)\nresult.inserted_count # returns 2 because two documents were inserted"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new('mongodb://127.0.0.1:27017/test')\ncollection = client[:people]\n\ncollection.find.each do |document|\n  #=> Yields a BSON::Document.\nend"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new('mongodb://127.0.0.1:27017/test')\ncollection = client[:people]\n\nputs collection.find( { name: 'Sally' } ).first"
                },
                {
                    "lang": "javascript",
                    "value": "{\"_id\" => 2, \"name\" => \"Sally\", \"hobbies\" => [\"skiing\", \"stamp collecting\"], \"siblings\" => { \"brothers\": 1, \"sisters\": 0 } }"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new('mongodb://127.0.0.1:27017/test')\ncollection = client[:people]\n\nputs collection.find(\"siblings.sisters\": 1 ).first"
                },
                {
                    "lang": "javascript",
                    "value": "{\"_id\"=>1, \"name\"=>\"Steve\", \"hobbies\"=>[\"hiking\", \"tennis\", \"fly fishing\"], \"siblings\"=>{\"brothers\"=>0, \"sisters\"=>1}}"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new('mongodb://127.0.0.1:27017/test')\ncollection = client[:people]\n\nresult = collection.update_one( { 'name' => 'Sally' }, { '$set' => { 'phone_number' => \"555-555-5555\" } } )\n\nputs collection.find( { 'name' => 'Sally' } ).first"
                },
                {
                    "lang": "javascript",
                    "value": "{\"_id\" => 2, \"name\" => \"Sally\", \"hobbies\" => [\"skiing\", \"stamp collecting\"], \"phone_number\" => \"555-555-5555\"}"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new('mongodb://127.0.0.1:27017/test')\ncollection = client[:people]\n\nresult = collection.update_many( {}, { '$set' => { 'age' => 36 } } )\n\nputs result.modified_count # returns 2 because 2 documents were updated"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new('mongodb://127.0.0.1:27017/test')\ncollection = client[:people]\n\nresult = collection.delete_one( { name: 'Steve' } )\n\nputs result.deleted_count # returns 1 because one document was deleted"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new('mongodb://127.0.0.1:27017/test')\ncollection = client[:people]\n\ncollection.insert_many([ { _id: 3, name: \"Arnold\" }, { _id: 4, name: \"Susan\" } ])\n\nputs collection.count # counts all documents in collection\n\nresult = collection.delete_many({ name: /$S*/ })\n\nputs result.deleted_count # returns the number of documents deleted"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new('mongodb://127.0.0.1:27017/test')\ncollection = client[:people]\n\ncollection.indexes.create_one({ name: 1 }, unique: true)"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new('mongodb://127.0.0.1:27017/test')\ncollection = client[:people]\n\ncollection.indexes.create_many([\n    { key: { name: 1 } , unique: true },\n    { key:  { hobbies: 1 } },\n  ])"
                }
            ],
            "preview": "Use Mongo::Client to establish a connection to a running MongoDB\ninstance.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "meta/404",
            "title": "File not found",
            "headings": [],
            "paragraphs": "The URL you requested does not exist or has been removed.",
            "code": [],
            "preview": "The URL you requested does not exist or has been removed.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "release-notes",
            "title": "Release Notes",
            "headings": [
                "2.16",
                "2.15",
                "2.14",
                "2.13",
                "2.12",
                "2.11",
                "2.10",
                "2.9"
            ],
            "paragraphs": "This page documents significant changes in driver releases. It is not an exhaustive list of changes and generally does not enumerate\nbug fixes; please consult the  releases page on GitHub  for a more\ncomprehensive list of changes in each version of the driver and the\n releases page in Jira \nfor the complete list of changes, including those internal to the driver and\nits test suite. This release adds the following new feature: The following minor improvement has been made: This release of the Ruby driver increases the minimum required Ruby version\nto 2.4 and deprecates support for MongoDB server versions below 3.6. Load balancer support. GridFS file retrieval no longer requires index creation privileges when\nthe indexes already exist, and is thus usable with users that have only\nread permissions. This release adds the following new features: The following smaller improvements have been made: Ruby 3.0 support. Ability to specify the  server API parameters . Support for Zstandard and Snappy  wire protocol compression . Query cache middleware  was moved to the\ndriver from Mongoid and is now usable in applications that do not use Mongoid. It is now possible to create collections with time-series options. Experimental support for  MongoDB Atlas Serverless  when not using a\nload balancer. The  OperationFailure  exception message now contains the server error code\nname, if provided by the server. The layout of the message was changed to\naccommodate the error code name. The generic SSL messaging has been removed from  SocketError  messages\nwhen TLS is used. TLS connections to MongoDB are now the norm, with Atlas\nrequiring TLS, and it is more likely that a connection fails due to failed\ncertificate verification than due to the server not having TLS enabled. A hook was added to permit applications to  modify the TLS context  used for TLS connections, for example to exclude\nciphers. Heartbeat succeeded and heartbeat failed  server monitoring events  are now linked to the respective heartbeat started\nevent, to improve usability. skip  and  limit  options are now prohibited when calling\n estimated_document_count , because the server command does not accept them. The driver will now omit command monitoring reply payloads when they are\nin response to sensitive commands. When the driver closes network sockets it now enforces the socket timeout. estimated_document_count  collection method now uses the  $collStats \naggregation pipeline stage instead of the count command on 5.0 and newer\nservers. The platform metadata sent by the driver to the server in the handshake\nnow includes the purpose of the connection being established, permitting\nadministrators to distinguish monitoring connections from application\nconnections. The driver now uses monotonic clock for timeouts. The driver will no longer mark servers unknown based on errors in\n writeErrors  field in the server response. Server selection timeout for  mongocryptd  has been increased to 10 seconds. This release adds the following new features: The following smaller improvements have been made: Support for Ruby versions 2.3 and 2.4 has been deprecated as of this release. Queries against Atlas Data Lake are now supported. The  query cache  has been moved from Mongoid into the\ndriver. Mongoid will use the driver's query cache as of driver 2.14.\nAs part of the move, several issues with the query cache have been fixed\nand its functionality was extended to cover aggregation pipeline queries\nand to support result sets of any size. Explain verbosity can now  be specified  when explaining. Mixed case read preference tag names are now supported. The driver will perform  OCSP endpoint verification \nby default when TLS is enabled. Due to lack of support in Ruby's  openssl \nextension, OCSP stapling is not yet implemented. Default logger level for  Client  objects is now info (up from debug).\nThis reduces the amount of log output produced by the driver by default. Database and collection write methods support specifying write concern for\nthe individual operations. Client#summary  method now shows the monitoring state of each server. When objects other than hashes are attempted to be inserted (which is not\nallowed), the driver now provides better diagnostics. DNS queries for SRV URIs are now subject to configured socket timeouts. When the  Client  object is reconnected, session pools are now cleared. This release implements the necessary client-side functionality to use the\nfeatures added in MongoDB 4.4. Specifically, the following new driver\nfunctionality has been added: The following smaller improvements have been made: Support for the  directConnection  URI option to provide a consistent\ncross-driver mechanims to discover deployment topology or force direct\nconnection. Support for  MONGODB-AWS authentication mechanism . When SCRAM authentication is used with 4.4 and newer servers, the driver will\ncomplete authentication with fewer network roundtrips. The driver creates an additional monitoring connection for 4.4 and newer\nservers, permitting the server to notify the driver when its state changes.\nThis reduces the time for the driver to discover the new primary during\nfailover events. Client  constructor can be given a block, in which case the client object\nwill be yielded to the block and automatically closed when the block ends. start_session  can be given a block, in which case the session object will\nbe yielded to the block and automatically ended when the block ends. Write options can now be specified for individual CRUD operations. The  :allow_disk_use  option was added to find operations. The  :authorized_databases  option was added to  list_databases \nmethod. The  list_collections  method now passes through all options. Ability to set an index  as hidden  when creating it. Ability to specify commit quorum when creating indexes. :wrapping_libraries   client option , to be used\nby libraries like Mongoid which wrap the driver to report their version to\nthe server for troubleshooting/statistics aggregation purposes. count_documents  can now be invoked with no arguments. The default TCP keep-alive time has been reduced to make the driver\ncorrectly detect dropped connections on Microsoft Azure. CursorNotFound  is now a resumable change stream error. The number of backtrace lines in exceptions handled by background threads\ncan now be configured. This release adds the following new features: The following smaller improvements have been made: Client-side encryption . list_collections  method now accepts the  :filter  option. Authentication exceptions now include server information to aid in\ntroubleshooting. This release adds the following new features: The following smaller improvements have been made: This release of the Ruby driver increases the minimum required Ruby version\nto 2.3, as well as minimum supported JRuby version to 9.2. If a minimum connection pool size is specified, the pool for each server\nwill create a background thread to eagerly establish connections up to\nthe specified minimum pool size. If the driver connects to the deployment using a SRV URI and the deployment\nis a sharded cluster, the driver will poll the SRV DNS records to\nautomatically discover new and removed mongos servers and adjust the\nset of known servers accordingly. The driver now permits unencoded subdelimiters in usernames and passwords in\nMongoDB URIs. User management helpers now accept the write concern option. The  command monitoring  logger provided with the\ndriver will now log connection ids used for each command. When legacy read retries are used, retry on the same set of server errors\nthat the modern retries would have retried on. The  distinct(nil)  call is prohibited because it is rejected by MongoDB\n4.4 and newer servers. This release implements the necessary client-side functionality to use the\nfeatures added in MongoDB 4.2. Specifically, the following new driver\nfunctionality has been added: The following smaller improvements have been made: Support for Ruby versions less than 2.3 is deprecated in this release. Support for sharded transactions. Applications can set the  :max_time_ms  option in  commit_transaction \nmethod. Support for database-level aggregation. Support for  $merge  aggregation pipeline stage. The update operations now accept an aggregation pipeline as an array. TLS regenotiation is now disabled when possible. Change streams now handle post-batch resume tokens provided by the server. All methods now accept  :write_concern  option for the write concern,\nincluding those that previously accepted the  :write  option. The query string in a MongoDB URI can now start with  & . This release adds the following new features: The following smaller improvements have been made: This release deprecates support for Ruby versions less than 2.3. A rewrite of the connection pool code with improved monitoring,\ncompliant with the CMAP specification A modern retryable reads implementation compliant with the cross-driver\nretryable reads specification, enabled by default. Modern retryable writes are now enabled by default. Legacy retryable writes can be disabled in most cases. The driver now supports certificate chains being provided as client\ncertificates for TLS connections. Ability to specify multiple CA certificates when creating a  Client . Ability to pass the private key and certificate via URI options. Support for the  startAfter  option in the  $changeStream \naggregation pipeline stage. Field order of BSON documents sent to the server changed for better logging. Certificate paths with unescaped slashes can now be specified in\nMongoDB URIs.",
            "code": [],
            "preview": "This page documents significant changes in driver releases.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "contribute",
            "title": "Contribute to the Driver",
            "headings": [
                "Report Bugs and Request Ruby Driver-Specific Features",
                "Request Product Features",
                "Contribute Code"
            ],
            "paragraphs": "To report a bug in the driver or request a feature specific to the Ruby driver: When creating an issue, please keep in mind that all information in JIRA\nfor the RUBY project, as well as the core server (the SERVER project),\nis publicly visible. PLEASE DO: PLEASE DO NOT: If you identified a potential security vulnerability in the Ruby driver or\nany other MongoDB product, please report it according to the instructions found\nin the  Create a Vulnerability Report . Visit  our issue tracker  and login\n(or create an account if you do not have one already). Navigate to the  RUBY project . Click  Create Issue  and fill out all of the applicable form\nfields. Provide as much information as possible about the issue. Provide detailed steps for reproducing the issue. Provide any applicable code snippets, stack traces and log data.\nDo not include any sensitive data or server logs. Specify version numbers of the driver and MongoDB server. Provide any sensitive data or server logs. Report potential security issues publicly (see 'Security Issues' below). Bug reports in JIRA for the Ruby driver and the core server (the  SERVER )\nprojects are public. To request a feature which is not specific to the Ruby driver, or which\naffects more than the driver alone (for example, a feature which requires\nMongoDB server support), please submit your idea through the\n MongoDB Feedback Forum . The MongoDB Ruby driver source is located\n at GitHub . The list of known issues in the driver is available\n in JIRA . We recommend creating a JIRA ticket before starting work on a bug fix or\nan improvement to the driver, to obtain feedback from the Ruby driver team\nas to the proposed changes. A JIRA ticket is not required to submit\na pull request but it is appreciated, especially for non-trivial changes. Pull requests should be made against the  master  branch and\ninclude relevant tests, if applicable. The Ruby driver team will backport\nthe changes to the stable branches, if needed. A MongoDB deployment is required to run the tests. Setup procedures and\nrecommendations for various deployments, as well as how to configure the\ndriver's test suite for the deployments, are covered in the  spec\nreadme . The driver is tested on  Evergreen ,\nMongoDB's in-house continuous integration platform. After a pull request\nis created, one of the Ruby driver team engineers will schedule an Evergreen\nbuild.",
            "code": [],
            "preview": "To report a bug in the driver or request a feature specific to the Ruby driver:",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/monitoring",
            "title": "Monitoring",
            "headings": [
                "Command Monitoring",
                "Server Discovery And Monitoring",
                "Server Heartbeats",
                "Heartbeat Event Intervals",
                "Connection Pool And Connection Monitoring",
                "Disabling Monitoring"
            ],
            "paragraphs": "The driver allows the application to be notified when certain events happen.\nThese events are organized into the following categories: Topology and server events are part of Server Discovery and Monitoring (SDAM). Command monitoring Topology lifecycle Server lifecycle Server heartbeats Connection pools and connections All user-initiated commands that are sent to the server publish events that\ncan be subscribed to for fine grained information. The monitoring API\npublishes a guaranteed start event for each command, then either a succeeded\nor a failed event. A subscriber must implement 3 methods:  started ,\n succeeded , and  failed , each which takes a single parameter for\nthe event. The following is an example logging subscriber based on a\nlogging subscriber used internally by the driver: To register a custom subscriber, you can do so globally for\nall clients or on a per-client basis: Sample output: The Ruby driver implements  Server Discovery And Monitoring (SDAM) specification .\nand makes the following events available to the application: For all events other than the heartbeat events, the  succeeded  method\nwill be called on each event subscriber with the event as the sole argument.\nAvailable data for events varies, therefore to log the events a separate\nclass is needed for each event type. A simple SDAM logging subscriber\ncan look like the following: To subscribe to SDAM events globally: Subscribing to SDAM events for a single client is a little more involved\nsince the events may be published during the client's construction: Sample output: Topology opening Server opening Server description changed Topology changed Server closed Topology closed Heartbeat events (covered below in a separate section) :sdam_proc  client option applies only to the client during whose\nconstruction it is given. When certain client options are changed via the\n Client#with  call, a new cluster may be created by the driver with\na default set of event subscribers. If this happens, the provided\n :sdam_proc  is not called and the application may miss events. The application can be notified of each server heartbeat by subscribing\nto SERVER_HEARTBEAT topic. A server heartbeat listener must implement\nthree methods:  started ,  succeeded  and  failed . Each heartbeat\ninvokes the  started  method on the listener, and then either  succeeded \nor  failed  method depending on the outcome of the heartbeat. All heartbeat events contain the address of the server that the heartbeat\nwas sent to. Succeeded and failed events contain the round trip time for\nthe hello or legacy hello command. Failed event also contains the exception\ninstance that was raised during hello or legacy hello command execution.\nPlease review the API documentation for ServerHeartbeatStarted,\nServerHeartbeatSucceeded and ServerHeartbeatFailed for event attribute details. The following is an example logging heartbeat event subscriber: Similarly to command events, the application can subscribe to heartbeat\nevents globally or for a specific client: Sample output: When connected to MongoDB 4.2 and earlier servers, Ruby driver by default\nissues heartbeats every  :heartbeat_frequency  (Ruby client option) seconds,\nand heartbeats are non-overlapping (the succeeded event for a heartbeat is\nguaranteed to be published before the started event for the next heartbeat is\npublished). When connected to MongoDB 4.4 and later servers, the driver uses\nmultiple monitoring threads and a more complex heartbeat protocol designed\nto detect changes in server state quicker; as a result, heartbeat event\nintervals can be more irregular and heartbeat events can overlap. Specifically,\nan  awaited heartbeat  can start or finish while a  non-awaited heartbeat \nis in progress, and vice versa. Use the  ServerHeartbeatStarted#awaited? ,\n ServerHeartbeatSucceeded#awaited?  and  ServerHeartbeatFailed#awaited? \nmethods to distinguish between non-awaited and awaited heartbeats. When a client is attempting to perform an operation and it does not have a\nsuitable server, the deployment is scanned more frequently - each server can\nbe polled up to every 500 milliseconds. It is also possible for the application\nto request a manual scan of a particular server; the driver enforces the\n500 millisecond minimum interval between scans. Each client maintains a connection pool for each server in the deployment that\nit is aware of, and publishes events for both connection pools and individual\nconnections. To subscribe to these events, define a subscriber class implementing\nthe method  pubished  which takes a single parameter for the event that\nis being published. Note that future versions of the driver may introduce\nadditional events published through this mechanism. The following events are currently implemented by the driver, following\nthe  CMAP specification : The driver provides a logging subscriber which may be used to log all\nconnection pool and connection-related events. This subscriber is not enabled\nby default because it will create log entries for each operation performed\nby the application. To enable this subscriber globally or per client: Sample output: PoolCreated PoolCleared PoolClosed ConnectionCreated ConnectionReady ConnectionClosed ConnectionCheckOutStarted ConnectionCheckOutFailed ConnectionCheckOutSucceeded ConnectionCheckedIn To turn off monitoring, set the client monitoring option to  false :",
            "code": [
                {
                    "lang": "ruby",
                    "value": "class CommandLogSubscriber\n  include Mongo::Loggable\n\n  def started(event)\n    log_debug(\"#{prefix(event)} | STARTED | #{format_command(event.command)}\")\n  end\n\n  def succeeded(event)\n    log_debug(\"#{prefix(event)} | SUCCEEDED | #{event.duration}s\")\n  end\n\n  def failed(event)\n    log_debug(\"#{prefix(event)} | FAILED | #{event.message} | #{event.duration}s\")\n  end\n\n  private\n\n  def logger\n    Mongo::Logger.logger\n  end\n\n  def format_command(args)\n    begin\n      args.inspect\n    rescue Exception\n      '<Unable to inspect arguments>'\n    end\n  end\n\n  def format_message(message)\n    format(\"COMMAND | %s\".freeze, message)\n  end\n\n  def prefix(event)\n    \"#{event.address.to_s} | #{event.database_name}.#{event.command_name}\"\n  end\nend"
                },
                {
                    "lang": "ruby",
                    "value": "subscriber = CommandLogSubscriber.new\n\nMongo::Monitoring::Global.subscribe(Mongo::Monitoring::COMMAND, subscriber)\n\nclient = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test' )\nclient.subscribe( Mongo::Monitoring::COMMAND, subscriber )"
                },
                {
                    "lang": "none",
                    "value": "D, [2018-09-23T13:47:31.258020 #4692] DEBUG -- : COMMAND | 127.0.0.1:27027 | test.hello | STARTED | {\"hello\"=>1, \"$readPreference\"=>{\"mode\"=>\"primary\"}, \"lsid\"=>{\"id\"=><BSON::Binary:0x47111693353080 type=uuid data=0x730341e880dc40a2...>}}\nD, [2018-09-23T13:47:31.259145 #4692] DEBUG -- : COMMAND | 127.0.0.1:27027 | test.hello | SUCCEEDED | 0.000791175s"
                },
                {
                    "lang": "ruby",
                    "value": "class SDAMLogSubscriber\n  include Mongo::Loggable\n\n  def succeeded(event)\n    log_debug(format_event(event))\n  end\n\n  private\n\n  def logger\n    Mongo::Logger.logger\n  end\n\n  def format_message(message)\n    format(\"SDAM | %s\".freeze, message)\n  end\nend\n\nclass TopologyOpeningLogSubscriber < SDAMLogSubscriber\n  private\n\n  def format_event(event)\n    \"Topology type '#{event.topology.display_name}' initializing.\"\n  end\nend\n\nclass ServerOpeningLogSubscriber < SDAMLogSubscriber\n  private\n\n  def format_event(event)\n    \"Server #{event.address} initializing.\"\n  end\nend\n\nclass ServerDescriptionChangedLogSubscriber < SDAMLogSubscriber\n  private\n\n  def format_event(event)\n    \"Server description for #{event.address} changed from \" +\n    \"'#{event.previous_description.server_type}' to '#{event.new_description.server_type}'.\"\n  end\nend\n\nclass TopologyChangedLogSubscriber < SDAMLogSubscriber\n  private\n\n  def format_event(event)\n    if event.previous_topology != event.new_topology\n      \"Topology type '#{event.previous_topology.display_name}' changed to \" +\n      \"type '#{event.new_topology.display_name}'.\"\n    else\n      \"There was a change in the members of the '#{event.new_topology.display_name}' \" +\n      \"topology.\"\n    end\n  end\nend\n\nclass ServerClosedLogSubscriber < SDAMLogSubscriber\n  private\n\n  def format_event(event)\n    \"Server #{event.address} connection closed.\"\n  end\nend\n\nclass TopologyClosedLogSubscriber < SDAMLogSubscriber\n  private\n\n  def format_event(event)\n    \"Topology type '#{event.topology.display_name}' closed.\"\n  end\nend"
                },
                {
                    "lang": "ruby",
                    "value": "topology_opening_subscriber = TopologyOpeningLogSubscriber.new\nserver_opening_subscriber = ServerOpeningLogSubscriber.new\nserver_description_changed_subscriber = ServerDescriptionChangedLogSubscriber.new\ntopology_changed_subscriber = TopologyChangedLogSubscriber.new\nserver_closed_subscriber = ServerClosedLogSubscriber.new\ntopology_closed_subscriber = TopologyClosedLogSubscriber.new\n\nMongo::Monitoring::Global.subscribe(Mongo::Monitoring::TOPOLOGY_OPENING,\n  topology_opening_subscriber)\nMongo::Monitoring::Global.subscribe(Mongo::Monitoring::SERVER_OPENING,\n  server_opening_subscriber)\nMongo::Monitoring::Global.subscribe(Mongo::Monitoring::SERVER_DESCRIPTION_CHANGED,\n  server_description_changed_subscriber)\nMongo::Monitoring::Global.subscribe(Mongo::Monitoring::TOPOLOGY_CHANGED,\n  topology_changed_subscriber)\nMongo::Monitoring::Global.subscribe(Mongo::Monitoring::SERVER_CLOSED,\n  server_closed_subscriber)\nMongo::Monitoring::Global.subscribe(Mongo::Monitoring::TOPOLOGY_CLOSED,\n  topology_closed_subscriber)"
                },
                {
                    "lang": "ruby",
                    "value": "topology_opening_subscriber = TopologyOpeningLogSubscriber.new\nserver_opening_subscriber = ServerOpeningLogSubscriber.new\nserver_description_changed_subscriber = ServerDescriptionChangedLogSubscriber.new\ntopology_changed_subscriber = TopologyChangedLogSubscriber.new\nserver_closed_subscriber = ServerClosedLogSubscriber.new\ntopology_closed_subscriber = TopologyClosedLogSubscriber.new\n\nsdam_proc = Proc.new do |client|\n  client.subscribe(Mongo::Monitoring::TOPOLOGY_OPENING,\n    topology_opening_subscriber)\n  client.subscribe(Mongo::Monitoring::SERVER_OPENING,\n    server_opening_subscriber)\n  client.subscribe(Mongo::Monitoring::SERVER_DESCRIPTION_CHANGED,\n    server_description_changed_subscriber)\n  client.subscribe(Mongo::Monitoring::TOPOLOGY_CHANGED,\n    topology_changed_subscriber)\n  client.subscribe(Mongo::Monitoring::SERVER_CLOSED,\n    server_closed_subscriber)\n  client.subscribe(Mongo::Monitoring::TOPOLOGY_CLOSED,\n    topology_closed_subscriber)\nend\n\nclient = Mongo::Client.new(['127.0.0.1:27017'], database: 'test',\n  sdam_proc: sdam_proc)"
                },
                {
                    "lang": "none",
                    "value": "D, [2018-10-09T13:58:03.489461 #22079] DEBUG -- : SDAM | Topology type 'Unknown' initializing.\nD, [2018-10-09T13:58:03.489699 #22079] DEBUG -- : SDAM | Server 127.0.0.1:27100 initializing.\nD, [2018-10-09T13:58:03.491384 #22079] DEBUG -- : SDAM | Server description for 127.0.0.1:27100 changed from 'unknown' to 'unknown'.\nD, [2018-10-09T13:58:03.491642 #22079] DEBUG -- : SDAM | Server localhost:27100 initializing.\nD, [2018-10-09T13:58:03.493199 #22079] DEBUG -- : SDAM | Server description for localhost:27100 changed from 'unknown' to 'primary'.\nD, [2018-10-09T13:58:03.493473 #22079] DEBUG -- : SDAM | Server localhost:27101 initializing.\nD, [2018-10-09T13:58:03.494874 #22079] DEBUG -- : SDAM | Server description for localhost:27101 changed from 'unknown' to 'secondary'.\nD, [2018-10-09T13:58:03.495139 #22079] DEBUG -- : SDAM | Server localhost:27102 initializing.\nD, [2018-10-09T13:58:03.496504 #22079] DEBUG -- : SDAM | Server description for localhost:27102 changed from 'unknown' to 'secondary'.\nD, [2018-10-09T13:58:03.496777 #22079] DEBUG -- : SDAM | Topology type 'Unknown' changed to type 'ReplicaSetNoPrimary'.\nD, [2018-10-09T13:58:03.497306 #22079] DEBUG -- : SDAM | Server 127.0.0.1:27100 connection closed.\nD, [2018-10-09T13:58:03.497606 #22079] DEBUG -- : SDAM | Topology type 'ReplicaSetNoPrimary' changed to type 'ReplicaSetWithPrimary'.\n\n# client.close\n\nD, [2018-10-09T13:58:05.342057 #22079] DEBUG -- : SDAM | Server localhost:27100 connection closed.\nD, [2018-10-09T13:58:05.342299 #22079] DEBUG -- : SDAM | Server localhost:27101 connection closed.\nD, [2018-10-09T13:58:05.342565 #22079] DEBUG -- : SDAM | Server localhost:27102 connection closed.\nD, [2018-10-09T13:58:05.342693 #22079] DEBUG -- : SDAM | Topology type 'ReplicaSetWithPrimary' closed."
                },
                {
                    "lang": "ruby",
                    "value": "class HeartbeatLogSubscriber\n  include Mongo::Loggable\n\n  def started(event)\n    log_debug(\"#{event.address} | STARTED\")\n  end\n\n  def succeeded(event)\n    log_debug(\"#{event.address} | SUCCEEDED | #{event.duration}s\")\n  end\n\n  def failed(event)\n    log_debug(\"#{event.address} | FAILED | #{event.error.class}: #{event.error.message} | #{event.duration}s\")\n  end\n\n  private\n\n  def logger\n    Mongo::Logger.logger\n  end\n\n  def format_message(message)\n    format(\"HEARTBEAT | %s\".freeze, message)\n  end\nend"
                },
                {
                    "lang": "ruby",
                    "value": "subscriber = HeartbeatLogSubscriber.new\n\nMongo::Monitoring::Global.subscribe(Mongo::Monitoring::SERVER_HEARTBEAT, subscriber)\n\nclient = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test' )\nclient.subscribe( Mongo::Monitoring::SERVER_HEARTBEAT, subscriber )"
                },
                {
                    "lang": "none",
                    "value": "D, [2018-09-23T13:44:10.707018 #1739] DEBUG -- : HEARTBEAT | 127.0.0.1:27027 | STARTED\nD, [2018-09-23T13:44:10.707778 #1739] DEBUG -- : HEARTBEAT | 127.0.0.1:27027 | SUCCEEDED | 0.000772381s"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Monitoring::Global.subscribe(\n  Mongo::Monitoring::CONNECTION_POOL,\n  Mongo::Monitoring::CmapLogSubscriber.new)\n\nclient = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test' )\nsubscriber = Mongo::Monitoring::CmapLogSubscriber.new\nclient.subscribe( Mongo::Monitoring::CONNECTION_POOL, subscriber )"
                },
                {
                    "lang": "none",
                    "value": "D, [2019-05-06T17:23:21.595412 #8576] DEBUG -- : MONGODB | EVENT: #<PoolCreated address=127.0.0.1:27741 options={...}>\nD, [2019-05-06T17:23:21.595584 #8576] DEBUG -- : MONGODB | EVENT: #<PoolCleared address=127.0.0.1:27741>\nD, [2019-05-06T17:23:21.603549 #8576] DEBUG -- : MONGODB | EVENT: #<PoolCreated address=localhost:27741 options={...}>\nD, [2019-05-06T17:23:21.603616 #8576] DEBUG -- : MONGODB | EVENT: #<ConnectionCheckOutStarted address=localhost:27741>\nD, [2019-05-06T17:23:21.603684 #8576] DEBUG -- : MONGODB | EVENT: #<ConnectionCreated address=localhost:27741 connection_id=1>\nD, [2019-05-06T17:23:21.604079 #8576] DEBUG -- : MONGODB | EVENT: #<ConnectionCheckedOut address=localhost:27741 connection_id=1>\nD, [2019-05-06T17:23:21.605759 #8576] DEBUG -- : MONGODB | EVENT: #<ConnectionReady address=localhost:27741 connection_id=1>\nD, [2019-05-06T17:23:21.605784 #8576] DEBUG -- : MONGODB | EVENT: #<ConnectionCheckedIn address=localhost:27741 connection_id=1>\nD, [2019-05-06T17:23:21.605817 #8576] DEBUG -- : MONGODB | EVENT: #<PoolCleared address=localhost:27741>\nD, [2019-05-06T17:23:21.605852 #8576] DEBUG -- : MONGODB | EVENT: #<ConnectionClosed address=localhost:27741 connection_id=1 reason=stale>"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test', :monitoring => false )"
                }
            ],
            "preview": "The driver allows the application to be notified when certain events happen.\nThese events are organized into the following categories:",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/additional-resources",
            "title": "Additional Resources",
            "headings": [
                "Screencasts",
                "Presentations",
                "Articles",
                "Projects",
                "Libraries"
            ],
            "paragraphs": "There are a number of good resources appearing all over the web for\nlearning about MongoDB and Ruby. A useful selection is listed below. If\nyou know of others, do let us know. Introduction to MongoDB - Part I An introduction to MongoDB via the MongoDB shell. Introduction to MongoDB - Part II In this screencast, Joon You teaches how to use the Ruby driver to\nbuild a simple Sinatra app. Introduction to MongoDB - Part III For the final screencast in the series, Joon You introduces\nMongoMapper and Rails. RailsCasts: MongoDB & MongoMapper Ryan Bates' RailsCast introducing MongoDB and MongoMapper. RailsCasts: Mongoid Ryan Bates' RailsCast introducing Mongoid. Introduction to MongoDB (Video) Mike Dirolf's introduction to MongoDB at Pivotal Labs, SF. MongoDB: A Ruby Document Store that doesn't rhyme with 'Ouch'\n(Slides) Wynn Netherland's introduction to MongoDB with some comparisons to\nCouchDB. MongoDB (is) for Rubyists (Slides) Kyle Banker's presentation on why MongoDB is for Rubyists (and all\nhuman-oriented programmers). Why I Think Mongo is to Databases What Rails was to Frameworks What if a key-value store mated with a relational database system? Mongo Tips John Nunemaker's articles on MongoDB and his Mongo Tips blog. A series of articles on aggregation with MongoDB and Ruby: Part I: Introduction of Aggregation in MongoDB Part II: MongoDB Grouping Elaborated Part III: Introduction to Map-Reduce in MongoDB Does the MongoDB Driver Support Feature X? An explanation of how the MongoDB drivers usually automatically\nsupport new database features. Capistrano Mongo Sync Sync your local development db with your remote production db using capistrano. Simple Pub/Sub A very simple pub/sub system. Mongo Queue An extensible thread safe job/message queueing system that uses\nMongoDB as the persistent storage engine. Resque-mongo A port of the Github's Resque to MongoDB. Mongo Admin A Rails plugin for browsing and managing MongoDB data. See the  live\ndemo . Sinatra Resource Resource Oriented Architecture (REST) for Sinatra and MongoMapper. NewsMonger A simple social news application demonstrating MongoMapper and Rails. Data Catalog API From  Sunlight Labs , a non-trivial\napplication using MongoMapper and Sinatra. Watchtower An example application using Mustache, MongoDB, and Sinatra. Shapado A question and answer site similar to Stack Overflow. Live version at\n shapado.com . ActiveExpando An extension to ActiveRecord to allow the storage of arbitrary\nattributes in MongoDB. ActsAsTree (MongoMapper) ActsAsTree implementation for MongoMapper. Machinist adapter (MongoMapper) Machinist adapter using MongoMapper. Mongo-Delegate A delegation library for experimenting with production data without\naltering it. A quite useful pattern. Remarkable Matchers (MongoMapper) Testing / Matchers library using MongoMapper. OpenIdAuthentication, supporting MongoDB as the datastore Brandon Keepers' fork of OpenIdAuthentication supporting MongoDB. MongoTree (MongoRecord) MongoTree adds parent / child relationships to MongoRecord. Merb_MongoMapper A plugin for the Merb framework for supporting MongoMapper models. Mongolytics (MongoMapper) A web analytics tool. Rack-GridFS A Rack middleware component that creates HTTP endpoints for files\nstored in GridFS.",
            "code": [],
            "preview": "There are a number of good resources appearing all over the web for\nlearning about MongoDB and Ruby. A useful selection is listed below. If\nyou know of others, do let us know.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/database-tasks",
            "title": "Databases",
            "headings": [
                "List Collections",
                "Arbitrary Comands",
                "Drop Database"
            ],
            "paragraphs": "The driver provides various helpers on database objects for executing\ncommands, getting collection lists, and administrative tasks. To get a list of collections or collection names for a database, use\n collections  and  collection_names , respectively. To execute any command on the database, use the  command  method. Specifying server API version as a client option and also specifying\nany of the respective command parameters to the  command  method\n(i.e. the  apiVersion ,  apiStrict  and  apiDeprecationErrors \ncommand parameters) at the same time is not allowed and will produce an error. To drop a database, use the  drop  method.",
            "code": [
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], database: 'music')\ndatabase = client.database\n\ndatabase.collections      # Returns an array of Collection objects.\ndatabase.collection_names # Returns an array of collection names as strings."
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], database: 'music')\ndatabase = client.database\n\nresult = database.command(:ping => 1)\nresult.first # Returns the BSON::Document returned from the server."
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\nclient.database.drop"
                }
            ],
            "preview": "The driver provides various helpers on database objects for executing\ncommands, getting collection lists, and administrative tasks.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/text-search",
            "title": "Text Search",
            "headings": [],
            "paragraphs": "MongoDB provides  text indexes \nto support text search queries on string content. Text indexes\ncan include any field whose value is a string or an array of\nstring elements. To perform a text search with the Ruby driver, first create a text\nindex with  indexes.create_one() . The following command creates a\ntext index on the  name  field of the  restaurants  collection in\nthe  test  database. Once the text index is created you can use it as part of a query. The\nfollowing code finds all documents in the  restaurants  collection\nwhich contain the word  garden , without case sensitivity. MongoDB Atlas also provides\n Atlas Search \nwhich is a more powerful and flexible text search solution.\nThe rest of this page discusses text indexes and not Atlas Search.",
            "code": [
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test')\nclient['restaurants'].indexes.create_one( { :name => 'text' } )"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test')\nclient[:restaurants].find(\n    { '$text' =>\n          { '$search' => 'garden', '$caseSensitive' => false }\n    }\n      ).each do |document|\n\n    #=> Yields a BSON::Document.\n\nend"
                }
            ],
            "preview": "MongoDB provides text indexes\nto support text search queries on string content. Text indexes\ncan include any field whose value is a string or an array of\nstring elements.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/authentication",
            "title": "Authentication",
            "headings": [
                "Providing credentials",
                "Auth Source",
                "Authentication Mechanisms",
                "SCRAM",
                "Client Certificate (X.509)",
                "AWS",
                "Providing Credentials Explicitly",
                "Automatically Retrieving Credentials",
                "LDAP (SASL PLAIN)",
                "Kerberos (GSSAPI)",
                "MONGODB-CR"
            ],
            "paragraphs": "MongoDB supports a variety of\n authentication mechanisms . For more information about configuring your MongoDB server for each of\nthese authentication mechanisms see MongoDB's\n online documentation . For more information about users and the Ruby driver's helpers for\nuser management, see the  User Management tutorial . If authentication is enabled, provide credentials when creating a new\nclient: Authentication credentials can be changed on a client instance to obtain\na new client using the  Client#with  method: It is also possible to change the client's database and credentials in\none step: A user's auth source is the database where that user's authentication\ncredentials are stored. The user's auth source may be specified whenever the credentials are specified: If no auth source is specified, then a default will be assumed by the client.\nThe default auth source depends on the authentication mechanism that is being\nused to connect. For the  MONGODB-CR ,  SCRAM-SHA-1 , and  SCRAM-SHA-256  authentication\nmechanisms, the default auth source is the database to which the client is\nconnecting; if no database is specified,  admin  database is the default\ndatabase and hence the default auth source. For the  PLAIN  mechanism (LDAP),\nthe default auth source is the database to which the client is connecting;\nif no database is specified, the  $external  database is used as the\nauth source. For the  AWS ,  GSSAPI  and  MONGODB_X509  mechanisms, the\nauth source is always  $external . When a client is constructed using an SRV URI, the driver will look for URI\noptions in a TXT DNS record that corresponds to the SRV record. Thus, for\nexample, MongoDB Atlas generally uses the  admin  database as its auth\nsource, but this is not specified in SRV URIs because the database is given\nas a URI option on the TXT records. Note that when using SRV URIs, the SRV query and the TXT query are performed\nseparately. On systems where DNS resolution is not 100% reliable, the\nfailure to look up TXT records can cause authentication errors, as the driver\nmay end up using an incorrect auth source. If reliable DNS resolution cannot\nbe guaranteed, the auth source can be specified explicitly in SRV URIs as\na URI option: When changing the database using the  with  method, the auth source is\ndetermined in the new  Client  instance using the full set of options\nthat applies to it. For example, if the original client had an auth source\nspecified, this auth source would take precedence over the database\ngiven in the  with  call. If the original client did not have an auth\nsource specified, the new database would be the new auth source, subject\nto the rules of the authentication mechanism used. MongoDB supports several authentication mechanisms, as detailed in this section.\nAuthentication mechanism to use can be explicitly specified when a Client is\ncreated; if authentication mechanism is not provided by the application, it is\nselected as follows: Note that: For MongoDB 4.0 and higher, the client performs SCRAM mechanism negotiation\nwith the server. If the user specified in client configuration permits\nauthentication with SCRAM-SHA-256, then SCRAM-SHA-256 is used for\nauthentication. Otherwise SCRAM-SHA-1 is used. For MongoDB 3.0 through 3.6, SCRAM-SHA-1 is used. For MongoDB 2.6, MONGODB-CR is used. X.509, AWS, LDAP and Kerberos authentication mechanisms must always be\nexplicitly requested. If the MongoDB server that the client is connecting to supports SCRAM,\nthe client will attempt to authenticate using SCRAM if no authentication\nmechanism is explicitly specified. To authenticate to MongoDB 3.0 and\nhigher servers using MONGODB-CR, the MONGODB-CR mechanism must be\nexplicitly requested. SCRAM authentication  is the default\nauthentication mechanism for MongoDB. There are two SCRAM mechanisms in\nMongoDB: SCRAM-SHA-1 (available as of MongoDB 3.0) and SCRAM-SHA-256\n(available as of MongoDB 4.0). If an authentication mechanism is not\nspecified but user credentials are, the driver will attempt to use SCRAM\nauthentication on server 3.0 or newer and will negotiate the mechanism\nto use based on the server version and the mechanisms defined for a\nparticular user (it is possible to configure a user in the server to only\nallow SCRAM-SHA-1 mechanism, only SCRAM-SHA-256 mechanism or both). To explicitly specify SCRAM-SHA-1 as the authentication mechanism, use the\n auth_mech: :scram  Ruby client option or the  SCRAM-SHA-1  as the value\nfor the  authMechanism  URI option, as follows: To explicitly specify SCRAM-SHA-256 as the authentication mechanism, use the\n auth_mech: :scram256  Ruby client option or the  SCRAM-SHA-256  as the\nvalue for the  authMechanism  URI option, as follows: The driver presents an X.509 certificate during TLS negotiation.\nThe MONGODB-X509 authentication mechanism authenticates a username\nderived from the distinguished subject name of this certificate. This authentication method requires the use of TLS connections with\ncertificate validation. To authenticate the client, you will need a valid TLS certificate\nand private encryption key. These can be stored in separate files,\nor together in one file (in the PEM format). Even if the certificate\nand private key are stored in the same file, you must specify the path to\nthat file by passing both the  ssl_cert  and  ssl_key  options\nto the client. For more information about configuring X.509 authentication in MongoDB,\nsee the  X.509 tutorial in the MongoDB Manual . Requires MongoDB Enterprise Edition and server version 4.4 or later. The AWS authentication mechanism uses AWS  Identity and Access Management (IAM) \nand AWS  Security Token Service (STS) \nto prove the client's identity to a MongoDB server. Briefly, AWS authentication\nworks as follows: AWS credentials are comprised of: Authentication with  AWS IAM credentials ,\nuses the access key ID and the secret access key. Authentication with\n temporary AWS IAM credentials \nuses all three components. Temporary credentials are used with: The Ruby driver allows providing both regular and temporary credentials\nexplicitly as Ruby options or URI options. If credentials are not explicitly\nprovided, the driver will attempt to retrieve them from environment variables\ndescribed below and from EC2 instance and ECS task metadata endpoints. The client uses AWS IAM credentials to create a signature that is sent to\nthe MongoDB server. The server sends a request to AWS STS using the client's signature. A successful STS request returns the username (technically, the ARN of\nthe IAM user or role) corresponding to the credentials that the client used.\nThe IAM user ARN is used by the server to look up a defined user, and the\nclient is considered to have authenticated as this user. Unlike other authentication mechanisms, the username that the application\nprovides when creating a client and the username of the server user are\ndifferent: the username on the client is the AWS access key ID, but the\nusername on the server is the ARN of the IAM user or role corresponding\nto the access key ID. The access key ID. The secret access key. The optional session token. The driver never sends the secret access key or the session token over\nthe network. STS  Assume Role \nrequests. EC2 instance roles . ECS task roles . AWS Lambda environment . Regular (non-temporary) IAM credentials can be provided as Ruby options,\nas follows: They can also be provided via a URI: To provide temporary credentials, specify the session token in the\nauthentication mechanism properties as follows: The temporary credentials can also be provided via a URI: When credentials are provided via a URI, they must be percent-escaped. The client can retrieve credentials from the environment or from EC2 or ECS\nmetadata endpoints. To retrieve credentials automatically, specify the\nAWS authentication mechanism but do not specify a username nor a password: The driver will try to obtain credentials from the following sources, in\nthe specified order: AWS_ACCESS_KEY_ID ,  AWS_SECRET_ACCESS_KEY  and  AWS_SESSION_TOKEN \nenvironment variables. These environment variables are recognized by\na variety of AWS-related libraries and tools such as the official\nAWS Ruby SDK and the AWS CLI. They are also defined when running in an\nAWS Lambda environment. The AWS  ECS task metadata endpoint .\nThis returns credentials associated with the ECS task role assigned to\nthe container. The AWS  EC2 instance metadata endpoint .\nThis returns credentials associated with the EC2 instance role assigned to\nthe instance. A credentials source that provides any credentials must provide a complete\nset of credentials. For example, the driver will raise an error if only\none of  AWS_ACCESS_KEY_ID  or  AWS_SECRET_ACCESS_KEY  environment\nvariables is populated but not the other. If an application is running in an ECS container on an EC2 instance and\n the container is allowed access to the instance metadata ,\nthe driver will attempt to retrieve credentials for the AWS authentication\nmechanism from the EC2 instance metadata endpoint, thus potentially\nauthenticating as the IAM role assigned to the EC2 instance, if it was not\nable to retrieve ECS task role credentials from the ECS task endpoint. Requires MongoDB Enterprise Edition. MongoDB Enterprise Edition supports the LDAP authentication mechanism\nwhich allows you to delegate authentication using a Lightweight Directory\nAccess Protocol  LDAP  server. For more information about configuring LDAP authentication in\nMongoDB, see the  SASL/LDAP tutorial in the MongoDB Manual . When using LDAP, passwords are sent to the server in plain text. For this\nreason, we strongly recommend enabling TLS when using LDAP as your\nauthentication mechanism. Requires MongoDB Enterprise Edition. To configure the MongoDB server to use Kerberos, please refer to the\n server Kerberos documentation . To use the Kerberos authentication mechanism with the Ruby MongoDB driver,\nan additional library implementing the Kerberos authenticator -\n mongo_kerberos  - must be\ninstalled and loaded. To do so, add to your  Gemfile : ... and add to your application code: If using Kerberos authentication with  MRI , the password is not specified\nin driver configuration and it is not sent to the MongoDB server by the driver.\nInstead a Kerberos session must be established externally to the driver\nand this session is used by the driver to prove the user's identity to\nthe server. Establishing this session requires that the host system is\nconfigured for Kerberos authentication; refer to the  Kerberos documentation \nor your operating system documentation for details. Use the  kinit utility \nto establish a Kerberos session. If using Kerberos authentication with  JRuby , the Kerberos session may\nbe estabished externally to the driver using the process described above\nfor MRI; alternatively, the password may be provided directly to the driver\nvia client configuration, or the path to a keytab file may be provided via\nconfiguration stored in the  java.security.auth.login.config  system property.\nAdditionally, the Java runtime environment must be configured for Kerberos;\nplease refer to the   MongoDB Java Driver Kerberos documentation \nfor more information. As per the server Kerberos documentation, the FQDN of the host\nrunning MongoDB must be specified when using Kerberos authentication. If using MongoDB URIs, be sure to percent-escape special characters like\n /  and  @  when they appear in the username. Deprecated:  MONGODB-CR mechanism is deprecated as of MongoDB 3.6 and\nremoved as of MongoDB 4.0. Please use  SCRAM authentication  instead. MONGODB-CR was the default authentication mechanism for MongoDB through\nversion 2.6. The mechanism can be explicitly set with the credentials: If the MongoDB server that the client is connecting to supports SCRAM,\nthe client will attempt to authenticate using SCRAM if no authentication\nmechanism is explicitly specified. To authenticate to MongoDB 3.0 and\nhigher servers using MONGODB-CR, the MONGODB-CR mechanism must be\nexplicitly requested.",
            "code": [
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ],\n                           user: 'test',\n                           password: '123',\n                           database: 'mydb' )\n\n# If using a URI:\nclient = Mongo::Client.new(\"mongodb://test:123@127.0.0.1:27017/mydb\")"
                },
                {
                    "lang": "ruby",
                    "value": "authenticated_client = client.with( user: 'another-user',\n                                    password: '123' )"
                },
                {
                    "lang": "ruby",
                    "value": "authenticated_music_client = client.with( database: 'music',\n                                          user:'test',\n                                          password:'123' )"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ],\n                           database: 'mydb',\n                           user: 'test',\n                           password: '123',\n                           auth_source: 'admin' )\n\n# If using a URI:\nclient = Mongo::Client.new(\"mongodb://test:123@127.0.0.1:27017/mydb?authSource=admin\")"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Client.new(\"mongodb+srv://username:myRealPassword@cluster0.mongodb.net/test?w=majority&authSource=admin\")"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ],\n                           database: 'mydb',\n                           user: 'test',\n                           password: '123',\n                           auth_mech: :scram )\n\nclient = Mongo::Client.new(\"mongodb://test:123@127.0.0.1:27017/mydb?authMechanism=SCRAM-SHA-1\")"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ],\n                           database: 'mydb',\n                           user: 'test',\n                           password: '123',\n                           auth_mech: :scram256 )\n\nclient = Mongo::Client.new(\"mongodb://test:123@127.0.0.1:27017/mydb?authMechanism=SCRAM-SHA-256\")"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ],\n                           auth_mech: :mongodb_x509,\n                           ssl: true,\n                           ssl_cert: '/path/to/client.pem',\n                           ssl_key: '/path/to/client.pem',\n                           ssl_ca_cert: '/path/to/ca.pem' )"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new(['mongodb.example.com'],\n  auth_mech: :aws,\n  user: '<AWS-ACCESS-KEY-ID>',\n  password: '<AWS-SECRET-ACCESS-KEY>',\n  database: 'mydb',\n)"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new(\n  'mongodb://<AWS-ACCESS-KEY-ID>:<AWS-SECRET-ACCESS-KEY>@mongodb.example.com/mydb?authMechanism=MONGODB-AWS')"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new(['mongodb.example.com'],\n  auth_mech: :aws,\n  user: '<AWS-ACCESS-KEY-ID>',\n  password: '<AWS-SECRET-ACCESS-KEY>',\n  auth_mech_properties: {\n    aws_session_token: '<AWS-SESSION-TOKEN>',\n  },\n  database: 'mydb',\n)"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new(\n  'mongodb://<AWS-ACCESS-KEY-ID>:<AWS-SECRET-ACCESS-KEY>@mongodb.example.com/mydb?authMechanism=MONGODB-AWS&authMechanismProperties=AWS_SESSION_TOKEN:<AWS-SESSION-TOKEN>')"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new(['mongodb.example.com'],\n  auth_mech: :aws,\n  database: 'mydb',\n)\n\n# Using a URI:\nclient = Mongo::Client.new(\n  'mongodb://mongodb.example.com/mydb?authMechanism=MONGODB-AWS')"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ],\n                           auth_mech: :plain,\n                           ssl: true,\n                           ssl_verify: true,\n                           ssl_cert: '/path/to/client.pem',\n                           ssl_ca_cert: '/path/to/ca.pem' )"
                },
                {
                    "lang": "ruby",
                    "value": "gem 'mongo', '~> 2'\ngem 'mongo_kerberos', '~> 2'"
                },
                {
                    "lang": "ruby",
                    "value": "require 'mongo'\nrequire 'mongo_kerberos'"
                },
                {
                    "lang": "ruby",
                    "value": "# Authenticate as appuser@MYREALM:\nclient = Mongo::Client.new(\"mongodb://appuser%40MYREALM@myserver.mycompany.com:27017/mydb?authMechanism=GSSAPI\")\n\n# Authenticate as myapp/appuser@MYREALM:\nclient = Mongo::Client.new(\"mongodb://myapp%2Fappuser%40MYREALM@myserver.mycompany.com:27017/mydb?authMechanism=GSSAPI\")\n\n# Authenticate using Ruby options:\nclient = Mongo::Client.new(['myserver.mycompany.com:27017'],\n                           auth_mech: :gssapi,\n                           user: 'myapp/appuser@MYREALM')"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ],\n                           database: 'mydb',\n                           user: 'test',\n                           password: '123',\n                           auth_mech: :mongodb_cr )"
                }
            ],
            "preview": "MongoDB supports a variety of\nauthentication mechanisms.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "tutorials/bson",
            "title": "BSON Tutorial",
            "headings": [
                "Installation",
                "Use With ActiveSupport",
                "BSON Serialization",
                "Byte Buffers",
                "Writing",
                "Reading",
                "Supported Classes",
                "BSON::Binary",
                "UUID Methods",
                "Legacy UUIDs",
                "BSON::Code",
                "BSON::CodeWithScope",
                "BSON::DBRef",
                "BSON::Document",
                "BSON::MaxKey",
                "BSON::MinKey",
                "BSON::ObjectId",
                "BSON::Timestamp",
                "BSON::Undefined",
                "BSON::Decimal128",
                "BSON::Decimal128 vs BigDecimal",
                "Symbol",
                "JSON Serialization",
                "Time Instances",
                "DateTime Instances",
                "Date Instances",
                "Regular Expressions",
                "Ruby vs MongoDB Regular Expressions",
                "Options / Flags / Modifiers",
                "^ Anchor",
                "$ Anchor",
                "BSON::Regexp::Raw Class",
                "Regular Expression Conversion",
                "Reading and Writing",
                "Key Order",
                "Duplicate Keys"
            ],
            "paragraphs": "This tutorial discusses using the Ruby BSON library. The BSON library can be installed from  Rubygems \nmanually or with bundler. To install the gem manually: To install the gem with bundler, include the following in your  Gemfile : The BSON library is compatible with MRI >= 2.5 and JRuby >= 9.2. Serialization for ActiveSupport-defined classes, such as TimeWithZone, is\nnot loaded by default to avoid a hard dependency of BSON on ActiveSupport.\nWhen using BSON in an application that also uses ActiveSupport, the\nActiveSupport-related code must be explicitly required: Getting a Ruby object's raw BSON representation is done by calling  to_bson \non the Ruby object, which will return a  BSON::ByteBuffer . For example: Generating an object from BSON is done via calling  from_bson  on the class\nyou wish to instantiate and passing it a  BSON::ByteBuffer  instance. BSON library 4.0 introduces the use of native byte buffers in MRI and JRuby\ninstead of using  StringIO , for improved performance. To create a  ByteBuffer  for writing (i.e. serializing to BSON),\ninstantiate  BSON::ByteBuffer  with no arguments: To write raw bytes to the byte buffer with no transformations, use\n put_byte  and  put_bytes  methods. They take a byte string as the argument\nand copy this string into the buffer.  put_byte  enforces that the argument\nis a string of length 1;  put_bytes  accepts any length strings.\nThe strings can contain null bytes. Subsequent write methods write objects of particular types in the\n BSON spec . Note that the type indicated\nby the method name takes precedence over the type of the argument -\nfor example, if a floating-point value is given to  put_int32 , it is\ncoerced into an integer and the resulting integer is written to the byte\nbuffer. To write a UTF-8 string (BSON type 0x02) to the byte buffer, use  put_string : Note that BSON strings are always encoded in UTF-8. Therefore, the\nargument must be either in UTF-8 or in an encoding convertable to UTF-8\n(i.e. not binary). If the argument is in an encoding other than UTF-8,\nthe string is first converted to UTF-8 and the UTF-8 encoded version is\nwritten to the buffer. The string must be valid in its claimed encoding,\nincluding being valid UTF-8 if the encoding is UTF-8.\nThe string may contain null bytes. The BSON specification also defines a CString type, which is used for\nexample for document keys. To write CStrings to the buffer, use  put_cstring : As with regular strings, CStrings in BSON must be UTF-8 encoded. If the\nargument is not in UTF-8, it is converted to UTF-8 and the resulting string\nis written to the buffer. Unlike  put_string , the UTF-8 encoding of\nthe argument given to  put_cstring  cannot have any null bytes, since the\nCString serialization format in BSON is null terminated. Unlike  put_string ,  put_cstring  also accepts symbols and integers.\nIn all cases the argument is stringified prior to being written: To write a 32-bit or a 64-bit integer to the byte buffer, use\n put_int32  and  put_int64  methods respectively. Note that Ruby\nintegers can be arbitrarily large; if the value being written exceeds the\nrange of a 32-bit or a 64-bit integer,  put_int32  and  put_int64 \nraise  RangeError . To write a 64-bit floating point value to the byte buffer, use  put_double : To obtain the serialized data as a byte string (for example, to send the data\nover a socket), call  to_s  on the buffer: put_byte  and  put_bytes  do not write a BSON type byte prior to\nwriting the argument to the byte buffer. If  put_int32  or  put_int64  are given floating point arguments,\nthe arguments are first coerced into integers and the integers are\nwritten to the byte buffer. ByteBuffer  keeps track of read and write positions separately.\nThere is no way to rewind the buffer for writing -  rewind  only affects\nthe read position. To create a  ByteBuffer  for reading (i.e. deserializing from BSON),\ninstantiate  BSON::ByteBuffer  with a byte string as the argument: Reading from the buffer is done via the following API: To restart reading from the beginning of a buffer, use  rewind : ByteBuffer  keeps track of read and write positions separately.\n rewind  only affects the read position. Core Ruby classes that have representations in the BSON specification and\nwill have a  to_bson  method defined for them are:  Object ,  Array ,\n FalseClass ,  Float ,  Hash ,  Integer ,  BigDecimal ,  NilClass ,\n Regexp ,  String ,  Symbol  (deprecated),  Time ,  TrueClass . In addition to the core Ruby objects, BSON also provides some special types\nspecific to the specification: Use  BSON::Binary  objects to store arbitrary binary data. The  Binary \nobjects can be constructed from binary strings as follows: By default,  Binary  objects are created with BSON binary subtype 0\n( :generic ). The subtype can be explicitly specified to indicate that\nthe bytes encode a particular type of data: Valid subtypes are  :generic ,  :function ,  :old ,  :uuid_old ,\n :uuid ,  :md5  and  :user . The data and the subtype can be retrieved from  Binary  instances using\n data  and  type  attributes, as follows: BSON::Binary  objects always store the data in  BINARY  encoding,\nregardless of the encoding that the string passed to the constructor\nwas in: To create a UUID BSON::Binary (binary subtype 4) from its RFC 4122-compliant\nstring representation, use the  from_uuid  method: To stringify a UUID BSON::Binary to an RFC 4122-compliant representation,\nuse the  to_uuid  method: The standard representation may be explicitly specified when invoking both\n from_uuid  and  to_uuid  methods: Note that the  :standard  representation can only be used with a Binary\nof subtype  :uuid  (not  :uuid_old ). Data stored in BSON::Binary objects of subtype 3 ( :uuid_old ) may be\npersisted in one of three different byte orders depending on which driver\ncreated the data. The byte orders are CSharp legacy, Java legacy and Python\nlegacy. The Python legacy byte order is the same as the standard RFC 4122\nbyte order; CSharp legacy and Java legacy byte orders have some of the bytes\nswapped. The Binary object containing a legacy UUID does not encode  which  format\nthe UUID is stored in. Therefore, methods that convert to and from the legacy\nUUID format take the desired format, or representation, as their argument.\nAn application may copy legacy UUID Binary objects without knowing which byte\norder they store their data in. The following methods for working with legacy UUIDs are provided for\ninteroperability with existing deployments storing data in legacy UUID formats.\nIt is recommended that new applications use the  :uuid  (subtype 4) format\nonly, which is compliant with RFC 4122. To stringify a legacy UUID BSON::Binary, use the  to_uuid  method specifying\nthe desired representation. Accepted representations are  :csharp_legacy ,\n :java_legacy  and  :python_legacy . Note that a legacy UUID BSON::Binary\ncannot be stringified without specifying a representation. To create a legacy UUID BSON::Binary from the string representation of the\nUUID, use the  from_uuid  method specifying the desired representation: These methods can be used to convert from one representation to another: Represents a string of JavaScript code. Represents a string of JavaScript code with a hash of values. The  CodeWithScope  type is deprecated as of MongoDB 4.2.1. Starting\nwith MongoDB 4.4, support from  CodeWithScope  is being removed from\nvarious server commands and operators such as  $where . Please use\nother BSON types and operators when working with MongoDB 4.4 and newer. This is a subclass of  BSON::Document  that provides accessors for the\ncollection, id, and database of the DBRef. For backwards compatibility with the MongoDB Ruby driver versions 2.17 and\nearlier,  BSON::DBRef  also can be constructed using the legacy driver API.\nThis API is deprecated and will be removed in a future version of  bson-ruby : The BSON::DBRef constructor will validate the given hash and will raise an ArgumentError\nif it is not a valid DBRef.  BSON::ExtJSON.parse_obj  and  Hash.from_bson  will not\nraise an error if given an invalid DBRef, and will parse a Hash or deserialize a\nBSON::Document instead. All BSON documents are deserialized into instances of BSON::DBRef if they are\nvalid DBRefs, otherwise they are deserialized into instances of BSON::Document.\nThis is true even when the invocation is made from the  Hash  class: This is a subclass of  Hash  that stores all keys as strings, but allows\naccess to them with symbol keys. All BSON documents are deserialized into instances of BSON::Document\n(or BSON::DBRef, if they happen to be a valid DBRef), even when the\ninvocation is made from the  Hash  class: Represents a value in BSON that will always compare higher to another value. Represents a value in BSON that will always compare lower to another value. Represents a 12 byte unique identifier for an object on a given machine. Represents a special time with a start and increment value. Represents a placeholder for a value that was not provided. Represents a 128-bit decimal-based floating-point value capable of emulating\ndecimal rounding with exact precision. The  BigDecimal   from_bson  and  to_bson  methods use the same\n BSON::Decimal128  methods under the hood. This leads to some limitations\nthat are imposed on the  BigDecimal  values that can be serialized to BSON\nand those that can be deserialized from existing  decimal128  BSON\nvalues. This change was made because serializing  BigDecimal  instances as\n BSON::Decimal128  instances allows for more flexibility in terms of querying\nand aggregation in MongoDB. The limitations imposed on  BigDecimal  are as\nfollows: decimal128  has a limited range and precision, while  BigDecimal  has no\nrestrictions in terms of range and precision.  decimal128  has a max value\nof approximately  10^6145  and a min value of approximately  -10^6145 ,\nand has a maximum of 34 bits of precision. decimal128  is able to accept signed  NaN  values, while  BigDecimal \nis not. All signed  NaN  values that are deserialized into  BigDecimal \ninstances will be unsigned. decimal128  maintains trailing zeroes when serializing to and\ndeserializing from BSON.  BigDecimal , however, does not maintain trailing\nzeroes and therefore using  BigDecimal  may result in a lack of precision. In BSON 5.0,  decimal128  is deserialized into  BigDecimal  by\ndefault. In order to have  decimal128  values in BSON documents\ndeserialized into  BSON::Decimal128 , the  mode: :bson  option can be set\non  from_bson . The BSON specification defines a symbol type which allows round-tripping\nRuby  Symbol  values (i.e., a Ruby  Symbol``is encoded into a BSON symbol\nand a BSON symbol is decoded into a Ruby ``Symbol ). However, since most\nprogramming langauges do not have a native symbol type, to promote\ninteroperabilty, MongoDB deprecated the BSON symbol type and encourages\nstrings to be used instead. By default, the BSON library encodes  Symbol  hash values as strings and\ndecodes BSON symbols into Ruby  Symbol  values: To force encoding of Ruby symbols to BSON symbols, wrap the Ruby symbols in\n BSON::Symbol::Raw : In BSON, hash  keys  are always strings. Non-string values will be\nstringified when used as hash keys: Some BSON types have special representations in JSON. These are as follows\nand will be automatically serialized in the form when calling  to_json  on\nthem. Object JSON BSON::Binary { \"$binary\" : \"\\x01\", \"$type\" : \"md5\" } BSON::Code { \"$code\" : \"this.v = 5\" } BSON::CodeWithScope { \"$code\" : \"this.v = value\", \"$scope\" : { v => 5 }} BSON::DBRef { \"$ref\" : \"collection\", \"$id\" : { \"$oid\" : \"id\" }, \"$db\" : \"database\" } BSON::MaxKey { \"$maxKey\" : 1 } BSON::MinKey { \"$minKey\" : 1 } BSON::ObjectId { \"$oid\" : \"4e4d66343b39b68407000001\" } BSON::Timestamp { \"t\" : 5, \"i\" : 30 } Regexp { \"$regex\" : \"[abc]\", \"$options\" : \"i\" } Times in Ruby can have nanosecond precision. Times in BSON (and MongoDB)\ncan only have millisecond precision. When Ruby  Time  instances are\nserialized to BSON or Extended JSON, the times are floored to the nearest\nmillisecond. Because of this flooring, applications are strongly recommended to perform\nall time calculations using integer math, as inexactness of floating point\ncalculations may produce unexpected results. The time as always rounded down. If the time precedes the Unix epoch\n(January 1, 1970 00:00:00 UTC), the absolute value of the time would\nincrease: JRuby as of version 9.2.11.0  rounds pre-Unix epoch times up rather than\ndown . bson-ruby works around\nthis and correctly floors the times when serializing on JRuby. BSON only supports storing the time as the number of seconds since the\nUnix epoch. Ruby's  DateTime  instances can be serialized to BSON,\nbut when the BSON is deserialized the times will be returned as\n Time  instances. DateTime  class in Ruby supports non-Gregorian calendars. When non-Gregorian\n DateTime  instances are serialized, they are first converted to Gregorian\ncalendar, and the respective date in the Gregorian calendar is stored in the\ndatabase. BSON only supports storing the time as the number of seconds since the\nUnix epoch. Ruby's  Date  instances can be serialized to BSON, but when\nthe BSON is deserialized the times will be returned as  Time  instances. When  Date  instances are serialized, the time value used is midnight\nof the day that the  Date  refers to in UTC. Both MongoDB and Ruby provide facilities for working with regular expressions,\nbut they use regular expression engines. The following subsections detail the\ndifferences between Ruby regular expressions and MongoDB regular expressions\nand describe how to work with both. MongoDB server uses  Perl-compatible regular expressions implemented using\nthe PCRE library  and  Ruby regular expressions  are implemented using the\n Onigmo regular expression engine ,\nwhich is a fork of  Oniguruma .\nThe two regular expression implementations generally provide equivalent\nfunctionality but have several important syntax differences, as described\nbelow. Unfortunately, there is no simple way to programmatically convert a PCRE\nregular expression into the equivalent Ruby regular expression,\nand there are currently no Ruby bindings for PCRE. Both Ruby and PCRE regular expressions support modifiers. These are\nalso called \"options\" in Ruby parlance and \"flags\" in PCRE parlance.\nThe meaning of  s  and  m  modifiers differs in Ruby and PCRE: When writing regular expressions intended to be used in both Ruby and\nPCRE environments (including MongoDB server and most other MongoDB drivers),\nhenceforth referred to as \"portable regular expressions\", avoid using\nthe  ^  and  $  anchors. The following sections provide workarounds and\nrecommendations for authoring portable regular expressions. Ruby does not have the  s  modifier, instead the Ruby  m  modifier\nperforms the same function as the PCRE  s  modifier which is to make the\nperiod ( . ) match any character including newlines. Confusingly, the\nRuby documentation refers to the  m  modifier as \"enabling multi-line mode\". Ruby always operates in the equivalent of PCRE's multi-line mode, enabled by\nthe  m  modifier in PCRE regular expressions. In Ruby the  ^  anchor\nalways refers to the beginning of line and the  $  anchor always refers\nto the end of line. In Ruby regular expressions, the  ^  anchor always refers to the beginning\nof line. In PCRE regular expressions, the  ^  anchor refers to the beginning\nof input by default and the  m  flag changes its meaning to the beginning\nof line. Both Ruby and PCRE regular expressions support the  \\A  anchor to refer to\nthe beginning of input, regardless of modifiers. When writing portable regular expressions: Use the  \\A  anchor to refer to the beginning of input. Use the  ^  anchor to refer to the beginning of line (this requires\nsetting the  m  flag in PCRE regular expressions). Alternatively use\none of the following constructs which work regardless of modifiers:\n-  (?:\\A|(?<=\\n))  (handles LF and CR+LF line ends)\n-  (?:\\A|(?<=[\\r\\n]))  (handles CR, LF and CR+LF line ends) In Ruby regular expressions, the  $  anchor always refers to the end\nof line. In PCRE regular expressions, the  $  anchor refers to the end\nof input by default and the  m  flag changes its meaning to the end\nof line. Both Ruby and PCRE regular expressions support the  \\z  anchor to refer to\nthe end of input, regardless of modifiers. When writing portable regular expressions: Use the  \\z  anchor to refer to the end of input. Use the  $  anchor to refer to the beginning of line (this requires\nsetting the  m  flag in PCRE regular expressions). Alternatively use\none of the following constructs which work regardless of modifiers:\n-  (?:\\z|(?=\\n))  (handles LF and CR+LF line ends)\n-  (?:\\z|(?=[\\n\\n]))  (handles CR, LF and CR+LF line ends) Since there is no simple way to programmatically convert a PCRE\nregular expression into the equivalent Ruby regular expression,\nbson-ruby provides the  BSON::Regexp::Raw  class for holding MongoDB/PCRE\nregular expressions. Instances of this class are called \"BSON regular\nexpressions\" in this documentation. Instances of this class can be created using the regular expression text\nas a string and optional PCRE modifiers: The  BSON::Regexp  module is included in the Ruby  Regexp  class, such that\nthe  BSON::  prefix may be omitted: To convert a Ruby regular expression to a BSON regular expression,\ninstantiate a  BSON::Regexp::Raw  object as follows: Note that the  BSON::Regexp::Raw  constructor accepts both the Ruby numeric\noptions and the PCRE modifier strings. To convert a BSON regular expression to a Ruby regular expression, call the\n compile  method on the BSON regular expression: Note that the  s  PCRE modifier was converted to the  m  Ruby modifier\nin the first example, and the last two examples were converted to the same\nregular expression even though the original BSON regular expressions had\ndifferent meanings. When a BSON regular expression uses the non-portable  ^  and  $ \nanchors, its conversion to a Ruby regular expression can change its meaning: When a Ruby regular expression is converted to a BSON regular expression\n(for example, to send to the server as part of a query), the BSON regular\nexpression always has the  m  modifier set reflecting the behavior of\n ^  and  $  anchors in Ruby regular expressions. Both Ruby and BSON regular expressions implement the  to_bson  method\nfor serialization to BSON: Both  Regexp  and  BSON::Regexp::Raw  classes implement the  from_bson \nclass method that deserializes a regular expression from a BSON byte buffer.\nMethods of both classes return a  BSON::Regexp::Raw  instance that\nmust be converted to a Ruby regular expression using the  compile  method\nas described above. BSON documents preserve the order of keys, because the documents are stored\nas lists of key-value pairs. Hashes in Ruby also preserve key order; thus\nthe order of keys specified in Ruby will be respected when serializing a\nhash to a BSON document, and when deserializing a BSON document into a hash\nthe order of keys in the document will match the order of keys in the hash. BSON specification allows BSON documents to have duplicate keys, because the\ndocuments are stored as lists of key-value pairs. Applications should refrain\nfrom generating such documents, because MongoDB server behavior is undefined\nwhen a BSON document contains duplicate keys. Since in Ruby hashes cannot have duplicate keys, when serializing Ruby hashes\nto BSON documents no duplicate keys will be generated. (It is still possible\nto hand-craft a BSON document that would have duplicate keys in Ruby, and\nsome of the other MongoDB BSON libraries may permit creating BSON documents\nwith duplicate keys.) Note that, since keys in BSON documents are always stored as strings,\nspecifying the same key as as string and a symbol in Ruby only retains the\nmost recent specification: When loading a BSON document with duplicate keys, the last value for a\nduplicated key overwrites previous values for the same key.",
            "code": [
                {
                    "lang": "sh",
                    "value": "gem install bson"
                },
                {
                    "lang": "ruby",
                    "value": "gem 'bson'"
                },
                {
                    "lang": "ruby",
                    "value": "require 'bson'\nrequire 'bson/active_support'"
                },
                {
                    "lang": "ruby",
                    "value": "\"Shall I compare thee to a summer's day\".to_bson\n1024.to_bson"
                },
                {
                    "lang": "ruby",
                    "value": "String.from_bson(byte_buffer)\nBSON::Int32.from_bson(byte_buffer)"
                },
                {
                    "lang": "ruby",
                    "value": "buffer = BSON::ByteBuffer.new"
                },
                {
                    "lang": "ruby",
                    "value": "buffer.put_byte(\"\\x00\")\n\nbuffer.put_bytes(\"\\xff\\xfe\\x00\\xfd\")"
                },
                {
                    "lang": "ruby",
                    "value": "buffer.put_string(\"hello, world\")"
                },
                {
                    "lang": "ruby",
                    "value": "buffer.put_cstring(\"hello, world\")"
                },
                {
                    "lang": "ruby",
                    "value": "buffer.put_cstring(:hello)\nbuffer.put_cstring(42)"
                },
                {
                    "lang": "ruby",
                    "value": "buffer.put_int32(12345)\nbuffer.put_int64(123456789012345)"
                },
                {
                    "lang": "ruby",
                    "value": "buffer.put_double(3.14159)"
                },
                {
                    "lang": "ruby",
                    "value": "buffer = BSON::ByteBuffer.new\nbuffer.put_string('testing')\nsocket.write(buffer.to_s)"
                },
                {
                    "lang": "ruby",
                    "value": "buffer = BSON::ByteBuffer.new(string) # a read mode buffer."
                },
                {
                    "lang": "ruby",
                    "value": "buffer.get_byte # Pulls a single byte from the buffer.\nbuffer.get_bytes(value) # Pulls n number of bytes from the buffer.\nbuffer.get_cstring # Pulls a null-terminated string from the buffer.\nbuffer.get_double # Pulls a 64-bit floating point from the buffer.\nbuffer.get_int32 # Pulls a 32-bit integer (4 bytes) from the buffer.\nbuffer.get_int64 # Pulls a 64-bit integer (8 bytes) from the buffer.\nbuffer.get_string # Pulls a UTF-8 string from the buffer."
                },
                {
                    "lang": "ruby",
                    "value": "buffer.rewind"
                },
                {
                    "lang": "ruby",
                    "value": "BSON::Binary.new(\"binary_string\")\n# => <BSON::Binary:0x47113101192900 type=generic data=0x62696e6172795f73...>"
                },
                {
                    "lang": "ruby",
                    "value": "BSON::Binary.new(\"binary_string\", :user)\n# => <BSON::Binary:0x47113101225420 type=user data=0x62696e6172795f73...>"
                },
                {
                    "lang": "ruby",
                    "value": "binary = BSON::Binary.new(\"binary_string\", :user)\nbinary.data\n=> \"binary_string\"\nbinary.type\n=> :user"
                },
                {
                    "lang": "ruby",
                    "value": "str = \"binary_string\"\nstr.encoding\n# => #<Encoding:US-ASCII>\nbinary = BSON::Binary.new(str)\nbinary.data\n# => \"binary_string\"\nbinary.data.encoding\n# => #<Encoding:ASCII-8BIT>"
                },
                {
                    "lang": "ruby",
                    "value": "uuid_str = \"00112233-4455-6677-8899-aabbccddeeff\"\nBSON::Binary.from_uuid(uuid_str)\n# => <BSON::Binary:0x46986653612880 type=uuid data=0x0011223344556677...>"
                },
                {
                    "lang": "ruby",
                    "value": "binary = BSON::Binary.new(\"\\x00\\x11\\x22\\x33\\x44\\x55\\x66\\x77\\x88\\x99\\xAA\\xBB\\xCC\\xDD\\xEE\\xFF\".force_encoding('BINARY'), :uuid)\n=> <BSON::Binary:0x46942046606480 type=uuid data=0x0011223344556677...>\nbinary.to_uuid\n=> \"00112233-4455-6677-8899aabbccddeeff\""
                },
                {
                    "lang": "ruby",
                    "value": "binary = BSON::Binary.from_uuid(uuid_str, :standard)\nbinary.to_uuid(:standard)"
                },
                {
                    "lang": "ruby",
                    "value": "binary = BSON::Binary.new(\"\\x00\\x11\\x22\\x33\\x44\\x55\\x66\\x77\\x88\\x99\\xAA\\xBB\\xCC\\xDD\\xEE\\xFF\".force_encoding('BINARY'), :uuid_old)\n=> <BSON::Binary:0x46942046606480 type=uuid data=0x0011223344556677...>\n\nbinary.to_uuid\n# => ArgumentError (Representation must be specified for BSON::Binary objects of type :uuid_old)\n\nbinary.to_uuid(:csharp_legacy)\n# => \"33221100-5544-7766-8899aabbccddeeff\"\n\nbinary.to_uuid(:java_legacy)\n# => \"77665544-3322-1100-ffeeddccbbaa9988\"\n\nbinary.to_uuid(:python_legacy)\n# => \"00112233-4455-6677-8899aabbccddeeff\""
                },
                {
                    "lang": "ruby",
                    "value": "uuid_str = \"00112233-4455-6677-8899-aabbccddeeff\"\n\nBSON::Binary.from_uuid(uuid_str, :csharp_legacy)\n# => <BSON::Binary:0x46986653650480 type=uuid_old data=0x3322110055447766...>\n\nBSON::Binary.from_uuid(uuid_str, :java_legacy)\n# => <BSON::Binary:0x46986653663960 type=uuid_old data=0x7766554433221100...>\n\nBSON::Binary.from_uuid(uuid_str, :python_legacy)\n# => <BSON::Binary:0x46986653686300 type=uuid_old data=0x0011223344556677...>"
                },
                {
                    "lang": "ruby",
                    "value": "BSON::Binary.from_uuid('77665544-3322-1100-ffeeddccbbaa9988',:java_legacy).to_uuid(:csharp_legacy)\n# => \"33221100-5544-7766-8899aabbccddeeff\""
                },
                {
                    "lang": "ruby",
                    "value": "BSON::Code.new(\"this.value = 5;\")"
                },
                {
                    "lang": "ruby",
                    "value": "BSON::CodeWithScope.new(\"this.value = age;\", age: 5)"
                },
                {
                    "lang": "ruby",
                    "value": "BSON::DBRef.new({\"$ref\" => \"collection\", \"$id\" => \"id\"})\nBSON::DBRef.new({\"$ref\" => \"collection\", \"$id\" => \"id\", \"database\" => \"db\"})"
                },
                {
                    "lang": "ruby",
                    "value": "BSON::DBRef.new(\"collection\", BSON::ObjectId('61eeb760a15d5d0f9f1e401d'))\nBSON::DBRef.new(\"collection\", BSON::ObjectId('61eeb760a15d5d0f9f1e401d'), \"db\")"
                },
                {
                    "lang": "ruby",
                    "value": "bson = {\"$ref\" => \"collection\", \"$id\" => \"id\"}.to_bson.to_s\nloaded = Hash.from_bson(BSON::ByteBuffer.new(bson))\n=> {\"$ref\"=>\"collection\", \"$id\"=>\"id\"}\nloaded.class\n=> BSON::DBRef"
                },
                {
                    "lang": "ruby",
                    "value": "BSON::Document[:key, \"value\"]\nBSON::Document.new"
                },
                {
                    "lang": "ruby",
                    "value": "bson = {test: 1}.to_bson.to_s\nloaded = Hash.from_bson(BSON::ByteBuffer.new(bson))\n=> {\"test\"=>1}\nloaded.class\n=> BSON::Document"
                },
                {
                    "lang": "ruby",
                    "value": "BSON::MaxKey.new"
                },
                {
                    "lang": "ruby",
                    "value": "BSON::MinKey.new"
                },
                {
                    "lang": "ruby",
                    "value": "BSON::ObjectId.new"
                },
                {
                    "lang": "ruby",
                    "value": "BSON::Timestamp.new(5, 30)"
                },
                {
                    "lang": "ruby",
                    "value": "BSON::Undefined.new"
                },
                {
                    "lang": "ruby",
                    "value": "# Instantiate with a String\nBSON::Decimal128.new(\"1.28\")\n\n# Instantiate with a BigDecimal\nd = BigDecimal(1.28, 3)\nBSON::Decimal128.new(d)"
                },
                {
                    "lang": "ruby",
                    "value": "{foo: :bar}.to_bson.to_s\n# => \"\\x12\\x00\\x00\\x00\\x02foo\\x00\\x04\\x00\\x00\\x00bar\\x00\\x00\"\n\n# 0x02 is the string type\nHash.from_bson(BSON::ByteBuffer.new(\"\\x12\\x00\\x00\\x00\\x02foo\\x00\\x04\\x00\\x00\\x00bar\\x00\\x00\".force_encoding('BINARY')))\n# => {\"foo\"=>\"bar\"}\n\n# 0x0E is the symbol type\nHash.from_bson(BSON::ByteBuffer.new(\"\\x12\\x00\\x00\\x00\\x0Efoo\\x00\\x04\\x00\\x00\\x00bar\\x00\\x00\".force_encoding('BINARY')))\n# => {\"foo\"=>:bar}"
                },
                {
                    "lang": "ruby",
                    "value": "{foo: BSON::Symbol::Raw.new(:bar)}.to_bson.to_s\n# => \"\\x12\\x00\\x00\\x00\\x0Efoo\\x00\\x04\\x00\\x00\\x00bar\\x00\\x00\""
                },
                {
                    "lang": "ruby",
                    "value": "Hash.from_bson({foo: 'bar'}.to_bson)\n# => {\"foo\"=>\"bar\"}\n\nHash.from_bson({1 => 2}.to_bson)\n# => {\"1\"=>2}"
                },
                {
                    "lang": "ruby",
                    "value": "time = Time.utc(1960, 1, 1, 0, 0, 0, 999_999)\ntime.to_f\n# => -315619199.000001\ntime.floor(3).to_f\n# => -315619199.001"
                },
                {
                    "lang": "ruby",
                    "value": "BSON::Regexp::Raw.new(\"^b403158\")\n# => #<BSON::Regexp::Raw:0x000055df63186d78 @pattern=\"^b403158\", @options=\"\">\n\nBSON::Regexp::Raw.new(\"^Hello.world$\", \"s\")\n# => #<BSON::Regexp::Raw:0x000055df6317f028 @pattern=\"^Hello.world$\", @options=\"s\">"
                },
                {
                    "lang": "ruby",
                    "value": "Regexp::Raw.new(\"^b403158\")\n# => #<BSON::Regexp::Raw:0x000055df63186d78 @pattern=\"^b403158\", @options=\"\">\n\nRegexp::Raw.new(\"^Hello.world$\", \"s\")\n# => #<BSON::Regexp::Raw:0x000055df6317f028 @pattern=\"^Hello.world$\", @options=\"s\">"
                },
                {
                    "lang": "ruby",
                    "value": "regexp = /^Hello.world/\nbson_regexp = BSON::Regexp::Raw.new(regexp.source, regexp.options)\n# => #<BSON::Regexp::Raw:0x000055df62e42d60 @pattern=\"^Hello.world\", @options=0>"
                },
                {
                    "lang": "ruby",
                    "value": "bson_regexp = BSON::Regexp::Raw.new(\"^hello.world\", \"s\")\nbson_regexp.compile\n# => /^hello.world/m\n\nbson_regexp = BSON::Regexp::Raw.new(\"^hello\", \"\")\nbson_regexp.compile\n# => /^hello.world/\n\nbson_regexp = BSON::Regexp::Raw.new(\"^hello.world\", \"m\")\nbson_regexp.compile\n# => /^hello.world/"
                },
                {
                    "lang": "ruby",
                    "value": "BSON::Regexp::Raw.new(\"^hello.world\", \"\").compile =~ \"42\\nhello world\"\n# => 3"
                },
                {
                    "lang": "ruby",
                    "value": "regexp_ruby = /^b403158/\n# => /^b403158/\nregexp_ruby.to_bson\n# => #<BSON::ByteBuffer:0x007fcf20ab8028>\n_.to_s\n# => \"^b403158\\x00m\\x00\"\n\nregexp_raw = Regexp::Raw.new(\"^b403158\")\n# => #<BSON::Regexp::Raw:0x007fcf21808f98 @pattern=\"^b403158\", @options=\"\">\nregexp_raw.to_bson\n# => #<BSON::ByteBuffer:0x007fcf213622f0>\n_.to_s\n# => \"^b403158\\x00\\x00\""
                },
                {
                    "lang": "ruby",
                    "value": "byte_buffer = BSON::ByteBuffer.new(\"^b403158\\x00\\x00\")\nregex = Regexp.from_bson(byte_buffer)\n# => #<BSON::Regexp::Raw:0x000055df63100d40 @pattern=\"^b403158\", @options=\"\">\nregex.pattern\n# => \"^b403158\"\nregex.options\n# => \"\"\nregex.compile\n# => /^b403158/"
                },
                {
                    "lang": "ruby",
                    "value": "BSON::Document.new(test: 1, 'test' => 2)\n=> {\"test\"=>2}"
                }
            ],
            "preview": "This tutorial discusses using the Ruby BSON library.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/projection",
            "title": "Projection",
            "headings": [
                "Projection Document",
                "Examples"
            ],
            "paragraphs": "By default, queries in MongoDB return all fields in matching\ndocuments. To limit the amount of data that MongoDB sends to\napplications, you can include a\n projection \ndocument in the query operation. The projection document limits the fields to return for all\nmatching documents. The projection document can specify the\ninclusion of fields or the exclusion of field and has the\nfollowing form: <value>  may be  0  (or  false ) to exclude the field, or\n 1  (or  true ) to include it. With the exception of the  _id \nfield, you may not have both inclusions and exclusions in the same\nprojection document. The following code example uses the  restaurants  sample dataset. To return only the  name ,  cuisine  and  _id  fields for\ndocuments that match the query filter, explicitly include the  name \nand  cuisine  fields in the projection document. The  _id  field is\nincluded automatically unless specifically excluded. To return  name  and  cuisine  but exclude all other fields,\nincluding  _id , use the following projection document: To return all fields  except  the address field, use the following:",
            "code": [
                {
                    "lang": "javascript",
                    "value": "{ 'projection': { field1: <value>, field2: <value> ... } }"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test')\ncollection = client[:restaurants]\n\ncollection.find({}, { 'projection' =>\n  { 'name' => 1, 'cuisine' => 1 } }).limit(5).each do |doc|\n  p doc\nend"
                },
                {
                    "lang": "javascript",
                    "value": "{ 'projection' => { 'name' => 1, 'cuisine' => 1, '_id' => 0 } }"
                },
                {
                    "lang": "javascript",
                    "value": "{ 'projection' => { 'address' => 0 } }"
                }
            ],
            "preview": "By default, queries in MongoDB return all fields in matching\ndocuments. To limit the amount of data that MongoDB sends to\napplications, you can include a\nprojection\ndocument in the query operation.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/change-streams",
            "title": "Change Streams",
            "headings": [
                "Watching for Changes on a Collection",
                "Watching for Changes on a Database",
                "Watching for Changes on a Cluster",
                "Closing a Change Stream",
                "Resuming a Change Stream"
            ],
            "paragraphs": "As of version 3.6 of the MongoDB server, a new  $changeStream  pipeline stage\nis supported in the aggregation framework. Specifying this stage first in an\naggregation pipeline allows users to request that notifications are sent for all\nchanges to a particular collection. As of MongoDB 4.0, change streams are\nsupported on databases and clusters in addition to collections. The Ruby driver provides an API for\nreceiving notifications for changes to a particular collection, database\nor cluster using this\nnew pipeline stage. Although you can create a change stream using the pipeline\noperator and aggregation framework directly, it is recommended to use the\ndriver API described below as the driver resumes the change stream one time\nif there is a timeout, a network error, a server error indicating that a\nfailover is taking place or another type of a resumable error. Change streams on the server require a  \"majority\"  read concern or no\nread concern. Change streams do not work properly with JRuby because of the issue documented  here .\nNamely, JRuby eagerly evaluates  #next  on an Enumerator in a background\ngreen thread, therefore calling  #next  on the change stream will cause\ngetMores to be called in a loop in the background. A collection change stream is created by calling the  #watch  method on a\ncollection: You can also receive the notifications as they become available: The  next  method blocks and polls the cluster until a change is available.\nUse the  try_next  method to iterate a change stream without blocking; this\nmethod will wait up to max_await_time_ms milliseconds for changes from the server,\nand if no changes are received it will return nil. If there is a non-resumable\nerror, both  next  and  try_next  will raise an exception.\nSee Resuming a Change Stream section below for an example that reads\nchanges from a collection indefinitely. The change stream can take filters in the aggregation framework pipeline\noperator format: A database change stream notifies on changes on any collection within the\ndatabase as well as database-wide events, such as the database being dropped. A database change stream is created by calling the  #watch  method on a\ndatabase object: A cluster change stream notifies on changes on any collection, any database\nwithin the cluster as well as cluster-wide events. A cluster change stream is created by calling the  #watch  method on a\nclient object (not the cluster object): You can close a change stream by calling its  #close  method: A change stream consists of two types of operations: the initial aggregation\nand  getMore  requests to receive the next batch of changes. The driver will automatically retry each  getMore  operation once on\nnetwork errors and when the server returns an error indicating it changed\nstate (for example, it is no longer the primary). The driver does not retry\nthe initial aggregation. In practical terms this means that, for example: To indefinitely and reliably watch for changes without losing any changes or\nprocessing a change more than once, the application must track the resume\ntoken for the change stream and restart the change stream when it experiences\nextended error conditions that cause the driver's automatic resume to also\nfail. The following code snippet shows an example of iterating a change stream\nindefinitely, retrieving the resume token using the  resume_token  change\nstream method and restarting the change stream using the  :resume_after \noption on all MongoDB or network errors: The above iteration is blocking at the  enum.next  call, and does not\npermit resuming processing in the event the Ruby process running this code\nis terminated. The driver also provides the  try_next  method which returns\n nil  (after a small waiting period) instead of blocking indefinitely when\nthere are no changes in the change stream. Using the  try_next  method,\nthe resume token may be persisted after each  getMore  request, even when\na particular request does not return any changes, such that the resume token\nremains at the top of the oplog and the application has an opportunity to\npersist it should the process handling changes terminates: Note that the resume token should be retrieved from the change stream after\nevery  try_next  call, even if the call returned no document. The resume token is also provided in the  _id  field of each change stream\ndocument. Reading the  _id  field is not recommended because it may be\nprojected out by the application, and because using only the  _id  field\nwould not advance the resume token when a  getMore  returns no documents. Calling  collection.watch  will fail if the cluster does not have\nenough available nodes to satisfy the  \"majority\"  read preference. Once  collection.watch  successfully returns, if the cluster subsequently\nexperiences an election or loses a node, but heals quickly enough,\nchange stream reads via  next  or  each  methods will continue\ntransparently to the application.",
            "code": [
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test')\ncollection = client[:test]\nstream = collection.watch\ncollection.insert_one(a: 1)\ndoc = stream.to_enum.next\nprocess(doc)"
                },
                {
                    "lang": "ruby",
                    "value": "stream = collection.watch\nenum = stream.to_enum\nwhile doc = enum.next\n  process(doc)\nend"
                },
                {
                    "lang": "ruby",
                    "value": "stream = collection.watch([{'$match' => { 'operationType' => {'$in' => ['insert', 'replace'] } } },\n                           {'$match' => { 'fullDocument.n' => { '$gte' => 1 } } }\n                          ])\nenum = stream.to_enum\nwhile doc = enum.next\n  process(doc)\nend"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test')\ndatabase = client.database\nstream = database.watch\nclient[:test].insert_one(a: 1)\ndoc = stream.to_enum.next\nprocess(doc)"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test')\nstream = client.watch\nclient[:test].insert_one(a: 1)\ndoc = stream.to_enum.next\nprocess(doc)"
                },
                {
                    "lang": "ruby",
                    "value": "stream.close"
                },
                {
                    "lang": "ruby",
                    "value": "token = nil\nloop do\n  begin\n    stream = collection.watch([], resume_after: token)\n    enum = stream.to_enum\n    while doc = enum.next\n      process(doc)\n      token = stream.resume_token\n    end\n  rescue Mongo::Error\n    sleep 1\n  end\nend"
                },
                {
                    "lang": "ruby",
                    "value": "token = nil\nloop do\n  begin\n    stream = collection.watch([], resume_after: token)\n    enum = stream.to_enum\n    doc = enum.try_next\n    if doc\n      process(doc)\n    end\n    token = stream.resume_token\n    # Persist +token+ to support resuming processing upon process restart\n  rescue Mongo::Error\n    sleep 1\n  end\nend"
                }
            ],
            "preview": "As of version 3.6 of the MongoDB server, a new $changeStream pipeline stage\nis supported in the aggregation framework. Specifying this stage first in an\naggregation pipeline allows users to request that notifications are sent for all\nchanges to a particular collection. As of MongoDB 4.0, change streams are\nsupported on databases and clusters in addition to collections.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/sessions",
            "title": "Sessions",
            "headings": [
                "Creating a session from a Mongo::Client",
                "Using a session",
                "Alternative way to create a session",
                "Unacknowledged Writes",
                "Causal Consistency",
                "End a session"
            ],
            "paragraphs": "Version 3.6 of the MongoDB server introduces the concept of logical sessions for clients.\nA session is an abstract concept that represents a set of sequential operations executed\nby an application that are related in some way. A session object can be created via a  Mongo::Client \nand passed to operation methods that should be executed in the context of that session. Please note that session objects are not thread safe. They must only be used by one thread at a time. A session can be created by calling the  start_session  method on a client and passing it a block: When using the block form, the session will be automatically ended by the driver after the block finishes executing. It is valid to call  start_session  with no options set. This will result in a\nsession that has no effect on the operations performed in the context of that session,\nother than to include a session ID in commands sent to the server. Please see the API docs for all supported\nsession options. An error will be thrown if the driver is connected to a deployment that does not support sessions and the\n start_session  method is called. Note that server sessions are discarded server-side if not used for a certain period of time.\nBe aware that if the application calls  #start_session  on a client and waits more than 1 minute to use\nthe session, it risks getting errors due to the session going stale before it is used. A session object can be passed to most driver methods so that the operation can be executed in the\ncontext of that session. Please see the API docs for which methods support a session argument. Create a session and execute an insert, then a find using that session: If you like to call methods on a  Mongo::Collection::View  in the context of a particular session, you can create the\n Mongo::Collection::View  with the session and then call methods on it: You can also pass the session option to the methods directly. This session will override any session associated with\nthe  Mongo::Collection::View : A session can be created by calling the  start_session  method on a client: When  start_session  is used without passing a block to it, the driver does not automatically clean up the session which can result in an accumulation of sessions on the server. Use  end_session  to manually end the session created. The server will automatically clean up old sessions after a timeout but the application should end sessions when the sessions are no longer needed. Unacknowledged writes are only allowed outside the session mechanism; if an explicit session is supplied for an\nunacknowledged write, the driver will not send the session id with the operation. Similarly, the driver will not use\nan implicit session for an unacknowledged write. A causally consistent session will let you read your writes and guarantee monotonically increasing\nreads from secondaries.\nTo create a causally consistent session, set the  causal_consistency  option to true: Since unacknowledged writes don't receive a response from the server (or don't wait for a response), the driver\nhas no way of keeping track of where the unacknowledged write is in logical time. Therefore, causally\nconsistent reads are not causally consistent with unacknowledged writes. Note that if you set the causal_consistency option to nil as in  (causal_consistency: nil) , it will be interpreted\nas false. To end a session, call the  end_session  method: The Ruby driver will then add the id for the corresponding server session to a pool for reuse.\nWhen a client is closed, the driver will send a command to the server to end all sessions it has cached\nin its server session pool. You may see this command in your logs when a client is closed. Note that when using the  block syntax  for  start_session  the session is automatically ended after\nthe block finishes executing.",
            "code": [
                {
                    "lang": "ruby",
                    "value": "client.start_session do |session|\n  # work with the session\nend"
                },
                {
                    "lang": "ruby",
                    "value": "client.start_session do |session|\n  client[:artists].insert_one({ :name => 'FKA Twigs' }, session: session)\n  client[:artists].find({ :name => 'FKA Twigs' }, limit: 1, session: session).first\nend"
                },
                {
                    "lang": "ruby",
                    "value": "client.start_session(causal_consistency: true) do |session|\n  view = client[:artists].find({ :name => 'FKA Twigs' }, session: session)\n  view.count # will use the session\nend"
                },
                {
                    "lang": "ruby",
                    "value": "client.start_session do |session|\n  client.start_session do |second_session|\n    view = client[:artists].find({ :name => 'FKA Twigs' }, session: session)\n    view.count(session: second_session) # will use the second_session\n  end\nend"
                },
                {
                    "lang": "ruby",
                    "value": "session = client.start_session"
                },
                {
                    "lang": "ruby",
                    "value": "session = client.start_session(causal_consistency: true)\n\n# The update message goes to the primary.\ncollection = client[:artists]\ncollection.update_one({ '_id' => 1 }, { '$set' => { 'x' => 0 } }, session: session)\n\n# Read your write, even when reading from a secondary!\ncollection.find({ '_id' => 1 }, session: session).first\n\n# This query returns data at least as new as the previous query,\n# even if it chooses a different secondary.\ncollection.find({ '_id' => 2 }, session: session).first"
                },
                {
                    "lang": "ruby",
                    "value": "session.end_session"
                }
            ],
            "preview": "Version 3.6 of the MongoDB server introduces the concept of logical sessions for clients.\nA session is an abstract concept that represents a set of sequential operations executed\nby an application that are related in some way. A session object can be created via a Mongo::Client\nand passed to operation methods that should be executed in the context of that session.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/bulk-operations",
            "title": "Bulk Writes",
            "headings": [
                "insert_one",
                "update_one",
                "update_many",
                "replace_one",
                "delete_one",
                "delete_many",
                "Bulk Write Splitting"
            ],
            "paragraphs": "The bulk write API sends several write operations to the server in a single\ncommand. Use the bulk write API to reduce the number of network round-trips\nwhen performing several writes at a time. For example, to efficiently perform\nmultiple updates, one might do: The following example shows how to execute different types of operations\nin the same request: The first argument to  bulk_write  is the list of operations to perform.\nEach operation must be specified as a hash with exactly one key which is\nthe operation name and the operation specification as the corresponding\nvalue. The supported operations are detailed below. The  bulk_write  method\nalso accepts the following options: Valid bulk write operations are the following: Option Description bypass_document_validation true  or  false . Whether to bypass document validation. ordered If the  ordered  option is set to  true  (which is the default),\nthe operations are applied in order and if any operation fails, subsequent\noperations are not attempted. If the  ordered  option is set to  false ,\nall specified operations are attempted. write_concern The write concern for the operation, specified as a hash. There is no  insert_many  bulk operation. To insert multiple documents,\nspecify multiple  insert_one  operations. The  :replace_one  operation requires that the replacement value is a\ndocument.  :replace_one  does not recognize MongoDB update operators in\nthe replacement value. In a future release the driver is expected to\nprohibit using keys beginning with  $  in the replacement document. The driver allows the application to submit arbitrarily large bulk write\nrequests. However, since MongoDB server limits the size of command documents\n(currently this limit is 48 MiB), bulk writes that exceed this limit will be\nsplit into multiple requests. When  client-side encryption  is used, the\nthreshold used for bulk write splitting is reduced to allow for overhead in\nthe ciphertext.",
            "code": [
                {
                    "lang": "ruby",
                    "value": "collection = client['colors']\ncollection.bulk_write([\n  {\n    update_one: {\n      filter: {name: 'yellow'},\n      update: {'$set' => {hex: 'ffff00'}},\n    },\n  },\n  {\n    update_one: {\n      filter: {name: 'purple'},\n      update: {'$set' => {hex: '800080'}},\n    },\n  },\n], ordered: true, write_concern: {w: :majority})"
                },
                {
                    "lang": "ruby",
                    "value": "collection.bulk_write([\n  { insert_one: { x: 1 } },\n  { update_one: {\n    filter: { x: 1 },\n    update: {'$set' => { x: 2 } },\n  } },\n  { replace_one: {\n    filter: { x: 2 },\n    replacement: { x: 3 },\n  } },\n], :ordered => true)"
                },
                {
                    "lang": "ruby",
                    "value": "{ insert_one: { x: 1 } }"
                },
                {
                    "lang": "ruby",
                    "value": "{ update_one: {\n  filter: { x: 1 },\n  update: { '$set' => { x: 2 } },\n  # upsert is optional and defaults to false\n  upsert: true,\n} }"
                },
                {
                    "lang": "ruby",
                    "value": "{ update_many: {\n  filter: { x: 1 },\n  update: { '$set' =>  { x: 2 } },\n  # upsert is optional and defaults to false\n  :upsert => true,\n} }"
                },
                {
                    "lang": "ruby",
                    "value": "{ replace_one: {\n  filter: { x: 1 },\n  replacement: { x: 2 },\n  # upsert is optional and defaults to false\n  upsert: true,\n} }"
                },
                {
                    "lang": "ruby",
                    "value": "{ delete_one: {\n  filter: { x: 1 },\n} }"
                },
                {
                    "lang": "ruby",
                    "value": "{ delete_many: {\n  filter: { x: 1 },\n} }"
                }
            ],
            "preview": "The bulk write API sends several write operations to the server in a single\ncommand. Use the bulk write API to reduce the number of network round-trips\nwhen performing several writes at a time. For example, to efficiently perform\nmultiple updates, one might do:",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/collection-tasks",
            "title": "Collections",
            "headings": [
                "Capped Collections",
                "Convert an Existing Collection to Capped",
                "Document Validation",
                "Add Validation to an Existing Collection",
                "Listing Collections",
                "Dropping Collections"
            ],
            "paragraphs": "MongoDB stores documents in collections. If a collection does not\nexist, MongoDB creates the collection when you first insert a\ndocument in that collection. You can also explicitly create a collection with various options,\nsuch as setting the maximum size or the documentation validation rules. Capped collections have maximum size or document counts that prevent\nthem from growing beyond maximum thresholds. All capped collections must\nspecify a maximum size and may also specify a maximum document count.\nMongoDB removes older documents if a collection reaches the maximum size\nlimit before it reaches the maximum document count. To create a  capped collection , use\nthe  capped: true  option along with a  size  in bytes. To convert an existing collection from non-capped to capped, use\nthe  convertToCapped  command. If you're using MongoDB version 3.2 or later, you can use\n document validation .\nCollections with validations compare each inserted or updated\ndocument against the criteria specified in the validator option.\nDepending on the  validationLevel  and  validationAction , MongoDB\neither returns a warning, or refuses to insert or update the document\nif it fails to meet the specified criteria. The following example creates a  contacts  collection with a validator\nthat specifies that inserted or updated documents should match at\nleast one of three following conditions: the  phone  field is a string the  email  field matches the regular expression the  status  field is either  Unknown  or  Incomplete . To add document validation criteria to an existing collection, use the\n collMod  command. The example below demonstrates how to add a\nvalidation to the  contacts  collection, ensuring that all new\ndocuments must contain an  age  field which is a number. Use  collections  or  collection_names  methods on a database\nobjects to list collections: To drop a collection, call  drop  on the collection object.",
            "code": [
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\ncollection = client[:artists, capped: true, size: 10000]\ncollection.create\ncollection.capped? # => true"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\ndb = client.database\ndb.command({ 'convertToCapped' => 'artists', 'size' => 10000 })"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test')\nclient[:contacts,\n\n    {\n       'validator' => { '$or' =>\n          [\n             { 'phone' => { '$type' => \"string\" } },\n             { 'email' => { '$regex' => /@mongodb\\.com$/ } },\n             { 'status' => { '$in' => [ \"Unknown\", \"Incomplete\" ] } }\n          ]\n       }\n    }\n\n  ].create"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test')\ndb = client.database\ndb.command({ 'collMod' => 'contacts',\n             'validator' =>\n               { 'age' =>\n                 { '$type' => \"number\" }\n               }\n           })"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\ndatabase = client.database\n\ndatabase.collections      # Returns an array of Collection objects.\ndatabase.collection_names # Returns an array of collection names as strings."
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\nartists = client[:artists]\nartists.drop"
                }
            ],
            "preview": "MongoDB stores documents in collections. If a collection does not\nexist, MongoDB creates the collection when you first insert a\ndocument in that collection.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/query-cache",
            "title": "Query Cache",
            "headings": [
                "Usage",
                "Interactions With Fibers",
                "Query Matching",
                "Limits",
                "Cache Invalidation",
                "Manual Cache Invalidation",
                "Transactions",
                "Aggregations",
                "System Collections",
                "Query Cache Middleware"
            ],
            "paragraphs": "The MongoDB Ruby driver provides a built-in query cache. When enabled, the\nquery cache saves the results of previously-executed find and aggregation\nqueries. When those same queries are performed again, the driver returns\nthe cached results to prevent unnecessary roundtrips to the database. The query cache is disabled by default. It can be enabled on the global\nscope as well as within the context of a specific block. The driver also\nprovides a  Rack middleware  to enable the\nquery cache automatically for each web request. To enable the query cache globally: Similarly, to disable it globally: To enable the query cache within the context of a block: And to disable the query cache in the context of a block: You may check whether the query cache is enabled at any time by calling\n Mongo::QueryCache.enabled? , which will return  true  or  false . The Query cache enablement flag is stored in fiber-local storage (using\n Thread.current .\nThis, in principle, permits query cache state to be per fiber, although\nthis is not currently tested. There are methods in the Ruby standard library, like  Enumerable#next ,\nthat  utilize fibers \nin their implementation. These methods would not see the query cache\nenablement flag when it is set by the applications, and subsequently would\nnot use the query cache. For example, the following code does not utilize\nthe query cache despite requesting it: Rewriting this code to use  first  instead of  next  would make it use\nthe query cache: A query is eligible to use cached results if it matches the original query\nthat produced the cached results. Two queries are considered matching if they\nare identical in the following values: For example, if you perform one query, and then perform a mostly identical query\nwith a different sort order, those queries will not be considered matching,\nand the second query will not use the cached results of the first. Namespace (the database and collection on which the query was performed) Selector (for aggregations, the aggregation pipeline stages) Skip Sort Projection Collation Read Concern Read Preference When performing a query with a limit, the query cache will reuse an existing\ncached query with a larger limit if one exists. For example: The query cache is cleared in part or in full on every write operation. Most\nwrite operations will clear the results of any queries were performed on the same\ncollection that is being written to. Some operations will clear the entire\nquery cache. The following operations will clear cached query results on the same database and\ncollection (including during bulk writes): The following operations will clear the entire query cache: insert_one update_one replace_one update_many delete_one delete_many find_one_and_delete find_one_and_update find_one_and_replace aggregation with  $merge  or  $out  pipeline stages commit_transaction abort_transaction You may clear the query cache at any time with the following method: This will remove all cached query results. Queries are cached within the context of a transaction, but the entire\ncache will be cleared when the transaction is committed or aborted. Transactions are often performed with a \"snapshot\" read concern level. Keep\nin mind that a query with a \"snapshot\" read concern cannot return cached\nresults from a query without the \"snapshot\" read concern, so it is possible\nthat a transaction may not use previously cached queries. To understand when a query will use a cached result, see the\n Query Matching  section. The query cache also caches the results of aggregation pipelines. For example: Aggregation results are cleared from the cache during every write operation,\nwith no exceptions. MongoDB stores system information in collections that use the  database.system.* \nnamespace pattern. These are called system collections. Data in system collections can change due to activity not triggered by the\napplication (such as internal server processes) and as a result of a variety of\ndatabase commands issued by the application. Because of the difficulty of\ndetermining when the cached results for system collections should be expired,\nqueries on system collections bypass the query cache. You may read more about system collections in the\n MongoDB documentation . Even when the query cache is enabled, query results from system collections\nwill not be cached. The driver provides a Rack middleware which enables the query cache for the\nduration of each web request. Below is an example of how to enable the\nquery cache middleware in a Ruby on Rails application: Please refer to the  Rails on Rack guide \nfor more information about using Rack middleware in Rails applications.",
            "code": [
                {
                    "lang": "ruby",
                    "value": "Mongo::QueryCache.enabled = true"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::QueryCache.enabled = false"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::QueryCache.cache do\n  Mongo::Client.new([ '127.0.0.1:27017' ], database: 'music') do |client|\n    client['artists'].find(name: 'Flying Lotus').first\n    #=> Queries the database and caches the result\n\n    client['artists'].find(name: 'Flying Lotus').first\n    #=> Returns the previously cached result\n  end\nend"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::QueryCache.uncached do\n  Mongo::Client.new([ '127.0.0.1:27017' ], database: 'music') do |client|\n    client['artists'].find(name: 'Flying Lotus').first\n    #=> Sends the query to the database; does NOT cache the result\n\n    client['artists'].find(name: 'Flying Lotus').first\n    #=> Queries the database again\n  end\nend"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::QueryCache.enabled = true\n\nclient['artists'].find({}, limit: 1).to_enum.next\n# Issues the query again.\nclient['artists'].find({}, limit: 1).to_enum.next"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::QueryCache.enabled = true\n\nclient['artists'].find({}, limit: 1).first\n# Utilizes the cached result from the first query.\nclient['artists'].find({}, limit: 1).first"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::QueryCache.cache do\n  Mongo::Client.new([ '127.0.0.1:27017' ], database: 'music') do |client|\n    client['artists'].find(genre: 'Rock', limit: 10)\n    #=> Queries the database and caches the result\n\n    client['artists'].find(genre: 'Rock', limit: 5)\n    #=> Returns the first 5 results from the cached query\n\n    client['artists'].find(genre: 'Rock', limit: 20)\n    #=> Queries the database again and replaces the previously cached query results\n  end\nend"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::QueryCache.clear"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::QueryCache.cache do\n  Mongo::Client.new([ '127.0.0.1:27017' ], database: 'music') do |client|\n    session = client.start_session\n\n    session.with_transaction do\n      client['artists'].insert_one({ name: 'Fleet Foxes' }, session: session)\n\n      client['artists'].find({}, session: session).first\n      #=> { name: 'Fleet Foxes' }\n      #=> Queries the database and caches the result\n\n      client['artists'].find({}, session: session).first\n      #=> { name: 'Fleet Foxes' }\n      #=> Returns the previously cached result\n\n      session.abort_transaction\n    end\n\n    client['artists'].find.first\n    #=> nil\n    # The query cache was cleared on abort_transaction\n  end\nend"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::QueryCache.cache do\n  Mongo::Client.new([ '127.0.0.1:27017' ], database: 'music') do |client|\n    client['artists'].aggregate([ { '$match' => { name: 'Fleet Foxes' } } ]).first\n    #=> Queries the database and caches the result\n\n    client['artists'].aggregate([ { '$match' => { name: 'Fleet Foxes' } } ]).first\n    #=> Returns the previously cached result\n  end\nend"
                },
                {
                    "lang": "ruby",
                    "value": "# config/application.rb\n\n# Add Mongo::QueryCache::Middleware at the bottom of the middleware stack\n# or before other middleware that queries MongoDB.\nconfig.middleware.use Mongo::QueryCache::Middleware"
                }
            ],
            "preview": "The MongoDB Ruby driver provides a built-in query cache. When enabled, the\nquery cache saves the results of previously-executed find and aggregation\nqueries. When those same queries are performed again, the driver returns\nthe cached results to prevent unnecessary roundtrips to the database.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/transactions",
            "title": "Transactions",
            "headings": [
                "Using Transactions",
                "Low Level API",
                "Retrying Commits",
                "Transaction Nesting"
            ],
            "paragraphs": "Version 4.0 of the MongoDB server introduces\n multi-document transactions .\n(Updates to multiple fields within a single document are atomic in all\nversions of MongoDB.) Ruby driver version 2.6.0 adds support for transactions. In order to start a transaction, the application must have a  session . The recommended way to use transactions is to utilize the  with_transaction \nhelper method: The  with_transaction  helper does the following: The block should be idempotent, because it may be called multiple times. The block may explicitly commit or abort the transaction, by calling\n commit_transaction  or  abort_transaction ; in this case  with_transaction \nwill not attempt to commit or abort (but may still retry the block on\ntransient transaction errors propagated out of the block). The block will also be retried if the transaction's commit result is unknown.\nThis may happen, for example, if the cluster undergoes an election during the\ncommit. In this case when the block is retried, the primary server of the\ntopology would likely have changed. Currently  with_transaction  will stop retrying the block and the commit once\n120 seconds pass since the beginning of its execution. This time is not\nconfigurable and may change in a future driver version. Note that this\ndoes not guarantee the overall runtime of  with_transactions  will be 120\nseconds or less - just that once 120 seconds of wall clock time have elapsed,\nfurther retry attempts will not be initiated. A low level API is also available if more control over transactions is desired. with_transaction  takes the same options as  start_transaction  does,\nwhich are read concern, write concern and read preference: It starts a transaction prior to calling the supplied block, and commits\nthe transaction when the block finishes. If any of the operations in the block, or the commit operation, result in\na transient transaction error, the block and/or the commit will be executed\nagain. A transaction can be started by calling the  start_transaction  method on a session: It is also possible to specify read concern, write concern and read preference\nwhen starting a transaction: To persist changes made in a transaction to the database, the transaction\nmust be explicitly committed. If a session ends with an open transaction,\n the transaction is aborted .\nA transaction may also be aborted explicitly. To commit or abort a transaction, call  commit_transaction  or\n abort_transaction  on the session instance: Note: an outstanding transaction can hold locks to various objects in the\nserver, such as the database. For example, the drop call in the following\nsnippet will hang for  transactionLifetimeLimitSeconds \nseconds (default 60) until the server expires and aborts the transaction: Since transactions are associated with server-side sessions, closing the client\ndoes not abort a transaction that this client initiated - the application must\neither call  abort_transaction  or wait for the transaction to time out on\nthe server side. In addition to committing or aborting the transaction, an\napplication can also end the session which will abort a transaction on this\nsession if one is in progress: The transaction commit  can be retried \nif it fails. Here is the Ruby code to do so: MongoDB does not support nesting transactions. Attempting to call\n start_transaction  or  with_transaction  when a transaction is already\nin progress will result in an error.",
            "code": [
                {
                    "lang": "ruby",
                    "value": "session = client.start_session\nsession.with_transaction do\n  collection.insert_one({hello: 'world'}, session: session)\nend"
                },
                {
                    "lang": "ruby",
                    "value": "session = client.start_session\nsession.with_transaction(\n  read_concern: {level: :majority},\n  write_concern: {w: 3},\n  read: {mode: :primary}\n) do\n  collection.insert_one({hello: 'world'}, session: session)\nend"
                },
                {
                    "lang": "ruby",
                    "value": "session = client.start_session\nsession.start_transaction"
                },
                {
                    "lang": "ruby",
                    "value": "session = client.start_session\nsession.start_transaction(\n  read_concern: {level: :majority},\n  write_concern: {w: 3},\n  read: {mode: :primary})"
                },
                {
                    "lang": "ruby",
                    "value": "session.commit_transaction\n\nsession.abort_transaction"
                },
                {
                    "lang": "ruby",
                    "value": "c1 = Mongo::Client.new(['127.0.0.1:27017']).use(:test_db)\nsession = c1.start_session\nc1['foo'].insert_one(test: 1)\nsession.start_transaction\nc1['foo'].insert_one({test: 2}, session: session)\n\nc2 = Mongo::Client.new(['127.0.0.1:27017']).use(:test_db)\n# hangs\nc2.database.drop"
                },
                {
                    "lang": "ruby",
                    "value": "session.end_session\n\nc2 = Mongo::Client.new(['127.0.0.1:27017']).use(:test_db)\n# ok\nc2.database.drop"
                },
                {
                    "lang": "ruby",
                    "value": "begin\n  session.commit_transaction\nrescue Mongo::Error => e\n  if e.label?('UnknownTransactionCommitResult')\n    retry\n  else\n    raise\n  end\nend"
                }
            ],
            "preview": "Version 4.0 of the MongoDB server introduces\nmulti-document transactions.\n(Updates to multiple fields within a single document are atomic in all\nversions of MongoDB.) Ruby driver version 2.6.0 adds support for transactions.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/schema-operations",
            "title": "Schema Operations",
            "headings": [],
            "paragraphs": "This section describes schema-related operations that the driver provides,\nincluding managing databases, collections, indexes and users.",
            "code": [],
            "preview": "This section describes schema-related operations that the driver provides,\nincluding managing databases, collections, indexes and users.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/collations",
            "title": "Collations",
            "headings": [
                "Overview",
                "Usage",
                "Collation Parameters",
                "Assign a Default Collation to a Collection",
                "Assign a Collation to an Index",
                "Operations that Support Collation",
                "find() and sort()",
                "find_one_and_update()",
                "find_one_and_delete()",
                "delete_many()",
                "Aggregation"
            ],
            "paragraphs": "Collations are sets of rules for how to compare strings, typically in a\nparticular natural language. For example, in Canadian French, the last accent in a given word\ndetermines the sorting order. Consider the following French words: The sort order using the Canadian French collation would result in\nthe following: If collation is unspecified, MongoDB uses the simple binary comparison for\nstrings.  As such, the sort order of the words would be: You can specify a default collation for collections and indexes when\nthey are created, or specify a collation for CRUD operations and\naggregations. For operations that support collation, MongoDB uses the\ncollection's default collation unless the operation specifies a\ndifferent collation. The only required parameter is  locale , which the server parses as\nan  ICU format locale ID .\nFor example, set  locale  to  en_US  to represent US English\nor  fr_CA  to represent Canadian French. For a complete description of the available parameters, see the\n MongoDB manual entry . The following example creates a new collection\ncalled  contacts  on the  test  database and assigns a default\ncollation with the  fr_CA  locale. Specifying a collation when you\ncreate the collection ensures that all operations involving a query\nthat are run against the\n contacts  collection use the  fr_CA  collation, unless the query\nspecifies another collation. Any indexes on the new collection also\ninherit the default collation, unless the creation command specifies\nanother collation. To specify a collation for an index, use the  collation \noption when you create the index. The following example creates an index on the  name \nfield of the  address_book  collection, with the  unique  parameter\nenabled and a default collation with  locale  set to  en_US . To use this index, make sure your queries also specify the same\ncollation. The following query uses the above index: The following queries do  NOT  use the index. The first query uses no\ncollation, and the second uses a collation with a different  strength \nvalue than the collation on the index. All reading, updating, and deleting methods support collation. Some\nexamples are listed below. Individual queries can specify a collation to use when matching\nand sorting results. The following query and sort operation uses\na German collation with the  locale  parameter set to  de . A collection called  names  contains the following documents: The following  find_one_and_update  operation on the collection\ndoes not specify a collation. Because  Gunter  is lexically first in the collection,\nthe above operation returns no results and updates no documents. Consider the same  find_one_and_update  operation but with the\ncollation specified.  The locale is set to  de@collation=phonebook . The operation returns the following updated document: Some locales have a  collation=phonebook  option available for\nuse with languages which sort proper nouns differently from other\nwords. According to the  de@collation=phonebook  collation,\ncharacters with umlauts come before the same characters without\numlauts. Set the  numericOrdering  collation parameter to  true \nto compare numeric string by their numeric values. The collection  numbers  contains the following documents: The following example matches the first document in which field  a \nhas a numeric value greater than 100 and deletes it. After the above operation, the following documents remain in the\ncollection: If you perform the same operation without collation, the server deletes\nthe first document it finds in which the lexical value of  a  is\ngreater than  \"100\" . After the above operation the document in which  a  was equal to\n \"16\"  has been deleted, and the following documents remain in the\ncollection: You can use collations with all the various bulk operations which\nexist in the Ruby driver. The collection  recipes  contains the following documents: Setting the  strength  parameter of the collation document to  1 \nor  2  causes the server to disregard case in the query filter. The\nfollowing example uses a case-insensitive query filter\nto delete all records in which the  cuisine  field matches\n French . After the above operation runs, the documents with  _id  values of\n 2  and  4  are deleted from the collection. To use collation with an aggregation operation, specify a collation in\nthe aggregation options. The following aggregation example uses a collection called  names \nand groups the  first_name  field together, counts the total\nnumber of results in each group, and sorts the\nresults by German phonebook order.",
            "code": [
                {
                    "lang": "none",
                    "value": "cote < cot\u00e9 < c\u00f4te < c\u00f4t\u00e9"
                },
                {
                    "lang": "none",
                    "value": "cote < c\u00f4te < cot\u00e9 < c\u00f4t\u00e9"
                },
                {
                    "lang": "none",
                    "value": "cote < cot\u00e9 < c\u00f4te < c\u00f4t\u00e9"
                },
                {
                    "lang": "ruby",
                    "value": "'collation' => {\n   'locale' => <string>,\n   'caseLevel' => <bool>,\n   'caseFirst' => <string>,\n   'strength' => <int>,\n   'numericOrdering' => <bool>,\n   'alternate' => <string>,\n   'maxVariable' => <string>,\n   'normalization' => <bool>,\n   'backwards' => <bool>\n}"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ \"127.0.0.1:27017\" ], :database => \"test\")\nclient[:contacts, { \"collation\" => { \"locale\" => \"fr_CA\" } } ].create"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ \"127.0.0.1:27017\" ], :database => \"test\")\nclient[:address_book].indexes.create_one( { \"first_name\" => 1 },\n                                        \"unique\" => true,\n                                        \"collation\" => { \"locale\" => \"en_US\" }\n                                       )"
                },
                {
                    "lang": "ruby",
                    "value": "client[:address_book].find({\"first_name\" : \"Adam\" },\n                            \"collation\" => { \"locale\" => \"en_US\" })"
                },
                {
                    "lang": "ruby",
                    "value": "client[:address_book].find({\"first_name\" : \"Adam\" })\n\nclient[:address_book].find({\"first_name\" : \"Adam\" },\n                            \"collation\" => { \"locale\" => \"en_US\", \"strength\" => 2 })"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ \"127.0.0.1:27017\" ], :database => \"test\")\ndocs = client[:contacts].find({ \"city\" => \"New York\" },\n  { \"collation\" => { \"locale\" => \"de\" } }).sort( \"name\" => 1 )"
                },
                {
                    "lang": "javascript",
                    "value": "{ \"_id\" : 1, \"first_name\" : \"Hans\" }\n{ \"_id\" : 2, \"first_name\" : \"Gunter\" }\n{ \"_id\" : 3, \"first_name\" : \"G\u00fcnter\" }\n{ \"_id\" : 4, \"first_name\" : \"J\u00fcrgen\" }"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ \"127.0.0.1:27017\" ], :database => \"test\")\ndoc = client[:names].find_one_and_update( {\"first_name\" => { \"$lt\" => \"Gunter\" }},\n  { \"$set\" => { \"verified\" => true } })"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ \"127.0.0.1:27017\" ], :database => \"test\")\ndoc = client[:names].find_one_and_update( { \"first_name\" => { \"$lt\" => \"Gunter\" } },\n  { \"$set\" => { \"verified\" => true } }, { \"collation\" => { \"locale\" => \"de@collation=phonebook\" },\n      :return_document => :after } )"
                },
                {
                    "lang": "javascript",
                    "value": "{ \"_id\" => 3, \"first_name\" => \"G\u00fcnter\", \"verified\" => true }"
                },
                {
                    "lang": "javascript",
                    "value": "{ \"_id\" : 1, \"a\" : \"16\" }\n{ \"_id\" : 2, \"a\" : \"84\" }\n{ \"_id\" : 3, \"a\" : \"179\" }"
                },
                {
                    "lang": "ruby",
                    "value": "docs = numbers.find_one_and_delete({ \"a\" => { \"$gt\" => \"100\" } },\n  { \"collation\" => { \"locale\" => \"en\", \"numericOrdering\" => true  } })"
                },
                {
                    "lang": "javascript",
                    "value": "{ \"_id\" : 1, \"a\" : \"16\" }\n{ \"_id\" : 2, \"a\" : \"84\" }"
                },
                {
                    "lang": "ruby",
                    "value": "numbers = client[:numbers]\ndocs = numbers.find_one_and_delete({ \"a\" => { \"$gt\" => \"100\" } })"
                },
                {
                    "lang": "javascript",
                    "value": "{ \"_id\" : 2, \"a\" : \"84\" }\n{ \"_id\" : 3, \"a\" : \"179\" }"
                },
                {
                    "lang": "javascript",
                    "value": "{ \"_id\" : 1, \"dish\" : \"veggie empanadas\", \"cuisine\" : \"Spanish\" }\n{ \"_id\" : 2, \"dish\" : \"beef bourgignon\", \"cuisine\" : \"French\" }\n{ \"_id\" : 3, \"dish\" : \"chicken mol\u00e9\", \"cuisine\" : \"Mexican\" }\n{ \"_id\" : 4, \"dish\" : \"chicken paillard\", \"cuisine\" : \"french\" }\n{ \"_id\" : 5, \"dish\" : \"pozole verde\", \"cuisine\" : \"Mexican\" }"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ \"127.0.0.1:27017\" ], :database => \"test\")\nrecipes = client[:recipes]\ndocs = recipes.delete_many({ \"cuisine\" => \"French\" },\n                             \"collation\" => { \"locale\" => \"en_US\", \"strength\" => 1 })"
                },
                {
                    "lang": "ruby",
                    "value": "aggregation = names.aggregate(\n  [\n    {\n      \"$group\" => { \"_id\" => \"$first_name\", \"name_count\" => { \"$sum\" => 1 } }\n    },\n    {\n        \"$sort\" => { \"_id\" => 1 }\n    },\n\n  ], { \"collation\" => { \"locale\" => \"de@collation=phonebook\" } }\n)\n\naggregation.each do |doc|\n  #=> Yields a BSON::Document.\nend"
                }
            ],
            "preview": "Collations are sets of rules for how to compare strings, typically in a\nparticular natural language.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/user-management",
            "title": "User Management",
            "headings": [
                "Users and Databases",
                "Creating Users",
                "User Information",
                "Updating Users",
                "Removing Users"
            ],
            "paragraphs": "The Mongo Ruby Driver provides a set of methods for managing users in a\nMongoDB deployment. All of these methods are defined on the\n Mongo::Auth::User::View  class, which defines the behavior for\nperforming user-related operations on a database. You can access a database's\nuser view by calling the  users  method on the correpsonding\n Mongo::Database  object: Note that this will open a view on the database to which the client is already\nconnected. To interact with the users defined on a different database, call\nthe client's  use  method and pass in the name of the database with which\nyou want to connect: In this example, all operations would be performed on the  users  database. For more information about users and user management, see MongoDB's\n online documentation . When a client connects to the server, MongoDB distinguishes the database\nthat the client will perform operations on from the  auth source \nwhich is the database storing the user that the client is authenticating as. In many cases, the auth source is the same as the database. When they differ,\nuser management operations must be done on the auth source database. For\nexample, to create a user authenticating with X.509 certifcate, which must be\ndefined on the  $external  database: Note that the auth source is not specified for creating the user - auth source\nis only used during the authentication process. If  #create  is invoked with\na  User  object with  auth_source  set, the auth source is ignored for\nthe purposes of user management. There are two ways to create a new database user with the Ruby Driver. The simplest way to create a new user is to use the  create  method,\npassing in a username, password, and roles: Another way to create a user is to first create a  Mongo::Auth::User  object\nwith all the user information and then pass that object into the  create \nmethod instead. Note that your new user's credentials will be stored in whatever database your\n client  object is currently connected to. This will be your user's\n auth_source , and you must be connected to that same database in order to\nupdate, remove, or get information about the user you just created in the future. The  create  method takes a  Hash  of options as an optional second argument.\nThe  :roles  option allows you to grant permissions to the new user.\nFor example, the  Mongo::Auth::Roles::READ_WRITE  role grants the user the\nability to both read from and write to the database in which they were created.\nEach role can be specified as a  String  or as a  Hash . If you would like\nto grant permissions to a user on a database other than the one on which they\nwere created, you can pass that database name in the role  Hash . To create\na user  alanturing  with permission to read and write on the  machines \ndatabase, you could execute the following code: For more information about roles in MongoDB, see the\n Built-in roles  documentation. In addition to the  :roles  option, the  create  method supports a\n :session  option, which allows you to specify a  Mongo::Session  object\nto use for this operation, as well as a  :write_concern  option,\nwhich specifies the write concern of this operation when performed on a\nreplica set. To view information about a user that already exists in the database, use the\n info  method: If the user exists, this method will return an  Array  object containing a\n Hash  with information about the user, such as their id, username, the\ndatabase they were created on, and their roles. If the user doesn't exist,\nthis method will return an empty Array. The  info  method also takes an optional  Hash  of options as a second\nargument. Currently, the only supported option is  :session , which allows\nyou to specify a  Mongo::Session  object to use for this operation. The Ruby Driver does not have a method that lists all of the users that\ncurrently exist in a database. To update a user that already exists in the database, you can use the\n update  method in one of two ways. The first way is to specify the name of\nthe user you wish to update, along with a new set of options. The second way to update a user is to pass an updated  Mongo::Auth::User \nobject to the  update  method in lieu of a username. Optionally, the  update  method takes a  Hash  of options as a second\nargument. The two possible options for this method are  :session , which\nallows you to specify a  Mongo::Session  object on which to perform this\noperation, and  :write_concern , which sets a write concern if this operation\nis performed on a replica set. You must include all user options in the options  Hash , even those options\nwhose values will remain the same. Omitting an option is the same as setting\nit to an empty value. To remove a user from the database, use the  remove  method: You may pass a  Hash  of options as a second argument. The two supported\noptions for the  remove  method are  :session  and  :write_concern .\n :session  allows you to specify a  Mongo::Session  object to use for\nthis operation.  :write_concern  specifies the write concern\nof the operation if you are running this command against a replica set. The Ruby Driver does not provide a method for removing all users\nfrom a database.",
            "code": [
                {
                    "lang": "ruby",
                    "value": "client.database.users"
                },
                {
                    "lang": "ruby",
                    "value": "client.use(:users).database.users"
                },
                {
                    "lang": "ruby",
                    "value": "client.use('$external').database.users.create(\n  'C=US,ST=New York,L=New York City,O=MongoDB,OU=x509,CN=localhost',\n  roles: [{role: 'read', db: 'admin'}],\n)"
                },
                {
                    "lang": "ruby",
                    "value": "client.database.users.create(\n  'alanturing',\n  password: 'enigma',\n  roles: [ Mongo::Auth::Roles::READWRITE ]\n)"
                },
                {
                    "lang": "ruby",
                    "value": "user = Mongo::User.new(\n  user: 'alanturing',\n  password: 'enigma',\n  roles: [ Mongo::Auth::Roles::READWRITE ]\n)\n\nclient.database.users.create(user)"
                },
                {
                    "lang": "ruby",
                    "value": "client.database.users.create(\n  'alanturing',\n  password: 'enigma',\n  roles: [{ role: Mongo::Auth::Roles::READWRITE, db: 'machines' }]\n)"
                },
                {
                    "lang": "ruby",
                    "value": "client.database.users.info('alanturing')"
                },
                {
                    "lang": "ruby",
                    "value": "client.database.users.update(\n  'alanturing',\n  roles: [ Mongo::Auth::Roles::READ_WRITE ]\n  password: 'turing-test'\n)"
                },
                {
                    "lang": "ruby",
                    "value": "user = Mongo::Auth::User.new({\n  user: 'alanturing',\n  roles: [ Mongo::Auth::Roles::READ_WRITE ],\n  password: 'turing-test'\n})\n\nclient.database.users.update(user)"
                },
                {
                    "lang": "ruby",
                    "value": "client.database.users.remove('alanturing')"
                }
            ],
            "preview": "The Mongo Ruby Driver provides a set of methods for managing users in a\nMongoDB deployment. All of these methods are defined on the\nMongo::Auth::User::View class, which defines the behavior for\nperforming user-related operations on a database. You can access a database's\nuser view by calling the users method on the correpsonding\nMongo::Database object:",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/map-reduce",
            "title": "Map-Reduce",
            "headings": [],
            "paragraphs": "Map-Reduce  is a data processing paradigm for\ncondensing large volumes of data into aggregated results. A map-reduce operation is issued on a collection view, as obtained from\n Collection#find  method, by calling the  map_reduce  method on the\nview. The  map_reduce  method takes three arguments: the mapper, the\nreducer and map-reduce options. The mapper and the reducer must be provided\nas strings containing JavaScript functions. For example, given the following collection with values 1 through 10: The following invocation will sum up the values less than 6: The  map_reduce  method returns an instance of\n Mongo::Collection::View::MapReduce  - a map-reduce view which holds\nthe parameters to be used for the operation. To execute the operation, either\niterate the results (by using e.g.  each ,  first  or  to_a  on the\nview object) or invoke the  execute  method. The  execute  method issues\nthe map-reduce operation but does not return the result set from the server,\nand is primarily useful for when the output of the operation is directed to\na collection as follows: Note that: Given a map-reduce view, it can be configured using the following methods: The following accessor methods are defined on the view object: The  aggregation framework  provides better performance\nand usability than map-reduce operations, and should be preferred for\nnew development. If the results of map-reduce are not directed to a collection, they are\nsaid to be retrieved inline. In this case the entire result set must fit in\nthe 16 MiB BSON document size limit. If the results of map-reduce are directed to a collection, and the\nmap-reduce view is iterated, the driver automatically retrieves the\nentire collection and returns its contents as the result set. The\ncollection is retrieved without sorting. If map-reduce is performed into\na collection that is not empty, the driver will return the documents\nas they exist in the collection after the map-reduce operation completes,\nwhich may include the documents that were in the collection prior to the\nmap-reduce operation. Method Description js_mode Sets the  jsMode  flag for the operation. out Directs the output to the specified collection, instead of returning\nthe result set. scope Sets the scope for the operation. verbose Sets whether to include the timing information in the result. Method Description js_mode Returns the current  jsMode  flag value. map_function Returns the map function as a string. out Returns the current output location for the operation. reduce_function Returns the reduce function as a string. scope Returns the current scope for the operation. verbose Returns whether to include the timing information in the result.",
            "code": [
                {
                    "lang": "ruby",
                    "value": "coll = client['foo']\n10.times do |i|\n  coll.insert_one(v: i)\nend"
                },
                {
                    "lang": "ruby",
                    "value": "coll.find(v: {'$lt' => 6}).map_reduce(\n  'function() { emit(null, this.v) }',\n  'function(key, values) { return Array.sum(values) }',\n).first['value']\n# => 15.0"
                },
                {
                    "lang": "ruby",
                    "value": "coll.find(...).map_reduce(...).out('destination_collection').execute"
                },
                {
                    "lang": "ruby",
                    "value": "coll.find(...).map_reduce(...).out('destination_collection').each do |doc|\n  # ...\nend\n\ncoll.find(...).map_reduce(...).out(replace: 'destination_collection', db: 'db_name').each do |doc|\n  # ...\nend"
                }
            ],
            "preview": "Map-Reduce is a data processing paradigm for\ncondensing large volumes of data into aggregated results.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/crud-operations",
            "title": "CRUD Operations",
            "headings": [
                "Key-value Pair Notation",
                "Creating Documents",
                "Specify a Decimal128 number",
                "Query Cache",
                "Reading",
                "Legacy $query Syntax",
                "Query Options",
                "Additional Query Operations",
                "Tailable Cursors",
                "Read Concern",
                "Read Preference",
                "Mode",
                "Tag sets",
                "Hedge",
                "Updating",
                "Update Options",
                "Deleting",
                "Delete Options",
                "Write Concern",
                "A Note about the BSON Symbol type"
            ],
            "paragraphs": "CRUD operations are those which deal with creating, reading, updating,\nand deleting documents. Key-value pairs appear in many different contexts in the MongoDB Ruby\ndriver, and there are some quirks of syntax with regard to how they can\nbe notated which depend on which version of Ruby you're using. When constructing a document, the following syntax is acceptable and\ncorrect for Ruby version 1.9 and later: If you're using Ruby version 2.2 or greater, you can optionally enclose\nyour keys in quotes. If you need to use any MongoDB operator which begins with  $ ,\nsuch as  $set ,  $gte , or  $near , you must enclose it in\nquotes. If you're using Ruby version 2.2 or greater, you can notate\nit as follows: If you're using an earlier version of Ruby, use the hashrocket symbol: Quoted strings and hashrockets for key-value pairs will work with any\nversion of Ruby: To insert documents into a collection, select a\ncollection on the client and call  insert_one  or  insert_many . Insert operations return a  Mongo::Operation::Result  object which\ngives you information about the insert itself. On MongoDB 2.6 and later, if the insert fails, an exception is\nraised, because write commands are used. On MongoDB 2.4, an exception is only raised if the insert fails and the\n write concern  is 1 or higher. Decimal128  is a\n BSON datatype \nthat employs 128-bit decimal-based floating-point values capable\nof emulating decimal rounding with exact precision. This\nfunctionality is intended for applications that handle\n monetary data ,\nsuch as financial and tax computations. The following example inserts a value of type  Decimal128  into\nthe  price  field of a collection named  inventory : The above operation produces the following document: You can also create a  Decimal128  object from a Ruby  BigDecimal \nobject, or with  Decimal128.from_string() . The Ruby driver provides a query cache. When enabled, the query cache will\nsave the results of find and aggregation queries and return those saved results\nwhen the same queries are performed again. To read more about the query cache, visit the\n query cache tutorial . The Ruby driver provides a fluent interface for queries using the  find \nmethod on the collection. Various options are available\nto the  find  method. The query is lazily executed against the server only when iterating the\nresults - at that point the query is dispatched and a  Mongo::Cursor  is\nreturned. To find all documents for a given filter, call  find  with the\nquery: To query nested documents, specify the keys in nested order using dot\nnotation. This usage is deprecated. The  find  method allows providing the query and the options using the\nlegacy  $query  syntax in the first parameter: When the query is executed against MongoDB 3.2 or newer, the driver will\nuse the protocol appropriate for the server version in question, automatically\nconverting the query as needed to either a find command or an OP_MSG payload. To add options to a query, chain the appropriate methods after the\n find  method. Note that the underlying object, the  Mongo::Collection::View ,\nis immutable and a new object will be returned after each method call. The following is a full list of the available options that can be added\nwhen querying and their corresponding methods as examples. Option Description allow_disk_use When set to true, the server can write temporary data to disk while\nexecuting the find operation. This option is only available on MongoDB\nserver versions 4.4 and newer. allow_partial_results For use with sharded clusters. If a shard is down, allows the query\nto return results from the shards that are up, potentially only getting\na portion of the results. batch_size(Integer) Specifies the size of each batch of documents the cursor will return on\neach  GETMORE  operation. comment(String) Adds a comment to the query. explain(**opts) Returns the query plan for the query. Pass the  explain options  via the keyword arguments using symbol\nkeys. The explain operation supports  :session  and  :read \n(for read preference) options. To specify these options for a single\nexplain operation, they must be given to the  find  method as\nfollows: If the read preference option is specified on the client or on the\ncollection, it will be passed to the explain operation: Note that the session option is not accepted when creating a collection\nobject. The explain command does not support passing the read concern option.\nIf the read concern is specifed on the client or collection level, or\nif the read concern is specified as a find option, it will NOT be passed\nby the driver to the explain command. The information returned by the server for the  explain  command\nvaries with server version and deployment topology. The driver's\n explain  method returns whatever the server provided. The return value of ``explain`` method is not part of the driver's\npublic API and depends on the server version and deployment topology. hint(Hash) Provides the query with an\n index hint  to use. limit(Integer) Limits the number of returned documents to the provided value. max_scan(Integer) Sets the maximum number of documents to scan if a full collection scan\nwould be performed. Deprecated as of MongoDB server version 4.0. max_time_ms(Integer) The maximum amount of time to allow the query to run, in milliseconds. no_cursor_timeout MongoDB automatically closes inactive cursors after a period of 10\nminutes. Call this for cursors to remain open indefinitely on the server. projection(Hash) Specifies the fields to include or exclude from the results. read(Hash) Changes the read preference for this query only. session(Session) The session to use. show_disk_loc(Boolean) Tells the results to also include the location of the documents on disk. skip(Integer) Skip the provided number of documents in the results. snapshot Execute the query in snapshot mode. Deprecated as of MongoDB server version 4.0. sort(Hash) Specifies sort criteria for the query. Get the total number of documents matching a filter, or the total number\nof documents in a collection. Get an approximate number of documents in the collection. Note that unlike  count_documents ,  estimated_document_count  does not\naccept a filter. Get an approximate number of documents matching a filter, or an approximate\nnumber of documents in the collection. Deprecated:  The  count  method is deprecated and does not work in\ntransactions. Please use  count_documents  to obtain an exact count of\ndocuments potentially matching a filter or  estimated_document_count \nto obtain an approximate number of documents in the collection. Filters out documents with duplicate values. Equivalent to the SQL\n distinct  clause. For capped collections you may use a  tailable cursor  that remains open\nafter the client exhausts the results in the initial cursor. The\nfollowing code example shows how a tailable cursor might be used: Read concern can be  set on the client \nor on the collection: The driver does not currently support setting read concern on an individual\nquery. Read concern can be specified when  starting a transaction . When a transaction is active,  any read concern\nspecified on the client or on the collection is ignored . When using the generic command helper, the read concern can be specified as\npart of the command: Read preference determines the candidate  replica set \nmembers to which a query or command can be sent. They consist of a  mode \nspecified as a symbol, an array of hashes known as  tag_sets ,\nthe  hedge  option, which is a Hash specifying hedged read behavior, and two\ntiming options:  local_threshold  and  server_selection_timeout . For more information on the algorithm used to select a server, please\nrefer to the  Server Selection documentation, available on GitHub . Read preference can be set as an option on the client or passed an\noption when a command is run on a database: Read preference can also be set for specific operations on a collection\nusing the  with  method: Defines the upper limit in seconds of the latency window\nbetween the nearest server and suitable servers to which an operation may be sent.\nThe default is 15 milliseconds, or 0.015 seconds. Defines how long to block for server selection\nbefore throwing an exception. The default is 30,000 milliseconds, or 30 seconds. Read preference does not apply to Standalone deployments. When a client\nis connected to a Standalone deployment, any application-specified read\npreference is ignored. There are five possible read preference modes:  :primary ,  :secondary ,\n :primary_preferred ,  :secondary_preferred  and``:nearest``.\nPlease see the  read preference documentation in the MongoDB Manual  for an explanation of the modes. When a client is directly connected to a server using the  :direct_connection \nRuby option or the  directConnection  URI option, read preference mode\nis automatically set to  :primary_preferred  to permit read operations\nagainst secondaries. If the application specified a  :primary  read\npreference mode, the mode is automatically converted to  :primary_preferred .\nIf another read preference mode is specified, it is passed to the server\nunchanged. The  tag_sets  parameter is an ordered list of tag sets used to\nrestrict the eligibility of servers for selection, such as for data\ncenter awareness. Please see the  read preference documentation in\nthe MongoDB Manual  for an explanation of tag sets. A read preference tag set (T) matches a server tag set (S) \u2013 or\nequivalently a server tag set (S) matches a read preference tag set\n(T) \u2014 if T is a subset of S. For example, the read preference tag set  { dc: 'ny', rack: 2 } \nmatches a secondary server with tag set  { dc: 'ny', rack: 2, size: 'large' } . A tag set that is an empty document matches any server, because\nthe empty tag set is a subset of any tag set. This means the default\n tag_sets  parameter  [{}]  matches all servers. The  hedge  parameter is a Hash that specifies whether the server should use\nhedged reads. With hedged reads, sharded clusters can route read operations to\ntwo replica set members and return results from the first respondent. The  hedge  option may only be specified on non-primary read preferences. It\nmust be provided as Hash with the key  enabled  set to  true  or  false . See the  MongoDB Manual  for\nmore information about hedged reads. The  hedge  option is only available on MongoDB server versions 4.4 and newer.\nAttempting to use this option on older server versions will result in an error. Updating documents is possible by executing a single or\nmultiple update, or by using the  $findAndModify  command. update_one update_many replace_one To update documents and return a document via  $findAndModify , use one of\nthe three provided helpers:  find_one_and_delete ,  find_one_and_replace ,\nor  find_one_and_update . You can opt to return the document before or after\nthe modification occurs. find_one_and_delete find_one_and_replace find_one_and_update To add options to an update command, specify them as key-value pairs in the options\nHash argument. The following is a list of the options that can be added to update operations,\nincluding  update_one ,  update_many ,  replace_one ,\n find_one_and_delete ,  find_one_and_update , and  find_one_and_replace . For more information about update options, see the MongoDB server documentation\non the following commands: Option Description array_filters An Array of filter documents that determine which array elements to modify\nfor an update operation on an array field. bypass_document_validation Whether to skip document-level validation before writing the document. collation Specifies a set of rules to use when comparing strings complying with the\nconventions of a particular language. hint The index to use for this operation. May be specified as a Hash\n(e.g. { _id: 1 }) or as a String (e.g. \"_id_\"). Supported on MongoDB\nserver versions 4.2 and newer for  update_one ,  update_many , and\n replace_one  commands, and on server versions 4.4 and newer for\n find_one_and_delete ,  find_one_and_update , and  find_one_and_replace \ncommands. projection The fields to exclude or include in the operation result (only available\non  find_one_and_delete ,  find_one_and_replace , and\n find_one_and_update  commands). return_document A symbol specifying whether to return the updated document as it was before or\nafter the update. Potential values are  :before  or  :after .\n(Only available on  find_one_and_update  and  find_one_and_replace  commands). sort How to sort the results of a find and modify command. Specified as a Hash\nkey-value pair, where the key is the name of the field to sort by, and\nthe value is either 1 or -1, specifying a sort in ascending or descending\norder (only available on  find_one_and_delete ,  find_one_and_replace ,\nand  find_one_and_update  commands). session The session to use for this operation. upsert Whether to upsert if the document doesn't exist. Cannot be used on\n find_one_and_delete  operation. update findAndModify delete_one delete_many To add options to a delete command, specify them as key-value pairs in the\noptions Hash argument. The following is a full list of the available options that can be added\nto  delete_one  and  delete_many  operations. For more information about update options, see the MongoDB server documentation\non the  delete command. Option Description collation Specifies a set of rules to use when comparing strings complying with the\nconventions of a particular language. hint The index to use for this operation. May be specified as a Hash\n(e.g. { _id: 1 }) or as a String (e.g. \"_id_\"). Supported on MongoDB\nserver versions 4.4 and newer. session The session to use for this operation. All write operations in MongoDB are executed with a write concern which is\nthe level of acknowledgment requested from MongoDB for the particular write.\nMore information about write concerns in general is available in the\n MongoDB manual . The Ruby driver supports specifying write concern on client, collection,\nsession (for transactions on that session), transaction, GridFS bucket\nand write stream levels, as well as when manually issuing commands via\n Database#command . As of driver version 2.10, all driver objects accepting write concerns do so\nthrough the  :write_concern  option, which should be given a hash with\nthe write concern options. Usage of the  :write  option is deprecated.\nIn driver versions 2.9 and below, client, collection and GridFS objects\ntook write concern options in the  :write  option with session and\ntransaction objects employing the  :write_concern  option. Below are some examples of passing write concerns to client and collection\nobjects. The  :write_concern  option can be provided when constructing\nnew client and collection objects,  or to the  #with  methods. GridFS examples are provided on the  GridFS  page. Driver versions 2.9 and earlier accepted write concerns on client and collection\nlevel via the  :write  option. This usage continues to be supported for\nbackwards compatibility, but is deprecated: If both  :write  and  :write_concern  options are provided, their\nvalues must be identical or an exception will be raised: When  #with  methods are used to alter the options on a client or collection,\nthe last provided option wins in case of naming differences: When using transactions, write concern is only sent to the server in\n commit_transaction  and  abort_transaction  operations\nper the  transactions specification .\nWrite concern may be set via the  :write_concern  option in a\n with_transaction  or  start_transaction  call, or via\n default_transaction_options  option on a session object.\nIf neither of these is set, write concern of the client is used; note\nthat transactions ignore write concerns of collections that are involved\nin their operations. Note that when setting the write concern as a\ntransaction option, the  :write  option is not recognized by any\ndriver version. When write concerns are inherited, inheritance applies to the entire\nwrite concern hash rather than individual elements. For example,  j: true \nis not inherited in the following case: Although CRUD operations accept an options hash, they currently do not\nrecognize the  :write_concern  option: The easiest workaround for this is to use  #with  to obtain a new collection\ninstance with the desired write concern: Write concern can also be manually specified in  Database#command : Note that writeConcern here is part of the operation rather than options,\nand the syntax is the camel case one that MongoDB server recognizes, not the\nunderscore one that Ruby driver uses. Because the BSON specification deprecated the BSON symbol type, the  bson  gem\nwill serialize Ruby symbols into BSON strings when used on its own. However, in\norder to maintain backwards compatibility with older datasets, the Ruby driver\noverrides this behavior to serialize Ruby symbols as BSON symbols. This is\nnecessary to be able to specify queries for documents which contain BSON\nsymbols as fields. Despite this, new documents with symbol type fields should\n not  be stored in the database; instead, use string fields. To override default behavior and configure the driver to encode symbol values\nas strings, include the following code snippet in your project:",
            "code": [
                {
                    "lang": "javascript",
                    "value": "document = { name: \"Harriet\", age: 36 }"
                },
                {
                    "lang": "javascript",
                    "value": "document = { \"name\": \"Harriet\", \"age\": 36 }"
                },
                {
                    "lang": "ruby",
                    "value": "collection.update_one({ name: \"Harriet\" }, { \"$set\": { age: 42 } })"
                },
                {
                    "lang": "ruby",
                    "value": "collection.update_one({ name: \"Harriet\" }, { \"$set\" => { age: 42 } })"
                },
                {
                    "lang": "ruby",
                    "value": "collection.update_one({ \"name\" => \"Harriet\" }, { \"$set\" => { age: 42 } })"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\n\nresult = client[:artists].insert_one( { :name => 'FKA Twigs' } )\nresult.n # returns 1, because 1 document was inserted.\n\nresult = client[:artists].insert_many([\n  { :name => 'Flying Lotus' },\n  { :name => 'Aphex Twin' }\n])\nresult.inserted_count # returns 2, because 2 documents were inserted."
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test')\n\nprice = BSON::Decimal128.new(\"428.79\")\nclient[:inventory].insert_one({ \"_id\" => 1,\n                                \"item\" => \"26 inch monitor\",\n                                \"price\" => price })"
                },
                {
                    "lang": "javascript",
                    "value": "{ \"_id\" : 1, \"item\" : \"26 inch monitor\", \"price\" : NumberDecimal(\"428.79\") }"
                },
                {
                    "lang": "ruby",
                    "value": "big_decimal = BigDecimal.new(428.79, 5)\nprice = BSON::Decimal128.new(big_decimal)\n# => BSON::Decimal128('428.79')\n\nprice = BSON::Decimal128.from_string(\"428.79\")\n# => BSON::Decimal128('428.79')"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\n\nclient[:artists].find(:name => 'Flying Lotus').each do |document|\n  #=> Yields a BSON::Document.\nend"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\nclient[:artists].find(\"records.releaseYear\": 2008).each do |document|\n  #=> Yields a BSON::Document.\nend"
                },
                {
                    "lang": "ruby",
                    "value": "collection.find(:'$query' => {name: 'Mr. Smith'})\n# Equivalent to:\ncollection.find(name: 'Mr. Smith')\n\ncollection.find(:'$query' => {name: 'Mr. Smith'}, :'$sort' => {age: 1})\n# Equivalent to:\ncollection.find(name: 'Mr. Smith').sort(age: 1)"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\n\ndocuments = client[:artists].find(:name => 'Flying Lotus').skip(10).limit(10)\ndocuments.each do |document|\n  #=> Yields a BSON::Document.\nend"
                },
                {
                    "lang": "ruby",
                    "value": "# All server versions - default explain behavior\nclient[:artists].find.explain\n\n# MongoDB 3.0 and newer\nclient[:artists].find.explain(verbosity: :query_planner)\nclient[:artists].find.explain(verbosity: :execution_stats)\nclient[:artists].find.explain(verbosity: :all_plans_execution)\n\n# Alternative syntax using camel case\nclient[:artists].find.explain(verbosity: \"queryPlanner\")\nclient[:artists].find.explain(verbosity: \"executionStats\")\nclient[:artists].find.explain(verbosity: \"allPlansExecution\")\n\n# MongoDB 2.6\nclient[:artists].find.explain(verbose: true)"
                },
                {
                    "lang": "ruby",
                    "value": "client[:artists].find({}, session: session).explain\n\nclient[:artists].find({}, read: {mode: :secondary_preferred}).explain"
                },
                {
                    "lang": "ruby",
                    "value": "client[:artists, read: {mode: :secondary_preferred}].find.explain"
                },
                {
                    "lang": "ruby",
                    "value": "client[:artists].find.projection(:name => 1)"
                },
                {
                    "lang": "ruby",
                    "value": "client[:artists].find.read(:mode => :secondary_preferred)"
                },
                {
                    "lang": "ruby",
                    "value": "client[:artists].find.sort(:name => -1)"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\n\nclient[:artists].find(:name => 'Flying Lotus').count_documents"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\n\nclient[:artists].estimated_document_count"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\n\nclient[:artists].find(:name => 'Flying Lotus').count"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\n\nclient[:artists].find.distinct(:name )"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\nclient[:artists].drop\nclient[:artists, capped: true, size: 512].create\n\nresult = client[:artists].insert_many([\n  { :name => 'Flying Lotus' },\n  { :name => 'Aphex Twin' }\n])\n\nenum = client[:artists].find({}, cursor_type: :tailable_await).to_enum\n\nwhile true\n  doc = enum.next\n  # do something\n  sleep(1)\nend"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new(['localhost:14420'], database: 'music',\n  read_concern: {level: :local})\n\nclient['collection'].find.to_a\n\ncollection = client['collection', read_concern: {level: :majority}]\n\ncollection.find.to_a"
                },
                {
                    "lang": "ruby",
                    "value": "client.database.command(collstats: 'test', readConcern: {level: :majority})"
                },
                {
                    "lang": "ruby",
                    "value": "# Set read preference on a client, used for all operations\nclient = Mongo::Client.new([ '127.0.0.1:27017' ],\n                           read: { mode: :secondary,\n                                   tag_sets: [ { 'dc' => 'nyc' } ]\n                                  } )\n\n# Set read preference for a given command\nclient.database.command( { collstats: 'test' }, read: { mode: secondary,\n                                                     tag_sets: [ { 'dc' => 'nyc' } ] } )"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\nartists = client[:artists]\nartists.with(:read => { :mode => :primary_preferred }).find.to_a"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new(\n  [ '127.0.0.1:27017' ],\n  read: { mode: :secondary, hedge: { enabled: true } },\n)"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\nartists = client[:artists]\n\nresult = artists.find(:name => 'Goldie').update_one(\"$inc\" => { :plays =>  1 } )\nresult.n # Returns 1.\n\nresult = artists.update_one( { :name => 'Goldie' }, { \"$inc\" => { :plays =>  1 } } )\nresult.n # Returns 1."
                },
                {
                    "lang": "ruby",
                    "value": "result = artists.find(:label => 'Hospital').update_many( \"$inc\" => { :plays =>  1 } )\nresult.modified_count # Returns the number of documents that were updated.\n\nresult = artists.update_many( { :label => 'Hospital' }, { \"$inc\" => { :plays =>  1 } } )\nresult.modified_count # Returns the number of documents that were updated."
                },
                {
                    "lang": "ruby",
                    "value": "result = artists.find(:name => 'Aphex Twin').replace_one(:name => 'Richard James')\nresult.modified_count # Returns 1.\n\nresult = artists.replace_one( { :name => 'Aphex Twin' }, { :name => 'Richard James' } )\nresult.modified_count # Returns 1."
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new( [ '127.0.0.1:27017' ], :database => 'music')\nartists = client[:artists]\n\nartists.find(:name => 'Jos\u00e9 James').find_one_and_delete # Returns the document."
                },
                {
                    "lang": "ruby",
                    "value": "doc = artists.find(:name => 'Jos\u00e9 James').find_one_and_replace(:name => 'Jos\u00e9')\ndoc # Return the document before the update.\n\ndoc = artists.find_one_and_replace({ :name => 'Jos\u00e9 James' }, { :name => 'Jos\u00e9' })\ndoc # Return the document before the update.\n\ndoc = artists.find(:name => 'Jos\u00e9 James').\n  find_one_and_replace( { :name => 'Jos\u00e9' }, :return_document => :after )\ndoc # Return the document after the update."
                },
                {
                    "lang": "ruby",
                    "value": "doc = artists.find(:name => 'Jos\u00e9 James').\n  find_one_and_update( '$set' => { :name => 'Jos\u00e9' } )\ndoc # Return the document before the update.\n\ndoc = artists.find_one_and_update( { :name => 'Jos\u00e9 James' }, { '$set' => { :name => 'Jos\u00e9' } } )\ndoc # Return the document before the update."
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\nartists = client[:artists]\n\nartists.indexes.create_one(name: 1)\n\n# Force the server to use the name index to perform this operation\nresult = artists.update_one(\n  { :name => 'Goldie' },\n  { \"$inc\" => { :plays =>  1 } },\n  { hint: { name: 1 } }\n)\nresult.n # Returns 1."
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\nartists = client[:artists]\n\nresult = artists.find(:name => 'Bj\u00f6rk').delete_one\nresult.deleted_count # Returns 1.\n\nresult = artists.delete_one(:name => 'Bj\u00f6rk')\nresult.deleted_count # Returns 1."
                },
                {
                    "lang": "ruby",
                    "value": "result = artists.find(:label => 'Mute').delete_many\nresult.deleted_count # Returns the number deleted.\n\nresult = artists.delete_many(:label => 'Mute')\nresult.deleted_count # Returns the number deleted."
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\nartists = client[:artists]\n\nartists.indexes.create_one(name: 1)\n\n# Force the server to use the name index to perform this operation\nresult = artists.find(:name => 'Bj\u00f6rk').delete_one(hint: { name: 1 })\nresult.deleted_count # Returns 1."
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], database: 'music',\n  write_concern: {w: 2})\nalt_client = client.with(write_concern: {w: :majority})\n\ncollection = client[:artists, write_concern: {w: 3}]\nalt_collection = collection.with(write_concern: {w: :majority})\n\n# Uses w: 3\ncollection.insert_one({name: 'SUN Project'})\n# Uses w: :majority\nalt_collection.insert_one({name: 'SUN Project'})"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], database: 'music',\n  write: {w: 2})\nalt_client = client.with(write: {w: :majority})\n\ncollection = client[:artists, write: {w: 3}]\nalt_collection = collection.with(write: {w: :majority})"
                },
                {
                    "lang": "ruby",
                    "value": "# OK\nclient = Mongo::Client.new([ '127.0.0.1:27017' ], database: 'music',\n  write_concern: {w: 3}, write: {w: 3})\n\n# Error\nclient = Mongo::Client.new([ '127.0.0.1:27017' ], database: 'music',\n  write_concern: {w: 3}, write: {w: :majority})"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], database: 'music',\n  write_concern: {w: 2})\nalt_client = client.with(write: {w: 3})\n\nalt_client.options[:write]\n# => {\"w\"=>3}\n\nalt_client.options[:write_concern]\n# => nil"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], database: 'music',\n  write_concern: {w: 2})\ncollection = client[:artists, write_concern: {w: :majority}]\n\n\nsession = client.start_session\nsession.with_transaction do\n  collection.insert_one({test: 1}, session: session)\n\n  # Uses w: 2 when committing\nend\n\n\nsession = client.start_session(default_transaction_options:\n  {write_concern: {w: 3})\n)\nsession.with_transaction do\n  collection.insert_one({test: 1}, session: session)\n\n  # Uses w: 3 when committing\nend\n\n\nsession = client.start_session\nsession.with_transaction(write_concern: {w: 3}) do\n  collection.insert_one({test: 1}, session: session)\n\n  # Uses w: 3 when committing\nend"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], database: 'music',\n  write_concern: {w: 1, j: true})\ncollection = client[:artists, write_concern: {w: 2}]\n\ncollection.write_concern.options\n# => #<Mongo::WriteConcern::Acknowledged:0x47289650367880 options={:w=>2}>"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], database: 'music',\n  write_concern: {w: 2})\ncollection = client[:artists, write_concern: {w: :majority}]\n\n# Still uses w: :majority\ncollection.insert_one({name: 'SUN Project'}, write_concern: {w: 1})"
                },
                {
                    "lang": "ruby",
                    "value": "# Uses w: 1\ncollection.with(write_concern: {w: 1}).insert_one(name: 'SUN Project')"
                },
                {
                    "lang": "ruby",
                    "value": "client.database.command(create: 'foo-collection', writeConcern: {w: :majority})"
                },
                {
                    "lang": "ruby",
                    "value": "class Symbol\n  def bson_type\n    BSON::String::BSON_TYPE\n  end\nend"
                }
            ],
            "preview": "CRUD operations are those which deal with creating, reading, updating,\nand deleting documents.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/driver-compatibility",
            "title": "Driver Compatibility",
            "headings": [
                "MongoDB Compatibility",
                "Ruby Compatibility",
                "Rails/ActiveSupport Compatibility",
                "TLS/SSL Compatibility",
                "Atlas Compatibility",
                "mongo_kerberos Compatibility",
                "JRuby and Kerberos Authentication",
                "JRuby and TLS Connections"
            ],
            "paragraphs": "The following compatibility table specifies the recommended\nversion(s) of the MongoDB Ruby driver for use with a specific version of\nMongoDB. Except when indicated, the specified driver versions expose or\ntake advantage of the features added in the corresponding server versions. MongoDB server releases are generally backwards compatible, meaning a\nparticular version of the driver will generally work with newer versions of\nthe server but may not take advantage of the functionality released in the\nnewer version of the server. The first column lists the driver versions.\u201cD\u201d in other columns means support\nfor that MongoDB version is deprecated and will be removed in a future driver\nversion. The driver does not support older versions of MongoDB. Ruby Driver MongoDB 5.0 MongoDB 4.4 MongoDB 4.2 MongoDB 4.0 MongoDB 3.6 MongoDB 3.4 MongoDB 3.2 MongoDB 3.0 MongoDB 2.6 2.16 D D D D 2.15 2.14 2.13 \u2713   2.12 2.11 \u2713   2.10 \u2713     2.9 2.8 2.7 2.6 2.5 2.4 2.3 2.2 2.0 OCSP verification is implemented as of driver version 2.14. Polling of SRV records in sharded topologies is\nimplemented as of driver version 2.11. Client-side encryption is implemented as of\ndriver version 2.12. The following compatibility table specifies the versions of Ruby supported\nby the various versions of the MongoDB Ruby driver. The first column lists the driver versions. \"D\" in a column means support\nfor that Ruby version is deprecated. The driver does not support older versions of Ruby. Ruby Driver Ruby 3.0 Ruby 2.7 Ruby 2.6 Ruby 2.5 Ruby 2.4 Ruby 2.3 Ruby 2.2 Ruby 2.1 Ruby 2.0 Ruby 1.9 JRuby 9.2 JRuby 9.1 JRuby 2.16 D 2.15 D D 2.14 D D 2.13 2.12 2.11 2.10 D D D D 2.9 D D D D 2.8 2.7 2.6 2.5 2.4 2.3 2.2 2.1 2.0 The Ruby driver does not depend on ActiveSupport. However, when an\napplication uses ActiveSupport or Ruby on Rails,\nit must load the driver's ActiveSupport\ncompatibility code for behavior like time serialization to be correct: Applications using Mongoid 7.0.6 or newer do not need to explicitly load\nthe driver's ActiveSupport code, since Mongoid automatically does so. The driver will utilize the protocols supported by the underlying Ruby\n openssl  extension. In turn, the  openssl  extension generally exposes\nthe functionality that exists in the operating system's OpenSSL library. Industry best practices, and some regulations, require the use of TLS 1.1\nor newer. Some operating systems or versions may not provide an OpenSSL version\nnew enough to support these TLS versions. Users of macOS older than 10.13 (High Sierra) will need to install Ruby from\n rvm ,  homebrew ,  macports , or another similar source. See\n installation information on ruby-lang.org  for more options. Users of Linux or other non-macOS Unix can check their OpenSSL version\nas follows: If the version number is less than 1.0.1 support for TLS 1.1 or newer is\nnot available. Contact your operating system vendor for a solution or upgrade\nto a newer distribution. You can check your Ruby interpreter by executing the following command: You should see \"TLS 1.X\" where X is >= 1. You can read more about TLS versions and their security implications  here . Driver version 2.6.1 \nor higher is recommended when using MongoDB Atlas, as this version has\nsignificant performance improvements when TLS connections are used, and all\nAtlas connections use TLS. When running on JRuby and connecting to Atlas Free Tier,\n driver version 2.6.4 \nor higher and Java 8 or higher are required. The following compatibility table specifies the version(s) of the\n mongo_kerberos library  to use with a specific version of\nthe driver. Ruby Driver mongo_kerberos  \u00a0  2.1 2.7 - 2.16 If the  mongo_kerberos  gem is used for Kerberos authentication with JRuby, the the JVM system\nproperty \"sun.security.jgss.native\" to will be set to \"true\" in order to facilitate the use of\nthe system cache of TGTs (e.g. TGTs obtained with  kinit ). Any other use of the JGSS library\nwill also be affected by this setting, meaning any TGTs in the system cache will be available for\nobtaining Kerberos credentials as well. Due to JRuby limitations: ECDSA server certificates are not supported. OCSP endpoint checking is not performed.",
            "code": [
                {
                    "lang": "ruby",
                    "value": "require 'mongo'\nrequire 'mongo/active_support'"
                },
                {
                    "lang": "sh",
                    "value": "openssl version"
                },
                {
                    "lang": "sh",
                    "value": "ruby -e \"require 'net/http'; require 'json'; puts JSON.parse(Net::HTTP.get(URI('https://www.howsmyssl.com/a/check')))['tls_version']\""
                }
            ],
            "preview": "The following compatibility table specifies the recommended\nversion(s) of the MongoDB Ruby driver for use with a specific version of\nMongoDB. Except when indicated, the specified driver versions expose or\ntake advantage of the features added in the corresponding server versions.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/indexing",
            "title": "Indexing",
            "headings": [
                "Creating Indexes",
                "The :commit_quorum option",
                "Dropping Indexes",
                "Listing Indexes"
            ],
            "paragraphs": "The driver provides the ability to create, drop and view\n indexes  on a collection through the  indexes  attribute: Indexes can be created one at a time, or several can be created in a single\noperation. When creating multiple indexes on MongoDB 3.0 and later, the indexes\nare created in parallel; on earlier versions they are created sequentially. To create a single index, use  indexes#create_one , passing the key\nspecification as the first argument and options as the second argument: To create multiple indexes, use  indexes#create_many  which accepts an array\nof index specifications. Unlike  create_one , each index specification\nis a hash with the  key  key mapped to the key specification and the\noptions being specified on the top level. The following is a full list of the available options that can be added\nwhen creating indexes. These options mirror the options supported by the\n createIndex command . Option Description :background Either  true  or  false . Tells the index to be created in the background. :expire_after Number of seconds to expire documents in the collection after. :name The name of the index. :sparse Whether the index should be sparse or not, either  true  or  false . :storage_engine The name of the storage engine for this particular index. :version The index format version to use. :default_language The default language of text indexes. :language_override The field name to use when overriding the default language. :text_version The version format for text index storage. :weights A document specifying fields and weights in text search. :sphere_version The 2d sphere index version. :bits Sets the maximum boundary for latitude and longitude in the 2d index. :max Maximum boundary for latitude and longitude in the 2d index. :min Minimum boundary for latitude and longitude in the 2d index. :bucket_size The number of units within which to group the location values in a geo haystack index. :partial_filter_expression A filter for a partial index. :hidden A Boolean specifying whether the index should be hidden; a hidden index\nis one that exists on the collection but will not be used by the query planner. On MongoDB server versions 4.4 and newer, the  :commit_quorum  option may be\nspecified on index creation. This option differs from other index options in that\nit determines server behavior during index creation, rather than determining\nthe behavior of an individual index. The  :commit_quorum  option specifies how many voting, data-bearing members\nof a replica set must complete the index build before the index is ready.\nPossible values are integers (0 to the number of voting, data-bearing members\nof the replica set), \"majority\", or \"votingMembers\". To specify  :commit_quorum  when creating one index, add another option\nto the second argument of the  indexes#create_one  method: To specify create options when creating multiple indexes, add a Hash specifying\n :commit_quorum  as a final element to the Array of indexes passed to\n indexes#create_many . Note that this Hash MUST be the final element in the\nArray. To drop an index, call  indexes#drop_one  or  indexes#drop_all . To list the indexes, iterate the  indexes  object: Each iteration returns an index specification as returned by the\n listIndexes  command. The shape and contents of the index specifications returned by this method\nmay change from one version of MongoDB to another.",
            "code": [
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], database: 'music')\nclient[:bands].indexes\n# => #<Mongo::Index::View:0x000055e2822b9318 @collection=#<Mongo::Collection:0x660 namespace=music.bands>, @batch_size=nil, @options={}>"
                },
                {
                    "lang": "ruby",
                    "value": "client[:bands].indexes.create_one(genre: 1)\n\nclient[:bands].indexes.create_one(\n  { name: 1 },\n  unique: true, expire_after: 120,\n)"
                },
                {
                    "lang": "ruby",
                    "value": "client[:bands].indexes.create_many([\n  { key: { genre: 1 } },\n  { key: { name: 1 }, unique: true, expire_after: 120 },\n])"
                },
                {
                    "lang": "ruby",
                    "value": "client[:bands].indexes.create_one(\n  { name: 1 },\n  unique: true, expire_after: 120, commit_quorum: 'majority'\n)"
                },
                {
                    "lang": "ruby",
                    "value": "client[:bands].indexes.create_many([\n  { key: { genre: 1 } },\n  { key: { name: 1 }, unique: true, expire_after: 120 },\n  { commit_quorum: 'majority' },\n])"
                },
                {
                    "lang": "ruby",
                    "value": "# Drops the name_1 index.\nclient[:bands].indexes.drop_one( 'name_1' )\n\n# Drops all indexes in the collection.\nclient[:bands].indexes.drop_all"
                },
                {
                    "lang": "ruby",
                    "value": "client[:bands].indexes.each do |index_spec|\n  p index_spec\n  # {\"v\"=>2, \"key\"=>{\"_id\"=>1}, \"name\"=>\"_id_\"}\n  # {\"v\"=>2, \"key\"=>{\"genre\"=>1}, \"name\"=>\"genre_1\"}\n  # {\"v\"=>2, \"unique\"=>true, \"key\"=>{\"name\"=>1}, \"name\"=>\"name_1\",\n  #  \"expireAfterSeconds\"=>120}\nend"
                }
            ],
            "preview": "The driver provides the ability to create, drop and view\nindexes on a collection through the indexes attribute:",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/client-side-encryption",
            "title": "Client-Side Encryption",
            "headings": [
                "Installation",
                "libmongocrypt",
                "mongocryptd",
                "Automatic Encryption",
                "Explicit Encryption",
                "Creating a Master Key",
                "Local Master Key",
                "AWS Master Key",
                "Remote Master Key",
                "Creating a Data Key",
                "Create a Data Key Using a Local Master Key",
                "Create a Data Key Using an AWS Master Key",
                "Auto-Encryption Options",
                ":key_vault_client",
                ":key_vault_namespace",
                ":schema_map",
                ":bypass_auto_encryption",
                ":extra_options"
            ],
            "paragraphs": "New in MongoDB 4.2, client-side encryption allows administrators and developers\nto encrypt specific fields in MongoDB documents before inserting them into the\ndatabase. With client-side encryption, developers can encrypt fields client-side without\nany server-side configuration or directives. Client-side encryption supports\nworkloads where applications must guarantee that unauthorized parties,\nincluding server administrators, cannot read the encrypted data. Enabling Client Side Encryption reduces the maximum write batch size and may\nhave a negative performance impact. Client-side encryption requires the installation of additional packages. Libmongocrypt is a C library used by the driver for client-side encryption.\nTo use client-side encryption, you must install the libmongocrypt binary\non the machine running your Ruby program. To download a pre-built binary: To build the binary from source: Once you have the libmongocrypt binary on your machine, specify the path to the\nbinary using the LIBMONGOCRYPT_PATH environment variable. It is recommended that\nyou add this variable to your rc files. For example: Download a tarball of all libmongocrypt variations  here . Extract the file you downloaded. You will see a list of directories, each\ncorresponding to an operating system. Find the directory that matches your\noperating system and open it. Inside that folder, open the folder called \"nocrypto.\" In either the\nlib or lb64 folder, you will find the libmongocrypt.so or\nlibmongocrypt.dylib or libmongocrypt.dll file, depending on your OS. Move that file to wherever you want to keep it on your machine. You may delete\nthe other files included in the tarball. Follow the instructions in the README in the  libmongocrypt GitHub repo . Mongocryptd is a daemon that tells the driver which fields to encrypt in a\ngiven operation. It is only required for automatic encryption, which is an\nenterprise-only feature. If you only intend to use explicit encryption, you may\nskip this step. Mongocryptd comes pre-packaged with enterprise builds of the MongoDB server\n(versions 4.2 and newer). For installation instructions, see the\n MongoDB manual . In order to configure mongocryptd (for example, which port it listens on or the\npath used to spawn the daemon), it is necessary to pass different options to the\n Mongo::Client  performing automatic encryption. See the  :extra_options \nsection of this tutorial for more information. Automatic encryption is a feature that allows users to configure a\n Mongo::Client  instance to always encrypt specific document fields when\nperforming database operations. Once the  Mongo::Client  is configured, it\nwill automatically encrypt any field that requires encryption before writing\nit to the database, and it will automatically decrypt those fields when reading\nthem. Client-side encryption implements envelope encryption, which is the practice of\nencrypting data with a data key, which is in turn encrypted using a master key.\nThus, using client-side encryption with MongoDB involves three main steps: The example below demonstrates how to follow these steps with a local master key\nin order to perform automatic encryption. The example above demonstrates using automatic encryption with a local master key.\nFor more information about using the AWS Key Management Service to create a\nmaster key and create data keys, see the following sections of this tutorial: Create a master key Create a data key (and encrypt it using the master key) Encrypt data using the data key Automatic encryption is an enterprise only feature that only applies to\noperations on a collection. Automatic encryption is not supported for operations\non a database or view, and operations that are not bypassed will result in\nerror (see  Auto Encryption Allow-List \n). To bypass automatic encryption for all operations, set  bypass_auto_encryption \nto true in  auto_encryption_options . Automatic encryption requires the authenticated user to have the listCollections privilege action. Creating A Master Key Creating A Data Key Explicit encryption is a feature that allows users to encrypt and decrypt\nindividual pieces of data such as strings, integers, or symbols. Explicit\nencryption is a community feature and does not require an enterprise build\nof the MongoDB server to use. To perform all explicit encryption and decryption\noperations, use an instance of the ClientEncryption class. Client-side encryption implements envelope encryption, which is the practice of\nencrypting data with a data key, which is in turn encrypted using a master key.\nThus, using client-side encryption with MongoDB involves three main steps: The example below demonstrates how to follow these steps with a local master key\nin order to perform explicit encryption. The example above demonstrates using explicit encryption with a local master key.\nFor more information about using the AWS Key Management Service to create a\nmaster key and create data keys, see the following sections of this tutorial: Create a master key Create a data key (and encrypt it using the master key) Encrypt data using the data key Creating A Master Key Creating A Data Key Both automatic encryption and explicit encryption require an encryption master key.\nThis master key is used to encrypt data keys, which are in turn used to encrypt\nuser data. The master key can be generated in one of two ways: by creating a\nlocal key, or by creating a key in the Amazon Web Services Key Management\nService (AWS KMS). A local master key is a 96-byte binary string. It should be persisted\non your machine as an environment variable or in a text file. Run the following code to generate a local master key using Ruby: Using a local master key is insecure and not recommended if you plan\nto use client-side encryption in production. It is recommended that you use Amazon's Key Management Service to create and\nstore your master key. To do so, follow steps 1 and 2 of the\n\n.. _remote-master-key: It is recommended that you use a remote Key Management Service to create and\nstore your master key. To do so, follow steps of the\n \"Set up a Remote Master Key\" \nin the MongoDB Client-Side Encryption documentation. For more information about creating a master key, see the\n\n Create a Master Key \nsection of the MongoDB manual. Once you have created a master key, create a data key by calling the\n #create_data_key  method on an instance of the  Mongo::ClientEncryption \nclass. This method generates a new data key and inserts it into the key vault\ncollection, which is the MongoDB collection in which you choose to store your\ndata keys. The  #create_data_key  method returns id of the newly-created\ndata key in the form of a BSON::Binary object. If you have created a local master key, you may use it to generate a new data\nkey with the following code snippet: See the  Local Master Key  section for more information\nabout generating a new local master key. Using a local master key is insecure and not recommended if you plan\nto use client-side encryption in production. If you have created an AWS master key, note the access key ID and the secret access\nkey of the IAM user that has permissions to use the key. Additionally, note\nthe AWS region and the Amazon Resource Number (ARN) of your master key. You will\nuse that information to generate a data key. See the  AWS Master Key  section of this tutorial  for more information about\ngenerating a new master key on AWS and finding the information you need to\ncreate data keys. For more information about creating a data key, see the\n Create a Data Encryption Key \nsection of the MongoDB manual. Automatic encryption can be configured on a  Mongo::Client  using the\n auto_encryption_options  option  Hash . This section provides an overview\nof the fields inside  auto_encryption_options  and explains how to choose their\nvalues. The key vault client is a  Mongo::Client  instance that will be used to connect\nto the MongoDB collection containing your encryption data keys. For example, if\nyour key vault was hosted on a MongoDB instance at  localhost:30000 : If your data keys are stored in the same MongoDB instance that stores your encrypted\ndata, you may leave this option blank, and the top-level client will be used\nto insert and fetch data keys. The key vault namespace is a  String  in the format  \"database_name.collection_name\" ,\nwhere  database_name  and  collection_name  are the name of the database and\ncollection in which you would like to store your data keys. For example, if your data\nkeys are stored in the  admin  database in the  datakeys  collection: There is no default key vault namespace, and this option must be provided. A schema map is a Hash with information about which fields to automatically\nencrypt and decrypt. The code snippet at the top of this tutorial demonstrates creating a schema\nmap using a Ruby  Hash . While this will work, schema maps can grow quite\nlarge and it could be unweildy to include them in your Ruby code. Instead, it is\nrecommended that you store them in a separate JSON (JavaScript Object Notation)\nfile. Before creating the JSON file, Base64-encode the UUID of the your data key. Then, create a new JSON file containing your schema map in the format defined by\nthe JSON Schema Draft 4 standard syntax. You can read more about formatting\nyour schema map in the  Automatic Encryption Rules \nsection of the MongoDB manual. When you intend to use your schema map, convert it to a Ruby  Hash  using the\n BSON::ExtJSON  module in the  bson  Ruby gem. It is also possible to supply a schema map as a validator on a MongoDB collection.\nThis is referred to as a \"remote schema map,\" while providing the schema map as\nan option on the  Mongo::Client  is called a \"local schema map.\" Supplying a local schema map provides more security than relying on JSON schemas\nobtained from the server. It protects against a malicious server advertising\na false JSON schema, which could trick the client into sending unencrypted\ndata that should be encrypted. See  Server-Side Field Level Encryption Enforcement \nin the MongoDB manual for more information about using the schema map to\ncreate a JSON schema validator on your collection. Specify Encrypted Fields Using JSON Schema ,\n Automatic Encryption Rules The  :bypass_auto_encryption  option is a  Boolean  that specifies whether the\n Mongo::Client  should skip encryption when writing to the database. If\n :bypass_auto_encryption  is  true , the client will still perform automatic\ndecryption of any previously-encrypted data. :extra_options  is a  Hash  of options related to spawning mongocryptd.\nEvery option in this  Hash  has a default value, so it is only necessary to\nprovide the options whose defaults you want to override. For example, if you would like to run mongocryptd on port 30000, provide\n extra_options  as follows: :mongocryptd_spawn_args  - This is an  Array<String>  containing arguments\nfor spawning mongocryptd. The Ruby driver will pass these arguments to\nmongocryptd on spawning the daemon. Possible arguments are: \"--idleShutdownTimeoutSecs\"  - The number of seconds mongocryptd must remain\nidle before it shuts itself down. The default value is 60. \"--port\"  - The port at which mongocryptd will listen for connections. The\ndefault is 27020. :mongocryptd_uri  - The URI that the driver will use to connect to mongocryptd.\nBy default, this is  \"mongodb://localhost:27020\" . :mongocryptd_spawn_path  - The path to the mongocryptd executable. The default\nis  \"mongocryptd\" . :mongocryptd_bypass_spawn  - A  Boolean  indicating whether the driver should\nskip spawning mongocryptd. The contents of  :extra_options  is subject to change in future versions\nof the client-side encryption API.",
            "code": [
                {
                    "lang": "bash",
                    "value": "export LIBMONGOCRYPT_PATH=/path/to/your/libmongocrypt.so"
                },
                {
                    "lang": "ruby",
                    "value": "require 'mongo'\n\n#####################################\n# Step 1: Create a local master key #\n#####################################\n\n# A local master key is a 96-byte binary blob.\nlocal_master_key = SecureRandom.random_bytes(96)\n# => \"\\xB2\\xBE\\x8EN\\xD4\\x14\\xC2\\x13\\xC3...\"\n\n#############################\n# Step 2: Create a data key #\n#############################\n\nkms_providers = {\n  local: {\n    key: local_master_key\n  }\n}\n\n# The key vault client is a Mongo::Client instance connected to the collection\n# that will store your data keys.\nkey_vault_client = Mongo::Client.new(['localhost:27017'])\n\n# Use an instance of Mongo::ClientEncryption to create a new data key\nclient_encryption = Mongo::ClientEncryption.new(\n  key_vault_client,\n  key_vault_namespace: 'admin.datakeys',\n  kms_providers: kms_providers\n)\n\ndata_key_id = client_encryption.create_data_key('local')\n# => <BSON::Binary... type=ciphertext...>\n\n#######################################################\n# Step 3: Configure Mongo::Client for auto-encryption #\n#######################################################\n\n# Create a schema map, which tells the Mongo::Client which fields to encrypt\nschema_map = {\n  'encryption_db.encryption_coll': {\n    properties: {\n      encrypted_field: {\n        encrypt: {\n          keyId: [data_key_id],\n          bsonType: \"string\",\n          algorithm: \"AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic\"\n        }\n      }\n    },\n    bsonType: \"object\"\n  }\n}\n\n# Configure the client for automatic encryption\nclient = Mongo::Client.new(\n  ['localhost:27017'],\n  auto_encryption_options: {\n    key_vault_namespace: 'admin.datakeys',\n    kms_providers: kms_providers,\n    schema_map: schema_map\n  }\n)\n\ncollection = client.use('encryption_db')['encryption_coll']\ncollection.drop # Make sure there is no data in the collection\n\n# The string \"sensitive data\" will be encrypted and stored in the database\n# as ciphertext\ncollection.insert_one(encrypted_field: 'sensitive data')\n\n# The data is decrypted before being returned to the user\ncollection.find(encrypted_field: 'sensitive data').first['encrypted_field']\n# => \"sensitive data\"\n\n# A client with no auto_encryption_options is unable to decrypt the data\nclient_no_encryption = Mongo::Client.new(['localhost:27017'])\nclient_no_encryption.use('encryption_db')['encryption_coll'].find.first['encrypted_field']\n# => <BSON::Binary... type=ciphertext...>"
                },
                {
                    "lang": "ruby",
                    "value": "require 'mongo'\n\n#####################################\n# Step 1: Create a local master key #\n#####################################\n\n# A local master key is a 96-byte binary blob.\nlocal_master_key = SecureRandom.random_bytes(96)\n# => \"\\xB2\\xBE\\x8EN\\xD4\\x14\\xC2\\x13\\xC3...\"\n\n#############################\n# Step 2: Create a data key #\n#############################\n\nkms_providers = {\n  local: {\n    key: local_master_key\n  }\n}\n\n# The key vault client is a Mongo::Client instance connected to the collection\n# that will store your data keys.\nkey_vault_client = Mongo::Client.new(['localhost:27017'])\n\n# Use an instance of Mongo::ClientEncryption to create a new data key\nclient_encryption = Mongo::ClientEncryption.new(\n  key_vault_client,\n  key_vault_namespace: 'admin.datakeys',\n  kms_providers: kms_providers\n)\n\ndata_key_id = client_encryption.create_data_key('local')\n# => <BSON::Binary... type=ciphertext...>\n\n#####################################################\n# Step 3: Encrypt a string with explicit encryption #\n#####################################################\n\n# The value to encrypt\nvalue = 'sensitive data'\n\n# Encrypt the value\nencrypted_value = client_encryption.encrypt(\n  'sensitive data',\n  {\n    key_id: data_key_id,\n    algorithm: \"AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic\"\n  }\n)\n\n# Create the client you will use to read and write the data to MongoDB\nclient = Mongo::Client.new(['localhost:27017'])\ncollection = client.use('encryption_db')['encryption_coll']\ncollection.drop # Make sure there is no data in the collection\n\n# Insert the encrypted value into the collection\ncollection.insert_one(encrypted_field: encrypted_value)\n\n# Use the client to read the encrypted value from the database, then\n# use the ClientEncryption object to decrypt it\nfind_result = collection.find(encrypted_field: encrypted_value).first['encrypted_field']\n# => <BSON::Binary...> (the find result is encrypted)\n\nunencrypted_result = client_encryption.decrypt(find_result)\n# => \"sensitive data\""
                },
                {
                    "lang": "ruby",
                    "value": "local_master_key = SecureRandom.random_bytes(96)\n# => \"\\xB2\\xBE\\x8EN\\xD4\\x14\\xC2\\x13\\xC3...\" (a binary blob)"
                },
                {
                    "lang": "ruby",
                    "value": "# A Mongo::Client instance that will be used to connect to the key vault\n# collection. Replace the server address with the address of the MongoDB\n# server where you would like to store your key vault collection.\nkey_vault_client = Mongo::Client.new(['localhost:27017'])\n\nclient_encryption = Mongo::ClientEncryption.new(\n  key_vault_client,\n  # Replace with the database and collection names for your key vault collection\n  key_vault_namespace: 'admin.datakeys',\n  kms_providers: {\n    local: {\n      key: local_master_key\n    }\n  }\n)\n\ndata_key_id = client_encryption.create_data_key('local')\n# => <BSON::Binary... type=ciphertext...>"
                },
                {
                    "lang": "ruby",
                    "value": "# A Mongo::Client instance that will be used to connect to the key vault\n# collection. Replace the server address with the address of the MongoDB\n# server where you would like to store your key vault collection.\nkey_vault_client = Mongo::Client.new(['localhost:27017'])\n\nclient_encryption = Mongo::ClientEncryption.new(\n  key_vault_client,\n  # Replace with the database and collection names for your key vault collection\n  key_vault_namespace: 'admin.datakeys',\n  kms_providers: {\n    aws: {\n      access_key_id: 'IAM-ACCESS-KEY-ID',\n      secret_access_key: 'IAM-SECRET-ACCESS-KEY'\n    }\n  }\n)\n\ndata_key_id = client_encryption.create_data_key(\n  'aws',\n  {\n    master_key: {\n      region: 'REGION-OF-YOUR-MASTER-KEY',\n      key: 'ARN-OF-YOUR-MASTER-KEY'\n    }\n\n  }\n)\n# => <BSON::Binary... type=ciphertext...>"
                },
                {
                    "lang": "ruby",
                    "value": "key_vault_client = Mongo::Client.new(['localhost:30000'])\n\nMongo::Client.new(['localhost:27017],\n  auto_encryption_options: {\n    key_vault_client: key_vault_client,\n    # ... (Fill in other options here)\n  }\n)"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Client.new(['localhost:27017],\n  auto_encryption_options: {\n    key_vault_namespace: 'admin.datakeys',\n    # ... (Fill in other options here)\n  }\n)"
                },
                {
                    "lang": "ruby",
                    "value": "Base64.encode64(data_key_id.data)\n# => \"sr6OTtQUwhPD...\" (a base64-encoded string)"
                },
                {
                    "lang": "json",
                    "value": "{\n  \"encryption_db.encryption_coll\": {\n    \"properties\": {\n      \"encrypted_field\": {\n        \"encrypt\": {\n          \"keyId\": [{\n            \"$binary\": {\n              \"base64\": \"YOUR-BASE64-ENCODED-DATA-KEY-ID\",\n              \"subType\": \"04\"\n            }\n          }],\n          \"bsonType\": \"string\",\n          \"algorithm\": \"AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic\"\n        }\n      }\n    },\n    \"bsonType\": \"object\"\n  }\n}"
                },
                {
                    "lang": "ruby",
                    "value": "schema_map = BSON::ExtJSON.parse(File.read('/path/to/your/file.json'))\n# => { 'encryption_db.encryption_coll' => { ... } }\n\nMongo::Client.new(['localhost:27017],\n  auto_encryption_options: {\n    schema_map: schema_map,\n    # ... (Fill in other options here)\n  }\n)"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Client.new(['localhost:27017],\n  auto_encryption_options: {\n    bypass_auto_encryption: true,\n    # ... (Fill in other options here)\n  }\n)"
                },
                {
                    "lang": "ruby",
                    "value": "  Mongo::Client.new(['localhost:27017],\n  auto_encryption_options: {\n    extra_options: {\n      mongocryptd_spawn_args: ['--port=30000'],\n      mongocryptd_uri: 'mongodb://localhost:30000',\n    }\n    # ... (Fill in other options here)\n  }\n)"
                }
            ],
            "preview": "New in MongoDB 4.2, client-side encryption allows administrators and developers\nto encrypt specific fields in MongoDB documents before inserting them into the\ndatabase.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/geospatial-search",
            "title": "Geospatial Search",
            "headings": [],
            "paragraphs": "MongoDB offers a number of indexes and query mechanisms to handle\ngeospatial information. This section demonstrates how to create\nand use\n geospatial indexes \nwith the Ruby driver. The examples on this page use a sample collection called\n restaurants  in the  test  database.\nA  sample dataset \nis available for download. The following is a sample document in the  restaurants \ncollection: The following example creates a  2dsphere  index on the\n address.coord  field: Once the index is created, you can use several operators to query\nagainst it, including the\n $near ,\n $geoWithin , and\n $geoIntersects \noperators. The following example uses the  $near  operator to find\nall restaurants within 500 meters of the given coordinates. To find all documents with a location within the\nperimeter of a given polygon, use the  $geoWithin \noperator:",
            "code": [
                {
                    "lang": "javascript",
                    "value": "{\n  \"address\": {\n     \"building\": \"1007\",\n     \"coord\": [ -73.856077, 40.848447 ],\n     \"street\": \"Morris Park Ave\",\n     \"zipcode\": \"10462\"\n  },\n  \"borough\": \"Bronx\",\n  \"cuisine\": \"Bakery\",\n  \"grades\": [\n     { \"date\": { \"$date\": 1393804800000 }, \"grade\": \"A\", \"score\": 2 },\n { \"date\": { \"$date\": 1299715200000 }, \"grade\": \"B\", \"score\": 14 }\n  ],\n  \"name\": \"Morris Park Bake Shop\",\n  \"restaurant_id\": \"30075445\"\n}"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test' )\nclient[:restaurants].indexes.create_one( { 'address.coord' => '2dsphere' })"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new('mongodb://127.0.0.1:27017/test')\ncollection = client[:restaurants]\n\ncollection.find(\n    { 'address.coord' =>\n      { \"$near\" =>\n        { \"$geometry\" =>\n          { \"type\" => \"Point\",  \"coordinates\" => [ -73.96, 40.78 ] },\n            \"$maxDistance\" => 500\n        }\n      }\n    }\n  ).each do |doc|\n\n    #=> Yields a BSON::Document.\n\n  end"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new('mongodb://127.0.0.1:27017/test')\ncollection = client[:restaurants]\n\ncollection.find(\n    { \"address.coord\" =>\n      { \"$geoWithin\" =>\n       { \"$geometry\" =>\n             { \"type\" => \"Polygon\" ,\n            \"coordinates\" => [ [ [ -73, 40 ], [ -74, 41 ], [ -72, 39 ], [ -73, 40 ] ] ]\n          }\n        }\n      }\n    }\n  ).each do |doc|\n\n    #=> Yields a BSON::Document.\n\n  end"
                }
            ],
            "preview": "MongoDB offers a number of indexes and query mechanisms to handle\ngeospatial information. This section demonstrates how to create\nand use\ngeospatial indexes\nwith the Ruby driver.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/aggregation",
            "title": "Aggregation",
            "headings": [
                "The Aggregation Pipeline",
                "Single Purpose Aggregation Operations",
                "Count",
                "Distinct"
            ],
            "paragraphs": "Aggregation framework \noperations process data records and return\ncomputed results. Aggregation operations group values from\nmultiple documents together, and can perform a variety of\noperations on the grouped data to return a single result. The aggregation pipeline is a framework for data aggregation\nmodeled on the concept of data processing pipelines. Documents\nenter a multi-stage pipeline that transforms the documents into\naggregated results. For a full explanation and a complete list of pipeline stages\nand operators, see the\n manual . The following example uses the aggregation pipeline on the\n restaurants  sample dataset to find\na list of the total number of 5-star restaurants, grouped by restaurant\ncategory. Inside the  aggregate  method, the first pipeline stage filters out\nall documents except those with  5  in the  stars  field. The\nsecond stage unwinds the  categories  field, which is an array, and\ntreats each item in the array as a separate document. The third stage\ngroups the documents by category and adds up the number of matching\n5-star results. Aggregation pipeline stages have a\n maximum memory use limit .\nTo handle large datasets, set the  allowDiskUse  option to true to enable\nwriting data to temporary files. You can call the  allow_disk_use  method the  aggregation \nobject to get a new object with the option set: Or you can pass an option to the  aggregate  method: MongoDB provides helper methods for some aggregation functions,\nincluding  count \nand  distinct . The following example demonstrates how to use the  count  method to\nfind the total number of documents which have the exact array\n [ 'Chinese', 'Seafood' ]  in the  categories  field. The  distinct  helper method eliminates results which contain\nvalues and returns one record for each unique value. The following example returns a list of unique values for the\n categories  field in the  restaurants  collection:",
            "code": [
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test')\ncoll = client['restaurants']\naggregation = coll.aggregate([\n       { '$match'=> { 'stars'=> 5 } },\n       { '$unwind'=> '$categories'},\n       { '$group'=> { '_id'=> '$categories', 'fiveStars'=> { '$sum'=> 1 } } }\n    ])\n\naggregation.each do |doc|\n  #=> Yields a BSON::Document.\nend"
                },
                {
                    "lang": "ruby",
                    "value": "aggregation = coll.aggregate([ <aggregration pipeline expressions> ])\naggregation_with_disk_use = aggregation.allow_disk_use(true)"
                },
                {
                    "lang": "ruby",
                    "value": "aggregation = coll.aggregate([ <aggregration pipeline expressions> ],\n                              :allow_disk_use => true)"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test')\ncoll = client['restaurants']\naggregation = coll.count({ 'categories': [ 'Chinese', 'Seafood' ] })\n\ncount = coll.count({ 'categories' => [ 'Chinese', 'Seafood' ] })"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test')\ncoll = client['restaurants']\naggregation = coll.distinct('categories')\n\naggregation.each do |doc|\n  #=> Yields a BSON::Document.\nend"
                }
            ],
            "preview": "Aggregation framework\noperations process data records and return\ncomputed results. Aggregation operations group values from\nmultiple documents together, and can perform a variety of\noperations on the grouped data to return a single result.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/working-with-data",
            "title": "Working With Data",
            "headings": [],
            "paragraphs": "This section describes in detail the functionality that the Ruby driver\nimplements for inserting, updating and retrieving data from MongoDB.",
            "code": [],
            "preview": "This section describes in detail the functionality that the Ruby driver\nimplements for inserting, updating and retrieving data from MongoDB.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/connection-and-configuration",
            "title": "Connection & Configuration",
            "headings": [],
            "paragraphs": "This section describes how to create the client objects and what configuration\noptions the driver provides, including authentication.",
            "code": [],
            "preview": "This section describes how to create the client objects and what configuration\noptions the driver provides, including authentication.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/gridfs",
            "title": "GridFS",
            "headings": [
                "Creating a GridFS object (\"Grid::FSBucket\")",
                "Working with write streams",
                "Working with read streams",
                "Finding file metadata",
                "Deleting files",
                "Working with Grid::File objects",
                "Inserting Files",
                "Finding Files",
                "Deleting Files"
            ],
            "paragraphs": "The driver provides a clean and simple interface to work with storage of\nchunked files in the database, also known as the pattern \"GridFS\". The API allows you to either\nwork with Grid::File objects or with read and write streams. You can create a GridFS object by calling  fs  on a database, with optional\narguments.  fs  returns a  Grid::FSBucket  object. The options that  Grid::FSBucket  supports are: For example, you can create a GridFS bucket object with a particular read preference: Option Description :bucket_name The name of the GridFS Bucket. Default is  fs . :fs_name The name of the GridFS Bucket. Takes precedence over  bucket_name .\nDefault is  fs . :chunk_size Specifies the size of each file chunk in the database. :write_concern The write concern to use when uploading files. Please see the\n Write Concern  section under CRUD operations\nfor how to work with write concerns. :write Deprecated. Same as  :write_concern . :read The read preference to use when downloading files. To upload a file to GridFS using a write stream, you can either open a stream\nand write to it directly or write the entire contents of an  IO  object to\nGridFS all at once. To open an upload stream and write to it: To upload the entire contents of an IO object in one call: Write streams support the following options: The options can be provided as the last argument to the write stream methods: Option Description :chunk_size Specifies the size of each file chunk in the database. :write_concern The write concern to use when uploading files. Please see the\n Write Concern  section under CRUD operations\nfor how to work with write concerns. :write Deprecated. Same as  :write_concern . To download a file from GridFS using a read stream, you can either open a\nread stream and read from it directly or download the entire file all at once. To open a download stream and read from it: To download the file all at once and write it to an IO object: You can also download a file specified by a name and (optionally)\nrevision number. Revision numbers are used to distinguish between files\nsharing the same name, ordered by date of upload. The revision number passed to\n open_download_stream_by_name  can be positive or negative. To download the entire contents of the file specified by name and (optionally)\nrevision number: Read streams support the following options: Some, but not all, of the read methods listed above pass these options to\nthe underlying read streams. Please consult the API documentation for each\nmethod to determine whether it supports a particular option. Option Description :read The read preference to use when downloading files. You can retrieve documents containing metadata about files in the GridFS files collection. You can delete a file by id. This object can be used to wrap a file to be inserted into the database using\nGridFS and the object that is retrieved. To create a file with raw data: To create a file from a Ruby  File  object: To change file options such as chunk size, pass options to the constructor: The following is a full list of the available options that files support. Option Description :chunk_size Sets the size of each file chunk in the database. :content_type Set a content type for the file. :filename  (Required) The file name. :upload_date The date the file was uploaded (stored). Files can be inserted into the database one at a time. File chunks are inserted\nby default into the  fs.chunks  collection and file metadata is inserted into the\n fs.files  collection. To insert into collections with a name prefix other than  fs , access the\nfilesystem with a  :fs_name  option. When the driver is inserting the first file into a bucket, it will attempt to create the required\nindexes on  files  and  chunks  collections. The required indexes are as follows: Files can also be streamed as an alternative to a direct insert. If the indexes cannot be created, such as due to the current user lacking the permissions to do so,\nthe file insert will be aborted. If the application does not have permissions to create indexes,\na database administrator must create the required indexes ahead of time. If the bucket already has files, the driver will not attempt to create indexes, even if they are\nmissing and the current user has permissions to create them. In this case a database administrator\nshould create the needed indexes as soon as possible to ensure data integrity. To retrieve a file from the database, call  find_one  with the appropriate filter. Files can also be streamed as an alternative to a direct find. To delete a file, pass the file object to  delete_one .",
            "code": [
                {
                    "lang": "ruby",
                    "value": "fs_bucket = database.fs( read: { mode: :secondary } )"
                },
                {
                    "lang": "ruby",
                    "value": "File.open('/path/to/my-file.txt', 'r') do |file|\n  fs_bucket.open_upload_stream('my-file.txt') do |stream|\n    stream.write(file)\n  end\nend"
                },
                {
                    "lang": "ruby",
                    "value": "File.open('/path/to/my-file.txt', 'r') do |file|\n  fs_bucket.upload_from_stream('my-file.txt', file)\nend"
                },
                {
                    "lang": "ruby",
                    "value": "fs_bucket.open_upload_stream('my-file.txt', write_concern: {w: 2}) do |stream|\n  stream.write_concern\n  # => #<Mongo::WriteConcern::Acknowledged:0x46980201422160 options={:w=>2}>\n\n  # ...\nend\n\nfs_bucket.upload_from_stream('my-file.txt', file, write_concern: {w: 2})"
                },
                {
                    "lang": "ruby",
                    "value": "File.open('/path/to/my-output-file.txt', 'w') do |file|\n  fs_bucket.open_download_stream(file_id) do |stream|\n    file.write(stream.read)\n  end\nend"
                },
                {
                    "lang": "ruby",
                    "value": "File.open('/path/to/my-output-file.txt', 'w') do |file|\n  fs_bucket.download_from_stream(file_id, file)\nend"
                },
                {
                    "lang": "ruby",
                    "value": "File.open('/path/to/my-output-file.txt', 'w') do |file|\n  fs_bucket.open_download_stream_by_name('my-file.txt', revision: -2) do |stream|\n    file.write(stream.read)\n  end\nend"
                },
                {
                    "lang": "ruby",
                    "value": "File.open('/path/to/my-output-file.txt', 'w') do |file|\n  fs_bucket.download_to_stream_by_name('my-file.txt', file, revision: -2)\nend"
                },
                {
                    "lang": "ruby",
                    "value": "fs_bucket.find(filename: 'my-file.txt')"
                },
                {
                    "lang": "ruby",
                    "value": "fs_bucket.delete(file_id)"
                },
                {
                    "lang": "ruby",
                    "value": "file = Mongo::Grid::File.new('I am a file', :filename => 'new-file.txt')"
                },
                {
                    "lang": "ruby",
                    "value": "file = File.open('/path/to/my-file.txt')\ngrid_file = Mongo::Grid::File.new(file.read, :filename => File.basename(file.path))"
                },
                {
                    "lang": "ruby",
                    "value": "file = File.open('/path/to/my-file.txt')\ngrid_file = Mongo::Grid::File.new(\n  file.read,\n  :filename => File.basename(file.path),\n  :chunk_size => 1024\n)"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\nfile = Mongo::Grid::File.new('I am a file', :filename => 'new-file.txt')\n\nclient.database.fs.insert_one(file)"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\nfile = Mongo::Grid::File.new('I am a file', :filename => 'new-file.txt')\n\nclient.database.fs(:fs_name => 'grid').insert_one(file)"
                },
                {
                    "lang": "ruby",
                    "value": "# files collection\n{ :filename => 1, :uploadDate => 1 }\n\n# chunks collection\n{ :files_id => 1, :n => 1 }, { :unique => true }"
                },
                {
                    "lang": "ruby",
                    "value": "client.database.fs.open_upload_stream(filename) do |stream|\n  stream.write(file)\nend"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\nclient.database.fs.find_one(:filename => 'new-file.txt') # Returns a Mongo::Grid::File"
                },
                {
                    "lang": "ruby",
                    "value": "client.database.fs.open_download_stream(file_id) do |stream|\n  io.write(stream.read)\nend\n\nfs.download_to_stream(file_id, io)"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'music')\nfs = client.database.fs\nfile = fs.find_one(:filename => 'new-file.txt')\nfs.delete_one(file)"
                }
            ],
            "preview": "The driver provides a clean and simple interface to work with storage of\nchunked files in the database, also known as the pattern \"GridFS\". The API allows you to either\nwork with Grid::File objects or with read and write streams.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "reference/create-client",
            "title": "Creating a Client",
            "headings": [
                "Using Mongo::Client",
                "Block Syntax",
                "Database Selection",
                "Connection Types",
                "Standalone Server Connection",
                "Replica Set Connection",
                "Sharded Cluster Connection",
                "Direct Connection",
                "Load Balancer Connection",
                "SRV URI Notes",
                "Client Options",
                "Ruby Options",
                "URI Options",
                "Timeout Options",
                "server_selection_timeout",
                "socket_timeout",
                "connect_timeout",
                "wait_queue_timeout",
                "max_time_ms",
                "wtimeout",
                "TLS Connections",
                "TLS vs SSL Option Names",
                "Enable TLS Connections",
                "Specify Client TLS Certificate",
                "Modifying SSLContext",
                "Using Intermediate Certificates",
                "Specify CA Certificate",
                "Specifying Multiple CA Certificates",
                "OCSP Verification",
                "IPv4/IPv6 Connections",
                "TCP Keepalive Configuration",
                "Connection Pooling",
                "Usage with Forking Servers",
                "Reconnecting Client Instances",
                "Troubleshooting",
                "Retryable Reads",
                "Modern Retryable Reads",
                "Legacy Retryable Reads",
                "Disabling Retryable Reads",
                "Retryable Writes",
                "Modern Retryable Writes",
                "Legacy Retryable Writes",
                "Disabling Retryable Writes",
                "Logging",
                "Changing the Logger Level",
                "Truncation",
                "Compression",
                "Server API Parameters",
                "Development Configuration",
                "Production Configuration"
            ],
            "paragraphs": "To connect to a MongoDB deployment, create a  Mongo::Client  object.\nProvide a list of hosts and options or a  connection string URI  to the``Mongo::Client`` constructor.\nThe client's selected database defaults to  admin . By default, the driver will automatically detect the topology used by the\ndeployment and connect appropriately. To connect to a local standalone MongoDB deployment, specify the host and\nport of the server. In most cases you would also specify the database name\nto connect to; if no database name is specified, the client will use the\n admin  database: To  connect to MongoDB Atlas ,\nspecify the Atlas deployment URI: The driver will discover all nodes in the cluster and connect to them as\nneeded. The hostname  localhost  is treated specially by the driver and will\nbe resolved to IPv4 addresses only. Another way to create a Mongo::Client object is to use the block syntax: Note that when creating a client using this syntax, the client is automatically closed after the block finishes executing. By default, the client will connect to the  admin  database. The  admin  database is a special database in MongoDB often used for\nadministrative tasks and storing administrative data such as users and\nroles (although users and roles may also be defined in other databases).\nIn a sharded cluster, the  admin  database\n exists on the config servers \nrather than the shard servers. Although it is possible to use the  admin \ndatabase for ordinary operations (such as storing application data), this\nis not recommended and the application should explicitly specify the\ndatabase it wishes to use. The database can be specified during  Client  construction: Given a  Client  instance, the  use  method can be invoked to obtain a\nnew  Client  instance configured with the specified database: There are other special databases in MongoDB which should be only used for\ntheir stated purposes: The  config  database. The  local  database. The  $external  database, which is used with  PLAIN ,\n Kerberos  and  X.509  authentication\nmechanisms. The driver will, by default, discover the type of deployment it is instructed\nto connect to (except for load-balanced deployments)\nand behave in the manner that matches the deployment type.\nThe subsections below describe how the driver behaves in each of the deployment\ntypes as well as how to force particular behavior, bypassing automatic\ndeployment type detection. Note that the detection of deployment type happens when the driver receives\nthe first reply from any of the servers it is instructed to connect to\n(unless the load-balancing mode is requested, see below). The driver will\nremain in the discovered or configured topology even if the underlying\ndeployment is replaced by one of a different type. In particular, when\nreplacing a replica set with a sharded cluster at the same address\nthe client instance must be recreated (such as by restarting the application)\nfor it to communicate with the sharded cluster. Automatic discovery of load-balanced deployments is currently not supported.\nLoad-balanced deployments will be treated as deployments of their underlying\ntype, which would generally be sharded clusters. The driver will fail to\ncorrectly operate when treating a load-balanced deployment as a sharded\ncluster, therefore when the deployment is a load-balanced one the client\nmust be explicitly configured to  connect to a load balancer . If the deployment is a single server, also known as a standalone deployment,\nall operations will be directed to the specified server. If the server is shut down and replaced by a replica set node, the driver\nwill continue sending all operations to that node, even if the node is or\nbecomes a secondary. To force a standalone connection, see the  direct connection  section below. When connecting to a  replica set , it is sufficient\nto pass the address of any node in the replica set to the driver.\nThe node does not have to be the primary and it may be a hidden node.\nThe driver will then automatically discover the remaining nodes. However, it is recommended to specify all nodes that are part of the\nreplica set, so that in the event of one or more nodes being unavailable\n(for example, due to maintenance or reconfiguration) the driver can still\nconnect to the replica set. Replica set connection examples: To make the driver verify the replica set name upon connection, pass it using\nthe  replica_set  Ruby option or the  replicaSet  URI option: If the deployment is not a replica set or uses a different replica set name,\nall operations will fail (until the expected replica set is returned by\nthe servers). It is also possible to force a replica set connection without specifying\nthe replica set name. Doing so is generally unnecessary and is deprecated: To connect to a MongoDB Atlas cluster which is deployed as a replica set,\nconnect to the URI: Please review the  SRV URI notes  if using SRV URIs. To connect to a  sharded cluster  deployment, specify\nthe addresses of the  mongos  routers: Note that unlike a replica set connection, you may choose to connect to a\nsubset of the  mongos  routers that exist in the deployment. The driver\nwill monitor each router and will use the ones that are available\n(i.e., the driver will generally handle individual routers becoming\nunavailable due to failures or maintenance). When specifying the list of\nrouters explicitly, the driver will not discover remaining routers that\nmay be configured and will not attempt to connect to them. The driver will automatically balance the operation load among the routers\nit is aware of. To connect to a MongoDB Atlas cluster which is deployed as a sharded cluster,\nconnect to the URI: When the driver connects to a sharded cluster via an SRV URI, it will\nperiodically poll the SRV records of the address specified in the URI\nfor changes and will automatically add and remove the  mongos  hosts\nto/from its list of servers as they are added and removed to/from the\nsharded cluster. To force a sharded cluster connection, use the  connect: :sharded \noption. Doing so is generally unnecessary and is deprecated: Please review the  SRV URI notes  if using SRV URIs. To disable the deployment type discovery and force all operations to be\nperformed on a particular server, specify the  direct_connection  option: Alternatively, the deprecated  connect: :direct  option is equivalent: The direct connection mode is most useful for performing operations on a\nparticular replica set node, although it also permits the underlying server\nto change type (e.g. from a replica set node to a  mongos  router, or vice\nversa). Unlike other deployment types, the driver does not currently automatically\ndetect a load-balanced deployment. To connect to a load balancer, specify the  load_balanced: true  Ruby option\nor the  loadBalanced=true  URI option: When using these options, if the specified server is not a load balancer,\nthe client will fail all operations (until the server becomes a load balancer). To treat the server as a load balancer even if it doesn't identify as such,\nuse the  connect: :load_balanced  Ruby option or the  connect=load_balanced \nURI option: When the driver connects to a\n mongodb+srv protocol \nURI, keep in mind the following: SRV URI lookup is performed synchronously when the client is constructed.\nIf this lookup fails for any reason, client construction will fail with an\nexception. When a client is constructed with a list of hosts, the driver\nwill attempt to contact and monitor those hosts for as long as the client\nobject exists. If one of these hosts does not resolve initially but becomes\nresolvable later, the driver will be able to establish a connection to such\na host when it becomes available. The initial SRV URI lookup must succeed\non the first attempt; subsequent host lookups will be retried by the driver\nas needed. The driver looks up URI options in the DNS TXT records corresponding to the\nSRV records. These options can be overridden by URI options specified in the\nURI and by Ruby options, in this order. Because the URI options are retrieved in a separate DNS query from the\nSRV lookup, in environments with unreliable network connectivity\nthe URI option query may fail when the SRV lookup succeeds. Such a failure\nwould cause the driver to use the wrong auth source leading to\nauthentication failures. This can be worked around by explicitly specifying\nthe auth source: If the topology of the constructed  Client  object is unknown or a\nsharded cluster, the driver will begin monitoring the specified SRV DNS\nrecords for changes and will automatically update the list of servers in the\ncluster. The updates will stop if the topology becomes a single or a replica\nset. Mongo::Client 's constructor accepts a number of options configuring the\nbehavior of the driver. The options can be provided in the options hash as\nRuby options, in the URI as URI options, or both. If both a Ruby option and\nthe analogous URI option are provided, the Ruby option takes precedence. The options passed directly should be symbols. Unless otherwise specified, Ruby options that deal with times are given in\nseconds. Option Description Type Default :app_name Application name that is printed to the mongod logs upon establishing a connection\nin server versions >= 3.4. String none :auth_mech Specifies the authenticaion mechanism to use. Can be one of:\n :gssapi ,  :mongodb_cr ,  :mongodb_x509 ,  :plain ,\n :scram ,  :scram256 . GSSAPI (Kerberos) authentication\n requires additional dependencies . Symbol If user credentials are not supplied,  nil . If user credentials\nare supplied, the default depends on server version.\nMongoDB 4.0 and later:  :scram256  if user credentials correspond\nto a user which supports SCRAM-SHA-256 authentication, otherwise\n :scram .\nMongoDB 3.0-3.6:  :scram .\nMongoDB 2.6:  :mongodb_cr :auth_mech_properties Provides additional authentication mechanism properties. The keys in properties are interpreted case-insensitively.\nWhen the client is created, keys are lowercased. Hash When using the GSSAPI authentication mechanism, the default properties\nare  {service_name: \"mongodb\"} . Otherwise the default is nil. :auth_source Specifies the authentication source. String For MongoDB 2.6 and later:  admin  if credentials are\nsupplied, otherwise the current database :auto_encryption_options A  Hash  of options for configuring automatic encryption. For more information about formatting these options, see the\n\"Auto-Encryption Options\" section of the  Client-Side Encryption tutorial . :key_vault_client  - A client connected to the MongoDB instance\nstoring the encryption data keys ( Mongo::Client , defaults to the\ntop-level client instance). :key_vault_namespace  - The namespace of the key vault collection\nin the format  \"database.collection\"  ( String , required). :kms_providers  - Key management service configuration information.\nOne or both of the keys  :local  and  :aws  must be specified\n( Hash , required). See the \"The  kms_providers  option`` section of the\n Client-Side Encryption tutorial  for more\ninformation about this option. :schema_map  - The JSONSchema for one or more collections specifying\nwhich fields should be encrypted ( Hash , optional, defaults to  nil ). :bypass_auto_encryption  - Whether to skip automatic encryption when\nperforming database operations ( Boolean , defaults to  false ). :extra_options  - Options related to spawning mongocryptd ( Hash ,\noptional, defaults to  nil ). Hash none :bg_error_backtrace Experimental. Controls whether and how backtraces are logged when\nerrors occur in background threads. If  true , the driver will log\ncomplete backtraces. If set to a positive integer, the driver will\nlog up to that many backtrace lines. If set to  false  or  nil ,\nno backtraces will be logged. Other values are an error. true ,  false ,  nil ,  Integer none :compressors A list of potential compressors to use, in order of preference.\nPlease see below for details on how the driver implements compression. Array<String> none :connect Deprecated.  Disables deployment topology discovery normally\nperformed by the dirver and forces the cluster topology to a specific\ntype. Valid values are  :direct ,  :load_balanced ,\n :replica_set  or  :sharded . If  :load_balanced  is used,\nthe client will behave as if it is connected to a load balancer\nregardless of whether the server(s) it connects to advertise themselves\nas load balancers. Symbol none :connect_timeout The number of seconds to wait to establish a socket connection\nbefore raising an exception. This timeout is also used for SRV DNS\nrecord resolution.  nil  and  0  mean no timeout.\nClient creation will fail with an error if an invalid timeout value\nis passed (such as a negative value or a non-numeric value). Float 10 :database The name of the database to connect to. String admin :direct_connection Connect directly to the specified host, do not discover deployment\ntopology. Boolean false :heartbeat_frequency The number of seconds for the server monitors to refresh\nserver states asynchronously. Float 10 :id_generator A custom object to generate ids for documents. Must respond to #generate. Object none :load_balanced Whether to expect to connect to a load balancer. Boolean false :local_threshold Specifies the maximum latency in seconds between the nearest\nserver and the servers that can be available for selection to operate on. Float 0.015 :logger A custom logger. Object Logger :max_idle_time The maximum time, in seconds, that a connection can be idle before it\nis closed by the connection pool. Warning:  when connected to a load balancer, the driver uses existing\nconnections for iterating cursors (which includes change streams)\nand executing transactions. Setting an idle time via this option may\ncause the driver to close connections that are needed for subsequent\noperations, causing those operations to fail. Integer none :max_pool_size The maximum size of the connection pool for each server. Integer 5 :max_read_retries The maximum number of read retries, when legacy read retries are used.\nSet to 0 to disable legacy read retries. Integer 1 :max_write_retries The maximum number of write retries, when legacy write retries are used.\nSet to 0 to disable legacy write retries. Integer 1 :min_pool_size The minimum number of connections in the connection pool for each\nserver. The driver does not create connections eagerly - a connection\nis only created when a MongoDB operation is to be executed and there\nare no available connections, and the total number of established\nconnections to the target server is below  :max_pool_size .\nHowever, once connections to a particular server are created, up to\n :min_pool_size  connections will be kept in the connection pool\nby the driver. Integer 0 :monitoring The monitoring object. Object none :password The password of the user to authenticate with. String none :platform Platform information to include in the metadata printed to the mongod logs upon establishing a\nconnection in server versions >= 3.4. String none :read Specifies the read preference mode and tag sets for selecting servers\nas a  Hash . Allowed Keys in the hash are  :mode ,  :tag_sets  and\n :max_staleness . If tag sets are provided, they must be an array of hashes. A server\nsatisfies the read preference if its tags match any one hash in the\nprovided tag sets. Each tag set must be a hash, and will be converted internally to\na  BSON::Document  instance prior to being used for server selection.\nHash keys can be strings or symbols. The keys are case sensitive.\nHash values must be strings, and are matched exactly against the values\nin the replica set configuration. Hash { :mode => :primary } :read_concern Specifies the read concern options. The only valid key is  level , for which the valid\nvalues are  :local ,  :majority , and  :snapshot . Hash none :read_retry_interval The interval, in seconds, in which reads on a mongos are retried. Integer 5 :replica_set When connecting to a replica set, this is the name of the set to\nfilter servers by. String none :retry_writes If a single-statement write operation fails from a network error, the driver automatically retries it once\nwhen connected to server versions 3.6+. Boolean true :sdam_proc Since the client begins monitoring the deployment in background as\nsoon as it is constructed, constructing a client and then subscribing\nto  SDAM  events in a separate statement may result in the\nsubscriber not receiving some of the SDAM events. The  :sdam_proc \noption permits adding event subscribers on the client being constructed\nbefore any SDAM events are published. Pass a  Proc  which will be called with the  Client  as the argument\nafter the client's event subscription mechanism has been initialized\nbut before any of the servers are added to the client. Use this\n Proc  to set up SDAM event subscribers on the client. Note: the client is not fully constructed when the  Proc  provided in\n :sdam_proc is invoked, in particular the cluster is nil at this time.\n``:sdam_proc  procedure should limit itself to calling\n Client#subscribe  and  Client#unsubscribe  methods on on the\npassed client only. Proc none :server_api The server API version requested.\nThis is a hash with the following allowed items:\n-  :version  (String)\n-  :strict  (true or false)\n-  :deprecation_errors  (true or false) Note that the server API version can only be specified as a Ruby option,\nnot as a URI option, and it cannot be overridden for database and\ncollection objects. If server API version is changed on a client (such as via the  with \ncall), the entire API version hash is replaced with the new specification\n(the old and the new individual fields are NOT merged). Hash none :server_selection_timeout The number of seconds to wait for an appropriate server to\nbe selected for an operation to be executed before raising an exception. Float 30 :socket_timeout The number of seconds to wait for an operation to execute on a\nsocket before raising an exception.  nil  and  0  mean no timeout.\nClient creation will fail with an error if an invalid timeout value\nis passed (such as a negative value or a non-numeric value). Float none :ssl Tell the client to connect to the servers via TLS. Boolean false :ssl_ca_cert The file path containing concatenated certificate authority certificates\nused to validate certs passed from the other end of the connection.\nOne of  :ssl_ca_cert ,  :ssl_ca_cert_string  or  :ssl_ca_cert_object \n(in order of priority) is required for  :ssl_verify . String none :ssl_ca_cert_object An array of OpenSSL::X509::Certificate representing the certificate\nauthority certificates used to validate certs passed from the other end\nof the connection. One of  :ssl_ca_cert ,  :ssl_ca_cert_string  or\n :ssl_ca_cert_object  (in order of priority) is required for  :ssl_verify . Array< OpenSSL::X509::Certificate > none :ssl_ca_cert_string A string containing concatenated certificate authority certificates\nused to validate certs passed from the other end of the connection.\nOne of  :ssl_ca_cert ,  :ssl_ca_cert_string  or  :ssl_ca_cert_object \n(in order of priority) is required for  :ssl_verify . String none :ssl_cert Path to the client certificate file used to identify the application to\nthe MongoDB servers. The file may also contain the certificate's private\nkey; if so, the private key is ignored by this option. The file may\nalso contain intermediate certificates forming the certificate chain\nfrom the client certificate to the CA certificate; any intermediate\ncertificates will be parsed by the driver and provided to the OpenSSL\ncontext in  extra_chain_cert  attribute. If intermediate certificates\nare provided, they must follow the client certificate which must be\nthe first certificate in the file. This option, if present, takes precedence over  :ssl_cert_string  and\n :ssl_cert_object  options. String none :ssl_cert_object The OpenSSL::X509::Certificate used to identify the application to\nthe MongoDB servers. Only one certificate may be passed through this\noption. OpenSSL::X509::Certificate none :ssl_cert_string A string containing the PEM-encoded certificate used to identify the\napplication to the MongoDB servers. The string may also contain the\ncertificate's private key; if so, the private key is ignored by this\noption. The string may also contain intermediate certificates forming\nthe certificate chain from the client certificate to the CA certificate;\nany intermediate certificates will be parsed by the driver and provided\nto the OpenSSL context in  extra_chain_cert  attribute. If intermediate\ncertificates are provided, they must follow the client certificate which\nmust be the first certificatet in the string. This option, if present, takes precedence over the  :ssl_cert_object \noption. String none :ssl_key The private keyfile used to identify the connection against MongoDB. Note that even if the key is stored in\nthe same file as the certificate, both need to be explicitly specified. This option, if present, takes\nprecedence over the values of :ssl_key_string and :ssl_key_object. String none :ssl_key_object The private key used to identify the connection against MongoDB. OpenSSL::PKey none :ssl_key_pass_phrase A passphrase for the private key. String none :ssl_key_string A string containing the PEM-encoded private key used to identify the\nconnection against MongoDB. This parameter, if present, takes precedence\nover the value of option :ssl_key_object. String none :ssl_verify Whether to perform peer certificate, hostname and OCSP endpoint\nvalidation. Note that the decision of whether to validate certificates\nwill be overridden if  :ssl_verify_certificate  is set, the decision\nof whether to validate hostnames will be overridden if\n :ssl_verify_hostname  is set and the decision of whether to validate\nOCSP endpoint will be overridden if  :ssl_verify_ocsp_endpoint  is set. Boolean true :ssl_verify_certificate Whether to perform peer certificate validation. This setting overrides\nthe  :ssl_verify  setting with respect to whether certificate\nvalidation is performed. Boolean true :ssl_verify_hostname Whether to perform peer hostname validation. This setting overrides\nthe  :ssl_verify  setting with respect to whether hostname validation\nis performed. Boolean true :ssl_verify_ocsp_endpoint Whether to validate server-supplied certificate against the OCSP\nendpoint specified in the certificate, if the OCSP endpoint is specified\nin the certificate. This setting overrides :ssl_verify with respect to\nwhether OCSP endpoint validation is performed. Boolean true :truncate_logs Whether to truncate the logs at the default 250 characters. Boolean true :user The name of the user to authenticate with. String none :wait_queue_timeout The number of seconds to wait for a connection in the connection\npool to become available. Float 10 :wrapping_libraries Information about libraries such as ODMs that are wrapping the driver.\nSpecify the lower level libraries first. Allowed hash keys: :name,\n:version, :platform. Example:  [name: 'Mongoid', version: '7.1.2'] Array<Hash> none :write Deprecated. Equivalent to  :write_concern  option. If both  :write \nand  :write_concern  are specified, their values must be identical. Hash { w: 1 } :write_concern Specifies write concern options as a  Hash .\nKeys in the hash can be  :w ,  :wtimeout ,  :j ,  :fsync .\nNote that  :wtimeout  is specified in milliseconds, not seconds. Hash { w: 1 } :zlib_compression_level The Zlib compression level to use, if using compression. See Ruby's Zlib module for valid levels. Integer none The Ruby driver does not implement certificate revocation list (CRL)\nchecking. Since the URI options are required to be in camel case, which is not the Ruby\nstandard, the following table shows URI options and their corresponding Ruby\noptions. URI options are explained in detail in the  Connection URI reference . Options that are set in  milliseconds  in the URI are\nrepresented as a  float  in Ruby and the units are  seconds . URI Option Ruby Option appName=String :app_name => String authMechanism=String :auth_mech => Symbol Auth mechanism values are converted as follows from URI options to\nRuby options: If a different value is provided for auth mechanism, it is converted\nto the Ruby option unmodified and retains its  String  type.\nNote that, while currently the driver allows a  Client  instance\nto be constructed with an unrecognized auth mechanism, this behavior\n may change in a future version of the driver . GSSAPI  =>  :gssapi MONGODB-CR  =>  :mongodb_cr MONGODB-X509  =>  :mongodb_x509 PLAIN  =>  :plain SCRAM-SHA-1  =>  :scram SCRAM-SHA-256  =>  :scram256 authMechanismProperties=Strings { :auth_mech_properties => { :service_realm => String, :canonicalize_host_name => true|false, :service_name => String } } Specified as comma-separated key:value pairs, e.g.  \"SERVICE_REALM:foo,CANONICALIZE_HOST_NAME:TRUE\" . authSource=String :auth_source => String compressors=Strings :compressors => Array<String> A comma-separated list of potential compressors to use, in order of\npreference. Please see below for details on how the driver implements\ncompression. connect=String :connect => Symbol The same values that the  :connect  Ruby option accepts are\naccepted here. For multi-word values, the values must be provided\nusing underscores to separate the words, i.e.\n connect=replica_set  and  connect=load_balanced . connectTimeoutMS=Integer :connect_timeout => Float Unlike the corresponding Ruby option which fails client creation on\ninvalid values (e.g. negative and non-numeric values), invalid values\nprovided via this URI option are ignored with a warning. directConnection=Boolean :direct_connection => Boolean fsync=Boolean { :write_concern => { :fsync => true|false }} heartbeatFrequencyMS=Integer :heartbeat_frequency => Float journal=Boolean { :write_concern => { :j => true|false }} loadBalanced=Boolean :load_balanced => Boolean localThresholdMS=Integer :local_threshold => Float maxIdleTimeMS=Integer :max_idle_time => Float maxStalenessSeconds=Integer { :read => { :max_staleness => Integer }} If the maxStalenessSeconds URI option value is -1, the driver treats\nthis as if the option was not given at all. Otherwise,\nif the option value is numeric, the Ruby option is set to the\nspecified value converted to an  Integer .\nNote that numeric values greater than 0 but less than 90, or less than\n-1, are accepted by the  Client  constructor but will cause server\nselection to fail (unless the option is changed via, for example, the\n with  method prior to any operations being performed on the driver).\nIf the option value is non-numeric, it is ignored and the driver\ntreats this case as if the option was not given at all. maxPoolSize=Integer :max_pool_size => Integer minPoolSize=Integer :min_pool_size => Integer readConcernLevel=String :read_concern => Hash readPreference=String { :read => { :mode => Symbol }} readPreferenceTags=Strings { :read => { :tag_sets => Array<Hash> }} Each instance of the readPreferenceTags field is a comma-separated key:value pair which will appear in the :tag_sets array in the order they are specified. For instance,  \"readPreferenceTags=dc:ny,rack:1&readPreferenceTags=dc:ny\"  will be converted to  [ { 'dc' => 'ny', 'rack' => '1' }, { 'dc' => 'ny' }] . replicaSet=String :replica_set => String retryWrites=Boolean :retry_writes => boolean serverSelectionTimeoutMS=Integer :server_selection_timeout => Float socketTimeoutMS=Integer :socket_timeout => Float Unlike the corresponding Ruby option which fails client creation on\ninvalid values (e.g. negative and non-numeric values), invalid values\nprovided via this URI option are ignored with a warning. ssl=Boolean :ssl => true|false tls=Boolean :ssl => boolean tlsAllowInvalidCertificates=Boolean :ssl_verify_certificate => boolean Because  tlsAllowInvalidCertificates  uses  true  to signify that\nverification should be disabled and  ssl_verify_certificate  uses\n false  to signify that verification should be disabled, the boolean\nis inverted before being used to set  ssl_verify_certificate . tlsAllowInvalidHostnames=Boolean :ssl_verify_hostname => boolean Because  tlsAllowInvalidHostnames  uses  true  to signify that\nverification should be disabled and  ssl_verify_hostname  uses\n false  to signify that verification should be disabled, the boolean\nis inverted before being used to set  ssl_verify_hostname . tlsCAFile=String :ssl_ca_cert => String tlsCertificateKeyFile=String :ssl_cert => String tlsCertificateKeyFile=String :ssl_key => String tlsCertificateKeyFilePassword=String :ssl_key_pass_phrase => String tlsDisableOCSPEndpointCheck=Boolean :ssl_verify_ocsp_endpoint => boolean Because  tlsDisableOCSPEndpointCheck  uses  true  to signify that\nverification should be disabled and  ssl_verify_ocsp_endpoint  uses\n false  to signify that verification should be disabled, the boolean\nis inverted before being used to set  ssl_verify_ocsp_endpoint . tlsInsecure=Boolean :ssl_verify => boolean Because tlsInsecure uses  true  to signify that verification should\nbe disabled and  ssl_verify  uses  false  to signify that\nverification should be disabled, the boolean is inverted before being\nused to set  ssl_verify . w=Integer|String { :write_concern => { :w => Integer|String }} waitQueueTimeoutMS=Integer :wait_queue_timeout => Float wtimeoutMS=Integer { :write_concern => { :wtimeout => Integer }} zlibCompressionLevel=Integer :zlib_compression_level => Integer The Ruby driver only fails connections when it receives a definitive signed\nresponse indicating that the server's certificate has been revoked.\nBecause of this, the driver does not recognize the\n tlsDisableCertificateRevocationCheck  URI option. If this option is\nprovided in a URI, it will be ignored. When executing an operation, the number of seconds to wait for the driver\nto find an appropriate server to send an operation to. Defaults to 30. A value of 0 means no timeout. When an invalid value (e.g. a negative value or a non-numeric value) is passed\nvia the URI option, the invalid input is ignored with a warning. When an\ninvalid value is passed directly to Client via a Ruby option, Client\nconstruction fails with an error. In replica set deployments, this timeout should be set to exceed the typical\n replica set election times \nin order for the driver to transparently handle primary changes. This timeout\nalso allows the application and the database to be started simultaneously;\nthe application will wait up to this much time for the database to become\navailable. If the application server is behind a reverse proxy, server selection timeout\nshould be lower than the request timeout configured on the reverse proxy (for\nexample, this applies to deployments on Heroku which has a fixed 30 second\ntimeout in the routing layer). In development this value can be lowered to\nprovide quicker failure when the server is not running. The number of seconds to wait for a socket read or write to complete on\nregular (non-monitoring) connections. Default is no timeout. A value of 0 means no timeout. When an invalid value (e.g. a negative value or a non-numeric value) is passed\nvia the URI option, the invalid input is ignored with a warning. When an\ninvalid value is passed directly to Client via a Ruby option, Client\nconstruction fails with an error. This timeout should take into account both network latency and operation\nduration. For example, setting this timeout to 5 seconds will abort queries\ntaking more than 5 seconds to execute on the server with  Mongo::Error::SocketTimeoutError . Note that even though by default there is no socket timeout set, the\noperating system may still time out read operations depending on its\nconfiguration. The keepalive settings are intended to detect broken network\nconnections (as opposed to aborting operations simply because they take a\nlong time to execute). Note that if an operation is timed out by the driver due to exceeding the\n socket_timeout  value, it is not aborted on the server. For this reason\nit is recommended to use  max_time_ms  option for potentially long running\noperations, as this will abort their execution on the server. This option does not apply to monitoring connections. The number of seconds to wait for a socket connection to be established to\na server. Defaults to 10. This timeout is also used as both connect timeout and socket timeout for\nmonitoring connections. When using a  mongodb+srv://  URI, this timeout is also used for SRV and TXT\nDNS lookups. Note that the timeout applies per lookup; due to DNS suffix search\nlists, multiple lookups may be performed as part of a single name resolution. The number of seconds to wait for a connection in the connection pool to\nbecome available. Defaults to 10. As of driver version 2.11, this timeout should be set to a value at least\nas large as  connect_timeout  because connection pool now fully establishes\nconnections prior to returning them, which may require several network\nround trips. Specified as an option on a particular operation, the number of milliseconds\nto allow the operation to execute for on the server. Not set by default. Consider using this option instead of a  socket_timeout  for potentially\nlong running operations to be interrupted on the server when they take too\nlong. The number of milliseconds to wait for a write to be acknowledged by the\nnumber of servers specified in the write concern. Not set by default, which\ninstructs the server to apply its default. This option can be set globally\non the client or passed to individual operations under  :write_concern . To connect to the MongoDB deployment using TLS: Enable TLS connections in  Mongo::Client . Specify the client TLS certificate. Specify the CA certificate to verify the server's TLS certificate. When using JRuby, ECDSA certificates are not currently supported. All MongoDB server versions supported by the Ruby driver (2.6 and higher)\nonly implement TLS. 2.6 and higher servers do not use SSL. For historical reasons, the Ruby option names pertaining to TLS configuration\nuse the  ssl  rather than the  tls  prefix. The next major version of\nthe Ruby driver (3.0) will use the  tls  prefix for Ruby option names. The URI option names use the  tls  prefix, with one exception: there is\na  ssl  URI option that is deprecated and equivalent to the  tls  URI\noption. TLS must be explicitly requested on the client side when the deployment\nrequires TLS connections - there is currently no automatic detection of\nwhether the deployment requires TLS. To request TLS connections, specify the following client options when\nconstructing a  Mongo::Client : The  :ssl  Ruby option. The  tls  URI option. The  ssl  URI option (deprecated). By default, MongoDB server will attempt to verify the connecting clients'\nTLS certificates, which requires the clients to specify their TLS certificates\nwhen connecting. This can be accomplished via: When using the Ruby options, the client TLS certificate and the corresponding\nprivate key may be provided separately. For example, if the certificate is\nstored in  client.crt  and the private key is stored in  client.key ,\na  Mongo::Client  may be constructed as follows: ssl_cert ,  ssl_cert_string ,  ssl_key  and  ssl_key_string  Ruby\noptions also permit the certificate and the key to be provided in the same\nfile or string, respectively. The files containing both certificate and\nprivate key frequently have the  .pem  extension. When both certificate\nand the private key are provided in the same file or string, both the\ncertifcate and the key options must be utilized, as follows: When using the URI option, the certificate and the key must be stored in a\nfile and both must be stored in the same file. Example usage: The  :ssl_cert / :ssl_cert_object / :ssl_cert_string  and\n :ssl_key / :ssl_key_object / :ssl_key_string / :ssl_key_pass_phrase \nRuby options. The  tlsCertificateKeyFile  URI option. URI option values must be properly URI escaped. This applies, for example, to\nslashes in the paths. It may be desirable to further configure TLS options in the driver, for example\nby enabling or disabling certain ciphers. Currently, the Ruby driver does not\nprovide a way to do this when initializing a  Mongo::Client . However, the Ruby driver provides a way to set global \"TLS context hooks\" --\nthese are user-provided  Proc``s that will be invoked before any TLS socket\nconnection and can be used to modify the underlying ``OpenSSL::SSL::SSLContext \nobject used by the socket. To set the TLS context hooks, add  Proc``s to the ``Mongo.tls_context_hooks \narray. This should be done before creating any Mongo::Client instances.\nFor example, in a Rails application this code could be placed in an initializer. Every  Proc  in  Mongo.tls_context_hooks  will be passed an\n OpenSSL::SSL::SSLContext  object as its sole argument. These  Proc``s will\nbe executed sequentially during the creation of every ``Mongo::Socket::SSL  object. It is possible to assign the entire array of hooks calling  Mongo.tls_context_hooks= ,\nbut doing so will remove any previously assigned hooks. It is recommended to use\nthe  Array#push  or  Array#unshift  methods to add new hooks. It is also possible to remove hooks from  Mongo.tls_context_hooks  by storing\na reference to the Procs somewhere else in the application, and then using\n Array#delete_if  to remove the desired hooks. Further information on configuring MongoDB server for TLS is available in the\n MongoDB manual . TLS context hooks are global and will affect every instance of  Mongo::Client .\nAny library that allows applications to enable these hooks should expose methods to\nmodify the hooks (which can be called by the application) rather than\nautomatically enabling the hooks when the library is loaded. It is possible to use certificate chains for both the client and the server\ncertificates. When using chains, the certificate authority parameter should\nbe configured to contain the trusted root certificates only; the intermediate\ncertificates, if any, should be provided in the server or client certificates\nby concatenating them after the leaf server and client certificates, respectively. :ssl_cert  and  :ssl_cert_string  Ruby options, as well as\n tlsCertificateKeyFile  URI option, support certificate chains.\n :ssl_cert_object  Ruby option, which takes an instance of\n OpenSSL::X509::Certificate , does not support certificate chains. The Ruby driver performs strict X.509 certificate verification, which requires\nthat both of the following fields are set in the intermediate certificate(s): More information about these flags can be found  in this Stack Overflow question . It is a common pitfall to concatenate intermediate certificates to the root\nCA certificates passed in  tlsCAFile  /  ssl_ca_cert  options. By doing\nso, the intermediate certificates are elevated to trusted status and are\nthemselves not verified against the actual CA root. More information on this\nissue is available  in this mailing list post . X509v3 Basic Constraints: CA: TRUE -- Can sign certificates X509v3 Key Usage: Key Cert Sign -- Can sign certificates The driver will attempt to verify the server's TLS certificate by default, and\nwill abort the connection if this verification fails. By default, the driver\nwill use the default system root certificate store as the trust anchor.\nTo specify the CA certificate that the server's certificate is signed with,\nuse: If any of these options are given, the server's certificate will be verified\nonly against the specified CA certificate and the default system root\ncertificate store will not be used. To not perform server TLS certificate verification, which is not\nrecommended, specify the  ssl_verify: false  Ruby option or the\n tlsInsecure=true  URI option. The  :ssl_ca_cert / :ssl_ca_cert_string / :ssl_ca_cert_object \nRuby options The  tlsCAFile  URI option. The  :ssl_ca_cert  Ruby option and  tlsCAFile  URI option can be used with\na file containing multiple certificates. All certificates thus referenced\nwill become trust anchors. The  :ssl_ca_cert_object  option takes an array of certificates, and thus\ncan also be used to add multiple certificates as certificate authorities. The  :ssl_ca_cert_string  option supports specifying only one CA certificate. Intermediate certificates must not be provided in files specified by the\nCA certificate options. Doing so would elevate the intermediate certificates\nto the status of root certificates, rather than verifying intermediate\ncertificates against the root certificates. If intermediate certificates need to be used, specify them as part of the\nclient or server TLS certificate files. If the certificate provided by the server contains an OCSP endpoint URI,\nthe driver will issue an OCSP request to the specified endpoint to verify the\nvalidity of the certificate. The OCSP endpoint check may be disabled by setting the\n :ssl_verify_ocsp_endpoint  Ruby option to  false  or by setting the\n tlsDisableOCSPEndpointCheck  URI option to  true  when creating a client. OCSP endpoint checking is not currently performed when running on JRuby,\nsince JRuby does not correctly expose the OCSP endpoint URI. When a client is constructed with  localhost  as the host name, it will\nattempt an IPv4 connection only (i.e. if  localhost  resolves to\n 127.0.0.1  and  ::1 , the driver will only try to connect to\n 127.0.0.1 ). When a client is constructed with hostnames other than  localhost , it will\nattempt both IPv4 and IPv6 connections depending on the addresses that the\nhostnames resolve to. The driver respects the order in which  getaddrinfo \nreturns the addresses, and will attempt to connect to them sequentially.\nThe first successful connection will be used. The driver does not currently implement the Happy Eyeballs algorithm. Where allowed by system configuration and the Ruby language runtime,\nthe driver enables TCP keepalive and, for each of the keepalive parameters\nlisted below, sets the value of the respective parameter to the specified\nvalue if the system value can be determined and is higher than the\nlisted driver value: To use lower values, or to change the parameters in environments like JRuby\nthat do not expose the required APIs, please adjust the parameters at the\nsystem level as described in the  MongoDB Diagnostics FAQ keepalive section . tcp_keepalive_time : 120 seconds tcp_keepalive_intvl : 10 seconds tcp_keepalive_cnt : 9 probes As of JRuby 9.2.14.0, JRuby does not implement the APIs required to\nset the keepalive parameters. When using JRuby, the driver will not be\nable to set the keepalive parameters and the system configuration will\nbe in effect. Mongo::Client  instances have a connection pool per server that the client\nis connected to. The pool creates connections on demand to support concurrent\nMongoDB operations issued by the application. There is no thread-affinity\nfor connections. The client instance opens one additional connection per known server\nfor monitoring the server's state. The size of each connection pool is capped at  max_pool_size , which defaults\nto 5. When a thread in the application begins an operation on MongoDB, it tries\nto retrieve a connection from the pool to send that operation on. If there\nare some connections available in the pool, it checks out a connection from\nthe pool and uses it for the operation. If there are no connections available\nand the size of the pool is less than the  max_pool_size , a new connection\nwill be created. If all connections are in use and the pool has reached its\nmaximum size, the thread waits for a connection to be returned to the pool by\nanother thread. The number of seconds the thread will wait for a connection to become available\nis configurable. This setting, called  wait_queue_timeout , is defined in\nseconds. If this timeout is reached, a  Timeout::Error  is raised. The\ndefault is 1 second. As of driver version 2.11, the driver eagerly creates connections up to\n min_pool_size  setting. Prior to driver version 2.11, the driver always\ncreated connections on demand. In all versions of the driver, once a connection\nis established, it will be kept in the pool by the driver as long as the pool\nsize does not exceed  min_pool_size . Note that, if  min_pool_size  is set to a value greater than zero, the\ndriver will establish that many connections to secondaries in replica set\ndeployments even if the application does not perform secondary reads. The\npurpose of these connections is to provide faster failover when the primary\nchanges. Here is an example of estimating the number of connections a multi-threaded\napplication will open: A client connected to a 3-node replica set opens 3\nmonitoring sockets. It also opens as many sockets as needed to support a\nmulti-threaded application's concurrent operations on each server, up to\n max_pool_size . If the application only uses the primary (the default),\nthen only the primary connection pool grows and the total connections is at\nmost 8 (5 connections for the primary pool + 3 monitoring connections).\nIf the application uses a read preference to query the secondaries, their\npools also grow and the total connections can reach 18 (5 + 5 + 5 + 3). The default configuration for a  Mongo::Client  works for most applications: Create this client  once  for each process, and reuse it for all operations.\nIt is a common mistake to create a new client for each request, which is very\ninefficient and not what the client was designed for. To support extremely high numbers of concurrent MongoDB operations within one\nprocess, increase  max_pool_size : Any number of threads are allowed to wait for connections to become available,\nand they can wait the default (1 second) or the  wait_queue_timeout  setting: When  #close  is called on a client by any thread, all connections are closed: Note that when creating a client using the  block syntax  described above, the client is automatically closed after the block finishes executing. When using the Mongo Ruby driver in a Web application with a forking web server\nsuch as Unicorn, Puma or Passenger, or when the application otherwise forks,\neach process should generally each have their own  Mongo::Client  instances.\nThis is because: The driver attempts to detect client use from forked processes and\nreestablish network connections when such use is detected, alleviating\nthe issue of file descriptor sharing. If both parent and child processes need to perform MongoDB operations,\nit is recommended for each of the processes to create their own\n Mongo::Client  instances. Specifically, the child process should create\nits own client instance and not use any of the instances that were created\nin the parent. If the parent continues to perform MongoDB operations using an already\nestablished client instance after forking children, this client instance will\ncontinue to operate normally as long as no child uses it in any way.\nThe child processes will not inherit any of the monitoring threads, and\nwill not perform background operations on the client instance. If the parent does not need to perform MongoDB operation after forking\nchildren (which is what typically happens in web applications), the parent\nshould close all of the client instances it created to free up connections\nand cease background monitoring: Applications using Mongoid should follow  Mongoid's forking guidance .\nThe guidance and sample code below is provided for applications using the\nRuby driver directly. The background threads remain in the parent process and are not transfered\nto the child process. File descriptors like network sockets are shared between parent and\nchild processes. If the parent process performs operations on the Mongo client and does not\nclose it, the parent process will continue consuming a connection slot\nin the cluster and will continue monitoring the cluster for as long as the\nparent remains alive. When the Ruby driver is used in a web application, it is recommended to not\ncreate any  Mongo::Client  instances in the management processes (prior to\nthe workers being forked), and instead only create client instances in the\nworkers. It is possible, although not recommended, to use the same  Mongo::Client \ninstances in parent and child processes. In order to do so, the instance\nmust be closed and reconnected in the child process so that the background\nthreads can be recreated: Web servers generally provide hooks that can be used by applications to\nperform actions when the worker processes are forked. The recommended hooks\nto use are: This documentation does not provide example code for using the aforementioned\nhooks, because there is no standard for client instance management when\nusing the Ruby driver directly.  Mongoid documentation \nhowever provides examples for closing clients in the parent process and\nreconnecting clients in the child processes. This pattern should be used with Ruby driver version 2.6.2 or higher.\nPrevious driver versions did not recreate monitoring threads when\nreconnecting. When closing and reconnecting the client instance in the child,\ndue to file descriptor sharing, the parent process may experience network\nand monitoring errors. For  Puma ,  before_fork  to close clients in the\nparent process and  on_worker_boot  to reconnect in the child processes. For  Unicorn ,\n before_fork  to close clients in the parent process and\n after_fork  to reconnect clients in the child processes. For  Passenger ,\n starting_worker_process  to reconnect clients in the child processes\n(Passenger does not appear to have a pre-fork hook). The client's  summary  method returns the current state of the client,\nincluding servers that the client is monitoring and their state. If any of\nthe servers are not being monitored, this is indicated by the  NO-MONITORING \nflag. A normally operating client will produce a summary similar to the following: A client that is missing background threads will produce a summary similar to\nthe following: The driver implements two mechanisms for retrying reads: modern and legacy.\nAs of driver version 2.9.0, the modern mechanism is used by default, and the\nlegacy mechanism is deprecated. When the modern mechanism is used, read operations are retried once in the\nevent of a network error, a \"not master\" error, or a \"node is recovering\" error.\nThe following operations are covered: When an operation returns a cursor, only the initial read command can be retried.\n getMore  operations on cursors are not retried by driver version 2.9.0 or\nnewer. Additionally, when a read operation is retried, a new server for the\noperation is selected; this may result in the retry being sent to a different\nserver from the one which received the first read. The behavior of modern retryable reads is covered in detail by the\n retryable reads specification . Note that the modern retryable reads can only be used with MongoDB 3.6 and\nhigher servers. When used with MongoDB 3.4 and lower servers, Ruby driver\nversion 2.9.0 and higher will not retry reads by default - the application\nmust explicitly request legacy retryable reads by setting the\n retry_reads: false  client option or using  retryReads=false  URI option. Collection#find \nand related methods Collection#aggregate Collection#count ,\n Collection#count_documents Change stream helpers:  Collection#watch ,\n Database#watch ,\n Client#watch Enumeration commands:  Client#list_mongo_databases ,\n Client#list_databases ,\n Client#database_names ,\n Database#collection_names ,\n Database#collections ,\n Database#list_collections ,\n Collection#indexes The legacy read retry behavior of the Ruby driver is available by setting the\n retry_reads: false  client option or passing the  retryReads=false  URI\noption to the client. When using legacy read retry behavior, the number of retries can be set\nby specifying the  max_read_retries  client option. When using driver version\n2.9.0 or higher, the set of operations which would be retried with legacy\nretryable reads is identical to the one described above for modern retryable\nreads. In older driver versions the behavior of legacy retryable writes was\ndifferent in that some of the operations were not retried. As of driver version 2.9.0, legacy read retries perform server selection prior\nto retrying the operation, as modern retriable writes do. In older driver\nversions read retries would be sent to the same server which the initial read\nwas sent to. To disable all read retries, set the following client options:\n retry_reads: false, max_read_retries: 0 . The driver implements two mechanisms for retrying writes: modern and legacy.\nAs of driver version 2.9.0, the modern mechanism is used by default on servers\nthat support it, and the legacy mechanism is deprecated and disabled by default\non all server versions. The following write methods used in day-to-day operations on collections\nare subject to write retries: collection#insert_one collection#update_one collection#delete_one collection#replace_one collection#find_one_and_update collection#find_one_and_replace collection#find_one_and_delete collection#bulk_write  (for all single statement ops, i.e. not for  update_many  or  delete_many ) The modern mechanism will retry failing writes once when the driver is\nconnected to a MongoDB 3.6 or higher replica set or a sharded cluster,\nbecause they require an oplog on the serer. Modern mechanism will not retry\nwrites when the driver is connected to a standalone MongoDB server or\nserver versions 3.4 or older. The following errors will cause writes to be retried: Prior to retrying the write the driver will perform server selection,\nsince the server that the original write was sent to is likely no longer\nusable. Network errors including timeouts \"not master\" errors \"node is recovering\" errors If modern retryable writes mechanism is disabled by setting the client\noption  retry_writes: false  or by using the  retryWrites=false \nURI option, the driver will utilize the legacy retryable writes mechanism.\nThe legacy mechanism retries writes on the same operations as the modern\nmechanism. By default the legacy mechanism retries once, like the modern\nmechanism does; to change the number of retries, set  :max_write_retries \nclient option. The difference between legacy and modern retry mechanisms is that the\nlegacy mechanism retries writes for a different set\nof errors compared to the modern mechanism, and specifically does not\nretry writes when a network timeout is encountered. To disable all write retries, set the following client options:\n retry_writes: false, max_write_retries: 0 . You can either use the default global driver logger or set your own. To set your own: See the  Ruby Logger documentation \nfor more information on the default logger API and available levels. To change the logger level: For more control, a logger can be passed to a client for per-client control over logging. The default logging truncates logs at 250 characters by default. To turn this off pass an\noption to the client instance. To use wire protocol compression, at least one compressor must be explicitly\nrequested using either the  :compressors  Ruby option or the  compressors \nURI option. If no compressors are explicitly requested, the driver will not\nuse compression, even if the required dependencies for one or more compressors\nare present on the system. The driver chooses the first compressor of the ones requested that is also\nsupported by the server. The driver currently supports  zstd ,  snappy  and\n zlib  compressors.  zstd  compressor is recommended as it produces\nthe highest compression at the same CPU consumption compared to the other\ncompressors. For maximum server compatibility all three compressors can be\nspecified, e.g. as  compressors: [\"zstd\", \"snappy\", \"zlib\"] . zstd  compressor requires the\n zstd-ruby  library to be installed.\n snappy  compressor requires the\n snappy  library to be installed.\nIf  zstd  or  snappy  compression is requested, and the respective\nlibrary is not loadable, the driver will raise an error during\n Mongo::Client  creation.  zlib  compression requires the  zlib \nstandard library extension to be present. The server support for various compressors is as follows: zstd  requires and is enabled by default in MongoDB 4.2 or higher. snappy  requires MongoDB 3.4 or higher and is enabled by default in\nMongoDB 3.6 or higher. zlib  requires MongoDB 3.6 or higher and is enabled by default in\nMongoDB 4.2 and higher. Starting with MongoDB 5.0, applications can request that the server behaves\nin accordance with a particular server API version. Server API parameters can be specified via the  :server_api  option to\n Client . These parameters cannot be provided via a URI. Currently the only defined API version is  \"1\" . It can be requested\nas follows: MongoDB server defines API versions as string values. For convenience, if the\nAPI version is provided as an integer, the Ruby driver will stringify it and\nsend it to the server as a string: Note that the server may define API versions that are not stringified integers.\nApplications must not assume that all legal API versions can be expressed\nas integers. When a particular API version is requested, operations which are part of that\nAPI version behave as specified in that API version. Operations which are not\npart of the specified API version behave as they would had the API version\nnot been specified at all. Operations whose behavior is subject to the\nconfigured API version are commands including command arguments, queries,\naggregation pipeline stages and arguments. Applications may request that the server rejects all operations which are not\npart of the specified API version by setting the  :strict  option: For example, since the  :tailable  option is not part of the server API\nversion 1, the following query would fail: Applications may request that the server rejects all operations which are\ndeprecated in the specified API version by setting the  :deprecation_errors \noption: Note that, as of this writing, there are no deprecated operations in API\nversion  \"1\" . If the server API parameters have been defined on a  Client  object,\nthey will be sent by the client as part of each   executed operation. MongoDB servers prior to 5.0 do not recognize the API parameters, and will\nproduce a variety of errors should the application configure them.\nThe Ruby driver will send the API parameters to all MongoDB 3.6 and newer\nservers, but the API parameters should only be configured when the application\nis communicating with MongoDB 5.0 or newer servers. The API parameters\ncannot be sent to MongoDB 3.4 and older servers that use the legacy wire\nprotocol; if an application configures the API parameters and connects to\nMongoDB 3.4 or older servers, the driver will produce an error on every\noperation. The  command helper  permits the application to\nsend manually constructed commands to the server. If the client is not\nconfigured with server API parameters, the command helper may be used to\nissue commands with API parameters: If the client is configured with server API parameters, the command helper\nmay not be used to issue commands with server API parameters. This includes the\ncase when the server API parameters provided to the client and to the\ncommand helper are identical. If a client is constructed with server API\nparameters, to send different API parameters (or none at all) a new client\nmust be constructed, either from scratch or using the  with  method. The server API parameters may only be specified on the client level.\nThey may not be specified on the database, collection, session, transaction\nor individual operation level. getMore  commands and commands in transactions do not accept\nAPI parameters, thus the driver will not send them in these cases. Driver's default configuration is suitable for production deployment.\nIn development, some settings can be adjusted to provide a better developer\nexperience. :server_selection_timeout : set this to a low value (e.g.,  1 )\nif your MongoDB server is running locally and you start it manually. A low\nserver selection timeout will cause the driver to fail quickly when there is\nno server running. Please consider the following when deploying an application using the Ruby\ndriver in production: As of driver version 2.11, the  :min_pool_size  client option is completely\nrespected - the driver will create that many connections to each server\nidentified as a standalone, primary or secondary. In previous driver versions\nthe driver created connections on demand. Applications using  :min_pool_size \nwill see an increase in the number of idle connections to all servers as of\ndriver version 2.11, and especially to secondaries in replica set deployments\nand to nodes in sharded clusters. If the application is reverse proxied to by another web server or a load\nbalancer,  server_selection_timeout  should generally be set to a lower\nvalue than the reverse proxy's read timeout. For exampe,  Heroku request timeout  is 30 seconds and\nis not configurable; if deploying a Ruby application using MongoDB to Heroku,\nconsider lowering server selection timeout to 20 or 15 seconds.",
            "code": [
                {
                    "lang": "ruby",
                    "value": "Mongo::Client.new([ '127.0.0.1:27017' ], database: 'mydb')\n\n# Or using the URI syntax:\nMongo::Client.new(\"mongodb://127.0.0.1:27017/mydb\")"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Client.new(\"mongodb+srv://username:myRealPassword@cluster0.mongodb.net/mydb?w=majority\")"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Client.new(...) do |client|\n  # work with the client\nend"
                },
                {
                    "lang": "ruby",
                    "value": "# Using Ruby client options:\nclient = Mongo::Client.new(['localhost'], database: 'mydb')\n\n# Using a MongoDB URI:\nclient = Mongo::Client.new('mongodb://localhost/mydb')"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new(['localhost'], database: 'mydb')\n\nadmin_client = client.use('admin')\n\n# Issue an administrative command\nadmin_client.database.command(replSetGetConfig: 1).documents.first"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Client.new([ '127.0.0.1:27017' ], database: 'mydb')\n\nMongo::Client.new([ '127.0.0.1:27017', '127.0.0.1:27018' ], database: 'mydb')\n\n# Or using the URI syntax:\nMongo::Client.new(\"mongodb://127.0.0.1:27017,127.0.0.1:27018/mydb\")"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Client.new([ '127.0.0.1:27017', '127.0.0.1:27018' ],\n  database: 'mydb', replica_set: 'myapp')\n\n# Or using the URI syntax:\nMongo::Client.new(\"mongodb://127.0.0.1:27017,127.0.0.1:27018/mydb?replicaSet=myapp\")"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Client.new([ '127.0.0.1:27017', '127.0.0.1:27018' ],\n  database: 'mydb', connect: :replica_set)\n\n# Or using the URI syntax:\nMongo::Client.new(\"mongodb://127.0.0.1:27017,127.0.0.1:27018/mydb?connect=replica_set\")"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Client.new(\"mongodb+srv://username:myRealPassword@cluster0.mongodb.net/test?w=majority\")"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Client.new([ '1.2.3.4:27017', '1.2.3.5:27017' ], database: 'mydb')\n\nMongo::Client.new(\"mongodb://1.2.3.4:27017,1.2.3.5:27017/mydb\")"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Client.new(\"mongodb+srv://username:myRealPassword@cluster0.mongodb.net/test?w=majority\")"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Client.new([ '127.0.0.1:27017', '127.0.0.1:27018' ],\n  database: 'mydb', connect: :sharded)\n\n# Or using the URI syntax:\nMongo::Client.new(\"mongodb://127.0.0.1:27017,127.0.0.1:27018/mydb?connect=sharded\")"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Client.new([ '1.2.3.4:27017' ], database: 'mydb', direct_connection: true)\n\n# Or using the URI syntax:\nMongo::Client.new(\"mongodb://1.2.3.4:27017/mydb?directConnection=true\")"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Client.new([ '1.2.3.4:27017' ], database: 'mydb', connect: :direct)\n\n# Or using the URI syntax:\nMongo::Client.new(\"mongodb://1.2.3.4:27017/mydb?connect=direct\")"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Client.new([ '1.2.3.4:27017' ], database: 'mydb', load_balanced: true)\n\n# Or using the URI syntax:\nMongo::Client.new(\"mongodb://1.2.3.4:27017/mydb?loadBalanced=true\")"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Client.new([ '1.2.3.4:27017' ],\n  database: 'mydb', load_balanced: true, connect: :load_balanced)\n\n# Or using the URI syntax:\nMongo::Client.new(\"mongodb://1.2.3.4:27017/mydb?loadBalanced=true&connect=load_balanced\")"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Client.new(\"mongodb+srv://username:myRealPassword@cluster0.mongodb.net/test?w=majority&authSource=admin\")"
                },
                {
                    "lang": "ruby",
                    "value": "{ read:\n  { mode: :secondary,\n    tag_sets: [ \"data_center\" => \"berlin\" ],\n    max_staleness: 5,\n  }\n}"
                },
                {
                    "lang": "ruby",
                    "value": "{ write_concern: { w: 2 } }"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([\"localhost:27017\"],\n  ssl: true,\n  ssl_cert: 'path/to/client.crt',\n  ssl_key: 'path/to/client.key',\n  ssl_ca_cert: 'path/to/ca.crt',\n)"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([\"localhost:27017\"],\n  ssl: true,\n  ssl_cert: 'path/to/client.pem',\n  ssl_key: 'path/to/client.pem',\n  ssl_ca_cert: 'path/to/ca.crt',\n)"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new(\n  \"mongodb://localhost:27017/?tls=true&tlsCertificateKeyFile=path%2fto%2fclient.pem&tlsCertificateKeyFile=path%2fto%2fca.crt\")"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo.tls_context_hooks.push(\n  Proc.new { |context|\n    context.ciphers = [\"AES256-SHA\"]\n  }\n)\n\n# Only the AES256-SHA cipher will be enabled from this point forward"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([\"localhost:27017\"])"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([\"localhost:27017\"], max_pool_size: 200)"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new([\"localhost:27017\"], wait_queue_timeout: 0.5)"
                },
                {
                    "lang": "ruby",
                    "value": "client.close"
                },
                {
                    "lang": "ruby",
                    "value": "client.reconnect"
                },
                {
                    "lang": "ruby",
                    "value": "client.close\nclient.reconnect"
                },
                {
                    "lang": "ruby",
                    "value": "client.summary\n=> \"#<Client cluster=#<Cluster\n  topology=ReplicaSetWithPrimary[localhost:14420,localhost:14421,localhost:14422,localhost:14423,name=ruby-driver-rs,v=1,e=7fffffff000000000000001f]\n  servers=[#<Server address=localhost:14420 PRIMARY replica_set=ruby-driver-rs pool=#<ConnectionPool size=0 (0-5) used=0 avail=0 pending=0>>,\n    #<Server address=localhost:14421 SECONDARY replica_set=ruby-driver-rs pool=#<ConnectionPool size=0 (0-5) used=0 avail=0 pending=0>>,\n    #<Server address=localhost:14422 SECONDARY replica_set=ruby-driver-rs pool=#<ConnectionPool size=0 (0-5) used=0 avail=0 pending=0>>,\n    #<Server address=localhost:14423 ARBITER replica_set=ruby-driver-rs>]>>\""
                },
                {
                    "lang": "ruby",
                    "value": "client.summary\n=> \"#<Client cluster=#<Cluster\n  topology=ReplicaSetWithPrimary[localhost:14420,localhost:14421,localhost:14422,localhost:14423,name=ruby-driver-rs,v=1,e=7fffffff000000000000001f]\n  servers=[#<Server address=localhost:14420 PRIMARY replica_set=ruby-driver-rs NO-MONITORING pool=#<ConnectionPool size=0 (0-5) used=0 avail=0 pending=0>>,\n    #<Server address=localhost:14421 SECONDARY replica_set=ruby-driver-rs NO-MONITORING pool=#<ConnectionPool size=0 (0-5) used=0 avail=0 pending=0>>,\n    #<Server address=localhost:14422 SECONDARY replica_set=ruby-driver-rs NO-MONITORING pool=#<ConnectionPool size=0 (0-5) used=0 avail=0 pending=0>>,\n    #<Server address=localhost:14423 ARBITER replica_set=ruby-driver-rs>]>>\""
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Logger.logger = other_logger"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Logger.logger.level = Logger::WARN"
                },
                {
                    "lang": "ruby",
                    "value": "my_logger = Logger.new(STDOUT)\nMongo::Client.new([ '127.0.0.1:27017' ], :database => 'test', :logger => my_logger )"
                },
                {
                    "lang": "ruby",
                    "value": "Mongo::Client.new([ '127.0.0.1:27017' ], :database => 'test', :truncate_logs => false )"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new(['localhost'], server_api: {version: \"1\"})"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new(['localhost'], server_api: {version: 1})"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new(['localhost'], server_api: {version: \"1\", strict: true})"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new(['localhost'], server_api: {version: \"1\", strict: true})\nclient['collection'].find({}, tailable: true)\n# => Mongo::Error::OperationFailure (BSON field 'FindCommand.tailable' is not allowed with apiStrict:true. (323) (on localhost:27017, modern retry, attempt 1))"
                },
                {
                    "lang": "ruby",
                    "value": "client = Mongo::Client.new(['localhost'], server_api: {version: \"1\", deprecation_errors: true})"
                },
                {
                    "lang": "ruby",
                    "value": "client.database.command(\n  ping: 1,\n  apiVersion: \"1\",\n  apiStrict: false,\n  apiDeprecationErrors: false,\n)"
                }
            ],
            "preview": "To connect to a MongoDB deployment, create a Mongo::Client object.\nProvide a list of hosts and options or a connection string URI to the``Mongo::Client`` constructor.\nThe client's selected database defaults to admin.",
            "tags": null,
            "facets": null
        }
    ]
}