{
    "url": "http://mongodb.com/docs/drivers/node/v4.6",
    "includeInGlobalSearch": false,
    "documents": [
        {
            "slug": "quick-start",
            "title": "Quick Start",
            "headings": [
                "Set up Your Project",
                "Install Node and npm",
                "Create the Project",
                "Add MongoDB as a Dependency",
                "Create a MongoDB Cluster",
                "Create a Free Tier Cluster in Atlas",
                "Connect to your Cluster",
                "Connect to Your Application",
                "Create your Node.js Application",
                "Run your Node.js Application",
                "Next Steps"
            ],
            "paragraphs": "This guide shows you how to create an application that uses the\nMongoDB Node.js driver to connect to a MongoDB cluster hosted on MongoDB Atlas. If\nyou prefer to connect to MongoDB using a different driver or programming\nlanguage, see our  list of official drivers . The Node.js driver is a library you can use to connect to and communicate\nwith MongoDB. MongoDB Atlas is a fully managed cloud database service that hosts your\nMongoDB servers. You can get started with your own free (no credit card\nrequired) MongoDB instance with this guide. Follow the steps below to connect a sample Node.js application to a MongoDB\ninstance on MongoDB Atlas. Ensure you have Node.js v12 or later and npm (Node Package Manager) installed\nin your development environment. For information on how to install Node.js and npm, see\n downloading and installing Node.js and npm . First, in your shell, create a directory for your project: Then, navigate into that directory: Next, initialize your project: Install the Node.js driver: This command performs the following actions: At this point, you are ready to use the Node.js driver with your\napplication. Downloads the  mongodb  package and the dependencies it requires Saves the package in the  node_modules  directory Records the dependency information in the  package.json  file Create a free tier MongoDB cluster on MongoDB Atlas to store and manage\nyour data. MongoDB Atlas hosts and manages your MongoDB database in the\ncloud. Complete the  Get Started with Atlas \nguide to set up a new Atlas account, a free tier cluster (a shared\nMongoDB instance) and load sample data into your cluster. You can connect to your MongoDB cluster by providing a\n connection string  which instructs the driver on where and how to\nconnect. The connection string includes information on the hostname\nor IP address and port of your cluster, the authentication mechanism,\nuser credentials when applicable, and other connection options. To connect to an instance or cluster not hosted on Atlas, see\n Other Ways to Connect to MongoDB . To retrieve your connection string for the cluster you created in\nthe previous step, log into your Atlas account and navigate to the\n Database  section and click the  Connect  button\nfor the cluster that you want to connect to as shown below. Proceed to the  Connect Your Application  section and select\nthe Node.js driver. Select the  Connection String Only  tab\nand click the  Copy  button to copy the connection string to\nyour clipboard as shown below. Save your connection string to a safe location. Create a file to contain your application called  index.js  in your\nproject directory. Add the following code, assigning the  uri \nvariable the value of your connection string. The preceding code example assigns the  MongoClient  variable using\n object destructuring ,\nintroduced in Node.js v6. You can create an instance of a\n MongoClient  without using object destructuring as shown in the\nfollowing code: Run the application you created from the previous step from the\ncommand line: You should see the details of the retrieved movie document in the output: If you encounter an error or no output, check whether you specified the\nproper connection string in the application code, and loaded the sample\ndata set in your Atlas cluster. At this point, you should have a working application that uses\nthe Node.js driver to connect to your MongoDB instance, runs a query\non the sample data, and prints out the result. Learn how to read and modify data using the Node.js driver in our\n CRUD Operations  guide or how to perform common\noperations in our  Usage Examples .",
            "code": [
                {
                    "lang": "bash",
                    "value": "mkdir node_quickstart"
                },
                {
                    "lang": "bash",
                    "value": "cd node_quickstart"
                },
                {
                    "lang": "bash",
                    "value": "npm init -y"
                },
                {
                    "lang": "bash",
                    "value": "npm install mongodb@4.5"
                },
                {
                    "lang": "js",
                    "value": "const { MongoClient } = require(\"mongodb\");\n\n// Replace the uri string with your connection string.\nconst uri =\n  \"mongodb+srv://<user>:<password>@<cluster-url>?retryWrites=true&w=majority\";\n\nconst client = new MongoClient(uri);\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db('sample_mflix');\n    const movies = database.collection('movies');\n\n     // Query for a movie that has the title 'Back to the Future'\n     const query = { title: 'Back to the Future' };\n     const movie = await movies.findOne(query);\n\n     console.log(movie);\n   } finally {\n     // Ensures that the client will close when you finish/error\n     await client.close();\n   }\n }\n run().catch(console.dir);"
                },
                {
                    "lang": "js",
                    "value": "const MongoClient = require(\"mongodb\").MongoClient;"
                },
                {
                    "lang": "none",
                    "value": "node index.js"
                },
                {
                    "lang": "none",
                    "value": "{\n  _id: ...,\n  plot: 'A young man is accidentally sent 30 years into the past...',\n  genres: [ 'Adventure', 'Comedy', 'Sci-Fi' ],\n  ...\n  title: 'Back to the Future',\n  ...\n}"
                }
            ],
            "preview": "This guide shows you how to create an application that uses the\nMongoDB Node.js driver to connect to a MongoDB cluster hosted on MongoDB Atlas. If\nyou prefer to connect to MongoDB using a different driver or programming\nlanguage, see our list of official drivers.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "issues-and-help",
            "title": "Issues & Help",
            "headings": [
                "Bugs / Feature Requests",
                "Pull Requests"
            ],
            "paragraphs": "Our developer community is vibrant and highly engaged, with extensive experience using Node.js with MongoDB. Often, the quickest way to get support for general questions is through the\n MongoDB Community Forums . Refer to our  support channels  documentation for more information. To report a bug or to request a new feature in the Node.js driver,\nplease open a case in our issue management tool, JIRA: Bug reports in JIRA for the Node.js driver and the Core Server (i.e. SERVER) project are  public . If you\u2019ve identified a security vulnerability in a driver or any other\nMongoDB project, please report it according to the instructions found in\nthe  Create a Vulnerability Report . Create an account and login . Navigate to  the NODE project . Click  Create Issue . Please provide as much information as possible about the\nissue and the steps to reproduce it. We are happy to accept contributions to help improve the driver.\nWe will review user contributions to ensure they meet the standards of the codebase.\nPull requests must pass the  travis.ci  checks as well as include documentation\nand tests. To get started check out the source and work on a branch: To run the test suite, you must have a server topology running and provide the URI to the command.\nFor example, if you have a single server running at  \"mongodb://localhost:27017\" , you can run the following: Note that, depending on the type of topology that you are running (standalone, replicaset, etc.), different tests will be run. There are many tools that can help you with setting up different topologies for local testing.\nSome examples are  mtools  and  mongo-orchestration .",
            "code": [
                {
                    "lang": "bash",
                    "value": "git clone https://github.com/mongodb/node-mongodb-native.git\ncd node-mongodb-native\nnpm install\ngit checkout -b myNewFeature"
                },
                {
                    "lang": "bash",
                    "value": "MONGODB_URI=\"mongodb://localhost:27017\" npm test"
                }
            ],
            "preview": "Our developer community is vibrant and highly engaged, with extensive experience using Node.js with MongoDB.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "faq",
            "title": "FAQ",
            "headings": [
                "How Does Connection Pooling Work in the Node Driver?",
                "How to fix a \"MongoServerSelectionError: connect ECONNREFUSED ::1:27017\" error?",
                "What Is the Difference Between \"connectTimeoutMS\", \"socketTimeoutMS\" and \"maxTimeMS\"?",
                "How Can I Prevent the Driver From Hanging During Connection or From Spending Too Long Trying to Reach Unreachable Replica Sets?",
                "What Happens to Running Operations If the Client Disconnects?",
                "How Can I Confirm That the Driver Closed Unusable Sockets?",
                "How Can I Prevent Sockets From Timing out Before They Become Active?",
                "What Does a Value of \"0\" mean for \"connectTimeoutMS\" and \"socketTimeoutMS\"?",
                "How Can I Prevent Long-Running Operations From Slowing Down the Server?",
                "What Does the \"keepAlive\" Setting Do?",
                "What Can I Do If I'm Experiencing Unexpected Network Behavior?",
                "What Can I Do If I'm Getting \"ECONNRESET\" When Calling \"client.connect()\"?",
                "How Can I Prevent a Slow Operation From Delaying Other Operations?",
                "How Can I Ensure My Connection String Is Valid for a Replica Set?"
            ],
            "paragraphs": "This page contains frequently asked questions and their corresponding answers. If you can't find an answer to your problem on this page,\nsee the  Issues & Help  page for next steps and more\nresources. Every  MongoClient  instance has a built-in connection pool for each server\nin your MongoDB topology. Connection pools open sockets on demand to\nsupport concurrent requests to MongoDB in your application. The maximum size of each connection pool is set by the  maxPoolSize  option, which\ndefaults to  100 . If the number of in-use connections to a server reaches\nthe value of  maxPoolSize , the next request to that server will wait\nuntil a connection becomes available. In addition to the sockets needed to support your application's requests,\neach  MongoClient  instance opens two additional sockets per server\nin your MongoDB topology for monitoring the server's state.\nFor example, a client connected to a three-node replica set opens six\nmonitoring sockets. If the application uses the default setting for\n maxPoolSize  and only queries the primary (default) node, then\nthere can be at most  106  total connections in the connection pool. If the\napplication uses a  read preference  to query the\nsecondary nodes, those connection pools grow and there can be\n 306  total connections. To support high numbers of concurrent MongoDB requests\nwithin one process, you can increase  maxPoolSize . Connection pools are rate-limited. The  maxConnecting  option\ndetermines the number of connections that the pool can create in\nparallel at any time. For example, if the value of  maxConnecting  is\n 2 , the third request that attempts to concurrently check out a\nconnection succeeds only when one the following cases occurs: You can set the minimum number of concurrent connections to\neach server with the  minPoolSize  option, which defaults to  0 .\nThe driver initializes the connection pool with this number of sockets. If\nsockets are closed, causing the total number\nof sockets (both in use and idle) to drop below the minimum, more\nsockets are opened until the minimum is reached. You can set the maximum number of milliseconds that a connection can\nremain idle in the pool by setting the  maxIdleTimeMS  option.\nOnce a connection has been idle for  maxIdleTimeMS , the connection\npool removes and replaces it. This option defaults to  0  (no limit). The following default configuration for a  MongoClient  works for most\napplications: MongoClient  supports multiple concurrent requests. For each process,\ncreate a client and reuse it for all operations in a process. This\npractice is more efficient than creating a client for each request. The driver does not limit the number of requests that\ncan wait for sockets to become available, and it is the application's\nresponsibility to limit the size of its pool to bound queuing\nduring a load spike. Requests wait for the amount of time specified in\nthe  waitQueueTimeoutMS  option, which defaults to  0  (no limit). A request that waits more than the length of time defined by\n waitQueueTimeoutMS  for a socket raises a connection error. Use this\noption if it is more important to bound the duration of operations\nduring a load spike than it is to complete every operation. When  MongoClient.close()  is called by any request, the driver\ncloses all idle sockets and closes all sockets that are in\nuse as they are returned to the pool. Calling  MongoClient.close() \ncloses only inactive sockets, so you cannot interrupt or terminate\nany ongoing operations by using this method. The driver closes these\nsockets only when the process completes. The connection pool finishes creating a connection and there are fewer\nthan  maxPoolSize  connections in the pool. An existing connection is checked back into the pool. The driver's ability to reuse existing connections improves due to\nrate-limits on connection creation. Beginning with version 17, Node.js defaults to using  IPV6 . You have a few\noptions to resolve this error: Start your  mongod  in  IPV6  mode with  the --ipv6 flag , or\nsetting the  net.ipv6  option to  true   in your configuration file . Explicitly use  IPV4  by specifying  family: 4  as an\n option to your MongoClient . To specify the optional settings for your  MongoClient , declare one or\nmore available settings in the  options  object of the constructor as\nfollows: To see all the available settings, see the\n MongoClientOptions \nAPI Documentation. To specify  maxTimeMS , chain the  maxTimeMS()  method with a\ntimeout specification to an operation that returns a  Cursor : Setting Description connectTimeoutMS connectTimeoutMS  is a  connection option  that sets the time, in milliseconds,\nfor an individual connection from your connection pool to\nestablish a TCP connection to the MongoDB server before\ntiming out. Default:  30000 To modify the allowed time for  MongoClient.connect  to establish a\nconnection to a MongoDB server, use the  serverSelectionTimeoutMS  option instead. socketTimeoutMS socketTimeoutMS  specifies the amount of time the driver waits\nfor an inactive socket before closing it. The default value is to\nnever time out the socket. This option applies only to sockets that\nhave already been connected. maxTimeMS maxTimeMS \nspecifies the maximum amount of time the server\nshould wait for an operation to complete after it has reached the\nserver. If an operation runs over the specified time limit, it\nreturns a timeout error. You can pass  maxTimeMS  only to an\nindividual operation or to a cursor. To prevent the driver from hanging during connection or to prevent the\ndriver from spending too long trying to reach unreachable replica sets,\nyou can set the  connectTimeoutMS  option of your\n connection options .\nGenerally, you should ensure that the\n connectTimeoutMS  setting is not lower than the longest network\nlatency you have to a member of the set. If one of the secondary members\nis on the other side of the planet and has a latency of 10000\nmilliseconds, setting the  connectTimeoutMS  to anything lower will\nprevent the driver from ever connecting to that member. Starting in MongoDB Server version 4.2, the server terminates\nrunning operations such as aggregations and find operations if the\nclient disconnects. To see a full list of operations affected by this\nbehavior, see the  Server version 4.2 release notes  in the Server manual. Other operations, such as write operations, continue to run on the\nMongoDB Server even if the client disconnects. This behavior can cause data\ninconsistencies if your application retries the operation after the\nclient disconnects. If you experience unexpected network behavior or if a MongoDB process\nfails with an error, you may not receive confirmation that the\ndriver correctly closed the corresponding socket. To make sure that the driver correctly closes the socket in these cases,\nset the  socketTimeoutMS  option. When a MongoDB process times out, the driver\nwill close the socket. We recommend that you select a value\nfor  socketTimeoutMS  that is two to three times as long as the\nexpected duration of the slowest operation that your application executes. Having a large connection pool does not always reduce reconnection\nrequests.  Consider the following example: An application has a connection pool size of 5 sockets and has the\n socketTimeoutMS  option set to 5000 milliseconds. Operations occur,\non average, every 3000 milliseconds, and reconnection requests are\nfrequent. Each socket times out after 5000 milliseconds, which means\nthat all sockets must do something during those 5000 milliseconds to\navoid closing. One message every 3000 milliseconds is not enough to keep the sockets\nactive, so several of the sockets will time out after 5000 milliseconds.\nTo avoid excessive socket timeouts, reduce the number of connections\nthat the driver can maintain in the connection pool by specifying the\n maxPoolSize  option. To specify the optional  maxPoolSize  setting for your  MongoClient , declare\nit in the  options  object of the constructor as follows: If you set the value of  connectTimeoutMS  or  socketTimeoutMS  to\n 0 , your application will use the operating system's default socket\ntimeout value. You can prevent long-running operations from slowing down the server by\nspecifying a timeout value. You can chain the  maxTimeMS()  method to\nan operation that returns a  Cursor  to set a timeout on a specific action. The following example shows how you can chain the  maxTimeMS()  method\nto an operation that returns a  Cursor : keepAlive  is a  connection-setting  that sets the number of\nmilliseconds to wait before initiating a  TLS keepAlive  on a TCP Socket. The  keepAlive  option\nwill keep a socket alive by sending periodic probes to MongoDB. However,\nthis only works if the operating system supports  SO_KEEPALIVE  . Internal firewalls that exist between application servers and MongoDB\nare often misconfigured and are overly aggressive in their removal of\nsocket connections. If you experience unexpected network behavior, here\nare some things to check: The firewall should send a  FIN packet  when closing a socket,allowing the driver to detect that the socket is closed. The firewall should allow  keepAlive  probes. In most operating systems, each connection is associated with a  file\ndescriptor . There is\ntypically a limit set by the operating system on the number of file\ndescriptors used by a single process. An  ECONNRESET  error can occur\nif the connection pool size surpasses the limit of  file descriptors . Consider the following operation: If this operation causes an  ECONNRESET  error, you may have run into\nthe  file descriptor  limit for your Node.js process. In that case you\nmust increase the number of  file descriptors  for the Node.js process. On\nMacOS and Linux you do this with the  ulimit  shell command. This sets the maximum number of  file descriptors  for the process to\n6000, allowing Node.js to connect with a pool size of 5000 sockets. To control the maximum size of a connection pool, you can set the\n maxPoolSize  option in the  connection options . The default value of  maxPoolSize  is\n 100 . If the number of in-use connections to a server reaches\n maxPoolSize , the next request to that server will wait\nuntil a connection becomes available. To prevent long-running operations\nfrom slowing down your application, you can increase  maxPoolSize . The driver does not limit the number of requests that can wait for\nsockets to become available. Requests wait for the amount of time\nspecified in the  waitQueueTimeoutMS  option, which\ndefaults to  0  (no limit). You should set this option if it is\nmore important to stop long-running operations than it is to complete\nevery operation. To learn more about connection pooling, see  How Does Connection\nPooling Work in the Node Driver? . The connection string passed to the driver must use exact hostnames for\nthe servers as set in the  Replica Set Config .\nGiven the following configuration settings for your Replica Set, in\norder for the Replica Set discovery and  failover  to work the driver should be able\nto reach  server1 ,  server2 , and  server3 . If you are unable to find the answer to your question here, try our forums and\nsupport channels listed in the  Issues and Help \nsection.",
            "code": [
                {
                    "lang": "js",
                    "value": "const client = new MongoClient(\"<connection string>\");"
                },
                {
                    "lang": "sh",
                    "value": "mongod --ipv6"
                },
                {
                    "lang": "yaml",
                    "value": "net:\n  ipv6: true"
                },
                {
                    "lang": "js",
                    "value": "const client = new MongoClient(uri, {\n  family: 4,\n});"
                },
                {
                    "lang": "javascript",
                    "value": "const client = new MongoClient(uri, {\n  connectTimeoutMS: <integer value>,\n  socketTimeoutMS: <integer value>\n});"
                },
                {
                    "lang": "javascript",
                    "value": "const cursor = collection.find({}).maxTimeMS(50);"
                },
                {
                    "lang": "javascript",
                    "value": "const client = new MongoClient(uri, {\n  maxPoolSize: <integer value>,\n});"
                },
                {
                    "lang": "javascript",
                    "value": "// Execute a find command\nawait collection\n  .find({ $where: \"sleep(100) || true\" })\n  .maxTimeMS(50);\n"
                },
                {
                    "lang": "sh",
                    "value": "ulimit -n 6000"
                },
                {
                    "lang": "javascript",
                    "value": "const uri = \"mongodb://localhost:27017/test?maxPoolSize=5000\";\n// create a new MongoClient\nconst client = new MongoClient(uri);\n\nawait client.connect(err => {\n  // connection\n});\n"
                },
                {
                    "lang": "JSON",
                    "value": "{\n  \"_id\": \"testSet\",\n  \"version\": 1,\n  \"protocolVersion\": 1,\n  \"members\": [\n    {\n      \"_id\": 1,\n      \"host\": \"server1:31000\"\n    },\n    {\n      \"_id\": 2,\n      \"host\": \"server2:31001\"\n    },\n    {\n      \"_id\": 3,\n      \"host\": \"server3:31002\"\n    }\n  ]\n}"
                }
            ],
            "preview": "This page contains frequently asked questions and their corresponding answers.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "upgrade",
            "title": "Upgrade Driver Versions",
            "headings": [
                "Overview",
                "Breaking Changes",
                "Version 4.x Breaking Changes",
                "Server Release Compatibility Changes",
                "Version 4.2 Server Release Support Changes"
            ],
            "paragraphs": "On this page, you can learn about any changes you might need to make to\nyour application to upgrade your driver to a new version without loss of\nfunctionality. Before you upgrade, perform the following actions: Ensure the new driver version is compatible with the MongoDB Server version\nyour application connects to and the version of Node.js that your\napplication runs on. See the  Compatibility \npage for this information. Address any breaking changes between the version of the driver\nyour application currently uses and your planned upgrade version in the\n Breaking Changes  section of this guide. To learn\nmore about the MongoDB Server release compatibility changes, see the\n Server Release Compatibility Changes  section. You can minimize the amount of changes that you need to make to your\napplication when upgrading driver versions by using the\n Stable API . A breaking change is a modification in a convention or behavior in\na specific version of the driver that may prevent your application from\nworking as expected. The breaking changes in this section are categorized by the major\nversion releases that introduced them. When upgrading driver versions,\naddress all the breaking changes between your current version and the\nplanned upgrade version. For more information about these changes, see\n the v4.0 changelog . Driver versions 4.x are not compatible with Node.js\nv12.8 or earlier. If you want to use this version of the driver, You must\nuse Node.js v12.9 or greater. Cursor  types no longer extend  Readable  directly. You cannot use a  ChangeStream  instance as an iterator after using\nit as an  EventEmitter . You also cannot do the reverse\u2014using an\n EventEmitter  instance as an iterator after using it as a  ChangeStream . The following methods no longer accept a callback parameter: Collection.find() Collection.aggregate() Db.aggregate() The default value of the  maxPoolSize  connection option is now\n 100 . The driver no longer supports the  gssapiServiceName  Kerberos\noption. Users should use  authMechanismProperties.SERVICE_NAME  instead. The driver no longer accepts non-boolean types, such as  0  or\n 1 , for boolean options. The  db.collection  type no longer accepts a callback. The  Db  type is no longer an  EventEmitter . You can listen to\nany events directly from the  MongoClient  instance. The driver removes support for the  Collection.group()  helper. The driver no longer includes the deprecated  GridStore  API. A server release compatibility change is a modification\nto the driver that discontinues support for a set of\nMongoDB Server versions. The driver discontinues support for a MongoDB Server version after it reaches\nend-of-life (EOL). To learn more about the MongoDB support for EOL products,\nsee the  Legacy Support Policy . The v4.2 driver drops support for MongoDB Server v3.4 and earlier.\nTo use the v4.2 driver, your MongoDB Server must be v3.6 or later. To learn\nhow to upgrade your MongoDB Server to v3.6, follow the link that corresponds\nto your MongoDB deployment configuration: Upgrade a Replica Set to 3.6 Upgrade a Standalone to 3.6 Upgrade a Sharded Cluster to 3.6",
            "code": [],
            "preview": "On this page, you can learn about any changes you might need to make to\nyour application to upgrade your driver to a new version without loss of\nfunctionality.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "whats-new",
            "title": "What's New",
            "headings": [
                "What's New in 4.6",
                "What's New in 4.5",
                "What's New in 4.4",
                "What's New in 4.3",
                "What's New in 4.2",
                "What's New in 4.1",
                "What's New in 4.0",
                "TypeScript",
                "Key Changes",
                "Node.js Version",
                "Cursor Improvements",
                "Cursor Stream API",
                "MongoClientOptions Interface",
                "createCollection()",
                "BulkWriteError \u2192 MongoBulkWriteError",
                "DB",
                "Collection.group()",
                "Authentication",
                "GridStore Removal",
                "Construction",
                "File Seeking",
                "File Upload & Download",
                "File Deletion",
                "Finding File Metadata",
                "Unified Topology",
                "Explain",
                "Command Monitoring",
                "Detailed List",
                "What's New in 3.7",
                "What's New in 3.6"
            ],
            "paragraphs": "Learn what's new in: Version 4.6 Version 4.5 Version 4.4 Version 4.3 Version 4.2 Version 4.1 Version 4.0 Version 3.7 Version 3.6 New features of the 4.6 Node.js driver release include: To learn more, see  v4.6.0 Release Highlights . Improved the  ChangeStreamDocument  in TypeScript. Even distribution of server selection based on load across servers. See  v4.5.0 Release Highlights \non GitHub. New features of the 4.4 Node.js driver release include: KMIP provider support when using CSFLE. TLS support when using CSFLE. Hostname canonicalization now accepts \"none\", \"forward\", and \"forwardAndReverse\" as  authMechanismProperties  when using GSSAPI. In the 4.0.0 release of the driver, the deprecated  collection.count()  method was inadvertently changed to behave like  collection.countDocuments() .\nIn this release, the  collection.count()  method is updated to match legacy behavior: If a query is provided,  collection.count()  behaves the same as  collection.countDocuments()  and performs a collection scan. If no query is  provided,  collection.count()  behaves the same as  collection.estimatedDocumentCount()  and relies on\ncollection metadata. The  cursor.count()  method is deprecated and will be removed in the next major version, along with  collection.count() .\nUse the  collection.estimatedDocumentCount()  or  collection.countDocuments() \nmethods instead. New features of the 4.3 Node.js driver release include: SOCKS5 support Option to  disable UTF-8 validation Type inference for nested documents New features of the 4.2 Node.js driver release include: srvMaxHosts  and  srvServiceName  DNS seedlist  connection options New features of the 4.1 Node.js driver release include: Added load balanced connection support for all cluster types including\nthe beta  Serverless platform . Added support for the  advanceClusterTime()  method to determine if\nthe  ClientSession  should update its cluster time. New features of the 4.0 Node.js driver release include: In this release of the driver, the deprecated  collection.count()  method was inadvertently changed to\nbehave like  collection.countDocuments() . This behavior is corrected in  version 4.4 . We'd love to hear your TypeScript related feature requests. Please submit\nideas on our  JIRA project here . We've migrated the driver to TypeScript. You can now harness the type\nhinting and intellisense features in editors that support it to develop\nyour MongoDB applications. Enjoy the benefits of this work in pure JavaScript\nprojects as well. The underlying BSON library used by this version is now migrated to\nTypeScript. Inline documentation is now consistently formatted to improve display\nin editors. If you are a user of the community types  @types/mongodb , there will\n likely be issues  adopting the types from our codebase. We could not\nachieve a one to one match in types due to the details of writing the\ncodebase in TypeScript. The minimum supported version of Node.js is now v12.9 or greater for\nversion 4 of the driver. Support for our 3.x branches will continue\nuntil summer 2022 to allow time to upgrade. 3.x supports back to Node.js v4. Our Cursor implementation is now updated to make it clear what is possible\nbefore and after execution of an operation. There was inconsistency surrounding how the cursor would error if a\nsetting was applied after cursor execution began. Now, the cursor will\nthrow an error when attempting to apply operations in an invalid state,\nsimilar to the following: MongoError: Cursor is already initialized Affected classes: AbstractCursor FindCursor AggregationCursor ChangeStreamCursor  (This is the underlying cursor for  ChangeStream ) ListCollectionsCursor Our Cursor types no longer extend  Readable  directly. They must be\ntransformed into a stream by calling  cursor.stream() . Use  hasNext()  and  next()  for manual iteration.\nUse  for await of  syntax or any  Promise  helpers for\nasynchronous iteration. With type hinting, you should find that options passed to a  MongoClient \nare enumerated and discoverable. We've made a large effort to process\nall options in the driver to give early warnings about incompatible settings\nto get your app up and running in a correct state quickly. checkServerIdentity  is no longer checked before being passed to the\nunderlying Node API. Previously, accepted values were  false , or\na function. Now, the argument must be a function. Specifying a\nboolean will result in an error being thrown. It is no longer required to specify  useUnifiedTopology  or  useNewUrlParser . This method no longer supports a  strict  option, which returned\nan error if the collection did not exist. To assert the existence of\na collection, use the  listCollections()  method instead. BulkWriteError  is now renamed to  MongoBulkWriteError . When running bulk operations that make writes you can encounter errors\ndepending on your settings. Import the new class name  MongoBulkWriteError \nwhen testing for errors in bulk operations. DB  is no longer an  EventEmitter . Listen for events directly from your\n MongoClient  instance. The  Collection.group()  helper, deprecated since MongoDB 3.4,\nis now removed. Use the aggregation pipeline  $group \noperator instead. gssapiServiceName  is now removed. Use  authMechanismProperties.SERVICE_NAME  in the URI or as an option on  MongoClientOptions . Specifying username and password as options is only supported in the URI\nor as an option on  MongoClientOptions . The GridStore API (already deprecated in 3.x) is now replaced with  GridFSBucket .\nFor more information on  GridFS , see the  mongodb manual . Below are some snippets that represent equivalent operations. GridFSBucket uses the Node.js Stream API. You can replicate file seeking\nby using the  start  and  end  options, creating a download stream\nfrom your  GridFSBucket . GridFSBucket  does not need to be closed like  GridStore . File metadata that used to be accessible on the  GridStore  instance can be\nfound by querying the bucket. We internally now only manage a  unifiedTopology  when you connect\nto a  mongod . The differences between this and previous versions\nis  detailed here . It is no longer required to specify  useUnifiedTopology  or  useNewUrlParser . You must use the new  directConnection   option \nto connect to uninitialized replica set members. Support is now added for fine-grained verbosity modes. You can learn more\nabout each mode  here . The  instrument()  method is now removed. Use command monitoring instead.\nSee our guide on  command monitoring \nfor more information. To view a full list of breaking changes introduced in this version, see the  Breaking\nChanges section  in the Upgrade guide. New features of the 3.7 Node.js driver release include: Added support for load balancer mode while enabling the  useUnifiedTopology  option Added support for  Stable API  while enabling the  useUnifiedTopology  option New features of the 3.6 Node.js driver release include: Added support for the  MONGODB-AWS  authentication mechanism using Amazon Web Services (AWS) Identity and Access Management (IAM) credentials The  find()  method supports  allowDiskUse()  for sorts that require too much memory to execute in RAM The  update()  and  replaceOne()  methods support index hints A reduction in recovery time for topology changes and failover events Improvements in validation testing for the default  writeConcern Authentication requires fewer round trips to the server, resulting in faster connection setup Shorter Salted Challenge Response Authentication Mechanism ( SCRAM ) conversations Ability to create collections and indexes for multiple document transactions Running validation for a collection in the background",
            "code": [
                {
                    "lang": "js",
                    "value": "const fc = collection.find({a: 2.3}).skip(1)\nfor await (const doc of fc) {\n  console.log(doc)\n  fc.limit(1) // incorrect usage, cursor already executing\n}"
                },
                {
                    "lang": "js",
                    "value": "const cursor = collection.find({})\nconst stream = cursor.stream()\nstream.on(\"data\", data => console.log)\nstream.on(\"error\", () => client.close())"
                },
                {
                    "lang": "js",
                    "value": "const collections = (await db.listCollections({}, { nameOnly: true })\n  .toArray()).map(\n    ({name}) => name\n  );\nif (!collections.includes(myNewCollectionName)) {\n  throw new Error(`${myNewCollectionName} doesn't exist`);\n}"
                },
                {
                    "lang": "js",
                    "value": "?authMechanismProperties.SERVICE_NAME\n// or\nnew MongoClient(url, { SERVICE_NAME: \"alternateServiceName\" })"
                },
                {
                    "lang": "js",
                    "value": "new MongoClient(\"mongodb://username:password@<host><port>\")\n// or\nnew MongoClient(url, { auth: { username: \"<>\", password: \"<>\" } })"
                },
                {
                    "lang": "javascript",
                    "value": "// old way\nconst gs = new GridStore(db, filename, mode[, options])\n// new way\nconst bucket = new GridFSBucket(client.db('test')[,options])"
                },
                {
                    "lang": "js",
                    "value": "bucket.openDownloadStreamByName(filename, { start: 0, end: 100 })"
                },
                {
                    "lang": "javascript",
                    "value": "await client.connect();\nconst filename = 'test.txt'; // whatever local file name you want\nconst db = client.db();\nconst bucket = new GridFSBucket(db);\n\nfs.createReadStream(filename)\n  .pipe(bucket.openUploadStream(filename))\n  .on('error', console.error)\n  .on('finish', () => {\n    console.log('done writing to db!');\n\n    bucket\n      .find()\n      .toArray()\n      .then(files => {\n        console.log(files);\n\n        bucket\n          .openDownloadStreamByName(filename)\n          .pipe(fs.createWriteStream('downloaded_' + filename))\n          .on('error', console.error)\n          .on('finish', () => {\n            console.log('done downloading!');\n            client.close();\n          });\n      });\n  });"
                },
                {
                    "lang": "js",
                    "value": "// old way\nGridStore.unlink(db, name, callback);\n// new way\nbucket.delete(file_id);"
                },
                {
                    "lang": "js",
                    "value": "const fileMetaDataList: GridFSFile[] = bucket.find({}).toArray();"
                }
            ],
            "preview": "Learn what's new in:",
            "tags": null,
            "facets": null
        },
        {
            "slug": "",
            "title": "MongoDB Node Driver",
            "headings": [
                "Introduction",
                "Quick Start",
                "Quick Reference",
                "What's New",
                "Usage Examples",
                "Fundamentals",
                "API",
                "FAQ",
                "Issues & Help",
                "Compatibility",
                "Upgrade Driver Versions",
                "Learn",
                "Developer Hub",
                "MongoDB University",
                "Take the free online course taught by MongoDB instructors"
            ],
            "paragraphs": "Welcome to the documentation site for the official MongoDB Node.js driver.\nYou can add the driver to your application to work with MongoDB\nin JavaScript or TypeScript. For more information about downloading and\ninstalling the Node.js driver, see\n Download and Install  in the\nQuick Start guide. Learn how to establish a connection to MongoDB Atlas and begin\nworking with data in the  Quick Start  section. See driver syntax examples for common MongoDB commands in the\n Quick Reference  section. For a list of new features and changes in each version, see the\n What's New  section. For fully runnable code snippets and explanations for common\nmethods, see the  Usage Examples  section. Learn how to perform the following tasks using the Node.js driver in the\nFundamentals section: Connect to MongoDB Use the Stable API Authenticate with MongoDB Read from and Write to MongoDB Access Return Values Transform your Data Create and Manage Transactions Create Indexes to Speed Up Queries Sort Using Collations Log Events in the Driver Monitor Driver Events Store and Retrieve Large Files in MongoDB Encrypt Fields from the Client Create and Query Time Series Collection Specify Type Parameters with TypeScript Specify BSON Serialization Settings For detailed information about classes and methods in the MongoDB\nNode.js driver, see the  MongoDB Node.js driver API documentation  . For answers to commonly asked questions about the MongoDB\nNode.js Driver, see the  Frequently Asked Questions (FAQ) \nsection. Learn how to report bugs, contribute to the driver, and find\nadditional resources for asking questions and receiving help in the\n Issues & Help  section. For the compatibility charts that show the recommended Node.js\nDriver version for each MongoDB Server version, see the\n Compatibility  section. Learn what changes you may need to make to your application to upgrade\ndriver versions in the  Upgrade Driver Versions  section. Visit the Developer Hub and MongoDB University to learn more about the\nMongoDB Node.js driver. The Developer Hub provides tutorials and social engagement for\ndevelopers. To learn how to use MongoDB features with the Node.js driver, see the\n How To's and Articles page . To ask questions and engage in discussions with fellow developers using\nthe Node.js driver, see the  forums page . MongoDB University provides free courses to teach everyone how to use MongoDB. Using MongoDB with Node.js Learn the essentials of Node.js application development with MongoDB.",
            "code": [],
            "preview": "Welcome to the documentation site for the official MongoDB Node.js driver.\nYou can add the driver to your application to work with MongoDB\nin JavaScript or TypeScript. For more information about downloading and\ninstalling the Node.js driver, see\nDownload and Install in the\nQuick Start guide.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "usage-examples",
            "title": "Usage Examples",
            "headings": [
                "Overview",
                "How to Use the Usage Examples",
                "Available Usage Examples"
            ],
            "paragraphs": "Usage examples provide convenient starting points for popular MongoDB\noperations. Each example provides: an explanation of the operation in the example showing the\npurpose and a sample use case for the method an explanation of how to use the operation, including parameters,\nreturn values, and common exceptions you might encounter a full Node.js program that you can copy and paste to run the example\nin your own environment These examples use the\n MongoDB Atlas sample data \ndatabase. You can use this sample data on the free tier\nof MongoDB Atlas by following the  Get Started with Atlas  guide or you\ncan  import the sample dataset into a local MongoDB instance . Once you have imported the dataset, you can copy and paste a usage\nexample into your development environment of choice. You can follow the\n quick start guide  to learn more about getting\nstarted with Node.js, npm, and the Node.js driver. Once you've copied\na usage example, you'll have to edit one line to get the example running\nwith your instance of MongoDB: All examples use ES module imports. You can\n enable ES module imports \nby adding the following key-value pair to your package.json file: You can use the  Atlas Connectivity Guide  to enable connectivity to your instance of\nAtlas and find the  connection string  to replace the  uri  variable in the\nusage example. If your instance uses  SCRAM authentication , you can replace  <user>  with your username,\n <password>  with your password, and  <cluster-url>  with the IP\naddress or URL of your instance. Consult the\n Connection Guide  for more information\nabout getting connected to your MongoDB instance. You can use any usage example with CommonJS  require . To use CommonJS  require , you\nmust swap out the ES module  import  statement for your CommonJS  require \nstatement. Click on the tabs to see the syntax for importing the driver with ES module\n import  and CommonJS  require : Find Operations Insert Operations Update Operations Delete Operations Count Documents Retrieve Distinct Values of a Field Run a Command Watch for Changes Perform Bulk Operations",
            "code": [
                {
                    "lang": "javascript",
                    "value": "// Replace the following with your MongoDB deployment's connection string.\nconst uri =\n   \"mongodb+srv://<user>:<password>@<cluster-url>?retryWrites=true&writeConcern=majority\";"
                },
                {
                    "lang": "json",
                    "value": "\"type\": \"module\""
                },
                {
                    "lang": "javascript",
                    "value": "import { MongoClient } from 'mongodb'"
                },
                {
                    "lang": "javascript",
                    "value": "const { MongoClient } = require('mongodb')"
                }
            ],
            "preview": "Usage examples provide convenient starting points for popular MongoDB\noperations. Each example provides:",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals",
            "title": "Fundamentals",
            "headings": [],
            "paragraphs": "Learn how to perform the following tasks using the Node.js driver in the\nFundamentals section: Connect to MongoDB Use the Stable API Authenticate with MongoDB Read from and Write to MongoDB Access Return Values Transform your Data Create and Manage Transactions Create Indexes to Speed Up Queries Sort Using Collations Log Events in the Driver Monitor Driver Events Store and Retrieve Large Files in MongoDB Encrypt Fields from the Client Create and Query Time Series Collection Specify Type Parameters with TypeScript Specify BSON Serialization Settings",
            "code": [],
            "preview": null,
            "tags": null,
            "facets": null
        },
        {
            "slug": "usage-examples/find-operations",
            "title": "Find Operations",
            "headings": [],
            "paragraphs": "Find a Document Find Multiple Documents",
            "code": [],
            "preview": null,
            "tags": null,
            "facets": null
        },
        {
            "slug": "usage-examples/insert-operations",
            "title": "Insert Operations",
            "headings": [],
            "paragraphs": "Insert a Document Insert Multiple Documents",
            "code": [],
            "preview": null,
            "tags": null,
            "facets": null
        },
        {
            "slug": "usage-examples/deleteOne",
            "title": "Delete a Document",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can delete a single document in a collection with\n collection.deleteOne() .\nThe  deleteOne()  method uses a query document that you provide\nto match the subset of the documents in the collection that match\nthe query. If you do not provide a query document (or if you provide an\nempty document), MongoDB matches all documents in the collection and\ndeletes the first match. You can specify additional query options using the\n options  object passed as the second parameter of the\n deleteOne  method. You can also pass a\n callback method \nas an optional third parameter. For more information on this method,\nsee the\n deleteOne() API documentation . If you specify a callback method,  deleteOne()  returns nothing. If you\ndo not specify one, this method returns a  Promise  that resolves to the\nresult object when it completes. See our guide on  Promises and\nCallbacks  for more information, or the\n API documentation  for\ninformation on the result object. If your application requires the deleted document after deletion,\nconsider using the\n collection.findOneAndDelete() .\nmethod, which has a similar interface to  deleteOne()  but also\nreturns the deleted document. The following snippet deletes a single document from the  movies \ncollection. It uses a  query document  that configures the query\nto match movies with a  title  value of \"Annie Hall\". If you run the preceding example, you should see the following output: On subsequent runs of the preceding example, as you already deleted the document that\nmatched your query, you should see the following output: You can use this example to connect to an instance of MongoDB\nand interact with a database that contains sample data. To learn more about connecting to your MongoDB\ninstance and loading a sample dataset, see the  Usage Examples\nguide . The JavaScript and TypeScript code snippets above are identical. There are no\nTypeScript specific features of the driver relevant to this use case.",
            "code": [
                {
                    "lang": "none",
                    "value": "Successfully deleted one document."
                },
                {
                    "lang": "none",
                    "value": "No documents matched the query. Deleted 0 documents."
                },
                {
                    "lang": "javascript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"sample_mflix\");\n    const movies = database.collection(\"movies\");\n\n    // Query for a movie that has title \"Annie Hall\"\n    const query = { title: \"Annie Hall\" };\n\n    const result = await movies.deleteOne(query);\n    if (result.deletedCount === 1) {\n      console.log(\"Successfully deleted one document.\");\n    } else {\n      console.log(\"No documents matched the query. Deleted 0 documents.\");\n    }\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "javascript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"sample_mflix\");\n    const movies = database.collection(\"movies\");\n\n    // Query for a movie that has title \"Annie Hall\"\n    const query = { title: \"Annie Hall\" };\n\n    const result = await movies.deleteOne(query);\n    if (result.deletedCount === 1) {\n      console.log(\"Successfully deleted one document.\");\n    } else {\n      console.log(\"No documents matched the query. Deleted 0 documents.\");\n    }\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                }
            ],
            "preview": "You can delete a single document in a collection with\ncollection.deleteOne().\nThe deleteOne() method uses a query document that you provide\nto match the subset of the documents in the collection that match\nthe query. If you do not provide a query document (or if you provide an\nempty document), MongoDB matches all documents in the collection and\ndeletes the first match.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "usage-examples/insertMany",
            "title": "Insert Multiple Documents",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can insert multiple documents using the\n collection.insertMany()  method. The  insertMany()  takes an array\nof documents to insert into the specified collection. You can specify additional options in the  options  object passed as the\nsecond parameter of the  insertMany()  method. Specify  ordered:true \nto prevent inserting the remaining documents if the insertion failed for a\nprevious document in the array. Specifying incorrect parameters for your  insertMany()  operation can\ncause problems. Attempting to insert a field to a value that would violate\nunique index rules will throw a  duplicate key error . If you specify a callback method,  insertMany()  returns nothing. If you\ndo not specify one, this method returns a  Promise  that resolves to the\nresult object when it completes. See our guide on  Promises and\nCallbacks  for more information, or the\n API documentation  for\ninformation on the result object. If you run the preceding example, you should see the following output: You can use this example to connect to an instance of MongoDB\nand interact with a database that contains sample data. To learn more about connecting to your MongoDB\ninstance and loading a sample dataset, see the  Usage Examples\nguide .",
            "code": [
                {
                    "lang": "none",
                    "value": "3 documents were inserted"
                },
                {
                    "lang": "javascript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"insertDB\");\n    const foods = database.collection(\"foods\");\n\n    // create an array of documents to insert\n    const docs = [\n      { name: \"cake\", healthy: false },\n      { name: \"lettuce\", healthy: true },\n      { name: \"donut\", healthy: false }\n    ];\n\n    // this option prevents additional documents from being inserted if one fails\n    const options = { ordered: true };\n\n    const result = await foods.insertMany(docs, options);\n    console.log(`${result.insertedCount} documents were inserted`);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "typescript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\ninterface Food {\n  name: string;\n  healthy: boolean;\n}\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"insertDB\");\n    // Specifying a schema is optional, but it enables type hints on\n    // finds and inserts\n    const foods = database.collection<Food>(\"foods\");\n\n    const result = await foods.insertMany(\n      [\n        { name: \"cake\", healthy: false },\n        { name: \"lettuce\", healthy: true },\n        { name: \"donut\", healthy: false },\n      ],\n      { ordered: true }\n    );\n    console.log(`${result.insertedCount} documents were inserted`);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                }
            ],
            "preview": "You can insert multiple documents using the\ncollection.insertMany() method. The insertMany() takes an array\nof documents to insert into the specified collection.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "quick-reference",
            "title": "Quick Reference",
            "headings": [],
            "paragraphs": "This page shows the driver syntax for several MongoDB commands and links to\ntheir related reference and API documentation. Command Syntax",
            "code": [
                {
                    "lang": "js",
                    "value": "await coll.findOne({ title: 'Hamlet' });"
                },
                {
                    "lang": "js",
                    "value": "{ title: 'Hamlet', type: 'movie', ... }"
                },
                {
                    "lang": "js",
                    "value": "coll.find({ year: 2005 });"
                },
                {
                    "lang": "js",
                    "value": "[\n  { title: 'Christmas in Boston', year: 2005, ... },\n  { title: 'Chicken Little', year: 2005, ... },\n  ...\n]"
                },
                {
                    "lang": "javascript",
                    "value": "await coll.insertOne({ title: 'Jackie Robinson' });"
                },
                {
                    "lang": "javascript",
                    "value": "await coll.insertMany([\n  { title: 'Dangal', rating: 'Not Rated' },\n  { title: 'The Boss Baby', rating: 'PG' }\n ]);"
                },
                {
                    "lang": "js",
                    "value": "await coll.updateOne(\n  { title: 'Amadeus' },\n  { $set: { 'imdb.rating': 9.5 } }\n);"
                },
                {
                    "lang": "js",
                    "value": "{ title: 'Amadeus', imdb: { rating: 9.5, ... } }"
                },
                {
                    "lang": "js",
                    "value": "await coll.updateMany(\n  { year: 2001 },\n  { $inc: { 'imdb.votes': 100 } }\n);"
                },
                {
                    "lang": "js",
                    "value": "[\n  { title: 'A Beautiful Mind', year: 2001, imdb: { votes: 826257, ... },\n  { title: 'Shaolin Soccer', year: 2001, imdb: { votes: 65442, ... },\n  ...\n]"
                },
                {
                    "lang": "js",
                    "value": "await coll.updateOne(\n  { title: 'Cosmos' },\n  { $push: { genres: 'Educational' } }\n):"
                },
                {
                    "lang": "js",
                    "value": "{ title: 'Cosmos', genres: [ 'Documentary', 'Educational' ] }"
                },
                {
                    "lang": "js",
                    "value": "await coll.replaceOne(\n  { name: 'Deli Llama', address: '2 Nassau St' },\n  { name: 'Lord of the Wings', zipcode: 10001 }\n);"
                },
                {
                    "lang": "js",
                    "value": "{ name: 'Lord of the Wings', zipcode: 10001 }"
                },
                {
                    "lang": "javascript",
                    "value": "await coll.deleteOne({ title: 'Congo' });"
                },
                {
                    "lang": "javascript",
                    "value": "await coll.deleteMany({ title: { $regex: /^Shark.*/ } });"
                },
                {
                    "lang": "js",
                    "value": "await coll.bulkWrite([\n  {\n    insertOne: {\n      document: {\n        title: 'A New Movie',\n        year: 2022\n      }\n    }\n  },\n  {\n    deleteMany: {\n      filter: { year: { $lt: 1970 } }\n    }\n  }\n]);"
                },
                {
                    "lang": "js",
                    "value": "BulkWriteResult {\n  result: {\n    ...\n  },\n  ...\n}"
                },
                {
                    "lang": "javascript",
                    "value": "coll.watch([ { $match: { year: { $gte: 2022 } } } ]);"
                },
                {
                    "lang": "js",
                    "value": "const cursor = coll.find();\nawait cursor.forEach(console.dir);"
                },
                {
                    "lang": "js",
                    "value": "[\n  { title: '2001: A Space Odyssey', ... },\n  { title: 'The Sound of Music', ... },\n  ...\n]"
                },
                {
                    "lang": "js",
                    "value": "const cursor = coll.find();\nconst results = await cursor.toArray();"
                },
                {
                    "lang": "js",
                    "value": "[\n  { title: '2001: A Space Odyssey', ... },\n  { title: 'The Sound of Music', ... },\n  ...\n]"
                },
                {
                    "lang": "js",
                    "value": "await coll.countDocuments({ year: 2000 });"
                },
                {
                    "lang": "js",
                    "value": "618"
                },
                {
                    "lang": "js",
                    "value": "await coll.distinct('year');"
                },
                {
                    "lang": "js",
                    "value": "[ 1891, 1893, 1894, 1896, 1903, ... ]"
                },
                {
                    "lang": "js",
                    "value": "coll.find().limit(2);"
                },
                {
                    "lang": "js",
                    "value": "[\n  { title: 'My Neighbor Totoro', ... },\n  { title: 'Am\u00e9lie', ... }\n]"
                },
                {
                    "lang": "js",
                    "value": "collection.find({ title: { $regex: /^Rocky/} }, { skip: 2 });"
                },
                {
                    "lang": "js",
                    "value": "[\n  { title: 'Rocky III', ... },\n  { title: 'Rocky IV', ... },\n  { title: 'Rocky V'}, ... }\n]"
                },
                {
                    "lang": "js",
                    "value": "coll.find().sort({ year: 1});"
                },
                {
                    "lang": "js",
                    "value": "[\n  { title: 'Newark Athlete', year: 1891, ... },\n  { title: 'Blacksmith Scene', year: 1893, ...},\n  { title: 'Dickson Experimental Sound Film', year: 1894},\n  ...\n]"
                },
                {
                    "lang": "js",
                    "value": "coll.find().project({ _id: 0, year: 1, imdb: 1 });"
                },
                {
                    "lang": "js",
                    "value": "[\n  { year: 2012, imdb: { rating: 5.8, votes: 230, id: 8256 }},\n  { year: 1985, imdb: { rating: 7.0, votes: 447, id: 1654 }},\n  ...\n]"
                },
                {
                    "lang": "javascript",
                    "value": "await coll.createIndex({ title: 1, year: -1 });"
                },
                {
                    "lang": "js",
                    "value": "// only searches fields with text indexes\ncoll.find({ $text: { $search: 'zissou' } });"
                },
                {
                    "lang": "js",
                    "value": "[\n  { title: 'The Life Aquatic with Steve Zissou', ... }\n]"
                },
                {
                    "lang": "javascript",
                    "value": "\"dependencies\": {\n  \"mongodb\": \"^4.5\",\n  ...\n}"
                }
            ],
            "preview": "This page shows the driver syntax for several MongoDB commands and links to\ntheir related reference and API documentation.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "usage-examples/updateOne",
            "title": "Update a Document",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can update a single document using the\n collection.updateOne() \nmethod. The  updateOne()  method accepts a filter\ndocument and an update document. If the query matches documents in the\ncollection, the method applies the updates from the update document to fields\nand values of them. The update document contains  update operators  that instruct the method\non the changes to make to the matches. You can specify additional query options using the  options  object\npassed as the second parameter of the  updateOne()  method.\nSet the  upsert  option to  true  to create a new document\nif no documents match the filter. For additional information, see the\n updateOne() API documentation . updateOne()  throws an exception if an error occurs during execution.\nIf you specify a value in your update document for the immutable field\n _id , the method throws an exception. If your update document contains\na value that violates unique index rules, the method throws a  duplicate\nkey error  exception. If you specify a callback method,  updateOne()  returns nothing. If you\ndo not specify one, this method returns a  Promise  that resolves to the\nresult object when it completes. See our guide on  Promises and\nCallbacks  for more information, or see the\n API documentation  for\ninformation on the result object. If your application requires the document after updating,\nconsider using the\n collection.findOneAndUpdate() .\nmethod, which has a similar\ninterface to  updateOne()  but also returns the original or updated\ndocument. The following example uses the  $set  update operator which specifies\nupdate values for document fields. For more information on update operators,\nsee the  MongoDB update operator reference documentation . If you run the example above, you should see the following output: You can use this example to connect to an instance of MongoDB\nand interact with a database that contains sample data. To learn more about connecting to your MongoDB\ninstance and loading a sample dataset, see the  Usage Examples\nguide .",
            "code": [
                {
                    "lang": "none",
                    "value": "1 document(s) matched the filter, updated 1 document(s)"
                },
                {
                    "lang": "javascript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"sample_mflix\");\n    const movies = database.collection(\"movies\");\n\n    // create a filter for a movie to update\n    const filter = { title: \"Random Harvest\" };\n\n    // this option instructs the method to create a document if no documents match the filter\n    const options = { upsert: true };\n\n    // create a document that sets the plot of the movie\n    const updateDoc = {\n      $set: {\n        plot: `A harvest of random numbers, such as: ${Math.random()}`\n      },\n    };\n\n    const result = await movies.updateOne(filter, updateDoc, options);\n    console.log(\n      `${result.matchedCount} document(s) matched the filter, updated ${result.modifiedCount} document(s)`,\n    );\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "typescript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\ninterface Movie {\n  plot: string;\n  title: string;\n}\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"sample_mflix\");\n    const movies = database.collection<Movie>(\"movies\");\n\n    const result = await movies.updateOne(\n      { title: \"Random Harvest\" },\n      {\n        $set: {\n          plot: `A harvest of random numbers, such as: ${Math.random()}`,\n        },\n      },\n      { upsert: true }\n    );\n    console.log(\n      `${result.matchedCount} document(s) matched the filter, updated ${result.modifiedCount} document(s)`\n    );\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                }
            ],
            "preview": "You can update a single document using the\ncollection.updateOne()\nmethod. The updateOne() method accepts a filter\ndocument and an update document. If the query matches documents in the\ncollection, the method applies the updates from the update document to fields\nand values of them. The update document contains update operators that instruct the method\non the changes to make to the matches.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "usage-examples/delete-operations",
            "title": "Delete Operations",
            "headings": [],
            "paragraphs": "Delete a Document Delete Multiple Documents",
            "code": [],
            "preview": null,
            "tags": null,
            "facets": null
        },
        {
            "slug": "usage-examples/findOne",
            "title": "Find a Document",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can query for a single document in a collection with the\n collection.findOne()  method. The  findOne()  method uses a query\ndocument that you provide to match only the subset of the documents in the\ncollection that match the query. If you don't provide a query document or if\nyou provide an empty document, MongoDB matches all documents in the\ncollection. The  findOne()  operation only returns the first matched\ndocument. For more information on querying MongoDB, see our\n documentation on query documents . You can also define additional query options such as\n sort \nand  projection \nto configure the returned document. You can specify the additional options\nin the  options  object passed as the second parameter of the\n findOne  method. For detailed reference documentation, see\n collection.findOne() . If you specify a callback method,  findOne()  returns nothing. If you do\nnot specify one, this method returns a  Promise  that resolves to the\nresult object when it completes. See our guide on  Promises and\nCallbacks  for more information, or the\n API documentation  for\ninformation on the result object. The following snippet finds a single document from the  movies \ncollection. It uses the following parameters: If you run the preceding example, you should see the following output: A  query document  that configures the query to return only\nmovies with the title of exactly the text  'The Room' . A  sort  that organizes matched documents in descending order by\nrating, so if our query matches multiple documents the returned\ndocument will be the document with the highest rating. A  projection  that explicitly excludes the  _id  field from\nreturned documents and explicitly includes only the  title  and\n imdb  object (and its embedded fields). You can use this example to connect to an instance of MongoDB\nand interact with a database that contains sample data. To learn more about connecting to your MongoDB\ninstance and loading a sample dataset, see the  Usage Examples\nguide .",
            "code": [
                {
                    "lang": "javascript",
                    "value": "{ title: 'The Room', imdb: { rating: 3.5, votes: 25673, id: 368226 } }"
                },
                {
                    "lang": "javascript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"sample_mflix\");\n    const movies = database.collection(\"movies\");\n\n    // Query for a movie that has the title 'The Room'\n    const query = { title: \"The Room\" };\n\n    const options = {\n      // sort matched documents in descending order by rating\n      sort: { \"imdb.rating\": -1 },\n      // Include only the `title` and `imdb` fields in the returned document\n      projection: { _id: 0, title: 1, imdb: 1 },\n    };\n\n    const movie = await movies.findOne(query, options);\n\n    // since this method returns the matched document, not a cursor, print it directly\n    console.log(movie);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "typescript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\ninterface IMDB {\n  rating: number;\n  votes: number;\n  id: number;\n}\n\nexport interface Movie {\n  title: string;\n  year: number;\n  released: Date;\n  plot: string;\n  type: \"movie\" | \"series\";\n  imdb: IMDB;\n}\n\ntype MovieSummary = Pick<Movie, \"title\" | \"imdb\">;\n\nasync function run(): Promise<void> {\n  try {\n    await client.connect();\n\n    const database = client.db(\"sample_mflix\");\n    // Specifying a Schema is always optional, but it enables type hinting on\n    // finds and inserts\n    const movies = database.collection<Movie>(\"movies\");\n\n    const movie = await movies.findOne<MovieSummary>(\n      { title: \"The Room\" },\n      {\n        sort: { rating: -1 },\n        projection: { _id: 0, title: 1, imdb: 1 },\n      }\n    );\n    console.log(movie);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                }
            ],
            "preview": "You can query for a single document in a collection with the\ncollection.findOne() method. The findOne() method uses a query\ndocument that you provide to match only the subset of the documents in the\ncollection that match the query. If you don't provide a query document or if\nyou provide an empty document, MongoDB matches all documents in the\ncollection. The findOne() operation only returns the first matched\ndocument. For more information on querying MongoDB, see our\ndocumentation on query documents.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "usage-examples/count",
            "title": "Count Documents",
            "headings": [
                "Example"
            ],
            "paragraphs": "The Node.js driver provides two methods for counting documents in a\ncollection: estimatedDocumentCount()  is faster than  countDocuments()  because\nthe estimation uses the collection's metadata rather than scanning the\ncollection. In contrast,  countDocuments()  takes longer to return, but\nprovides an  accurate  count of the number of documents and supports\nspecifying a filter. Choose the appropriate method for your workload. To specify which documents you wish to count,  countDocuments() \naccepts a  query  parameter.\n countDocuments()  counts the documents that match the specified query. countDocuments()  and  estimatedDocumentCount()  support optional\nsettings that affect the method's execution. Refer to the reference\ndocumentation for each method for more information. If you specify a callback method,  countDocuments()  and\n estimatedDocumentCount()  return nothing. If you do not specify one,\nthis method returns a  Promise  that resolves to the result object\nwhen it completes. See our guide on  Promises and Callbacks  for more information, or the\n API documentation  for\ninformation on the result object. collection.countDocuments()  returns the number of documents in\nthe collection that match the specified query. If you specify an empty\nquery document,  countDocuments()  returns the total number of\ndocuments in the collection. collection.estimatedDocumentCount()  returns an\n estimation  of the number of documents in the collection based on\ncollection metadata. You can improve performance when using  countDocuments()  to return the\ntotal number of documents in a collection by avoiding a collection scan. To\ndo this, use a  hint  to take\nadvantage of the built-in index on the  _id  field. Use this technique only\nwhen calling  countDocuments()  with an empty query parameter. The following example estimates the number of documents in the\n movies  collection in the  sample_mflix  database, and then returns\nan accurate count of the number of documents in the  movies \ncollection with  Canada  in the  countries  field. If you run the preceding sample code, you should see the following output: You can use this example to connect to an instance of MongoDB\nand interact with a database that contains sample data. To learn more about connecting to your MongoDB\ninstance and loading a sample dataset, see the  Usage Examples\nguide . The JavaScript and TypeScript code snippets above are identical. There are no\nTypeScript specific features of the driver relevant to this use case.",
            "code": [
                {
                    "lang": "javascript",
                    "value": "collection.countDocuments({}, { hint: \"_id_\" });"
                },
                {
                    "lang": "none",
                    "value": "Estimated number of documents in the movies collection: 23541\nNumber of movies from Canada: 1349"
                },
                {
                    "lang": "javascript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"sample_mflix\");\n    const movies = database.collection(\"movies\");\n\n    // Estimate the total number of documents in the collection\n    // and print out the count.\n    const estimate = await movies.estimatedDocumentCount();\n    console.log(`Estimated number of documents in the movies collection: ${estimate}`);\n\n    // Query for movies from Canada.\n    const query = { countries: \"Canada\" };\n\n    // Find the number of documents that match the specified\n    // query, (i.e. with \"Canada\" as a value in the \"countries\" field)\n    // and print out the count.\n    const countCanada = await movies.countDocuments(query);\n    console.log(`Number of movies from Canada: ${countCanada}`);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "javascript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"sample_mflix\");\n    const movies = database.collection(\"movies\");\n\n    // Estimate the total number of documents in the collection\n    // and print out the count.\n    const estimate = await movies.estimatedDocumentCount();\n    console.log(`Estimated number of documents in the movies collection: ${estimate}`);\n\n    // Query for movies from Canada.\n    const query = { countries: \"Canada\" };\n\n    // Find the number of documents that match the specified\n    // query, (i.e. with \"Canada\" as a value in the \"countries\" field)\n    // and print out the count.\n    const countCanada = await movies.countDocuments(query);\n    console.log(`Number of movies from Canada: ${countCanada}`);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                }
            ],
            "preview": "The Node.js driver provides two methods for counting documents in a\ncollection:",
            "tags": null,
            "facets": null
        },
        {
            "slug": "usage-examples/distinct",
            "title": "Retrieve Distinct Values of a Field",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can retrieve a list of distinct values for a field across a collection by using\nthe  collection.distinct() \nmethod. Call the  distinct()  method on a  Collection  object with a document\nfield name parameter as a  String  to produce a list that contains one of each\nof the different values found in the specified document field as shown below: You can specify a document field within an  embedded document  using\n dot notation . If you call\n distinct()  on an document field that contains an array, the method\ntreats each element as a separate value. See the following example of\na method call to the  wins  field in the  awards  subdocument: You can specify additional query options using the  options  object passed\nas the third parameter to the  distinct()  method. For details on the\nquery parameters, see the\n distinct() method in the API documentation . If you specify a value for the document field name that is not of type\n String  such as a  Document ,  Array ,  Number , or  null ,\nthe method does not execute and returns a  TypeMismatch  error with a\nmessage that resembles the following: Visit  Retrieve Distinct Values  for more information about the  distinct() \nmethod. If you specify a callback method,  distinct()  returns nothing. If you do\nnot specify one, this method returns a  Promise  that resolves to the\nresult object when it completes. See our guide on  Promises and Callbacks \nfor more information, or the\n API documentation  for\ninformation on the result object. \"key\" had the wrong type. Expected string, found <non-string type> The following snippet retrieves a list of distinct values for the  year \ndocument field from the  movies  collection. It uses a query document to\nmatch movies that include \"Barbara Streisand\" as a  director . If you run the preceding example, you should see the following output: You can use this example to connect to an instance of MongoDB\nand interact with a database that contains sample data. To learn more about connecting to your MongoDB\ninstance and loading a sample dataset, see the  Usage Examples\nguide .",
            "code": [
                {
                    "lang": "javascript",
                    "value": "const distinctValues = collection.distinct(\"countries\", query);"
                },
                {
                    "lang": "javascript",
                    "value": "const distinctValues = collection.distinct(\"awards.wins\", query);"
                },
                {
                    "lang": "json",
                    "value": "[ 1983, 1991, 1996 ]"
                },
                {
                    "lang": "javascript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\nasync function run() {\n  try {\n    await client.connect();\n\n    // define a database and collection on which to run the method\n    const database = client.db(\"sample_mflix\");\n    const movies = database.collection(\"movies\");\n\n    // specify the document field\n    const fieldName = \"year\";\n\n    // specify an optional query document\n    const query = { directors: \"Barbra Streisand\" };\n\n    const distinctValues = await movies.distinct(fieldName, query);\n\n    console.log(distinctValues);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "typescript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\ninterface Movie {\n  directors: string;\n  year: number;\n}\n\nasync function run() {\n  try {\n    await client.connect();\n\n    // define a database and collection on which to run the method\n    const database = client.db(\"sample_mflix\");\n    const movies = database.collection<Movie>(\"movies\");\n\n    const distinctValues = await movies.distinct(\"year\", {\n      directors: \"Barbra Streisand\",\n    });\n\n    console.log(distinctValues);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                }
            ],
            "preview": "You can retrieve a list of distinct values for a field across a collection by using\nthe collection.distinct()\nmethod. Call the distinct() method on a Collection object with a document\nfield name parameter as a String to produce a list that contains one of each\nof the different values found in the specified document field as shown below:",
            "tags": null,
            "facets": null
        },
        {
            "slug": "compatibility",
            "title": "Compatibility",
            "headings": [
                "MongoDB Compatibility",
                "Compatibility Table Legend",
                "Language Compatibility"
            ],
            "paragraphs": "The following compatibility table specifies the recommended versions of\nthe MongoDB Node.js driver for use with MongoDB. The first column lists the driver version. Icon Explanation \u2713 All features are supported. \u229b The Driver version will work with the MongoDB version, but not all\nnew MongoDB features are supported. No mark The Driver version is not tested with the MongoDB version. Node.js Driver Version MongoDB 7.0 MongoDB 6.0 MongoDB 5.0 MongoDB 4.4 MongoDB 4.2 MongoDB 4.0 MongoDB 3.6 MongoDB 3.4 MongoDB 3.2 MongoDB 3.0 MongoDB 2.6 6.0 to 6.5 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 5.7 to 5.9 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 5.0 to 5.6 \u229b \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 4.8 to 4.17 \u229b \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 4.2 to 4.7 \u229b \u229b \u2713 \u2713 \u2713 \u2713 \u2713 4.0 to 4.1 \u229b \u229b \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 3.7  \u229b \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 3.6 \u229b \u229b \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 3.3 to 3.5 \u229b \u229b \u229b \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 3.1 to 3.2 \u229b \u229b \u229b \u229b \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 3.0 \u2713 \u2713 \u2713 \u2713 \u2713 2.2.12 \u2713 \u2713 \u2713 \u2713 2.0.14 \u2713 \u2713 1.4.29 \u2713 \u2713 When using Node.js Driver version 3.7, you must set the  useUnifiedTopology  flag to  true  for certain features. The following compatibility table specifies the recommended versions of\nthe MongoDB Node.js driver for use with a specific version of Node.js. The first column lists the driver version. For more information on how to read the compatibility tables, see our guide on\n MongoDB Compatibility Tables. Node.js Driver Version Node.js v20.x.x Node.js v18.x.x Node.js v16.x.x Node.js v14.x.x Node.js v12.x.x Node.js v10.x.x Node.js v8.X.X Node.js v6.X.X Node.js v4.X.X Node.js v0.12.X Node.js v0.10.X Node.js v0.8.X 6.X  \u2713 \u2713 \u2713 5.6.X to 5.9.X \u2713 \u2713 \u2713 \u2713 5.0.0 to 5.5.X \u2713 \u2713 \u2713 4.X \u2713 \u2713 \u2713 \u2713 3.X \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 2.X \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 >= 1.4.18 \u2713 \u2713 \u2713 1.4.X \u2713 \u2713 Versions 6.0 and later of the Node.js driver require Node.js v16.20.1 or later.",
            "code": [],
            "preview": "The following compatibility table specifies the recommended versions of\nthe MongoDB Node.js driver for use with MongoDB.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "usage-examples/changeStream",
            "title": "Watch for Changes",
            "headings": [
                "Open a Change Stream",
                "Example"
            ],
            "paragraphs": "You can watch for changes in MongoDB using the  watch()  method on the\nfollowing objects: For each object, the  watch()  method opens a  change stream  to\nemit  change event  documents when they occur. The  watch()  method optionally takes an  aggregation pipeline  which consists of an array of  aggregation stages \nas the first parameter. The aggregation stages filter and transform the change events. In the following snippet, the  $match  stage matches all change event documents with a  runtime  value of less than\n15, filtering all others out. The  watch()  method accepts an  options  object as the second parameter. Refer to the links at the end of this\nsection for more information on the settings you can configure with this object. The  watch()  method returns an instance of a  ChangeStream . You can read events from\nchange streams by iterating over them or listening for events. Select the tab that corresponds to the way you want to\nread events from the change stream below. Visit the following resources for additional material on the classes and\nmethods presented above: Collection Database MongoClient Using a  ChangeStream  in  EventEmitter  and  Iterator  mode\nconcurrently is not supported by the driver and causes an error. This\nis to prevent undefined behavior, where the driver cannot guarantee\nwhich consumer receives documents first. You can call methods on the  ChangeStream  object such as: hasNext()  to check for remaining documents in the stream next()  to request the next document in the stream close()  to close the ChangeStream You can attach listener functions to the  ChangeStream   object by calling the  on()  method. This method is inherited from the Javascript\n EventEmitter  class. Pass the string  \"change\"  as the first parameter and your callback function as the\nsecond parameter as shown below: The callback function triggers when a change event is emitted. You can specify logic in the callback to process\nthe change event document when it is received. You can control the change stream by calling  pause()  to stop emitting events or  resume()  to continue to emit events. To stop processing change events, call the  close()  method on the\n ChangeStream  instance. This closes the change stream and frees resources. Change streams Change events Aggregation pipeline Aggregation stages ChangeStream class API documentation Collection.watch() , Db.watch() , MongoClient.watch() API documentation The following example opens a change stream on the  haikus  collection in\nthe  insertDB  database. Let's create a listener function to receive and\nprint change events that occur on the collection. First, open the change stream on the collection and then define a callback\non the change stream using the  on()  method. Once set, generate a change\nevent by performing a change to the collection. To generate the change event on the collection, let's use  insertOne() \nmethod to add a new document. Since the  insertOne()  may run before the\nlistener function can register, we use a timer, defined as\n simulateAsyncPause  to wait 1 second before executing the insert. We also use  simulateAsyncPause  after the insertion of the document\nto provide ample time for the listener function to receive the change\nevent and for the callback to complete its execution before\nclosing the  ChangeStream  instance using the  close()  method. The timers used in this example are only necessary for this demonstration\nto make sure there is enough time to register listener and have the\ncallback process the event before exiting. If you run the preceding example, you should see the following output: You can use this example to connect to an instance of MongoDB\nand interact with a database that contains sample data. To learn more about connecting to your MongoDB\ninstance and loading a sample dataset, see the  Usage Examples\nguide . The JavaScript and TypeScript code snippets above are identical. There are no\nTypeScript specific features of the driver relevant to this use case. Change events that contain information on update operations only return the modified\nfields by default rather than the full updated document. You can configure\nyour change stream to also return the most current version of the document\nby setting the  fullDocument  field of the options object to\n \"updateLookup\"  as follows:",
            "code": [
                {
                    "lang": "javascript",
                    "value": "const pipeline = [ { $match: { runtime: { $lt: 15 } } } ];\nconst changeStream = collection.watch(pipeline);"
                },
                {
                    "lang": "javascript",
                    "value": "changeStream.on(\"change\", (changeEvent) => { /* your callback function */ });"
                },
                {
                    "lang": "javascript",
                    "value": "changeStream.close();"
                },
                {
                    "lang": "javascript",
                    "value": "received a change to the collection:          {\n  _id: { _data: '825EC...' },\n  operationType: 'insert',\n  clusterTime: new Timestamp { ... },\n  fullDocument: { _id: new ObjectId(...), title: 'Record of a Shriveled Datum', content: 'No bytes, no problem. Just insert a document, in MongoDB' },\n  ns: { db: 'insertDB', coll: 'haikus' },\n  documentKey: { _id: new ObjectId(...) }\n}\nclosed the change stream"
                },
                {
                    "lang": "javascript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\nconst simulateAsyncPause = () =>\n  new Promise(resolve => {\n    setTimeout(() => resolve(), 1000);\n  });\n\nlet changeStream;\nasync function run() {\n  try {\n    await client.connect();\n    const database = client.db(\"insertDB\");\n    const collection = database.collection(\"haikus\");\n\n    // open a Change Stream on the \"haikus\" collection\n    changeStream = collection.watch();\n\n    // set up a listener when change events are emitted\n    changeStream.on(\"change\", next => {\n      // process any change event\n      console.log(\"received a change to the collection: \\t\", next);\n    });\n\n    await simulateAsyncPause();\n\n    await collection.insertOne({\n      title: \"Record of a Shriveled Datum\",\n      content: \"No bytes, no problem. Just insert a document, in MongoDB\",\n    });\n\n    await simulateAsyncPause();\n\n    await changeStream.close();\n    \n    console.log(\"closed the change stream\");\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);"
                },
                {
                    "lang": "javascript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\nconst simulateAsyncPause = () =>\n  new Promise(resolve => {\n    setTimeout(() => resolve(), 1000);\n  });\n\nlet changeStream;\nasync function run() {\n  try {\n    await client.connect();\n    const database = client.db(\"insertDB\");\n    const collection = database.collection(\"haikus\");\n\n    // open a Change Stream on the \"haikus\" collection\n    changeStream = collection.watch();\n\n    // set up a listener when change events are emitted\n    changeStream.on(\"change\", next => {\n      // process any change event\n      console.log(\"received a change to the collection: \\t\", next);\n    });\n\n    await simulateAsyncPause();\n\n    await collection.insertOne({\n      title: \"Record of a Shriveled Datum\",\n      content: \"No bytes, no problem. Just insert a document, in MongoDB\",\n    });\n\n    await simulateAsyncPause();\n\n    await changeStream.close();\n    \n    console.log(\"closed the change stream\");\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);"
                },
                {
                    "lang": "javascript",
                    "value": "const options = { fullDocument: \"updateLookup\" };\n// This could be any pipeline.\nconst pipeline = [];\n\nconst changeStream = collection.watch(pipeline, options);"
                }
            ],
            "preview": "You can watch for changes in MongoDB using the watch() method on the\nfollowing objects:",
            "tags": null,
            "facets": null
        },
        {
            "slug": "usage-examples/updateMany",
            "title": "Update Multiple Documents",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can update multiple documents using the\n collection.updateMany()  method.\nThe  updateMany()  method accepts a filter document and an update document. If the query matches documents in the\ncollection, the method applies the updates from the update document to fields\nand values of the matching documents. The update document requires an  update operator  to modify a field in a document. You can specify additional options in the  options  object passed in\nthe third parameter of the  updateMany()  method. For more detailed\ninformation, see\n the updateMany() API documentation . If you specify a callback method,  updateMany()  returns nothing. If you\ndo not specify one, this method returns a  Promise  that resolves to the\nresult object when it completes. See our guide on  Promises and\nCallbacks  for more information, or see the\n API documentation  for\ninformation on the result object. If you run the preceding example, you should see the following output: You can use this example to connect to an instance of MongoDB\nand interact with a database that contains sample data. To learn more about connecting to your MongoDB\ninstance and loading a sample dataset, see the  Usage Examples\nguide .",
            "code": [
                {
                    "lang": "none",
                    "value": "Updated 477 documents"
                },
                {
                    "lang": "javascript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"sample_mflix\");\n    const movies = database.collection(\"movies\");\n\n    // create a filter to update all movies with a 'G' rating\n    const filter = { rated: \"G\" };\n\n    // increment every document matching the filter with 2 more comments\n    const updateDoc = {\n      $set: {\n        random_review: `After viewing I am ${\n          100 * Math.random()\n        }% more satisfied with life.`,\n      },\n    };\n    const result = await movies.updateMany(filter, updateDoc);\n    console.log(`Updated ${result.modifiedCount} documents`);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "typescript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\nenum Rating {\n  G = \"G\",\n  PG = \"PG\",\n  PG_13 = \"PG-13\",\n  R = \"R\",\n  NR = \"NOT RATED\",\n}\n\ninterface Movie {\n  rated: Rating;\n  random_review?: string;\n}\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"sample_mflix\");\n    const movies = database.collection<Movie>(\"movies\");\n    const result = await movies.updateMany(\n      { rated: Rating.G },\n      {\n        $set: {\n          random_review: `After viewing I am ${\n            100 * Math.random()\n          }% more satisfied with life.`,\n        },\n      }\n    );\n    console.log(`Updated ${result.modifiedCount} documents`);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                }
            ],
            "preview": "You can update multiple documents using the\ncollection.updateMany() method.\nThe updateMany() method accepts a filter document and an update document. If the query matches documents in the\ncollection, the method applies the updates from the update document to fields\nand values of the matching documents. The update document requires an update operator to modify a field in a document.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "usage-examples/update-and-replace-operations",
            "title": "Update & Replace Operations",
            "headings": [],
            "paragraphs": "Update a Document Update Multiple Documents Replace a Document",
            "code": [],
            "preview": null,
            "tags": null,
            "facets": null
        },
        {
            "slug": "usage-examples/replaceOne",
            "title": "Replace a Document",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can replace a single document using the\n collection.replaceOne()  method.\n replaceOne()  accepts a query document and a replacement document. If\nthe query matches a document in the collection, it replaces the first\ndocument that matches the query with the provided replacement document.\nThis operation removes all fields and values in the original document and\nreplaces them with the fields and values in the replacement document. The\nvalue of the  _id  field remains the same unless you explicitly specify\na new value for  _id  in the replacement document. You can specify additional options, such as  upsert , using the\noptional  options  parameter. If you set the  upsert  option field to\n true  the method inserts a new document if no document matches the query. The  replaceOne()  method throws an exception if an error occurs\nduring execution. For example, if you specify a value that violates a\nunique index rule,  replaceOne()  throws a  duplicate key error . If you specify a callback method,  replaceOne()  returns nothing. If you\ndo not specify one, this method returns a  Promise  that resolves to the\nresult object when it completes. See our guide on  Promises and\nCallbacks  for more information, or the\n API documentation  for\ninformation on the result object. If your application requires the document after updating,\nuse the  collection.findOneAndReplace() \nmethod which has a similar interface to  replaceOne() .\nYou can configure  findOneAndReplace()  to return either the\noriginal matched document or the replacement document. If you run the preceding example, you should see the following output: You can use this example to connect to an instance of MongoDB\nand interact with a database that contains sample data. To learn more about connecting to your MongoDB\ninstance and loading a sample dataset, see the  Usage Examples\nguide .",
            "code": [
                {
                    "lang": "none",
                    "value": "Modified 1 document(s)"
                },
                {
                    "lang": "javascript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"sample_mflix\");\n    const movies = database.collection(\"movies\");\n\n    // create a query for a movie to update\n    const query = { title: { $regex: \"The Cat from\" } };\n    // create a new document that will be used to replace the existing document\n    const replacement = {\n      title: `The Cat from Sector ${Math.floor(Math.random() * 1000) + 1}`,\n    };\n\n    const result = await movies.replaceOne(query, replacement);\n    console.log(`Modified ${result.modifiedCount} document(s)`);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "typescript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\ninterface Movie {\n  title: string;\n}\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"sample_mflix\");\n    const movies = database.collection<Movie>(\"movies\");\n\n    const result = await movies.replaceOne(\n      { title: { $regex: \"The Cat from\" } },\n      {\n        title: `The Cat from Sector ${Math.floor(Math.random() * 1000) + 1}`,\n      }\n    );\n    console.log(`Modified ${result.modifiedCount} document(s)`);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                }
            ],
            "preview": "You can replace a single document using the\ncollection.replaceOne() method.\nreplaceOne() accepts a query document and a replacement document. If\nthe query matches a document in the collection, it replaces the first\ndocument that matches the query with the provided replacement document.\nThis operation removes all fields and values in the original document and\nreplaces them with the fields and values in the replacement document. The\nvalue of the _id field remains the same unless you explicitly specify\na new value for _id in the replacement document.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "usage-examples/find",
            "title": "Find Multiple Documents",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can query for multiple documents in a collection with\n collection.find() . The  find()  method uses a query document that you\nprovide to match the subset of the documents in the collection that match the\nquery. If you don't provide a query document (or if you provide an empty\ndocument), MongoDB returns all documents in the collection. For more\ninformation on querying MongoDB, see our\n documentation on query documents . You can also define additional query options such as\n sort \nand\n projection \nto configure the result set. You can specify these in the options\nparameter in your  find()  method call in  sort  and  projection \nobjects. See  collection.find()  for more\ninformation on the parameters you can pass to the method. The  find()  method returns a  FindCursor  that\nmanages the results of your query. You can iterate through the matching\ndocuments using one of the following  cursor methods : If no documents match the query,  find()  returns an empty cursor. next() toArray() forEach() The following snippet finds documents from the  movies  collection. It\nuses the following parameters: If you run the preceding example, you should see the following output: The  sort  and  projection  options can also be specified as methods\n( sort()  and  project() , respectively) chained to the  find()  method.\nThe following two commands are equivalent: A  query document  that configures the query to return only\nmovies with a runtime of less than 15 minutes. A  sort  that organizes returned documents in ascending order by\ntitle (alphabetical order in which \"A\" comes before \"Z\" and \"1\" before\n\"9\"). A  projection  that explicitly excludes the  _id  field from\nreturned documents and explicitly includes only the  title  and\n imdb  object (and its embedded fields). You can use this example to connect to an instance of MongoDB\nand interact with a database that contains sample data. To learn more about connecting to your MongoDB\ninstance and loading a sample dataset, see the  Usage Examples\nguide .",
            "code": [
                {
                    "lang": "javascript",
                    "value": "{ title: '10 Minutes', imdb: { rating: 7.9, votes: 743, id: 339976 } }\n{ title: '3x3', imdb: { rating: 6.9, votes: 206, id: 1654725 } }\n{ title: '7:35 in the Morning', imdb: { rating: 7.3, votes: 1555, id: 406501 } }\n{ title: '8', imdb: { rating: 7.8, votes: 883, id: 1592502 } }\n..."
                },
                {
                    "lang": "javascript",
                    "value": "collection.find({ runtime: { $lt: 15 } }, { sort: { title: 1 }, projection: { _id: 0, title: 1, imdb: 1 }});\ncollection.find({ runtime: { $lt: 15 } }).sort({ title: 1}).project({ _id: 0, title: 1, imdb: 1 });"
                },
                {
                    "lang": "javascript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"sample_mflix\");\n    const movies = database.collection(\"movies\");\n\n    // query for movies that have a runtime less than 15 minutes\n    const query = { runtime: { $lt: 15 } };\n\n    const options = {\n      // sort returned documents in ascending order by title (A->Z)\n      sort: { title: 1 },\n      // Include only the `title` and `imdb` fields in each returned document\n      projection: { _id: 0, title: 1, imdb: 1 },\n    };\n\n    const cursor = movies.find(query, options);\n\n    // print a message if no documents were found\n    if ((await movies.countDocuments(query)) === 0) {\n      console.log(\"No documents found!\");\n    }\n\n    // replace console.dir with your callback to access individual elements\n    await cursor.forEach(console.dir);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "typescript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\ntype Minutes = number;\n\ninterface IMDB {\n  rating: number;\n  votes: number;\n  id: number;\n}\n\ninterface Movie {\n  title: string;\n  imdb: IMDB;\n  runtime: Minutes;\n}\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"sample_mflix\");\n    const movies = database.collection<Movie>(\"movies\");\n\n    const query = { runtime: { $lt: 15 } };\n    const cursor = movies.find<Movie>(\n      query,\n      {\n        sort: { title: 1 },\n        projection: { _id: 0, title: 1, imdb: 1 },\n      }\n    );\n\n    if ((await movies.countDocuments(query)) === 0) {\n      console.warn(\"No documents found!\");\n    }\n\n    await cursor.forEach(console.dir);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                }
            ],
            "preview": "You can query for multiple documents in a collection with\ncollection.find(). The find() method uses a query document that you\nprovide to match the subset of the documents in the collection that match the\nquery. If you don't provide a query document (or if you provide an empty\ndocument), MongoDB returns all documents in the collection. For more\ninformation on querying MongoDB, see our\ndocumentation on query documents.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "usage-examples/command",
            "title": "Run a Command",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can run all raw database operations using the\n db.command()  method. Call the  command()  method with\nyour command object on an instance of a database for diagnostic and\nadministrative tasks such as fetching server stats or initializing a replica\nset. You can specify additional options in the  options  object passed in\nthe second parameter of the  command()  method. For more information\non the options you can pass, see the\n db.command() API documentation . You can\nalso pass a  callback method  as an\noptional third parameter. If you specify a callback method,  command()  returns nothing. If you do\nnot specify one, this method returns a  Promise  that resolves to the\nresult object when it completes. See our guide on  Promises and\nCallbacks  for more information, or the\n API documentation  for\ninformation on the result object. Use the  MongoDB Shell  for administrative tasks instead of\nthe Node.js driver whenever possible. When you run the preceding command, you should see the following output: You can use this example to connect to an instance of MongoDB\nand interact with a database that contains sample data. To learn more about connecting to your MongoDB\ninstance and loading a sample dataset, see the  Usage Examples\nguide . The JavaScript and TypeScript code snippets above are identical. There are no\nTypeScript specific features of the driver relevant to this use case.",
            "code": [
                {
                    "lang": "javascript",
                    "value": "{\n  db: 'sample_mflix',\n  collections: 6,\n  views: 0,\n  objects: 75620,\n  ...\n}"
                },
                {
                    "lang": "javascript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const db = client.db(\"sample_mflix\");\n    // find the storage statistics for the \"sample_mflix\" database using the 'dbStats' command\n    const result = await db.command({\n      dbStats: 1,\n    });\n    console.log(result);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "javascript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const db = client.db(\"sample_mflix\");\n    // find the storage statistics for the \"sample_mflix\" database using the 'dbStats' command\n    const result = await db.command({\n      dbStats: 1,\n    });\n    console.log(result);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                }
            ],
            "preview": "You can run all raw database operations using the\ndb.command() method. Call the command() method with\nyour command object on an instance of a database for diagnostic and\nadministrative tasks such as fetching server stats or initializing a replica\nset.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "usage-examples/deleteMany",
            "title": "Delete Multiple Documents",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can delete several documents in a collection at once using the\n collection.deleteMany()  method.\nPass a query document to the  deleteMany()  method to specify a subset\nof documents in the collection to delete. If you do not provide a query\ndocument (or if you provide an empty document), MongoDB matches all documents\nin the collection and deletes them. While you can use  deleteMany() \nto delete all documents in a collection, consider using\n drop()  instead for better performance\nand clearer code. You can specify additional options in the  options  object passed in\nthe second parameter of the  deleteMany()  method. You can also pass a\ncallback method as the optional third parameter. For more detailed\ninformation, see the\n deleteMany() API documentation . If you specify a callback method,  deleteMany()  returns nothing. If you\ndo not specify one, this method returns a  Promise  that resolves to the\nresult object when it completes. See our guide on  Promises and\nCallbacks  for more information, or the\n API documentation  for\ninformation on the result object. The following snippet deletes multiple documents from the  movies \ncollection. It uses a  query document  that configures the query to\nmatch and delete movies with the title \"Santa Claus\". The first time you run the preceding example, you should see the following output: On subsequent runs of the example, as you already deleted all relevant\ndocuments, you should see the following output: You can use this example to connect to an instance of MongoDB\nand interact with a database that contains sample data. To learn more about connecting to your MongoDB\ninstance and loading a sample dataset, see the  Usage Examples\nguide .",
            "code": [
                {
                    "lang": "none",
                    "value": "Deleted 19 documents"
                },
                {
                    "lang": "none",
                    "value": "Deleted 0 documents"
                },
                {
                    "lang": "javascript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"sample_mflix\");\n    const movies = database.collection(\"movies\");\n    // Query for all movies with a title containing the string \"Santa\"\n    const query = { title: { $regex: \"Santa\" } };\n\n    const result = await movies.deleteMany(query);\n    console.log(\"Deleted \" + result.deletedCount + \" documents\");\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "typescript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\ninterface Movie {\n  title: string;\n}\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"sample_mflix\");\n    const movies = database.collection<Movie>(\"movies\");\n    const result = await movies.deleteMany({ title: { $regex: \"Santa\" } });\n    console.log(\"Deleted \" + result.deletedCount + \" documents\");\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                }
            ],
            "preview": "You can delete several documents in a collection at once using the\ncollection.deleteMany() method.\nPass a query document to the deleteMany() method to specify a subset\nof documents in the collection to delete. If you do not provide a query\ndocument (or if you provide an empty document), MongoDB matches all documents\nin the collection and deletes them. While you can use deleteMany()\nto delete all documents in a collection, consider using\ndrop() instead for better performance\nand clearer code.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/monitoring",
            "title": "Monitoring",
            "headings": [],
            "paragraphs": "Cluster Monitoring : monitoring\nchanges in a cluster Command Monitoring : monitoring\nthe execution status of commands Connection Pool Monitoring : monitoring\nthe driver's connection pool",
            "code": [],
            "preview": null,
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/connection",
            "title": "Connection",
            "headings": [
                "Overview"
            ],
            "paragraphs": "Learn how to configure your application's connection to a MongoDB\ndeployment using the Node.js driver. In the following sections, you will\nlearn: For information about authenticating to MongoDB,\nsee  Authentication  and\n Enterprise Authentication Mechanisms . How to Connect to MongoDB The Available Connection Options How to Enable Network Compression How to Enable TLS on a Connection How to Connect to MongoDB Atlas from AWS Lambda",
            "code": [],
            "preview": "Learn how to configure your application's connection to a MongoDB\ndeployment using the Node.js driver. In the following sections, you will\nlearn:",
            "tags": null,
            "facets": null
        },
        {
            "slug": "usage-examples/bulkWrite",
            "title": "Perform Bulk Operations",
            "headings": [
                "Example"
            ],
            "paragraphs": "The  bulkWrite()  method performs batch write operations against a\n single  collection. This method reduces the number of network round trips from\nyour application to the server which therefore increases the throughput and\nperformance. Bulk writes return a collection of results for all operations\nonly after  all  operations passed to the method complete. You can specify one or more of the following write operations in\n bulkWrite() : The  bulkWrite()  method accepts the following parameters: If you create an index with a  unique index \nconstraint, you might encounter a duplicate key write error during an\noperation in the following format: Similarly, if you attempt to perform a bulk write against a collection\nthat uses  schema validation , you may\nencounter warnings or errors related to the formatting of inserted or\nmodified documents. If you specify a callback method,  bulkWrite()  returns nothing. If you\ndo not specify one, this method returns a  Promise  that resolves to\nthe result object when it completes. See our guide on  Promises\nand Callbacks  for more information, or the\n API documentation  for information on\nthe result object. insertOne updateOne updateMany deleteOne deleteMany replaceOne operations : specifies the bulk write operations to\nperform. Pass each operation to  bulkWrite()  as an object in\nan array. For examples that show the syntax for each write operation, see\nthe  bulkWrite API documentation . options :  optional  settings that affect the execution\nof the operation, such as whether the write operations should execute in\nsequential order and the write concern. By default, MongoDB executes bulk write operations one-by-one in the\nspecified order (i.e. serially). During an ordered bulk write, if\nan error occurs during the processing of an operation, MongoDB returns\nwithout processing the remaining operations in the list. In contrast,\nwhen  ordered  is  false , MongoDB continues to process remaining\nwrite operations in the list. Unordered operations are theoretically faster\nsince MongoDB can execute them in parallel, but should only be used if\nthe writes do not depend on order. The following code sample performs a bulk write operation on the\n theaters  collection in the  sample_mflix  database. The example call\nto  bulkWrite()  includes examples of  insertOne ,  updateMany , and\n deleteOne  write operations: When you run the preceding example, you should see the following output: You can use this example to connect to an instance of MongoDB\nand interact with a database that contains sample data. To learn more about connecting to your MongoDB\ninstance and loading a sample dataset, see the  Usage Examples\nguide .",
            "code": [
                {
                    "lang": "sh",
                    "value": "Error during bulkWrite, BulkWriteError: E11000 duplicate key error collection: ..."
                },
                {
                    "lang": "javascript",
                    "value": "BulkWriteResult {\n  result: {\n    ok: 1,\n    writeErrors: [],\n    writeConcernErrors: [],\n    insertedIds: [ [Object], [Object] ],\n    nInserted: 2,\n    nUpserted: 0,\n    nMatched: 1,\n    nModified: 1,\n    nRemoved: 0,\n    upserted: [],\n    lastOp: { ts: [Timestamp], t: 17 }\n  },\n  insertedCount: 2,\n  matchedCount: 1,\n  modifiedCount: 1,\n  deletedCount: 0,\n  upsertedCount: 0,\n  upsertedIds: {},\n  insertedIds: { '0': 5ec4..., '1': 5ec4... },\n  n: 2\n}"
                },
                {
                    "lang": "javascript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"sample_mflix\");\n    const theaters = database.collection(\"theaters\");\n\n    const result = await theaters.bulkWrite([\n      {\n        insertOne: {\n          document: {\n            location: {\n              address: {\n                street1: \"3 Main St.\",\n                city: \"Anchorage\",\n                state: \"AK\",\n                zipcode: \"99501\",\n              },\n            },\n          },\n        },\n      },\n      {\n        insertOne: {\n          document: {\n            location: {\n              address: {\n                street1: \"75 Penn Plaza\",\n                city: \"New York\",\n                state: \"NY\",\n                zipcode: \"10001\",\n              },\n            },\n          },\n        },\n      },\n      {\n        updateMany: {\n          filter: { \"location.address.zipcode\": \"44011\" },\n          update: { $set: { is_in_ohio: true } },\n          upsert: true,\n        },\n      },\n      {\n        deleteOne: { filter: { \"location.address.street1\": \"221b Baker St\" } },\n      },\n    ]);\n\n    console.log(result);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "typescript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\ninterface Address {\n  street1: string;\n  city: string;\n  state: string;\n  zipcode: string;\n}\n\ninterface Theater {\n  location: { address: Address };\n  is_in_ohio?: boolean;\n}\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"sample_mflix\");\n    const theaters = database.collection<Theater>(\"theaters\");\n\n    const result = await theaters.bulkWrite([\n      {\n        insertOne: {\n          document: {\n            location: {\n              address: {\n                street1: \"3 Main St.\",\n                city: \"Anchorage\",\n                state: \"AK\",\n                zipcode: \"99501\",\n              },\n            },\n          },\n        },\n      },\n      {\n        insertOne: {\n          document: {\n            location: {\n              address: {\n                street1: \"75 Penn Plaza\",\n                city: \"New York\",\n                state: \"NY\",\n                zipcode: \"10001\",\n              },\n            },\n          },\n        },\n      },\n      {\n        updateMany: {\n          // Important: You lose type safety when you use dot notation in queries\n          filter: { \"location.address.zipcode\": \"44011\" },\n          update: { $set: { is_in_ohio: true } },\n          upsert: true,\n        },\n      },\n      {\n        deleteOne: {\n          filter: { \"location.address.street1\": \"221b Baker St\" },\n        },\n      },\n    ]);\n\n    console.log(result);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                }
            ],
            "preview": "The bulkWrite() method performs batch write operations against a\nsingle collection. This method reduces the number of network round trips from\nyour application to the server which therefore increases the throughput and\nperformance. Bulk writes return a collection of results for all operations\nonly after all operations passed to the method complete.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud",
            "title": "CRUD Operations",
            "headings": [],
            "paragraphs": "CRUD (Create, Read, Update, Delete) operations allow you to work with\nthe data stored in MongoDB. The CRUD operation documentation is categorized in two sections: Some operations combine aspects of read and write operations. See our\nguide on  compound operations \nto learn more about these hybrid methods. Read Operations  find and return\ndocuments stored within your MongoDB database. Write Operations  insert, modify,\nor delete documents in your MongoDB database. If you are looking for additional resources for learning topics related\nto CRUD, check out the following posts on the  MongoDB Developer Hub : Learn how to apply  CRUD Operations \nwith an example scenario. Analyze data in MongoDB Atlas using the  Aggregation Pipeline .",
            "code": [],
            "preview": "CRUD (Create, Read, Update, Delete) operations allow you to work with\nthe data stored in MongoDB.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/logging",
            "title": "Logging",
            "headings": [
                "Temporary Alternative"
            ],
            "paragraphs": "The driver doesn't use the logger in versions 4.0 and later.\nAttempting to use prior logger settings in this version won't print\nanything in the log. Instead, see our monitoring guides: Command Monitoring Cluster Monitoring Connection Pool Monitoring The Node.js team is currently working on rewriting the logger. In the\nmeantime, you can output monitor events using the following snippet:",
            "code": [
                {
                    "lang": "javascript",
                    "value": "const uri = \"mongodb+srv://<user>:<password>@<cluster-url>?writeConcern=majority\";\nconst client = new MongoClient(uri, { monitorCommands:true });\n\nclient.on('commandStarted', (event) => console.debug(event));\nclient.on('commandSucceeded', (event) => console.debug(event));\nclient.on('commandFailed', (event) => console.debug(event));"
                }
            ],
            "preview": "The Node.js team is currently working on rewriting the logger. In the\nmeantime, you can output monitor events using the following snippet:",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/stable-api",
            "title": "Stable API",
            "headings": [
                "Overview",
                "Enable the Stable API on a MongoDB Client",
                "Stable API Options"
            ],
            "paragraphs": "The Stable API feature requires MongoDB Server 5.0 or later. You should only use the Stable API feature if all the MongoDB\nservers you are connecting to support this feature. In this guide, you can learn how to specify the  Stable API  when\nconnecting to a MongoDB instance or replica set. You can use the\nStable API feature to force the server to run operations with behavior\ncompatible with the specified  API version . An API version defines the\nexpected behavior of the operations it covers and the format of server\nresponses. If you change to a different API version, the operations are not\nguaranteed to be compatible and the server responses are not guaranteed to\nbe similar. When you use the Stable API feature with an official MongoDB driver, you\ncan update your driver or server without worrying about backward compatibility\nissues of the commands covered by the Stable API. See the MongoDB reference page on the  Stable API \nfor more information including a list of commands it covers. The following sections describe how you can enable the Stable API for\nyour MongoDB client and the options that you can specify. To enable the Stable API, you must specify an API version in the  MongoClientOptions \npassed to your  MongoClient . Once you instantiate a  MongoClient  instance with\na specified API version, all commands you run with that client use that\nversion of the Stable API. The example below shows how you can instantiate a  MongoClient  that\nsets the Stable API version and connects to a server by performing the\nfollowing operations: For more information on the methods and classes referenced in this\nsection, see the following API Documentation: If you need to run commands using more than one version of the\nStable API, instantiate a separate client with that version. If you need to run commands not covered by the Stable API, make sure the\n\"strict\" option is disabled. See the section on\n Stable API Options  for more\ninformation. Specify a server URI to connect to. Specify a Stable API version in the  MongoClientOptions  object, using a\nconstant from the  ServerApiVersion  object. Instantiate a  MongoClient , passing the URI and the  MongoClientOptions \nto the constructor. If you specify an API version and connect to a MongoDB server that does\nnot support the Stable API, your application may throw an error when\nconnecting to your MongoDB server with the following text: ServerApiVersion MongoClientOptions MongoClient You can enable or disable optional behavior related to the Stable API as\ndescribed in the following table. The following example shows how you can set the options of the  ServerApi \ninterface. For more information on the options in this section, see the following\nAPI Documentation: Option Name Description version strict deprecationErrors ServerApi",
            "code": [
                {
                    "lang": "javascript",
                    "value": "const { MongoClient, ServerApiVersion } = require(\"mongodb\");\n\nconst uri = \"mongodb+srv://<user>:<password>@<cluster-url>?retryWrites=true&w=majority\";\nconst client = new MongoClient(uri, { serverApi: ServerApiVersion.v1 });"
                },
                {
                    "lang": "none",
                    "value": "MongoParseError: Invalid server API version=..."
                },
                {
                    "lang": "javascript",
                    "value": "const { MongoClient, ServerApiVersion } = require(\"mongodb\");\n\nconst uri = \"mongodb+srv://<user>:<password>@<cluster-url>?retryWrites=true&w=majority\";\nconst client = new MongoClient(uri,\n    {\n        serverApi: {\n            version: ServerApiVersion.v1,\n            strict: true,\n            deprecationErrors: true,\n        }\n    });"
                }
            ],
            "preview": "In this guide, you can learn how to specify the Stable API when\nconnecting to a MongoDB instance or replica set. You can use the\nStable API feature to force the server to run operations with behavior\ncompatible with the specified API version. An API version defines the\nexpected behavior of the operations it covers and the format of server\nresponses. If you change to a different API version, the operations are not\nguaranteed to be compatible and the server responses are not guaranteed to\nbe similar.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/promises",
            "title": "Promises and Callbacks",
            "headings": [
                "Overview",
                "Promises",
                "Await",
                "Callbacks",
                "Operational Considerations"
            ],
            "paragraphs": "The Node.js driver uses the asynchronous Javascript API to communicate with\nyour MongoDB cluster. Asynchronous Javascript allows you to execute operations without waiting for\nthe processing thread to become free. This helps prevent your application\nfrom becoming unresponsive when\nexecuting long-running operations. For more information about asynchronous\nJavascript, see the MDN web documentation on\n Asynchronous Javascript . This section describes two features of asynchronous Javascript --\n Promises  and  Callbacks  -- that you can use with the Node.js driver to\naccess the results of your method calls to your MongoDB cluster. A Promise is an object returned by the asynchronous method call that allows\nyou to access information on the eventual success or failure of the operation\nthat they wrap. The Promise is in the  Pending  state if the operation is\nstill running,  Fulfilled  if the operation completed successfully, and\n Rejected  if the operation threw an exception. For more information on\nPromises and related terminology, see the MDN documentation on\n Promises . Most driver methods that communicate with your MongoDB cluster such as\n findOneAndUpdate() ,  countDocuments() , and  update()  return Promise\nobjects and already contain logic to handle the success or failure of the\noperation. You can define your own logic that executes once the Promise reaches the\n Fulfilled  or  Rejected  state by appending the  then()  method.\nThe first parameter of  then()  is the method that gets called when the\nPromise reaches the  Fulfilled  state and the optional second parameter is\nthe method that gets called when it reaches the  Rejected  state. The\n then()  method returns a Promise to which you can append additional\n then()  methods. When you append one or more  then()  methods to a Promise, each call passes\nits execution result to the next one. This pattern is called\n Promise chaining . The following code snippet shows an example of Promise\nchaining by appending a single  then()  method. If you only need to handle Promise transitions to the  Rejected  state,\nrather than passing a  null  first parameter to  then() , you can instead\nuse the  catch()  method which accepts a single callback, executed when the\nPromise transitions to the  Rejected  state. The  catch()  method is often appended at the end of a Promise chain to\nhandle any exceptions thrown. The following code snippet demonstrates appending\na  catch()  method to the end of a Promise chain. Certain methods in the driver such as  find()  return a  Cursor \ninstead of a Promise. To determine what type each method returns, refer to\nthe  Node.js API documentation . If you are using  async  functions, you can use the  await  operator on\na Promise to pause further execution until the Promise reaches either the\n Fulfilled  or  Rejected  state and returns. Since the  await  operator\nwaits for the resolution of the Promise, you can use it in place of\nPromise chaining to sequentially execute your logic. The following code\nsnippet uses  await  to execute the same logic as the first Promise\nchaining example. For additional information, see the MDN documentation on\n await . A callback is a method that gets called after another method has\nfinished executing. This allows the enclosing method to continue to execute\nother commands until the original operation completes. Callbacks are often\nused to enforce the order of processing commands. In the MongoDB Node.js driver, you can optionally declare a callback method to\nasync operations that normally return Promises. Once the operation completes\nexecution, the callback method executes as shown in the following code\nsnippet: For more information on the callback method signature for the specific\ndriver method, see the  API documentation . If you specify a callback, the method  does not  return a Promise. One common mistake when using  async  methods is to forget to use  await \noperator on Promises to get the value of the result rather than the Promise\nobject. Consider the following example in which we iterate over a cursor\nusing  hasNext() , which returns a Promise that resolves to a boolean that\nindicates whether additional results exist, and  next()  which returns a\nPromise that resolves to the next entry the cursor is pointing to. Since the call to  hasNext()  returns a  Promise , the conditional\nstatement returns  true  regardless of the value that it resolves to. If we alter the code to  await  the call to  next()  only, as demonstrated\nin the following code snippet, it throws the following error:\n MongoError: Cursor is closed . While  hasNext()  is not called until after the result of  next()  returns,\nthe call to  hasNext()  returns a Promise which evaluates to  true  rather\nthan the value it resolves to, similar to the prior example. The code\nattempts to call  next()  on a Cursor that has already returned its results\nand closed as a result. If we alter the code to only  await  the call to  hasNext()  as shown in\nthe following example, the console prints Promise objects rather than the\ndocument objects. Use  await  before both the  hasNext()  and  next()  method calls to\nensure that you are operating on the correct return values as demonstrated\nin the following code: For additional information on using Promises and Callbacks with the MongoDB\nNode.js driver, see this MongoDB University course video on  asynchronous\nJavascript programming .",
            "code": [
                {
                    "lang": "js",
                    "value": "collection\n  .updateOne({ name: \"Mount McKinley\" }, { $set: { meters: 6190 } })\n  .then(\n    res => console.log(`Updated ${res.result.n} documents`),\n    err => console.error(`Something went wrong: ${err}`),\n  );"
                },
                {
                    "lang": "js",
                    "value": "deleteOne({ name: \"Mount Doom\" })\n  .then(result => {\n    if (result.deletedCount !== 1) {\n      throw \"Could not find Mount Doom!\";\n    }\n    return new Promise((resolve, reject) => {\n      ...\n    });\n  })\n  .then(result => console.log(`Vanquished ${result.quantity} Nazgul`))\n  .catch(err => console.error(`Fatal error occurred: ${err}`));"
                },
                {
                    "lang": "js",
                    "value": "async function run() {\n  ...\n  try {\n    res = await collection.updateOne(\n      { name: \"Mount McKinley\" },\n      { $set: { meters: 6190 } },\n    );\n    console.log(`Updated ${res.result.n} documents`);\n  } catch (err) {\n    console.error(`Something went wrong: ${err}`);\n  }\n}"
                },
                {
                    "lang": "js",
                    "value": "collection.findOneAndUpdate(\n  { name: \"Barronette Peak\" },\n  { $set: { name: \"Baronette Peak\" } },\n  {},\n  function(error, result) {\n    if (!error) {\n      console.log(`Operation completed successfully: ${result.ok}`);\n    } else {\n      console.log(`An error occurred: ${error}`);\n    }\n  },\n);"
                },
                {
                    "lang": "js",
                    "value": "async function run() {\n  ...\n  // WARNING: this snippet may cause an infinite loop\n  const cursor = collection.find();\n\n  while (cursor.hasNext()) {\n    console.log(cursor.next());\n  }\n}"
                },
                {
                    "lang": "js",
                    "value": "async function run() {\n  ...\n  // WARNING: this snippet throws a MongoError\n  const cursor = collection.find();\n\n  while (cursor.hasNext()) {\n    console.log(await cursor.next());\n  }\n}"
                },
                {
                    "lang": "js",
                    "value": "async function run() {\n  ...\n  // WARNING: this snippet prints Promises instead of the objects they resolve to\n  const cursor = collection.find();\n\n  while (await cursor.hasNext()) {\n    console.log(cursor.next());\n  }\n}"
                },
                {
                    "lang": "js",
                    "value": "async function run() {\n  ...\n  const cursor = collection.find();\n\n  while (await cursor.hasNext()) {\n    console.log(await cursor.next());\n  }\n}"
                }
            ],
            "preview": "The Node.js driver uses the asynchronous Javascript API to communicate with\nyour MongoDB cluster.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/authentication",
            "title": "Authentication",
            "headings": [
                "Overview"
            ],
            "paragraphs": "These guides show you how to authenticate to a MongoDB instance using the\nNode.js driver. The  Authentication Mechanisms  guide contains\nsample connection code using each authentication mechanism supported in the\nMongoDB Community Edition which includes: The  Enterprise Authentication Mechanisms  guide contains sample\nconnection code using authentication mechanisms available only in MongoDB\nEnterprise Edition which includes: DEFAULT SCRAM-SHA-256 SCRAM-SHA-1 MONGODB-CR MONGODB-AWS X.509 Kerberos (GSSAPI/SSPI) LDAP (PLAIN) For instructions on MongoDB driver installation and deployment setup, see\nour  Connect to MongoDB guide . Select your\nMongoDB deployment type and the Node.js client.",
            "code": [],
            "preview": "These guides show you how to authenticate to a MongoDB instance using the\nNode.js driver.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "usage-examples/insertOne",
            "title": "Insert a Document",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can insert a document into a collection using the\n collection.insertOne()  method. To\ninsert a document, define an object that contains the fields and values that\nyou want to store. If the specified collection does not exist, the\n insertOne()  method creates the collection. You can specify additional query options using the  options  parameter.\nFor more information on the method parameters, see the\n insertOne() API documentation . You\ncan also pass a callback method as an optional third parameter.\nFor more information on this method, see the\n insertOne() API documentation . If the operation successfully inserts a document, it appends an\n insertedId  field to the object passed in the method call, and sets the\nvalue of the field to the  _id  of the inserted document. If you specify a callback method,  insertOne()  returns nothing. If you\ndo not specify one, this method returns a  Promise  that resolves to the\nresult object when it completes. See our guide on  Promises and\nCallbacks  for more information, or the\n API documentation  for\ninformation on the result object. If you run the preceding example, you should see the following output: You can use this example to connect to an instance of MongoDB\nand interact with a database that contains sample data. To learn more about connecting to your MongoDB\ninstance and loading a sample dataset, see the  Usage Examples\nguide .",
            "code": [
                {
                    "lang": "none",
                    "value": "A document was inserted with the _id: <your _id value>"
                },
                {
                    "lang": "javascript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"insertDB\");\n    const haiku = database.collection(\"haiku\");\n    // create a document to insert\n    const doc = {\n      title: \"Record of a Shriveled Datum\",\n      content: \"No bytes, no problem. Just insert a document, in MongoDB\",\n    }\n    const result = await haiku.insertOne(doc);\n\n    console.log(`A document was inserted with the _id: ${result.insertedId}`);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "typescript",
                    "value": "import { MongoClient } from \"mongodb\";\n\n// Replace the uri string with your MongoDB deployment's connection string.\nconst uri = \"<connection string uri>\";\n\nconst client = new MongoClient(uri);\n\ninterface Haiku {\n  title: string;\n  content: string;\n}\n\nasync function run() {\n  try {\n    await client.connect();\n\n    const database = client.db(\"insertDB\");\n    // Specifying a Schema is optional, but it enables type hints on\n    // finds and inserts\n    const haiku = database.collection<Haiku>(\"haiku\");\n    const result = await haiku.insertOne({\n      title: \"Record of a Shriveled Datum\",\n      content: \"No bytes, no problem. Just insert a document, in MongoDB\",\n    });\n    console.log(`A document was inserted with the _id: ${result.insertedId}`);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                }
            ],
            "preview": "You can insert a document into a collection using the\ncollection.insertOne() method. To\ninsert a document, define an object that contains the fields and values that\nyou want to store. If the specified collection does not exist, the\ninsertOne() method creates the collection.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/time-series",
            "title": "Time Series",
            "headings": [
                "Overview",
                "Create a Time Series Collection",
                "Query a Time Series Collection"
            ],
            "paragraphs": "In this guide, you can learn about time series collections in the MongoDB\nNode.js driver. We recommend that you create a time series collection using the MongoDB Shell\n( mongosh ). For detailed instructions on creating a time series collection\nusing the MongoDB Shell, see our\n MongoDB Manual entry on time series collections . Since you query a time series collection in the same way you query other\ncollection types in MongoDB, the Node.js driver has no features specifically for\nquerying time series data. For more information on querying data in the MongoDB Node.js driver, see the\nfollowing resources: Guide On Read Operations Guide On Aggregation MongoDB version 5.0 introduces window functions into the MongoDB aggregation\npipeline. You can use window functions to perform operations on a\ncontiguous span of time series data. For more information, see\n the reference documentation for the $setWindowFields aggregation stage .",
            "code": [],
            "preview": "In this guide, you can learn about time series collections in the MongoDB\nNode.js driver.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/bson",
            "title": "BSON Settings",
            "headings": [
                "Overview"
            ],
            "paragraphs": "Learn how to configure your application's BSON serialization settings.\nThe guides in this section describe the following topics: Undefined Values : Control how the\ndriver serializes undefined values UTF-8 Validation : Enable or disable\nthe UTF-8 validation feature",
            "code": [],
            "preview": "Learn how to configure your application's BSON serialization settings.\nThe guides in this section describe the following topics:",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/indexes",
            "title": "Indexes",
            "headings": [
                "Overview",
                "Query Coverage and Performance",
                "Operational Considerations",
                "Index Types",
                "Single Field Indexes",
                "Compound Indexes",
                "Multikey Indexes (Indexes on Array Fields)",
                "Clustered Indexes",
                "Text Indexes",
                "Geospatial Indexes",
                "Unique Indexes",
                "List Indexes"
            ],
            "paragraphs": "Indexes are data structures that support the efficient execution of queries in\nMongoDB. They contain copies of parts of the data in documents to make\nqueries more efficient. Without indexes, MongoDB must scan  every  document in a collection to find\nthe documents that match each query. These collection scans are slow and can\nnegatively affect the performance of your application. By using an index to\nlimit the number of documents MongoDB scans, queries can be more efficient\nand therefore return faster. When you execute a query against MongoDB, your query can include three\nparts: When all the fields specified in the query criteria and projection of a\nquery are indexed, MongoDB returns results directly from the index\nwithout scanning any documents in the collection or loading them into\nmemory. For additional information on how to ensure your index covers your query\ncriteria and projection, see the MongoDB manual articles on\n query coverage \nand  index intersection . query criteria that specify field(s) and value(s) you are looking for options that affect the query's execution (e.g. read concern) projection criteria to specify the fields MongoDB should return (optional) To improve query performance, build indexes on fields that appear often in\nyour application's queries and operations that return sorted results.\nEach index that you add consumes disk space and memory when active so you\nshould track index memory and disk usage for capacity planning. In addition,\nwhen a write operation updates an indexed field, MongoDB also has to update\nthe related index. For more information on designing your data model and choosing indexes\nappropriate for your application, see the MongoDB server documentation on\n Indexing Strategies  and\n Data Modeling and Indexes . MongoDB supports a number of different index types to support querying\nyour data. The following sections describe the most common index types\nand provide sample code for creating each index type. Single field indexes  are indexes that improve performance for queries\nthat specify ascending or descending sort order on a single field of a\ndocument. The following example uses the  createIndex()  method to create an\nascending order index on the  title  field in the  movies  collection in\nthe  sample_mflix  database. The following is an example of a query that would be covered by the index\ncreated above. To learn more, see   Single Field Indexes . Compound indexes  are indexes that improve performance for queries that\nspecify ascending or descending sort order for  multiple  fields of\na document. You must specify the direction (ascending or descending) for\neach field in the index. The following example uses the  createIndex()  method to create a compound\nindex on the  type  and  genre  fields in the  movies  collection in the\n sample_mflix  database. The following is an example of a query that would be covered by the index\ncreated above. To learn more, see   Compound Indexes . Multikey indexes  are indexes that improve the performance of queries on\nfields that contain array values. You can create a multikey index on a field with an array value by\ncalling the  createIndex()  method. The following code creates an ascending\nindex on the  cast  field in the  movies  collection of the\n sample_mflix  database: The following code queries the multikey index to find\ndocuments with a  cast  field value that contains \"Viola Davis\": Multikey indexes behave differently from non-multikey indexes in terms of\nquery coverage, index bound computation, and sort behavior. For a full\nexplanation of multikey indexes, including a discussion of their behavior\nand limitations, refer to the  Multikey Indexes page  in the MongoDB Server manual. Clustered indexes  are indexes that improve the performance of\ninsert, update, and delete operations on  clustered collections .\nClustered collections store documents ordered by the clustered index key\nvalue. To create a clustered index, specify the  clusteredIndex  option in\nthe  CollectionOption . The  clusteredIndex  option must specify the\n _id  field as the key and the unique field as  true . The following example uses the  createCollection()  method to create a\nclustered index on the  _id  field in the  vendors  collection of the\n tea  database. To learn more, see\n Clustered Indexes  and\n Clustered Collections . Text indexes  support text search queries on string content. These indexes\ncan include any field whose value is a string or an array of string elements. MongoDB supports text search for various languages, so you can specify the\ndefault language as an option when creating the index. You can also\nspecify a weight option to prioritize certain text fields in your\nindex. These weights denote the significance of fields relative to the\nother indexed fields. To learn more about text searches, see our guide on  text search queries . The following example uses the  createIndex()  method to perform the\nfollowing actions: The following query uses the text index created in the preceding code: To learn more about text indexes, see  Text Indexes  in the Server manual. Create a  text  index on the  title  and  body  fields in the\n blogPosts  collection Specify  english  as the default language Set the field weight of  body  to  10  and  title  to  3 MongoDB supports queries of geospatial coordinate data using  2dsphere\nindexes . With a 2dsphere index, you can query the geospatial data for\ninclusion, intersection, and proximity. For more information on querying\ngeospatial data with the MongoDB Node.js driver, read our\n Search Geospatial  guide. To create a 2dsphere index, you must specify a field that contains\nonly  GeoJSON objects . For more details on this type, see the MongoDB\nserver manual page on  GeoJSON objects . The  location.geo  field in following sample document from the\n theaters  collection in the  sample_mflix  database is a GeoJSON Point\nobject that describes the coordinates of the theater: The following example uses the  createIndexes()  method to create a\n 2dsphere  index on the  location.geo  field in the  theaters \ncollection in the  sample_mflix  database to enable geospatial searches. MongoDB also supports  2d  indexes for calculating distances on a\nEuclidean plane and for working with the \"legacy coordinate pairs\" syntax\nused in MongoDB 2.2 and earlier. To learn more, see\n Geospatial Queries . Unique indexes  ensure that the indexed fields do not store duplicate\nvalues. By default, MongoDB creates a unique index on the  _id  field\nduring the creation of a collection. To create a unique index, specify the\nfield or combination of fields that you want to prevent duplication on and\nset the  unique  option to  true . The following example uses the  createIndex()  method to create a unique\nindex on the  theaterId  field in the  theaters  collection of the\n sample_mflix  database. If you attempt to perform a write operation that stores a duplicate value\nthat violates the unique index, MongoDB will throw an error that resembles\nthe following: To learn more, see  Unique Indexes . You can use the  listIndexes()  method to list all of the indexes for\na collection. The  listIndexes()  method takes an optional\n ListIndexesOptions \nparameter. The  listIndexes()  method returns an object of type\n ListIndexesCursor . The following code uses the  listIndexes()  method to list all the\nindexes in a collection:",
            "code": [
                {
                    "lang": "js",
                    "value": "const database = client.db(\"sample_mflix\");\nconst movies = database.collection(\"movies\");\n\n// Create an ascending index on the \"title\" field in the\n// \"movies\" collection.\nconst result = await movies.createIndex({ title: 1 });\nconsole.log(`Index created: ${result}`);"
                },
                {
                    "lang": "js",
                    "value": "const query = { title: \"Batman\" }\nconst sort = { title: 1 };\nconst projection = { _id: 0, title: 1 };\n\nconst cursor = movies\n  .find(query)\n  .sort(sort)\n  .project(projection);"
                },
                {
                    "lang": "js",
                    "value": "const database = client.db(\"sample_mflix\");\nconst movies = database.collection(\"movies\");\n\n// Create an ascending index on the \"type\" and \"genre\" fields\n// in the \"movies\" collection.\nconst result = await movies.createIndex({ type: 1, genre: 1 });\nconsole.log(`Index created: ${result}`);"
                },
                {
                    "lang": "js",
                    "value": "const query = { type: \"movie\", genre: \"Drama\" };\nconst sort = { type: 1, genre: 1 };\nconst projection = { _id: 0, type: 1, genre: 1 };\n\nconst cursor = movies\n  .find(query)\n  .sort(sort)\n  .project(projection);"
                },
                {
                    "lang": "js",
                    "value": "const database = client.db(\"sample_mflix\");\nconst movies = database.collection(\"movies\");\n\n// Create a multikey index on the \"cast\" field\nconst result = await movies.createIndex({ cast: 1 });"
                },
                {
                    "lang": "js",
                    "value": "const query = { cast: \"Viola Davis\" };\nconst projection = { _id: 0, cast: 1 , title: 1 };\n\nconst cursor = movies\n  .find(query)\n  .project(projection);"
                },
                {
                    "lang": "javascript",
                    "value": "const db = client.db('tea');\nawait db.createCollection('ratings', {\n  clusteredIndex: {\n    key: { _id: 1 },\n    unique: true\n  }\n});"
                },
                {
                    "lang": "js",
                    "value": "const myDB = client.db(\"testDB\");\nconst myColl = myDB.collection(\"blogPosts\");\n\n// Create a text index on the \"title\" and \"body\" fields\nconst result = await myColl.createIndex(\n  { title: \"text\", body: \"text\" },\n  { default_language: \"english\" },\n  { weights: { body: 10, title: 3 } }\n);"
                },
                {
                    "lang": "js",
                    "value": "const query = { $text: { $search: \"life ahead\" } };\nconst projection = { _id: 0, title: 1 };\nconst cursor = myColl.find(query).project(projection);"
                },
                {
                    "lang": "json",
                    "value": "{\n   \"_id\" : ObjectId(\"59a47286cfa9a3a73e51e75c\"),\n   \"theaterId\" : 104,\n   \"location\" : {\n      \"address\" : {\n         \"street1\" : \"5000 W 147th St\",\n         \"city\" : \"Hawthorne\",\n         \"state\" : \"CA\",\n         \"zipcode\" : \"90250\"\n      },\n      \"geo\" : {\n         \"type\" : \"Point\",\n         \"coordinates\" : [\n            -118.36559,\n            33.897167\n         ]\n      }\n   }\n}"
                },
                {
                    "lang": "js",
                    "value": "const database = client.db(\"sample_mflix\");\nconst movies = database.collection(\"movies\");\n\n// Create a 2dsphere index on the \"location.geo\" field in the \"theaters\" collection.\nconst result = await movies.createIndex({ \"location.geo\": \"2dsphere\" });\nconsole.log(`Index created: ${result}`);"
                },
                {
                    "lang": "none",
                    "value": "E11000 duplicate key error index"
                },
                {
                    "lang": "js",
                    "value": "const database = client.db(\"sample_mflix\");\nconst movies = database.collection(\"movies\");\n\n// Create a unique index on the \"theaterId\" field in the \"theaters\" collection.\nconst result = await movies.createIndex({ theaterId: 1 }, { unique: true });\nconsole.log(`Index created: ${result}`);"
                },
                {
                    "lang": "js",
                    "value": "const result = await collection.listIndexes().toArray();\nconsole.log(\"Existing indexes:\\n\");\nfor(const doc in result){\n    console.log(doc);\n}"
                }
            ],
            "preview": "Indexes are data structures that support the efficient execution of queries in\nMongoDB. They contain copies of parts of the data in documents to make\nqueries more efficient.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/transactions",
            "title": "Transactions",
            "headings": [
                "Overview",
                "Transaction APIs",
                "Core API",
                "Callback API",
                "Transaction Settings",
                "Examples",
                "Sample Data",
                "Core API Implementation",
                "Callback API Implementation",
                "Payment Transaction Result"
            ],
            "paragraphs": "Read this guide to learn how to perform  transactions  in MongoDB using the\nNode.js driver. A transaction is a unit of work, composed of a series of\noperations that you want either to succeed together, or fail together when one\nor more of the operations fail. This behavior is called  atomicity .\nAtomicity is a property in which transactions composed of one or more\noperations occur all at once, such that no other client can observe them as\nseparate operations, and that it leaves no changes if one of the operations\nfails. Since all write operations on a single document in MongoDB are atomic, you\nmay benefit most from transactions when you must make an atomic change that\nmodifies multiple documents, which is called a multi-document transaction.\nSimilar to write operations on a single document, multi-document transactions\nare  ACID compliant , which means MongoDB guarantees the data involved\nin your transaction operations remains consistent, even if it encounters\nunexpected errors. Learn more from this MongoDB article on\n ACID transactions . You can use the driver to perform multi-document transactions. In MongoDB, multi-document transactions run within a  client session .\nA client session is a grouping of related read or write operations that\nyou want to ensure run sequentially. We recommend you reuse\nyour client for multiple sessions and transactions instead of\ninstantiating a new client each time. When combined with majority read and\nwrite concerns, the driver can guarantee causal consistency between the\noperations. See the server manual guide on\n Client Sessions and Causal Consistency Guarantees \nfor more information. Learn more about how to use the driver to run multi-document transactions on\nMongoDB in the following sections of this guide: To run multi-document transactions, you must use MongoDB version 4.0 or\nlater. For a detailed list of limitations, see the  Transactions and\nOperations  section in\nthe server manual. Transaction APIs Transaction Settings Core API and Callback API Examples To implement a transaction with the driver, you can use either the\n Core API  or the  Callback API . To use the Core API, you declare the\nstart and commit points of the transaction. To use the Callback API, you pass\na callback function that contains the logic you want to run as a transaction. The Core API features methods to start, cancel, or commit a transaction.\nWhen you commit the transaction, you send a request to the server to make the\nchanges from your operations atomically. When using this API, you must handle\ncertain transaction errors returned by the server manually. See\n TransientTransactionError \nand\n UnknownTransactionCommitResult \nfor more information on these errors. To start, cancel, or commit your transaction, you can call the corresponding\nmethod on the  Session  object: See the  Core API example  for\na sample transaction implementation. startTransaction() commitTransaction() abortTransaction() The Callback API enables you to run a transaction by passing a callback\nfunction that encapsulates the series of operations that make up the\ntransaction. This API automatically handles certain transaction errors\nreturned by the server. See\n TransientTransactionError \nand\n UnknownTransactionCommitResult \nfor more information on these errors. To create a transaction, pass a callback function that encapsulates your\ntransaction logic to the  withTransaction()  method on a  Session \nobject. The driver automatically retries the transaction when it encounters\ncertain errors reported by the server. See the  Callback API example \nfor a sample transaction implementation. When you instantiate a transaction, you can specify the following options to\nset the default behavior for that transaction: If you do not provide values, the driver uses the client settings. You can specify the transaction options in the Core API using code that\nresembles the following: You can specify the transaction options in the Callback API using code that\nresembles the following: Setting Description readConcern Specifies how to check for the consistency of the data that the\nread operations retrieve from replica sets. See  Read Concern  in the server\nmanual for more information. writeConcern Specifies conditions in which to acknowledge the write.\nSee  Write Concern  in the\nserver manual for more information. readPreference See  Read Preference \nin the server manual for more information. maxCommitTimeMS Specifies the maximum amount of time to allow a commit action on a\ntransaction to run in milliseconds. Consider a scenario in which a customer purchases items from your online\nstore. To record the purchase, your application needs to update\ninformation related to inventory, the customer's orders, and register the\norder details. Suppose you organize the data updates as follows: A purchase can fail several ways such as if there's insufficient quantity of\nthe item in inventory, if the order couldn't be completed, or if your\npayment system is offline. If the payment fails, you can use a transaction to make sure that you\navoid exposing any partial updates that might cause data consistency issues\nfor other operations that depend on that data. Collection Operation Description of the Change orders insert Record the purchase information customers update Append the order id to associate it with the customer inventory update Subtract quantity of ordered items The code examples require the following sample data in the  testdb \ndatabase to run the multi-document payment transaction: The document in the  customers  collection in this example contains the\nfollowing: The documents in the  inventory  collection in this example contain the\nfollowing: The code examples also perform operations on the  orders  collection, but\ndo not require any prior sample documents. The code examples use the  cart  and  payment  variables to represent\na sample list of items purchased and the order payment details as follows: A document in the  customers  collection that describes a customer and\ntheir orders. Documents in the  inventory  collection that each track quantity and\ndescription of an item. The examples in the following sections require that you create the\ncollections outside of the transaction or that you are using MongoDB 4.4 or\nlater. For more information on creating collections inside a transaction,\nsee the\n Create Collections and Indexes in a Transaction \nserver guide. The code example in this section demonstrates how you can use the Core API to\nrun the multi-document payment transaction in a session. This function\nshows how you can perform the following: Note that you must pass the session object to each CRUD operation that\nyou want to run on that session. The code and comments in the  catch  block demonstrate how you can identify\nthe server transaction errors and where you can place your logic to handle\nthem. Make sure to include the  MongoError  type from the driver in your\ncode as shown in the following sample import statement: See the  Payment Transaction Result \nsection to see what your collections should contain after you run the\ntransaction. Start a session Start a transaction, specifying transaction options Perform data operations in the same session Commit a transaction, or cancel it if the driver encounters an error End a session The code examples in this section show how you can use the Callback API to\nrun the multi-document payment transaction in a session. The following code example shows how you can start the session and pass an\nanonymous callback function that contains the operations you want to run\nas a transaction. Rather than pass an anonymous callback function, you can pass a named\nfunction that returns a Promise. See the following  placeOrder() \nexample callback function that you can pass to  withTransaction()  to run\nas a transaction: See the  Payment Transaction Result \nsection to see what your collections should contain after you run the\ntransaction. If your application completes the payment transaction, your\ndatabase should contain all the updates, and if an exception interrupted your\ntransaction, none of the changes should exist in your database. The  customers  collection should contain the customer document with an\norder id appended to the orders field: The  inventory  collection should contain updated quantities for the\nitems \"sunblock\" and \"beach towel\": The  orders  collection should contain the order and payment\ninformation:",
            "code": [
                {
                    "lang": "javascript",
                    "value": "const transactionOptions = {\n  readPreference: 'primary',\n  readConcern: { level: 'local' },\n  writeConcern: { w: 'majority' },\n  maxCommitTimeMS: 1000\n};\nsession.startTransaction(transactionOptions);"
                },
                {
                    "lang": "javascript",
                    "value": "const transactionOptions = {\n  readPreference: 'primary',\n  readConcern: { level: 'local' },\n  writeConcern: { w: 'majority' },\n  maxCommitTimeMS: 1000\n};\nawait session.withTransaction(\n  async (session) => { /* your transaction here */ },\n  transactionOptions);"
                },
                {
                    "lang": "json",
                    "value": "{ _id: 98765, orders: [] }"
                },
                {
                    "lang": "json",
                    "value": "[\n { name: \"sunblock\", sku: 5432, qty: 85 },\n { name: \"beach towel\", sku: 7865, qty: 41 }\n]"
                },
                {
                    "lang": "javascript",
                    "value": "const cart = [\n  { name: 'sunblock', sku: 5432, qty: 1, price: 5.19 },\n  { name: 'beach towel', sku: 7865, qty: 2, price: 15.99 }\n];\nconst payment = { customer: 98765, total: 37.17 };"
                },
                {
                    "lang": "javascript",
                    "value": "const { MongoError, MongoClient } = require('mongodb');"
                },
                {
                    "lang": "javascript",
                    "value": "async function placeOrder(client, cart, payment) {\n  const transactionOptions = {\n    readConcern: { level: 'snapshot' },\n    writeConcern: { w: 'majority' },\n    readPreference: 'primary'\n  };\n\n  const session = client.startSession();\n  try {\n    session.startTransaction(transactionOptions);\n\n    const ordersCollection = client.db('testdb').collection('orders');\n    const orderResult = await ordersCollection.insertOne(\n      {\n        customer: payment.customer,\n        items: cart,\n        total: payment.total,\n      },\n      { session }\n    );\n\n    const inventoryCollection = client.db('testdb').collection('inventory');\n    for (let i=0; i<cart.length; i++) {\n      const item = cart[i];\n\n      // Cancel the transaction when you have insufficient inventory\n      const checkInventory = await inventoryCollection.findOne(\n        {\n          sku: item.sku,\n          qty: { $gte: item.qty }\n        },\n        { session }\n      )\n      if (checkInventory === null) {\n        throw new Error('Insufficient quantity or SKU not found.');\n      }\n\n      await inventoryCollection.updateOne(\n        { sku: item.sku },\n        { $inc: { 'qty': -item.qty }},\n        { session }\n      );\n    }\n\n    const customerCollection = client.db('testdb').collection('customers');\n    await customerCollection.updateOne(\n      { _id: payment.customer },\n      { $push:  { orders: orderResult.insertedId }},\n      { session }\n    );\n    await session.commitTransaction();\n    console.log('Transaction successfully committed.');\n\n  } catch (error) {\n    if (error instanceof MongoError && error.hasErrorLabel('UnknownTransactionCommitResult')) {\n      // add your logic to retry or handle the error\n    }\n    else if (error instanceof MongoError && error.hasErrorLabel('TransientTransactionError')) {\n      // add your logic to retry or handle the error\n    } else {\n      console.log('An error occured in the transaction, performing a data rollback:' + error);\n    }\n    await session.abortTransaction();\n  } finally {\n    await session.endSession();\n  }\n}"
                },
                {
                    "lang": "javascript",
                    "value": "const transactionOptions = {\n  readPreference: 'primary',\n  readConcern: { level: 'local' },\n  writeConcern: { w: 'majority' },\n  maxCommitTimeMS: 1000\n};\n\nconst session = client.startSession();\ntry {\n  await session.withTransaction(\n    async (session) => { /* your transaction here */ },\n    transactionOptions);\n} catch(error) {\n  console.log('Encountered an error during the transaction: ' + error);\n} finally {\n  await session.endSession();\n}"
                },
                {
                    "lang": "javascript",
                    "value": "async function placeOrder(client, session, cart, payment) {\n  const ordersCollection = client.db('testdb').collection('orders');\n  const orderResult = await ordersCollection.insertOne(\n    {\n      customer: payment.customer,\n      items: cart,\n      total: payment.total,\n    },\n    { session }\n  );\n\n  const inventoryCollection = client.db('testdb').collection('inventory');\n  for (let i=0; i<cart.length; i++) {\n    const item = cart[i];\n\n    // Cancel the transaction when you have insufficient inventory\n    const checkInventory = await inventoryCollection.findOne(\n      {\n        sku: item.sku,\n        qty: { $gte: item.qty }\n      },\n      { session }\n    );\n\n    if (checkInventory === null) {\n      await session.abortTransaction();\n      console.error('Insufficient quantity or SKU not found.');\n    }\n\n    await inventoryCollection.updateOne(\n      { sku: item.sku },\n      { $inc: { 'qty': -item.qty }},\n      { session }\n    );\n  }\n\n  const customerCollection = client.db('testdb').collection('customers');\n  await customerCollection.updateOne(\n    { _id: payment.customer },\n    { $push:  { orders: orderResult.insertedId }},\n    { session }\n  );\n}"
                },
                {
                    "lang": "json",
                    "value": "{\n  \"_id\": 98765,\n  \"orders\": [\n    \"61dc...\"\n  ]\n}"
                },
                {
                    "lang": "json",
                    "value": "[\n  {\n    \"_id\": ...,\n    \"name\": \"sunblock\",\n    \"sku\": 5432,\n    \"qty\": 84\n  },\n  {\n    \"_id\": ...,\n    \"name\": \"beach towel\",\n    \"sku\": 7865,\n    \"qty\": 39\n  }\n]"
                },
                {
                    "lang": "json",
                    "value": "[\n  {\n    \"_id\": \"...\",\n    \"customer\": 98765,\n    \"items\": [\n      {\n        \"name\": \"sunblock\",\n        \"sku\": 5432,\n        \"qty\": 1,\n        \"price\": 5.19\n      },\n      {\n        \"name\": \"beach towel\",\n        \"sku\": 7865,\n        \"qty\": 2,\n        \"price\": 15.99\n      }\n    ],\n    \"total\": 37.17\n  }\n]"
                }
            ],
            "preview": "Read this guide to learn how to perform transactions in MongoDB using the\nNode.js driver. A transaction is a unit of work, composed of a series of\noperations that you want either to succeed together, or fail together when one\nor more of the operations fail. This behavior is called atomicity.\nAtomicity is a property in which transactions composed of one or more\noperations occur all at once, such that no other client can observe them as\nseparate operations, and that it leaves no changes if one of the operations\nfails.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/typescript",
            "title": "TypeScript",
            "headings": [
                "Overview",
                "Features",
                "Type Parameters that Extend Document",
                "Type Parameters of Any Type",
                "Type Safety and Dot Notation",
                "Referencing Keys that Incorporate Variables",
                "Insert Operations and the _id Field",
                "Find Methods and the _id Field",
                "Known Limitations",
                "Recursive Types and Dot Notation",
                "Mutual Recursion"
            ],
            "paragraphs": "In this guide, you can learn about the  TypeScript  features and limitations\nof the MongoDB Node.js driver. TypeScript is a strongly typed programming\nlanguage that compiles to JavaScript. The TypeScript compiler offers type checking in real time. Code editors that\nsupport TypeScript can provide autocomplete suggestions, display documentation\ninline, and identify type-related errors. All TypeScript features of the driver are optional. All valid JavaScript\ncode written with the driver is also valid TypeScript code. For more information, see the\n TypeScript website . If you use TypeScript, you can specify a type for some classes in the driver.\nAll classes that accept a type parameter in the driver have the default type\n Document . The  Document  interface has the following definition: All object types extend the  Document  interface. For more information on object types, see the\n TypeScript handbook . The following classes accept all types that extend the  Document  interface: You can pass a type parameter that extends the  Document  interface like this: Collection ChangeStream Keys not listed in your specified type parameter receive the  any  type.\nThe following code snippet demonstrates this behavior: The following classes accept all type parameters: You can find a code snippet that shows how to specify a type for the  FindCursor \nclass in the\n Find Multiple Documents Usage Example . FindCursor AggregationCursor If you specify a query or update with  dot notation , the Node.js driver\nprovides type safety if your query or update does not\n reference a nested instance of a recursive type .\nDot notation is a syntax you can use to navigate nested JSON objects. The following code snippet defines the  ClassificationPet  interface,\nwhich includes a  classification  field that enables you to specify the\ngenus and color of dogs and cats: The following code snippet correctly raises a type error when specifying\nthe genus of an unsupported animal in a query: The type error raised by the preceding code snippet is as follows: If you need to query a collection or perform another operation with a\nkey that incorporates variables, you must use an  as const \nassertion when specifying the key. This mechanism allows your\ncode to compile successfully as long as the input types are correct. The following code snippet defines the  ClassificationPet  interface\nand the  Mealtime  interface.  ClassificationPet  includes a\n mealtimes  field that contains an array of  Mealtime  interfaces,\neach of which includes a  time  field: The following code snippet performs a find-and-update operation on a\ncollection of  ClassificationPet  documents. The operation\nupdates the nested  time  field of the  Mealtime  instance at index\n 1 . The index position is specified by the variable  mealCounter : To learn more about dot notation, see\n Dot Notation \nin the MongoDB manual. To learn more about the limitations of dot notation in the\nNode.js driver, see the\n Recursive Types and Dot Notation \nsection. How you specify the  _id  field in type parameters passed to your\n Collection  instance affects the behavior\nof insert operations. The following table describes how different\n _id  field specifications affect insert operations: If you must specify the  _id  field as required in the type you define to represent\ndocuments in your collection but you do not want to specify values for the\n _id  field in insert operations, use the  OptionalId  helper type when you\ncreate your collection. The  OptionalId  type accepts a type parameter as an\nargument and returns that type with an optional  _id  field. The following code snippet defines the  IdPet  interface, which\nincludes a type for the  _id  field: The following code uses the preceding interface along with the\n OptionalId  type to insert a document without specifying a value for the\n _id  field: To learn more about the  _id  field, see\n The _id Field  in the MongoDB\nmanual. To learn more about the types, interfaces, and classes discussed in this section, see the\nfollowing resources: _id  field type Example Type Required on insert Behavior on insert OptionalId  API documentation PkFactory  API documentation ObjectId  source code The  find  and  findOne  methods of the  Collection  class include\nthe  _id  field in their return type. The driver infers the type of the\nreturned  _id  field based on the type parameter you passed to your\n Collection  instance. If the type parameter you passed to your  Collection  instance includes the\n _id  field in its schema, the driver infers that the  _id  field returned\nfrom the method is of the type specified in the schema. However, if the type parameter you passed to your  Collection  instance does not\ninclude the  _id  field in its schema, the driver infers that the type of the\n _id  field returned from the method is  ObjectId . The following code uses the  Pet \ninterface to return a document with an  _id  inferred to be of type  ObjectId : The following code uses the  IdNumberPet  interface to return a\ndocument with an  _id  inferred to be of type  number : To learn more about the classes and methods discussed in this section, see the following\nAPI documentation: The type parameter passed to your  Collection  influences only the type\ninference of the fields returned from the method. The driver does not convert\nthe field to the specified type. The type of each field in your type\nparameter's schema should match the type of the corresponding field in the\ncollection. If you specify a  projection  in a find\nmethod, you should pass a type parameter to your find method that reflects\nthe structure of your projected documents.\nWithout a type parameter, TypeScript cannot check at compile time that you\nare using your projected documents safely. To show this behavior, the following code snippet passes type checking but\nraises an error at runtime: To catch this error at compile time, pass a type parameter that does not include\nthe  _id  field to your find method: To view a runnable TypeScript example that includes a find method applying a\nprojection, see the\n Find a Document  page. Collection find findOne Learn about the following TypeScript specific limitations of the Node.js driver: No type safety for dot notation references to nested instances of recursive types No mutually recursive types The Node.js driver cannot provide type safety within nested instances of\n recursive types  referenced through dot notation. A recursive type is a type that references itself. You can update\nthe  Pet  interface\nto be recursive by allowing a pet to have its own pet. The following is the\nrecursive  Pet  interface: The following code snippet references a nested instance of the\n RecursivePet  interface\nwith an incorrect type using dot notation, but the TypeScript compiler\ndoes not raise a type error: The following code snippet references a top-level instance of the\n RecursivePet  interface with an incorrect type and raises a type error: The error raised by the preceding code snippet is as follows: If you must have type safety within nested instances of recursive types,\nyou must write your query or update without dot notation. To learn more about dot notation, see\n Dot Notation \nin the MongoDB manual. The Node.js driver does not traverse nested recursive types when\ntype checking dot notation keys to avoid hitting\nTypeScript's recursive depth limit. You cannot specify a  mutually recursive  type as a type parameter. A mutually recursive type exists when two types contain a property that is of\nthe other's type. You can update the\n Pet  interface\nto be mutually recursive by allowing a pet to have a handler, and defining a\nhandler to have a pet. The following are the mutually\nrecursive  Pet  and  Handler  interfaces: If you specify a mutually recursive type, the TypeScript compiler raises the\nfollowing error: In this driver version, you cannot specify a mutually recursive type as a\ntype parameter. To specify a mutually recursive type as a type parameter,\nuse version 4.11 or newer.",
            "code": [
                {
                    "lang": "typescript",
                    "value": "interface Document {\n  [key: string]: any;\n}"
                },
                {
                    "lang": "typescript",
                    "value": "interface Pet {\n  name: string;\n  age: number;\n}\n\nconst database = client.db(\"<your database>\");\nconst collection = database.collection<Pet>(\"<your collection>\");\n"
                },
                {
                    "lang": "typescript",
                    "value": "interface User {\n  email: string;\n}\n\nconst database = client.db(\"<your database>\");\nconst collection = db.collection<User>(\"<your collection>\");\ncollection.find({ age: \"Accepts any type!\" });"
                },
                {
                    "lang": "typescript",
                    "value": "interface ClassificationPet {\n  name: string;\n  age: number;\n  classification: { genus: \"Canis\" | \"Felis\"; color: string };\n}"
                },
                {
                    "lang": "typescript",
                    "value": "database\n  .collection<ClassificationPet>(\"<your collection>\")\n  .find({ \"classification.genus\": \"Sylvilagus\" });"
                },
                {
                    "lang": "none",
                    "value": "No overload matches this call.\n...\nType '\"Sylvilagus\"' is not assignable to type 'Condition<\"Canis\" | \"Felis\">'."
                },
                {
                    "lang": "typescript",
                    "value": "interface ClassificationPet {\n  name: string;\n  mealtimes: Mealtime[];\n}\n\ninterface Mealtime{\n  time: string;\n  amount: number;\n}"
                },
                {
                    "lang": "typescript",
                    "value": "const mealCounter = 1;\n\nawait collection.findOneAndUpdate(\n  { name: \"Lassie\" },\n  { $set: { [`mealtimes.${mealCounter}.time` as const]: '4:00 PM' } },\n);"
                },
                {
                    "lang": "typescript",
                    "value": "interface IdPet {\n  _id: ObjectId;\n  name: string;\n  age: number;\n}"
                },
                {
                    "lang": "typescript",
                    "value": "const database = client.db(\"<your database>\");\nconst collection = db.collection<OptionalId<IdPet>>(\"<your collection>\");\n\ncollection.insertOne({\n  name: \"Spot\",\n  age: 2\n});"
                },
                {
                    "lang": "typescript",
                    "value": "const database = client.db(\"<your database>\");\nconst collection = db.collection<Pet>(\"<your collection>\");\n\nconst document = await collection.findOne({\n  name: \"Spot\",\n});\nconst id : ObjectId = document._id;"
                },
                {
                    "lang": "typescript",
                    "value": "interface IdNumberPet {\n  _id: number;\n  name: string;\n  age: number;\n}\n\nconst database = client.db(\"<your database>\");\nconst collection = db.collection<IdNumberPet>(\"<your collection>\");\n\nconst document = await collection.findOne({\n  name: \"Spot\",\n});\nconst id : number = document._id;"
                },
                {
                    "lang": "typescript",
                    "value": "const doc = await collection.findOne(\n  {},\n  { projection: { _id: 0, name: 1 } }\n);\nconsole.log(doc._id.generationTime);"
                },
                {
                    "lang": "typescript",
                    "value": "interface ProjectedDocument {\n   name: string\n}\n\nconst doc = await collection.findOne<ProjectedDocument>(\n  {},\n  { projection: { _id: 0, name: 1 } }\n);\n// Compile time error: Property '_id' does not exist on type 'ProjectedDocument'.\nconsole.log(doc._id.generationTime);"
                },
                {
                    "lang": "typescript",
                    "value": "interface RecursivePet {\n   pet?: RecursivePet;\n   name: string;\n   age: number;\n}"
                },
                {
                    "lang": "typescript",
                    "value": "database\n   .collection<RecursivePet>(\"<your collection>\")\n   .findOne({ \"pet.age\": \"Spot\" });"
                },
                {
                    "lang": "typescript",
                    "value": "database\n   .collection<RecursivePet>(\"<your collection>\")\n   .findOne({ pet: \"Spot\" });"
                },
                {
                    "lang": "none",
                    "value": "index.ts(19,59): error TS2769: No overload matches this call.\nThe last overload gave the following error.\nType 'string' is not assignable to type 'Condition<Pet>'."
                },
                {
                    "lang": "typescript",
                    "value": "interface MutuallyRecursivePet {\n   handler?: Handler;\n   name: string;\n   age: number;\n}\n\ninterface Handler {\n   pet: MutuallyRecursivePet;\n   name: string;\n}"
                },
                {
                    "lang": "none",
                    "value": "error TS2615: Type of property 'r' circularly references itself in mapped type '{ [Key in keyof MutuallyRecursive]..."
                }
            ],
            "preview": "In this guide, you can learn about the TypeScript features and limitations\nof the MongoDB Node.js driver. TypeScript is a strongly typed programming\nlanguage that compiles to JavaScript.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/aggregation",
            "title": "Aggregation",
            "headings": [
                "Overview",
                "Aggregation vs. Query Operations",
                "Useful References",
                "Runnable Examples",
                "Aggregation Example",
                "Additional Aggregation Examples"
            ],
            "paragraphs": "In this guide, you can learn how to use  aggregation operations  in\nthe MongoDB Node.js driver. Aggregation operations are expressions you can use to produce reduced\nand summarized results in MongoDB. MongoDB's aggregation pipeline, part\nof the Query API, allows you to create a pipeline that consists of one\nor more stages, each of which performs a specific operation on your data. You can think of the aggregation pipeline as similar to an automobile factory.\nAutomobile manufacturing requires the use of assembly stations organized\ninto assembly lines. Each station has specialized tools, such as\ndrills and welders. The factory transforms and\nassembles the initial parts and materials into finished products. The  aggregation pipeline  is the assembly line,  aggregation stages  are the assembly stations, and\n operator expressions  are the specialized tools. Using query operations, such as the  find()  method, you can perform the following actions: Using aggregation operations, you can perform the following actions: Aggregation operations have some  limitations : Select  which documents  to return. Select  which fields  to return. Sort the results. Perform all query operations. Rename fields. Calculate fields. Summarize data. Group values. Returned documents must not violate the  BSON-document size limit \nof 16 megabytes. Pipeline stages have a memory limit of 100 megabytes by default. If necessary, you may exceed this limit by setting the  allowDiskUse \nproperty of  AggregateOptions  to  true . See the\n AggregateOptions API documentation \nfor more details. The  $graphLookup  stage has a strict\nmemory limit of 100 megabytes and will ignore  allowDiskUse . Expression operators Aggregation pipeline Aggregation stages Operator expressions The example uses sample data about restaurants. The following code\ninserts data into the  restaurants  collection of the  aggregation \ndatabase: For more information on connecting to your MongoDB deployment, see the  Connection Guide . To perform an aggregation, pass a list of aggregation stages to the\n collection.aggregate()  method. In the example, the aggregation pipeline uses the following aggregation stages: This example should produce the following output: For more information, see the  aggregate() API documentation . A  $match  stage to filter for documents whose\n categories  array field contains the element  Bakery . A  $group  stage to group the matching documents by the  stars \nfield, accumulating a count of documents for each distinct value of  stars . You can find another aggregation pipeline example  in this MongoDB Blog\npost .",
            "code": [
                {
                    "lang": "javascript",
                    "value": "const db = client.db(\"aggregation\");\nconst coll = db.collection(\"restaurants\");\n\nconst docs = [\n    { stars: 3, categories: [\"Bakery\", \"Sandwiches\"], name: \"Rising Sun Bakery\" },\n    { stars: 4, categories: [\"Bakery\", \"Cafe\", \"Bar\"], name: \"Cafe au Late\" },\n    { stars: 5, categories: [\"Coffee\", \"Bakery\"], name: \"Liz's Coffee Bar\" },\n    { stars: 3, categories: [\"Steak\", \"Seafood\"], name: \"Oak Steakhouse\" },\n    { stars: 4, categories: [\"Bakery\", \"Dessert\"], name: \"Petit Cookie\" },\n];\n\nconst result = await coll.insertMany(docs);"
                },
                {
                    "lang": "json",
                    "value": "{ _id: 4, count: 2 }\n{ _id: 3, count: 1 }\n{ _id: 5, count: 1 }"
                },
                {
                    "lang": "javascript",
                    "value": "const pipeline = [\n    { $match: { categories: \"Bakery\" } },\n    { $group: { _id: \"$stars\", count: { $sum: 1 } } }\n];\n\nconst aggCursor = coll.aggregate(pipeline);\nfor await (const doc of aggCursor) {\n    console.log(doc);\n}"
                }
            ],
            "preview": "In this guide, you can learn how to use aggregation operations in\nthe MongoDB Node.js driver.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/collations",
            "title": "Collations",
            "headings": [
                "Overview",
                "Usage",
                "Collation Parameters",
                "Collation Examples",
                "Set a Default Collation on a Collection",
                "Assign a Collation to an Index",
                "Collation Query Examples",
                "find() and sort() Example",
                "findOneAndUpdate() Example",
                "findOneAndDelete() Example",
                "Aggregation Example"
            ],
            "paragraphs": "Collations are available in MongoDB 3.4 and later. This guide shows you how to use  collations , a set of sorting rules, to\nrun operations using string ordering for specific languages and locales (a\ncommunity or region that shares common language idioms). MongoDB sorts strings using  binary collation  by default. This collation\nmethod uses the  ASCII standard \ncharacter values to compare and order strings. Languages and locales\nhave specific character ordering conventions that differ from the ASCII\nstandard. For example, in Canadian French, the right-most accented character determines\nthe ordering for strings when the other characters are the same. Consider the\nfollowing French words:  cote ,  cot\u00e9 ,  c\u00f4te , and  c\u00f4t\u00e9 . MongoDB sorts them in the following order using the default binary collation: MongoDB sorts them in the following order using the Canadian French collation: You can specify a collation when you create a new collection or new index. You\ncan also specify a collation for  CRUD operations \nand aggregations. When you create a new collection with a collation, you define the default\ncollation for any of the  operations that support collation  called on that\ncollection. You can override the collation for an operation by specifying a\ndifferent one. When you create an index with a collation, you specify the sort order for\noperations that use that index. To use the collation in the index, you\nmust provide a matching collation in the operation, and the operation must\nuse the index. While most index types support collation, the following\ntypes support only binary comparison: Currently, you cannot create a collation on an existing collection. To use\ncollations with an existing collection, create an index with the collation\nand specify the same collation in your operations on it. text 2d geoHaystack The collation object contains the following parameters: You must specify the  locale  field in the collation; all other fields\nare optional. For a complete list of supported locales and the default values\nfor the  locale  fields, see  Supported Languages and Locales .\nFor descriptions of each field, see the  Collation Document MongoDB\nmanual entry . In the following example, we create a new collection called  souvenirs  and\nassign a default collation with the \" fr_CA \" locale. The collation applies\nto all  operations that support collation  performed on that\ncollection. Any of the operations that support collations automatically apply the collation\ndefined on the collection. The query below searches the  souvenirs \ncollection and applies the \" fr_CA \" locale collation: You can specify a different collation as a parameter in an operation that\nsupports collations. The following query specifies the \" is \" Iceland locale\nand  caseFirst  optional parameter with the value \" upper \": In the following example, we create a new index on the  title  field of\na collection with a collation set to the \" en_US \" locale. The following query uses the index we created: The following queries  do not  use the index that we created.  The first\nquery does not include a collation and the second contains a different\nstrength value than the collation on the index. Operations that read, update, and delete documents from a collection can use\ncollations. This section includes examples of a selection of these. See the\nMongoDB manual for a full list of  operations that support collation . The following example calls both  find()  and  sort()  on a collection\nthat uses the default binary collation. We use the German collation by\nsetting the value of the  locale  parameter to  de . The following example calls the  findOneAndUpdate()  operation on a\ncollection that uses the default binary collation. The collection contains the\nfollowing documents: Consider the following  findOneAndUpdate()  operation on this collection\nwhich  does not  specify a collation: Since \"Gunter\" is the first sorted result when using a binary collation, none\nof the documents come lexically before and match the  $lt  comparison\noperator in the query document. As a result, the operation does not update any\ndocuments. Consider the same operation with a collation specified with the locale set to\n de@collation=phonebook . This locale specifies the  collation=phonebook \noption which contains rules for prioritizing proper nouns, identified by\ncapitalization of the first letter. The  de@collation=phonebook  locale and\noption sorts characters with umlauts before the same characters without\numlauts. Since \"G\u00fcnter\" lexically comes before \"Gunter\" using the\n de@collation=phonebook  collation specified in  findOneAndUpdate() ,\nthe operation returns the following updated document: The following example calls the  findOneAndDelete()  operation on a\ncollection that uses the default binary collation and contains the following\ndocuments: In this example, we set the  numericOrdering  collation parameter to  true \nto sort numeric strings based on their numerical order instead of their\nlexical order. After you run the operation above, the collection contains the following\ndocuments: If you perform the same operation without collation on the original\ncollection of three documents, it matches documents based on the lexical value\nof the strings (\" 16 \", \" 84 \", and \" 179 \"), and deletes the first\ndocument it finds that matches the query criteria. Since all the documents contain lexical values in the  a  field that\nmatch the criteria (greater than the lexical value of \" 100 \"), the operation\nremoves the first result. After you run the operation above, the collection\ncontains the following documents: To use collation with the  aggregate \noperation, pass the collation document in the options field, after the\narray of pipeline stages. The following example shows an aggregation pipeline on a collection that uses\nthe default binary collation. The aggregation groups the  first_name  field,\ncounts the total number of results in each group, and sorts the results by\nthe German phonebook ( de@collation=phonebook  locale) order. You can specify only one collation on an aggregation.",
            "code": [
                {
                    "lang": "none",
                    "value": "cote\ncot\u00e9\nc\u00f4te\nc\u00f4t\u00e9"
                },
                {
                    "lang": "none",
                    "value": "cote\nc\u00f4te\ncot\u00e9\nc\u00f4t\u00e9"
                },
                {
                    "lang": "javascript",
                    "value": "collation: {\n  locale: <string>,\n  caseLevel: <bool>,\n  caseFirst: <string>,\n  strength: <int>,\n  numericOrdering: <bool>,\n  alternate: <string>,\n  maxVariable: <string>,\n  backwards: <bool>\n}"
                },
                {
                    "lang": "javascript",
                    "value": "// Create the collection with a collation\ndb.createCollection(\"souvenirs\", {\n  collation: { locale: \"fr_CA\" },\n});"
                },
                {
                    "lang": "javascript",
                    "value": "collection.find({type: \"photograph\"});"
                },
                {
                    "lang": "javascript",
                    "value": " collection.find({type: \"photograph\"},\n   { collation: { locale: \"is\", caseFirst: \"upper\" } }\n );"
                },
                {
                    "lang": "javascript",
                    "value": "collection.createIndex(\n  { 'title' : 1 },\n  { 'collation' : { 'locale' : 'en_US' } });\n"
                },
                {
                    "lang": "javascript",
                    "value": "collection.find({\"year\": 1980}, {\"collation\" : {\"locale\" : \"en_US\" }})\n  .sort({\"title\": -1});"
                },
                {
                    "lang": "javascript",
                    "value": "// no collation specified\ncollection.find({\"year\": 1980})\n  .sort({\"title\": -1});\n\n// collation differs from the one on the index\ncollection.find({\"year\": 1980}, {\"collation\" : {\"locale\" : \"en_US\", \"strength\": 2 }})\n  .sort({\"title\": -1});"
                },
                {
                    "lang": "javascript",
                    "value": "collection.find({ city: \"New York\" }, { collation: { locale: \"de\" } })\n  .sort({ name: 1 });\n"
                },
                {
                    "lang": "none",
                    "value": "{ \"_id\" : 1, \"first_name\" : \"Hans\" }\n{ \"_id\" : 2, \"first_name\" : \"Gunter\" }\n{ \"_id\" : 3, \"first_name\" : \"G\u00fcnter\" }\n{ \"_id\" : 4, \"first_name\" : \"J\u00fcrgen\" }"
                },
                {
                    "lang": "none",
                    "value": "{ lastErrorObject: { updatedExisting: true, n: 1 },\n  value: { _id: 3, first_name: 'G\u00fcnter' },\n  ok: 1 }"
                },
                {
                    "lang": "javascript",
                    "value": "collection.findOneAndUpdate(\n  { first_name : { $lt: \"Gunter\" } },\n  { $set: { verified: true } }\n);"
                },
                {
                    "lang": "javascript",
                    "value": "collection.findOneAndUpdate(\n  { first_name: { $lt: \"Gunter\" } },\n  { $set: { verified: true } },\n  { collation: { locale: \"de@collation=phonebook\" } },\n);"
                },
                {
                    "lang": "none",
                    "value": "{ \"_id\" : 1, \"a\" : \"16\" }\n{ \"_id\" : 2, \"a\" : \"84\" }\n{ \"_id\" : 3, \"a\" : \"179\" }"
                },
                {
                    "lang": "none",
                    "value": "{ \"_id\" : 1, \"a\" : \"16\" }\n{ \"_id\" : 2, \"a\" : \"84\" }"
                },
                {
                    "lang": "none",
                    "value": "{ \"_id\" : 2, \"a\" : \"84\" }\n{ \"_id\" : 3, \"a\" : \"179\" }"
                },
                {
                    "lang": "javascript",
                    "value": "collection.findOneAndDelete(\n  { a: { $gt: \"100\" } },\n  { collation: { locale: \"en\", numericOrdering: true } },\n);"
                },
                {
                    "lang": "javascript",
                    "value": "await collection.findOneAndDelete({ a: { $gt: \"100\" } });"
                },
                {
                    "lang": "javascript",
                    "value": "collection.aggregate(\n  [\n    { $group: { \"_id\": \"$first_name\", \"nameCount\": { \"$sum\": 1 } } },\n    { $sort: { \"_id\": 1 } },\n  ],\n  { collation: { locale: \"de@collation=phonebook\" } },\n);\n"
                }
            ],
            "preview": "Collations are available in MongoDB 3.4 and later.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud/query-document",
            "title": "Specify a Query",
            "headings": [
                "Overview",
                "Literal Value Queries",
                "Comparison Operators",
                "Logical Operators",
                "Element Operators",
                "Evaluation Operators"
            ],
            "paragraphs": "Most CRUD operations allow you to narrow the set of matched documents by\nspecifying matching criteria in a  query document . Query documents contain\none or more query operators that apply to specific fields which  determine which\ndocuments to include in the result set. In a query document, you can match fields against literal values\n(e.g.  { title: 'The Room' } ) or you can compose\n query operators  to express more\ncomplex matching criteria. In this guide, we cover the following categories\nof query operators in MongoDB and show examples on how to use them: Use the following code snippet to create a collection of documents that\ndescribe an inventory of fruit to follow along with our query operator\nexamples: Comparison Operators Logical Operators Element Operators Evaluation Operators Your query operation may return a reference to a\ncursor that contains matching documents. To learn how to\nexamine data stored in the cursor, see the\n Cursor Fundamentals page . Literal value queries allow you to query for data that exactly matches\na value you provide in the query document. A literal value query has two\nparts: a field name and a value. Documents returned from such a query\nmust contain a field that has exactly the same name as the provided name\nand a value for that field that is exactly the same as the provided\nvalue. The following operation uses a literal query to search for\ndocuments containing a field called \"name\" that has a value of \"apples\": This code snippet returns the following results: Literal value queries are equivalent to the  $eq  comparison\noperator. As a result, the following two queries are equivalent: Comparison operators allow you to query for data based on comparisons\nwith values in a collection. Common comparison operators include\n $gt  for \"greater than\" comparisons,  $lt  for \"less than\" comparisons,\nand  $ne  for \"not equal to\" comparisons. The following operation uses\nthe comparison operator  $gt  to search for documents with a quantity\nvalue greater than 5 and prints them out: This code snippet returns the following results: Logical operators allow you to query for data using logic applied to the\nresults of field-level operators. For instance, you can use the  $or \nmethod to query for documents that match either a  $gt  comparison\noperator or a literal value query. The following operation uses the\nlogical operator  $not  to search for documents with a quantity value\nthat is not greater than 5 and prints them out: This code snippet returns the following results: For more information on comparison operators, see the reference manual\nentry for  Comparison Query Operators . Whenever a query document contains multiple elements, those elements\nare combined together with an implicit  $and  logical operator to\nfigure out which documents match the query. As a result, the following\ntwo queries are equivalent: Element operators allow you to query based on the presence, absence, or\ntype of a field. The following operation uses the element operator\n $exists  to search for documents containing the  microsieverts \nfield: This code snippet returns the following results: For more information on this operator, see the reference manual entry for\nthe  $exists operator . Evaluation operators allow you to execute higher level logic, like\nregex and text searches, when querying for documents in a collection.\nCommon evaluation operators include  $regex  and  $text .\nThe following operation uses the evaluation operator  $mod  to search\nfor documents with a quantity value that is divisible by 3 with\na remainder of 0: This code snippet returns the following results: For more information on this operator, see the reference manual entry for\nthe  $mod operator .",
            "code": [
                {
                    "lang": "javascript",
                    "value": "await collection.insertMany([\n  { \"_id\": 1, \"name\": \"apples\", \"qty\": 5, \"rating\": 3 },\n  { \"_id\": 2, \"name\": \"bananas\", \"qty\": 7, \"rating\": 1, \"microsieverts\": 0.1 },\n  { \"_id\": 3, \"name\": \"oranges\", \"qty\": 6, \"rating\": 2 },\n  { \"_id\": 4, \"name\": \"avocados\", \"qty\": 3, \"rating\": 5 },\n]);"
                },
                {
                    "lang": "javascript",
                    "value": "const query = { \"name\": \"apples\" };\nconst cursor = collection.find(query);\nawait cursor.forEach(console.dir);"
                },
                {
                    "lang": "javascript",
                    "value": "{ \"_id\": 1, \"name\": \"apples\", \"qty\": 5, \"rating\": 3 }"
                },
                {
                    "lang": "javascript",
                    "value": "collection.find({\n   rating: { $eq: 5 }\n})"
                },
                {
                    "lang": "javascript",
                    "value": "collection.find({\n   rating: 5\n})"
                },
                {
                    "lang": "javascript",
                    "value": "// $gt means \"greater than\"\nconst query = { qty: { $gt : 5 } };\nconst cursor = collection.find(query);\nawait cursor.forEach(console.dir);"
                },
                {
                    "lang": "javascript",
                    "value": "{ \"_id\": 2, \"name\": \"bananas\", \"qty\": 7, \"rating\": 1 }\n{ \"_id\": 3, \"name\": \"oranges\", \"qty\": 6, \"rating\": 2 }"
                },
                {
                    "lang": "javascript",
                    "value": "const query = { qty: { $not: { $gt: 5 }}};\nconst cursor = collection.find(query);\nawait cursor.forEach(console.dir);"
                },
                {
                    "lang": "javascript",
                    "value": "{ \"_id\": 4, \"name\": \"avocados\", \"qty\": 3, \"rating\": 5 }\n{ \"_id\": 1, \"name\": \"apples\", \"qty\": 5, \"rating\": 3 }"
                },
                {
                    "lang": "javascript",
                    "value": "collection.find({\n  rating: { $eq: 5 },\n  qty: { $gt: 4 }\n})"
                },
                {
                    "lang": "javascript",
                    "value": "collection.find({\n  $and: [\n     { rating: { $eq: 5 }},\n     { qty: { $gt: 4 }}\n  ]\n})"
                },
                {
                    "lang": "javascript",
                    "value": "const query = { microsieverts: { $exists: true } };\nconst cursor = collection.find(query);\nawait cursor.forEach(console.dir);"
                },
                {
                    "lang": "javascript",
                    "value": "{ \"_id\": 2, \"name\": \"bananas\", \"qty\": 7, \"rating\": 1, \"microsieverts\": 0.1 }"
                },
                {
                    "lang": "javascript",
                    "value": "// $mod means \"modulo\" and returns the remainder after division\nconst query = { qty: { $mod: [ 3, 0 ] } };\nconst cursor = collection.find(query);\nawait cursor.forEach(console.dir);"
                },
                {
                    "lang": "javascript",
                    "value": "{ \"_id\": 3, \"name\": \"oranges\", \"qty\": 6, \"rating\": 2 }\n{ \"_id\": 4, \"name\": \"avocados\", \"qty\": 3, \"rating\": 5 }"
                }
            ],
            "preview": "Most CRUD operations allow you to narrow the set of matched documents by\nspecifying matching criteria in a query document. Query documents contain\none or more query operators that apply to specific fields which  determine which\ndocuments to include in the result set.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud/read-operations",
            "title": "Read Operations",
            "headings": [],
            "paragraphs": "Retrieve Data Access Data From a Cursor Retrieve Distinct Values Sort Results Skip Returned Results Limit the Number of Returned Results Specify Which Fields to Return Search Geospatially Search Text",
            "code": [],
            "preview": null,
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud/write-operations",
            "title": "Write Operations",
            "headings": [],
            "paragraphs": "Insert a Document Generate Custom Values for  _id Delete a Document Change a Document Update Arrays in a Document Insert or Update in a Single Operation",
            "code": [],
            "preview": null,
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud/compound-operations",
            "title": "Compound Operations",
            "headings": [
                "Overview",
                "Built-in Methods"
            ],
            "paragraphs": "Most database requests only need to read data out of a database or\nwrite data into a database. However, client applications sometimes need\nto read and write data in a single interaction with the database. Compound operations combine read and write operations\nin a single atomic statement, so there's no chance of data changing in\nbetween a read and a subsequent write; in fact, both operations take\nplace in the same line of code from the perspective of your client\napplication. This property can be useful in cases where you want to write to a\nspecific document, but you haven't found it yet. If you just perform a\nread for the document's  _id  and then try to alter the document you\njust found, it's possible that someone else can alter the document in\nbetween your read and write operations. This doesn't stop you from doing\nthis work, but it can make error handling much more difficult. Compound\noperations help keep your logic straightforward by handling that logic\nentirely inside the database behind a layer of abstraction, so you don't\nhave to worry about it. While you can accomplish this task using\nseparate reads and writes, doing so requires the client application to\ngracefully handle potential errors at any stage of the process and in\nmultiple potential error states. This increases the complexity of your\ncode and can make your client application brittle and difficult to test. There are three major compound operations: All three methods accept an optional  options  object with\nconfigurable  sort  and\n projection  options\nthat work just like their read operation equivalents.\n findOneAndUpdate()  and  findOneAndDelete()  allow the client to\nconfigure the  returnDocument   option, a boolean that determines if\nthe method returns the pre-update or post-update version of the modified\ndocument. findOneAndDelete() \nmatches multiple documents to a supplied query and removes the first\nof those matched documents. findOneAndUpdate() \nmatches multiple documents to a supplied query and updates the first\nof those matched documents using the provided update document. findOneAndReplace() \nmatches multiple documents to a supplied query and replaces the first\nof those matched documents using the provided replacement document.",
            "code": [],
            "preview": "Most database requests only need to read data out of a database or\nwrite data into a database. However, client applications sometimes need\nto read and write data in a single interaction with the database.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud/read-operations/geo",
            "title": "Search Geospatially",
            "headings": [
                "Overview",
                "Coordinates on an Earth-like Sphere",
                "Coordinates on a 2D Plane",
                "Examples",
                "Query by Proximity",
                "Query Within a Range"
            ],
            "paragraphs": "You can query data based on geographical location using geospatial query\noperators. You can format geospatial queries using one of the following\ncoordinate systems: This section contains examples of geospatial queries using different\nquery operators that you can run against your Atlas sample dataset. Coordinates on an Earth-like Sphere Coordinates on a 2D Plane For geospatial queries using longitude and latitude coordinates\non an Earth-like sphere, use the  GeoJSON \nquery format. While GeoJSON has  multiple types , all GeoJSON data\ntypes use some form of the following structure: The object type determines the number of coordinates. For instance, a\n Point  requires only one coordinate: a longitude and a latitude.\nA  Line  uses two coordinates: a longitude and a latitude for each end.\nA  Polygon  consists of a list of coordinates in which the first and last\ncoordinate are the same, effectively closing the polygon. To learn more\nabout the GeoJSON shapes you can use in MongoDB, consult the\n GeoJSON manual entry . To enable querying GeoJSON data, you must add the field to a  2dsphere \nindex. The following snippet creates an index on the  location.geo  field in\nthe  theaters  collection using the  createIndex()  method: You can also express geospatial queries using  x  and  y  coordinates in\na two-dimensional Euclidean plane. Until MongoDB, this was the only format\ncompatible with geospatial queries, and are now referred to as\n\"legacy coordinate pairs\". Legacy coordinate pairs use the following structure: The field should contain an array of two values in which the first represents\nthe  x  axis value and the second represents the  y  axis value. To enable querying using legacy coordinate pairs, create a  2d  index on\nthe field on the collection. The following snippet creates an index on the\n coordinates  field in the  shipwrecks  collection using the\n createIndex()  method: See the\n MongoDB server manual page on legacy coordinate pairs \nfor more information. Spherical ( 2dsphere ) and flat ( 2d ) indexes support some, but\nnot all, of the same query operators. For a full list of operators\nand their index compatibility, consult the\n manual entry for geospatial queries . The following examples use the MongoDB Atlas sample dataset. You can learn how to set up your own free-tier Atlas cluster and how to load the sample dataset in our\n quick start guide . The examples use the  theaters  collection in the  sample_mflix  database\nfrom the sample dataset. The  theaters  collection contains a  2dsphere  index\non the  location.geo  field. The  $near \noperator accepts a set of longitude-latitude coordinates and returns\ndocuments ordered from nearest to farthest. To limit the results to a\nmaximum distance in meters, use the  $maxDistance  option. For a\ncomplete list of options, see the reference documentation for  $near .\nThe following example queries for theaters within  10,000  meters of\n [ -73.9667, 40.78 ] . The  $geoWithin  operator\nselects documents with geospatial data that exist within a specified\nshape. The following example searches for movie theaters in the New\nEngland area: See the  MongoDB server manual page on geospatial query operators \nfor more information on the operators you can use in your query.",
            "code": [
                {
                    "lang": "javascript",
                    "value": "<field> : {\n   type: <GeoJSON type>,\n   coordinates: [\n      [longitude_1, latitude_1],\n      ...\n      [longitude_n, latitude_n]\n   ]\n}"
                },
                {
                    "lang": "javascript",
                    "value": "db.theaters.createIndex({location.geo: \"2dsphere\"})"
                },
                {
                    "lang": "javascript",
                    "value": "<field> : [ x, y ]"
                },
                {
                    "lang": "javascript",
                    "value": "db.shipwrecks({coordinates: \"2d\"})"
                },
                {
                    "lang": "javascript",
                    "value": "  const query = {\n    \"location.geo\": {\n      $near: {\n        $geometry: { type: \"Point\", coordinates: [-73.9667, 40.78] },\n        $maxDistance: 10000,\n      },\n    },\n  };\n\n  // find documents based on our query\n  const cursor = theaters.find(query);"
                },
                {
                    "lang": "javascript",
                    "value": "  const query = {\n    \"location.geo\": {\n      $geoWithin: {\n        $geometry: {\n          type: \"Polygon\",\n          coordinates: [\n            [\n              [-72, 40],\n              [-74, 41],\n              [-72, 39],\n              [-72, 40],\n            ],\n          ],\n        },\n      },\n    },\n  };\n\n  // find documents based on our query\n  const cursor = theaters.find(query);"
                }
            ],
            "preview": "You can query data based on geographical location using geospatial query\noperators. You can format geospatial queries using one of the following\ncoordinate systems:",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/encrypt-fields",
            "title": "In-Use Encryption",
            "headings": [
                "Overview",
                "Queryable Encryption",
                "Client-side Field Level Encryption"
            ],
            "paragraphs": "You can use the Node.js driver to encrypt specific document fields by using a\nset of features called  in-use encryption . In-use encryption allows\nyour application to encrypt data  before  sending it to MongoDB\nand query documents with encrypted fields. In-use encryption prevents unauthorized users from viewing plaintext\ndata as it is sent to MongoDB or while it is in an encrypted database. To\nenable in-use encryption in an application and authorize it to decrypt\ndata, you must create encryption keys that only your application can\naccess. Only applications that have access to your encryption\nkeys can access the decrypted, plaintext data. If an attacker gains\naccess to the database, they can only see the encrypted ciphertext data\nbecause they lack access to the encryption keys. You might use in-use encryption to encrypt fields in your MongoDB\ndocuments that contain the following types of sensitive data: MongoDB offers the following features to enable in-use encryption: Credit card numbers Addresses Health information Financial information Any other sensitive or personally identifiable information (PII) Queryable Encryption Client-side Field Level Encryption Queryable Encryption is the next-generation in-use encryption feature,\nfirst introduced as a preview feature in MongoDB Server version 6.0 and\nas a generally available (GA) feature in MongoDB 7.0. Queryable\nEncryption supports searching encrypted fields for equality and encrypts\neach value uniquely. To learn more about Queryable Encryption, see  Queryable\nEncryption  in the Server manual. The implementation of Queryable Encryption in MongoDB 6.0 is incompatible with the GA version introduced in MongoDB 7.0. The Queryable Encryption preview feature is no longer supported. Client-side Field Level Encryption (CSFLE) was introduced in MongoDB\nServer version 4.2 and supports searching encrypted fields for equality.\nCSFLE differs from Queryable Encryption in that you can select either a\ndeterministic or random encryption algorithm to encrypt fields. You can only\nquery encrypted fields that use a deterministic encryption algorithm when\nusing CSFLE. When you use a random encryption algorithm to encrypt\nfields in CSFLE, they can be decrypted, but you cannot perform equality\nqueries on those fields. When you use Queryable Encryption, you cannot\nspecify the encryption algorithm, but you can query all encrypted\nfields. When you deterministically encrypt a value, the same input value\nproduces the same output value. While deterministic encryption allows\nyou to perform queries on those encrypted fields, encrypted data with\nlow cardinality is susceptible to code breaking by frequency analysis. To learn more about CSFLE, see  CSFLE  in the\nServer manual. To learn more about these concepts, see the following Wikipedia\nentries: Cardinality Frequency Analysis",
            "code": [],
            "preview": "You can use the Node.js driver to encrypt specific document fields by using a\nset of features called in-use encryption. In-use encryption allows\nyour application to encrypt data before sending it to MongoDB\nand query documents with encrypted fields.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/gridfs",
            "title": "GridFS",
            "headings": [
                "Overview",
                "How GridFS Works",
                "Create a GridFS Bucket",
                "Upload Files",
                "Retrieve File Information",
                "Download Files",
                "Rename Files",
                "Delete Files",
                "Delete a GridFS Bucket",
                "Additional Resources"
            ],
            "paragraphs": "In this guide, you can learn how to store and retrieve large files in\nMongoDB using  GridFS . GridFS is a specification that describes how\nto split files into chunks during storage\nand reassemble them during retrieval. The driver implementation of\nGridFS manages the operations and organization of\nthe file storage. You should use GridFS if the size of your file exceeds the BSON-document\nsize limit of 16 megabytes. For more detailed information on whether GridFS is\nsuitable for your use case, see the  GridFS server manual page . Navigate the following sections to learn more about GridFS operations\nand implementation: Create a GridFS Bucket Upload Files Retrieve File Information Download Files Rename Files Delete Files Delete a GridFS Bucket GridFS organizes files in a  bucket , a group of MongoDB collections\nthat contain the chunks of files and descriptive information.\nBuckets contain the following collections, named using the convention\ndefined in the GridFS specification: When you create a new GridFS bucket, the driver creates the  chunks \nand  files  collections, prefixed with the default bucket name  fs , unless\nyou specify a different name. The driver also creates an index on each\ncollection to ensure efficient retrieval of files and related\nmetadata. The driver only creates the GridFS bucket on the first write\noperation if it does not already exist. The driver only creates indexes if\nthey do not exist and when the bucket is empty. For more information on\nGridFS indexes, see the server manual page on  GridFS Indexes . When storing files with GridFS, the driver splits the files into smaller\npieces, each represented by a separate document in the  chunks  collection.\nIt also creates a document in the  files  collection that contains\na unique file id, file name, and other file metadata. You can upload the file from\nmemory or from a stream. The following diagram describes how GridFS splits\nfiles when uploading to a bucket: When retrieving files, GridFS fetches the metadata from the  files \ncollection in the specified bucket and uses the information to reconstruct\nthe file from documents in the  chunks  collection. You can read the file\ninto memory or output it to a stream. The  chunks  collection stores the binary file chunks. The  files  collection stores the file metadata. Create a bucket or get a reference to an existing one to begin storing\nor retrieving files from GridFS. Create a  GridFSBucket \ninstance, passing a database as the parameter. You can then use the\n GridFSBucket  instance to call read and write operations on the files\nin your bucket: Pass your bucket name as the second parameter to the  create()  method\nto create or reference a bucket with a custom name other than the\ndefault name  fs , as shown in the following example: For more information, see the  GridFSBucket API documentation . Use the  openUploadStream()  method from  GridFSBucket  to create an upload\nstream for a given file name. You can use the  pipe()  method to\nconnect a Node.js  fs  read stream to the upload stream. The\n openUploadStream()  method allows you to specify configuration information\nsuch as file chunk size and other field/value pairs to store as metadata. Set\nthese options as parameters of  openUploadStream()  as shown in the\nfollowing code snippet: See the  openUploadStream() API documentation  for more information. In this section, you can learn how to retrieve file metadata stored in the\n files  collection of the GridFS bucket. The metadata contains information\nabout the file it refers to, including: Call the  find()  method on the  GridFSBucket  instance to retrieve\nfiles from a GridFS bucket. The method returns a  FindCursor  instance\nfrom which you can access the results. The following code example shows you how to retrieve and print file metadata\nfrom all your files in a GridFS bucket. Among the different ways that you can\ntraverse the retrieved results from the  FindCursor  iterable, the\nfollowing example uses the  forEach()  method to display the results: The  find()  method accepts various query specifications and can be\ncombined with other methods such as  sort() ,  limit() , and  project() . For more information on the classes and methods mentioned in this section,\nsee the following resources: The  _id  of the file The name of the file The length/size of the file The upload date and time A  metadata  document in which you can store any other information find() API documentation FindCursor API documentation Cursor Fundamentals page Read Operations page You can download files from your MongoDB database by using the\n openDownloadStreamByName()  method from  GridFSBucket  to create a\ndownload stream. The following example shows you how to download a file referenced\nby the file name, stored in the  filename  field, into your working\ndirectory: Alternatively, you can use the  openDownloadStream() \nmethod, which takes the  _id  field of a file as a parameter: For more information on the  openDownloadStreamByName()  method, see\nits  API documentation . If there are multiple documents with the same  filename  value,\nGridFS will stream the most recent file with the given name (as\ndetermined by the  uploadDate  field). The GridFS streaming API cannot load partial chunks. When a download\nstream needs to pull a chunk from MongoDB, it pulls the entire chunk\ninto memory. The 255 kilobyte default chunk size is usually\nsufficient, but you can reduce the chunk size to reduce memory\noverhead. Use the  rename()  method to update the name of a GridFS file in your\nbucket. You must specify the file to rename by its  _id  field\nrather than its file name. The following example shows how to update the  filename  field to\n\"newFileName\" by referencing a document's  _id  field: For more information on this method, see the  rename() \nAPI documentation. The  rename()  method only supports updating the name of one file at\na time. To rename multiple files, retrieve a list of files matching the\nfile name from the bucket, extract the  _id  field from the files you\nwant to rename, and pass each value in separate calls to the  rename() \nmethod. Use the  delete()  method to remove a file from your bucket. You must\nspecify the file by its  _id  field rather than its file name. The following example shows you how to delete a file by referencing its  _id  field: For more information on this method, see the  delete() \nAPI documentation. The  delete()  method only supports deleting one file at a time. To\ndelete multiple files, retrieve the files from the bucket, extract\nthe  _id  field from the files you want to delete, and pass each value\nin separate calls to the  delete()  method. Use the  drop()  method to remove a bucket's  files  and  chunks \ncollections, which effectively deletes the bucket. The following\ncode example shows you how to delete a GridFS bucket: For more information on this method, see the  drop() \nAPI documentation. MongoDB GridFS specification",
            "code": [
                {
                    "lang": "javascript",
                    "value": "const db = client.db(dbName);\nconst bucket = new mongodb.GridFSBucket(db);"
                },
                {
                    "lang": "javascript",
                    "value": "const bucket = new mongodb.GridFSBucket(db, { bucketName: 'myCustomBucket' });"
                },
                {
                    "lang": "javascript",
                    "value": "fs.createReadStream('./myFile').\n     pipe(bucket.openUploadStream('myFile', {\n         chunkSizeBytes: 1048576,\n         metadata: { field: 'myField', value: 'myValue' }\n     }));"
                },
                {
                    "lang": "javascript",
                    "value": "const cursor = bucket.find({});\ncursor.forEach(doc => console.log(doc));"
                },
                {
                    "lang": "javascript",
                    "value": "bucket.openDownloadStreamByName('myFile').\n     pipe(fs.createWriteStream('./outputFile'));"
                },
                {
                    "lang": "javascript",
                    "value": "bucket.openDownloadStream(ObjectId(\"60edece5e06275bf0463aaf3\")).\n     pipe(fs.createWriteStream('./outputFile'));"
                },
                {
                    "lang": "javascript",
                    "value": "bucket.rename(ObjectId(\"60edece5e06275bf0463aaf3\"), \"newFileName\");"
                },
                {
                    "lang": "javascript",
                    "value": "bucket.delete(ObjectId(\"60edece5e06275bf0463aaf3\"));"
                },
                {
                    "lang": "javascript",
                    "value": "bucket.drop();"
                }
            ],
            "preview": "In this guide, you can learn how to store and retrieve large files in\nMongoDB using GridFS. GridFS is a specification that describes how\nto split files into chunks during storage\nand reassemble them during retrieval. The driver implementation of\nGridFS manages the operations and organization of\nthe file storage.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud/read-operations/skip",
            "title": "Skip Returned Results",
            "headings": [
                "Overview",
                "Sample Documents",
                "Example"
            ],
            "paragraphs": "Use  skip  to omit documents from the beginning of the list of\nreturned documents for a read operation. You can combine  skip  with\n sort  to omit the top\n(for descending order) or bottom (for ascending order) results for a\ngiven query. Since the  order of documents returned  is not guaranteed in\nthe absence of a sort, using  skip  without using  sort  omits\narbitrary documents. If the value of  skip  exceeds the number of matched documents for\na query, that query returns no documents. Follow the instructions in the examples below to insert data into\na collection and perform a sort and skip on the results of a query.\nConsider a collection containing documents that describe varieties of\nfruit: Your query operation may return a reference to a\ncursor that contains matching documents. To learn how to\nexamine data stored in the cursor, see the\n Cursor Fundamentals page . In the following example, we query the collection with a filter that\nmatches all the documents and pass options that specifies  sort  and\n skip  commands as query options. The sort option specifies that fruit\ndocuments with higher ratings should be returned before ones with lower\nratings. The skip option specifies that the first 2 documents should be\nomitted from the result: Since we specified that the first  2  documents should be skipped, the\nthird and fourth highest rating documents are printed by the code snippet\nabove: The  sort  and  skip  options can also be specified as methods chained to\nthe  find  method. The following two commands are equivalent:",
            "code": [
                {
                    "lang": "json",
                    "value": "[\n   { \"_id\": 1, \"name\": \"apples\", \"qty\": 5, \"rating\": 3 },\n   { \"_id\": 2, \"name\": \"bananas\", \"qty\": 7, \"rating\": 1 },\n   { \"_id\": 3, \"name\": \"oranges\", \"qty\": 6, \"rating\": 2 },\n   { \"_id\": 4, \"name\": \"avocados\", \"qty\": 3, \"rating\": 5 },\n]"
                },
                {
                    "lang": "javascript",
                    "value": "// define an empty query document\nconst query = {};\nconst options = {\n   // sort in descending (-1) order by rating\n   sort : { rating: -1 },\n   // omit the first two documents\n   skip : 2,\n}\n\nconst cursor = collection.find(query, options);\nawait cursor.forEach(console.dir);"
                },
                {
                    "lang": "json",
                    "value": "{ \"_id\": 3, \"name\": \"oranges\", \"qty\": 6, \"rating\": 2 }\n{ \"_id\": 2, \"name\": \"bananas\", \"qty\": 7, \"rating\": 1 }"
                },
                {
                    "lang": "javascript",
                    "value": "collection.find(query, { sort: { rating: -1}, skip: 2});\ncollection.find(query).sort({rating: -1}).skip(2);"
                }
            ],
            "preview": "Use skip to omit documents from the beginning of the list of\nreturned documents for a read operation. You can combine skip with\nsort to omit the top\n(for descending order) or bottom (for ascending order) results for a\ngiven query. Since the order of documents returned is not guaranteed in\nthe absence of a sort, using skip without using sort omits\narbitrary documents.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud/read-operations/cursor",
            "title": "Access Data From a Cursor",
            "headings": [
                "Overview",
                "Cursor Paradigms",
                "For Each Functional Iteration",
                "Return an Array of All Documents",
                "Asynchronous Iteration",
                "Manual Iteration",
                "Stream API",
                "Event API",
                "Cursor Utility Methods",
                "Rewind",
                "Close"
            ],
            "paragraphs": "Read operations that return multiple documents do not immediately return\nall values matching the query. Because a query can potentially match\nvery large sets of documents, these operations rely upon an\nobject called a cursor. A cursor fetches documents in batches to reduce both\nmemory consumption and network bandwidth usage. Cursors are highly configurable and offer\nmultiple interaction paradigms for different use cases. The following functions directly return cursors: Other methods such as  Collection.findOne() \nand  Collection.watch()  use\ncursors internally, and return the results of the operations instead of\na cursor. Collection.find() Collection.aggregate() Collection.listIndexes() Db.aggregate() Db.listCollections() You can work with cursors using a number of  cursor paradigms .\nMost cursor paradigms allow you to access query results one document at\na time, abstracting away network and caching logic. However, since use\ncases differ, other paradigms offer different access patterns, like\npulling all matching documents into a collection in process memory. Do not combine different cursor paradigms on a single cursor.\nOperations such as  hasNext() ,  forEach() , and  toArray() \neach predictably modify the original cursor. If you mix these calls\non a single cursor, you may receive unexpected results. Because asynchronous calls directly modify the cursor, executing\nasynchronous calls on a single cursor simultaneously can also cause\nundefined behavior. Always wait for the previous\nasynchronous operation to complete before running another. When you reach the last result through iteration or through an at-once\nfetch, the cursor is exhausted which means it ceases to respond to methods\nthat access the results. You can pass a function to the  forEach()  method of any cursor to iterate through\nresults in a functional style: For use cases that require all documents matched by a query to be held\nin memory at the same time, use  toArray() .\nNote that large numbers of matched documents can cause performance issues\nor failures if the operation exceeds memory constraints. Consider using\n forEach()  to iterate\nthrough results unless you want to return all documents at once. Cursors implement the  AsyncIterator  interface, which\nallows you to use cursors in  for ...``await`` loops: You can use the  hasNext() \nmethod to check if a cursor can provide additional data, and then use\nthe  next() \nmethod to retrieve the subsequent element of the cursor: Cursors expose the  stream()  method to convert them to Node Readable Streams. These streams operate in  Object\nMode , which passes JavaScript objects rather than Buffers or Strings through the pipeline. As Readable Streams, cursors also support the Event API's\n close ,  data ,  end  and  readable  events: To reset a cursor to its initial position in the set of returned\ndocuments, use  rewind() . Cursors consume memory and network resources both in the client\napplication and in the connected instance of MongoDB. Use\n close() \nto free up a cursor's resources in both the client application\nand the MongoDB server:",
            "code": [
                {
                    "lang": "javascript",
                    "value": "  const cursor = collection.find({});\n  await cursor.forEach(doc => console.log(doc));"
                },
                {
                    "lang": "javascript",
                    "value": "  const cursor = collection.find({});\n  const allValues = await cursor.toArray();"
                },
                {
                    "lang": "javascript",
                    "value": "  const cursor = collection.find({});\n  console.log(\"async\");\n  for await (const doc of cursor) {\n    console.log(doc);\n  }"
                },
                {
                    "lang": "javascript",
                    "value": "  const cursor = collection.find({});\n\n  while (await cursor.hasNext()) {\n    console.log(await cursor.next());\n  }"
                },
                {
                    "lang": "javascript",
                    "value": "  const cursor = collection.find({});\n  cursor.stream().on(\"data\", doc => console.log(doc));"
                },
                {
                    "lang": "javascript",
                    "value": "  const cursor = collection.find({});\n  // the \"data\" event is fired once per document\n  cursor.on(\"data\", data => console.log(data));"
                },
                {
                    "lang": "javascript",
                    "value": "  const cursor = collection.find({});\n  const firstResult = await cursor.toArray();\n  console.log(\"First count: \" + firstResult.length);\n  await cursor.rewind();\n  const secondResult = await cursor.toArray();\n  console.log(\"Second count: \" + secondResult.length);"
                },
                {
                    "lang": "javascript",
                    "value": "  await cursor.close();"
                }
            ],
            "preview": "Read operations that return multiple documents do not immediately return\nall values matching the query. Because a query can potentially match\nvery large sets of documents, these operations rely upon an\nobject called a cursor. A cursor fetches documents in batches to reduce both\nmemory consumption and network bandwidth usage. Cursors are highly configurable and offer\nmultiple interaction paradigms for different use cases.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud/read-operations/distinct",
            "title": "Retrieve Distinct Values",
            "headings": [
                "Overview",
                "Sample Documents",
                "Distinct",
                "Document Field Parameter",
                "Example",
                "Query Parameter",
                "Example",
                "Options Parameter",
                "Example",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "Use the  distinct()  method to retrieve all distinct values for a specified field\nacross a collection. Consider a collection called  restaurants  that contains documents with restaurant data.\nThe examples on this page use the following  restaurants  documents to demonstrate the\nusage of  distinct() : Your query operation may return a reference to a\ncursor that contains matching documents. To learn how to\nexamine data stored in the cursor, see the\n Cursor Fundamentals page . The  distinct()  method requires a document field as a parameter. You can specify the\nfollowing optional parameters to adjust the method output: A  query  parameter to refine your results An  options  parameter to set collation rules Pass the name of the document field to return a list of the field's unique values. The \" Queens \" and \" Manhattan \" borough values each appear more than\nonce in the sample documents. However, the following example retrieves the\nunique values of the  borough  field: This code outputs the following  borough  values: You can specify a query parameter to return unique values for documents that match\nyour query. Visit  Specify a Query  for more information on constructing a\nquery filter. The following example outputs the distinct values of the  cuisine  field but\nexcludes restaurants in \" Brooklyn \": In this case, the query filter matches every borough value except for \" Brooklyn \". This\nprevents  distinct()  from outputting one  cuisine  value, \" Middle Eastern \".\nThe code outputs the following values: You can specify the collation to the  distinct()  method by defining a\n collation  field as an  options  parameter. This field allows you to set\nregional rules for string ordering and comparisons. See  Collations  for instructions on applying collations. When using the  options  parameter, you must also specify a  query  parameter. If\nyou don't want to use a query filter, define the query as  {} . The following example uses a  collation  field to specify German language ordering\nconventions when outputting the distinct  restaurant  values: In this case, German string ordering conventions place words beginning with \"\u00c4\" before\nthose beginning with \"B\". The code outputs the following: Without specifying a  collation  field, the output order would follow default\nbinary collation rules. These rules place words beginning with \"\u00c4\" after the those\nwith unaccented first letters: For a runnable example of retrieving distinct values, see  Retrieve Distinct Values of a Field . To learn more about the  distinct()  method and its parameters, you can visit the\n API documentation .",
            "code": [
                {
                    "lang": "json",
                    "value": "[\n   { \"_id\": 1, \"restaurant\": \"White Bear\", \"borough\": \"Queens\", \"cuisine\": \"Chinese\" },\n   { \"_id\": 2, \"restaurant\": \"Via Carota\", \"borough\": \"Manhattan\", \"cuisine\": \"Italian\" },\n   { \"_id\": 3, \"restaurant\": \"Borgatti's\", \"borough\": \"Bronx\", \"cuisine\": \"Italian\" },\n   { \"_id\": 4, \"restaurant\": \"Tanoreen\", \"borough\": \"Brooklyn\", \"cuisine\": \"Middle Eastern\" },\n   { \"_id\": 5, \"restaurant\": \"\u00c4pfel\", \"borough\": \"Queens\", \"cuisine\": \"German\" },\n   { \"_id\": 6, \"restaurant\": \"Samba Kitchen\", \"borough\": \"Manhattan\", \"cuisine\": \"Brazilian\" },\n]"
                },
                {
                    "lang": "javascript",
                    "value": "// specify \"borough\" as the field to return values for\nconst cursor = collection.distinct(\"borough\");\nawait cursor.forEach(console.dir);"
                },
                {
                    "lang": "json",
                    "value": "[ \"Bronx\", \"Brooklyn\", \"Manhattan\", \"Queens\" ]"
                },
                {
                    "lang": "javascript",
                    "value": "// exclude Brooklyn restaurants from the output\nconst query = { borough: { $ne: \"Brooklyn\" }};\n\n// find the filtered distinct values of \"cuisine\"\nconst cursor = collection.distinct(\"cuisine\", query);\nawait cursor.forEach(console.dir);"
                },
                {
                    "lang": "json",
                    "value": "[ \"Brazilian\", \"Chinese\", \"German\", \"Italian\" ]"
                },
                {
                    "lang": "javascript",
                    "value": "// define an empty query document\nconst query = {};\n// specify German string ordering conventions\nconst options = { collation: { locale: \"de\" }};\n\nconst cursor = collection.distinct(\"restaurant\", query, options);\nawait cursor.forEach(console.dir);"
                },
                {
                    "lang": "json",
                    "value": "[ \"\u00c4pfel\", \"Borgatti's\", \"Samba Kitchen\", \"Tanoreen\", \"Via Carota\", \"White Bear\" ]"
                },
                {
                    "lang": "json",
                    "value": "[ \"Borgatti's\", \"Samba Kitchen\", \"Tanoreen\", \"Via Carota\", \"White Bear\", \"\u00c4pfel\" ]"
                }
            ],
            "preview": "Use the distinct() method to retrieve all distinct values for a specified field\nacross a collection.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud/read-operations/project",
            "title": "Specify Which Fields to Return",
            "headings": [
                "Overview",
                "Sample Documents",
                "Single Field",
                "Multiple Fields"
            ],
            "paragraphs": "Use a projection to control which fields appear in the documents\nreturned by read operations. Many requests only require certain fields,\nso projections can help you limit unnecessary network bandwidth usage.\nProjections work in two ways: These two methods of projection are mutually exclusive: if you\nexplicitly include fields, you cannot explicitly exclude fields, and\nvice versa. Explicitly include fields with a value of  1 . This has the\nside-effect of implicitly excluding all unspecified fields. Implicitly exclude fields with a value of  0 . This has the\nside-effect of implicitly including all unspecified fields. Consider the following collection containing documents that describe\nvarieties of fruit: Your query operation may return a reference to a\ncursor that contains matching documents. To learn how to\nexamine data stored in the cursor, see the\n Cursor Fundamentals page . In the following query, pass the projection to only return the  name \nfield of each document: The projection document specifies a value of  1  for  name  to\nindicate that the read operation result should  include  the  name \nfield of each returned document. As a result, this projection implicitly\nexcludes the  qty  and  rating  fields. Passing this projection to\n find()  with an empty query document and no sort document yields\nthe following results: Despite the fact that this projection only explicitly included the\n name  field, the query returned the  _id  field as well! This happens because the  _id  field is a special case: it is always\nincluded in every query unless explicitly specified otherwise. That's\nbecause  _id  is a unique identifier for each document, a property\nthat can be very useful when constructing queries. The  movies \ncollection is a good example of why this property is useful: because\nremakes and even separate works can sometimes reuse movie titles, you\nneed a unique  _id  value to refer to any specific movie.  _id  is\nthe only exception to the mutually exclusive include-exclude behavior in\nprojections: you  can  explicitly exclude  _id  even when explicitly\nincluding other fields if you do not want  _id  to be present in\nreturned documents. The projection document specifies a value of  1  for  name  to\nindicate that the read operation result should  include  the  name \nfield of each returned document. As a result, this projection implicitly\nexcludes the  qty  and  rating  fields. Passing this projection to\n find()  with an empty query document and no sort document yields\nthe following results: You can also specify multiple fields to include in your projection. Note: the\norder in which you specify the fields in the projection does not alter the\norder in which they are returned. This example that identifies two fields to include in the projection yields\nthe following results: For additional projection examples, see the\n MongoDB Manual page on Project Fields to Return from Query .",
            "code": [
                {
                    "lang": "json",
                    "value": "[\n  { \"_id\": 1, \"name\": \"apples\", \"qty\": 5, \"rating\": 3 },\n  { \"_id\": 2, \"name\": \"bananas\", \"qty\": 7, \"rating\": 1 },\n  { \"_id\": 3, \"name\": \"oranges\", \"qty\": 6, \"rating\": 2 },\n  { \"_id\": 4, \"name\": \"avocados\", \"qty\": 3, \"rating\": 5 },\n]"
                },
                {
                    "lang": "javascript",
                    "value": "// return only* the name field\nconst projection = { name: 1 };\nconst cursor = collection.find().project(projection);\nawait cursor.forEach(console.dir);"
                },
                {
                    "lang": "json",
                    "value": "{ \"_id\": 1, \"name\": \"apples\" }\n{ \"_id\": 2, \"name\": \"bananas\" }\n{ \"_id\": 3, \"name\": \"oranges\" }\n{ \"_id\": 4, \"name\": \"avocados\" }"
                },
                {
                    "lang": "javascript",
                    "value": "// return only the name field\nconst projection = { _id: 0, name: 1 };\nconst cursor = collection.find().project(projection);\nawait cursor.forEach(console.dir);"
                },
                {
                    "lang": "json",
                    "value": "{ \"name\": \"apples\" }\n{ \"name\": \"bananas\" }\n{ \"name\": \"oranges\" }\n{ \"name\": \"avocados\" }"
                },
                {
                    "lang": "javascript",
                    "value": "const projection = { _id: 0, rating: 1, name: 1 };\nconst cursor = collection.find().project(projection);\nawait cursor.forEach(console.dir);"
                },
                {
                    "lang": "json",
                    "value": "  { \"name\": \"apples\", \"rating\": 3 }\n  { \"name\": \"bananas\", \"rating\": 1 }\n  { \"name\": \"oranges\", \"rating\": 2 }\n  { \"name\": \"avocados\", \"rating\": 5 }"
                }
            ],
            "preview": "Use a projection to control which fields appear in the documents\nreturned by read operations. Many requests only require certain fields,\nso projections can help you limit unnecessary network bandwidth usage.\nProjections work in two ways:",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud/read-operations/sort",
            "title": "Sort Results",
            "headings": [
                "Overview",
                "Sample Documents",
                "Example"
            ],
            "paragraphs": "Use  sort  to change the order in which read operations return\ndocuments.  Sort  tells MongoDB to order returned documents by the\nvalues of one or more fields in a certain direction. To sort returned\ndocuments by a field in ascending (lowest first) order, use a value of\n 1 . To sort in descending (greatest first) order instead, use  -1 .\nIf you do not specify a sort, MongoDB does not guarantee the order of\nquery results. Follow the instructions in the examples below to insert data into\na collection and perform a sort on the results of a query.\nConsider a collection containing documents that describe books. To\ninsert this data into a collection, run the following operation: Your query operation may return a reference to a\ncursor that contains matching documents. To learn how to\nexamine data stored in the cursor, see the\n Cursor Fundamentals page . Pass the following sort document to a read operation to ensure that the\noperation returns books with longer lengths before books with shorter\nlengths: In this case, the number  -1  tells the read operation to sort the\nbooks in descending order by length.  find()  returns the following\ndocuments when this sort is used with an empty query: Sometimes, the order of two or more documents is ambiguous using a\nspecified sort. In the above case, both \"A Dance with Dragons\" and\n\"Infinite Jest\" have  1104  pages, so the order in which they are\nreturned is not guaranteed. To resolve ties in your sorted results in a\nrepeatable way, add additional fields to the sort document: With the addition of the  author  field to the sort document, the read\noperation sorts matching documents first by  length  and, in the event\nof a tie, then by  author . Matched document fields are compared in\nthe same order as fields are specified in the sort document.  find() \nreturns the following ordering of documents when this sort is used on\nthe documents matching the query, sorting \"Martin\" before \"Wallace\" for\nthe two books with the same length:",
            "code": [
                {
                    "lang": "javascript",
                    "value": "await collection.insertMany([\n  { \"_id\": 1, \"name\": \"The Brothers Karamazov\", \"author\": \"Dostoyevsky\", \"length\": 824 },\n  { \"_id\": 2, \"name\": \"Les Mis\u00e9rables\", \"author\": \"Hugo\", \"length\": 1462 },\n  { \"_id\": 3, \"name\": \"Atlas Shrugged\", \"author\": \"Rand\", \"length\": 1088 },\n  { \"_id\": 4, \"name\": \"Infinite Jest\", \"author\": \"Wallace\", \"length\": 1104 },\n  { \"_id\": 5, \"name\": \"Cryptonomicon\", \"author\": \"Stephenson\", \"length\": 918 },\n  { \"_id\": 6, \"name\": \"A Dance with Dragons\", \"author\": \"Martin\", \"length\": 1104 },\n]);"
                },
                {
                    "lang": "javascript",
                    "value": "// define an empty query document\nconst query = {};\n// sort in descending (-1) order by length\nconst sort = { length: -1 };\nconst cursor = collection.find(query).sort(sort);\nawait cursor.forEach(console.dir);"
                },
                {
                    "lang": "json",
                    "value": "{ \"_id\": 2, \"title\": \"Les Mis\u00e9rables\", \"author\": \"Hugo\", \"length\": 1462 }\n{ \"_id\": 4, \"title\": \"Infinite Jest\", \"author\": \"Wallace\", \"length\": 1104 }\n{ \"_id\": 6, \"title\": \"A Dance with Dragons\", \"author\": \"Martin\", \"length\": 1104 }\n{ \"_id\": 3, \"title\": \"Atlas Shrugged\", \"author\": \"Rand\", \"length\": 1088 }\n{ \"_id\": 5, \"title\": \"Cryptonomicon\", \"author\": \"Stephenson\", \"length\": 918 }\n{ \"_id\": 1, \"title\": \"The Brothers Karamazov\", \"author\": \"Dostoyevsky\", \"length\": 824 }"
                },
                {
                    "lang": "javascript",
                    "value": "// define an empty query document\nconst query = {};\n// sort in ascending (1) order by length\nconst sort = { length: 1, author: 1 };\nconst cursor = collection.find(query).sort(sort);\nawait cursor.forEach(console.dir);"
                },
                {
                    "lang": "json",
                    "value": "{ \"_id\": 1, \"title\": \"The Brothers Karamazov\", \"author\": \"Dostoyevsky\", \"length\": 824 }\n{ \"_id\": 5, \"title\": \"Cryptonomicon\", \"author\": \"Stephenson\", \"length\": 918 }\n{ \"_id\": 3, \"title\": \"Atlas Shrugged\", \"author\": \"Rand\", \"length\": 1088 }\n{ \"_id\": 6, \"title\": \"A Dance with Dragons\", \"author\": \"Martin\", \"length\": 1104 }\n{ \"_id\": 4, \"title\": \"Infinite Jest\", \"author\": \"Wallace\", \"length\": 1104 }\n{ \"_id\": 2, \"title\": \"Les Mis\u00e9rables\", \"author\": \"Hugo\", \"length\": 1462 }"
                }
            ],
            "preview": "Use sort to change the order in which read operations return\ndocuments. Sort tells MongoDB to order returned documents by the\nvalues of one or more fields in a certain direction. To sort returned\ndocuments by a field in ascending (lowest first) order, use a value of\n1. To sort in descending (greatest first) order instead, use -1.\nIf you do not specify a sort, MongoDB does not guarantee the order of\nquery results.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud/read-operations/limit",
            "title": "Limit the Number of Returned Results",
            "headings": [
                "Overview",
                "Sample Documents",
                "Limit",
                "Skip"
            ],
            "paragraphs": "Use  limit  to cap the number of documents that can be returned from a\nread operation.  limit  functions as a cap on the maximum number of\ndocuments that the operation can return, but the operation can return\na smaller number of documents if there are not enough documents present\nto reach the limit. If  limit  is used with the\n skip  method, the skip applies\nfirst and the limit only applies to the documents left over after\nthe skip. Follow the instructions in the examples below to insert data into\na collection and return only certain results from a query using a sort,\na skip, and a limit. Consider the following collection of documents that\ndescribe books: Your query operation may return a reference to a\ncursor that contains matching documents. To learn how to\nexamine data stored in the cursor, see the\n Cursor Fundamentals page . The following example queries the collection to return the top three\nlongest books. It matches all the documents with the query, applies\na  sort  on the  length  field to return books with longer lengths before\nbooks, and applies a  limit  to return only  3  results: The code example above outputs the following three documents, sorted by\nlength: You can also apply  sort  and  limit  by specifying them in an\n options  object in your call to the  find()  method. The following two\ncalls are equivalent: For more information on the  options  settings for the  find() \nmethod, see the\n API documentation on find() . The order in which you call  limit  and  sort  does not matter\nbecause the driver reorders the calls to apply the sort first and the\nlimit after it. The following two calls are equivalent: To see the next three books in the results, append the  skip()  method,\npassing the number of documents to bypass as shown below: This operation returns the documents that describe the fourth through sixth\nbooks in order of longest-to-shortest length: You can combine skip and limit in this way to implement paging for your\ncollection, returning only small \"slices\" of the collection at once.",
            "code": [
                {
                    "lang": "json",
                    "value": "[\n  { \"_id\": 1, \"name\": \"The Brothers Karamazov\", \"author\": \"Dostoyevsky\", \"length\": 824 },\n  { \"_id\": 2, \"name\": \"Les Mis\u00e9rables\", \"author\": \"Hugo\", \"length\": 1462 },\n  { \"_id\": 3, \"name\": \"Atlas Shrugged\", \"author\": \"Rand\", \"length\": 1088 },\n  { \"_id\": 4, \"name\": \"Infinite Jest\", \"author\": \"Wallace\", \"length\": 1104 },\n  { \"_id\": 5, \"name\": \"Cryptonomicon\", \"author\": \"Stephenson\", \"length\": 918 },\n  { \"_id\": 6, \"name\": \"A Dance With Dragons\", \"author\": \"Tolkein\", \"length\": 1104 },\n]"
                },
                {
                    "lang": "javascript",
                    "value": "// define an empty query document\nconst query = {};\n// sort in descending (-1) order by length\nconst sort = { length: -1 };\nconst limit = 3;\nconst cursor = collection.find(query).sort(sort).limit(limit);\nawait cursor.forEach(console.dir);"
                },
                {
                    "lang": "json",
                    "value": "{ \"_id\": 2, \"title\": \"Les Mis\u00e9rables\", \"author\": \"Hugo\", \"length\": 1462 }\n{ \"_id\": 6, \"title\": \"A Dance With Dragons\", \"author\": \"Martin\", \"length\": 1104 }\n{ \"_id\": 4, \"title\": \"Infinite Jest\", \"author\": \"Wallace\", \"length\": 1104 }"
                },
                {
                    "lang": "javascript",
                    "value": "collection.find(query).sort({ length: -1 }).limit(3);\ncollection.find(query, { sort: { length: -1 }, limit: 3 });"
                },
                {
                    "lang": "javascript",
                    "value": "collection.find(query).sort({ length: -1 }).limit(3);\ncollection.find(query).limit(3).sort({ length: -1 });"
                },
                {
                    "lang": "javascript",
                    "value": "// define an empty query document\nconst query = {};\n// sort in descending (-1) order by length\nconst sort = { length: -1 };\nconst limit = 3;\nconst skip = 3;\nconst cursor = collection.find(query).sort(sort).limit(limit).skip(skip);\nawait cursor.forEach(console.dir);"
                },
                {
                    "lang": "json",
                    "value": "{ \"_id\": 3, \"title\": \"Atlas Shrugged\", \"author\": \"Rand\", \"length\": 1088 }\n{ \"_id\": 5, \"title\": \"Cryptonomicon\", \"author\": \"Stephenson\", \"length\": 918 }\n{ \"_id\": 1, \"title\": \"The Brothers Karamazov\", \"author\": \"Dostoyevsky\", \"length\": 824 }"
                }
            ],
            "preview": "Use limit to cap the number of documents that can be returned from a\nread operation. limit functions as a cap on the maximum number of\ndocuments that the operation can return, but the operation can return\na smaller number of documents if there are not enough documents present\nto reach the limit. If limit is used with the\nskip method, the skip applies\nfirst and the limit only applies to the documents left over after\nthe skip.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud/read-operations/retrieve",
            "title": "Retrieve Data",
            "headings": [
                "Overview",
                "Find",
                "Aggregate",
                "Watch / Subscribe"
            ],
            "paragraphs": "You can use read operations to retrieve data from your MongoDB database.\nThere are multiple types of read operations that access the data in\ndifferent ways. If you want to request results based on a set of criteria\nfrom the existing set of data, you can use a find operation such as the\n find()  or  findOne()  methods. You can also further specify the information you are requesting by\nincluding additional parameters or by chaining other methods such as: You can also use an aggregation operation to retrieve data. This type of\noperation allows you to apply an ordered pipeline of transformations to the\nmatched data. If you want to monitor the database for incoming data that matches a set of\ncriteria, you can use the watch operation to be notified in real-time when\nmatching data is inserted. Sort Results Skip Returned Results Limit the Number of Returned Results Specify Which Fields to Return Your query operation may return a reference to a\ncursor that contains matching documents. To learn how to\nexamine data stored in the cursor, see the\n Cursor Fundamentals page . You can call the  find()  method on a  Collection  object. The\nmethod accepts a query document that describes the documents you want to\nretrieve. For more information on how to specify your query document,\nsee the  Specify a Query  guide. To access the results, you can optionally pass a callback in the method\ncall or resolve the returned  Promise  object. See our guide on\n Promises and Callbacks  for more\ninformation. If you resolve the  Promise  returned by  find() , you receive\na reference to a  Cursor  with which you can navigate matched documents.\nIf you resolve the  Promise  returned by  findOne() , you receive the\nmatching document or  null  if there are no matches. See the  find()  and  findOne()  for fully-runnable examples. To execute a find operation that has no query criteria, you can\npass an empty query or omit the query document in your find\nmethod parameters. The following operations both return all documents in the\n myColl  collection: If you don't pass a query or pass an empty query\nto the  findOne()  method, the operation returns a single\ndocument from a collection. You can specify options in a find operation even when you pass an\nempty query. For example, the following code shows how you can\nspecify a projection as an option while executing a find operation\nwith an empty query parameter: A pizza restaurant wants to find all pizzas ordered by Lemony Snicket\nyesterday. They run the following  find()  query on the\n orders  collection: Once the operation returns, the  findResult  variable references a\n Cursor . You can print the documents retrieved using the  forEach() \nmethod as shown below: The output might resemble the following: If you want to run a custom processing pipeline to retrieve data from your\ndatabase, you can use the  aggregate()  method. This method accepts\naggregation expressions to run in sequence. These expressions let you filter,\ngroup, and arrange the result data from a collection. See the MongoDB server manual pages on  aggregation \nfor more information on how to construct an aggregation pipeline. A pizza restaurant wants to run a status report on-demand to\nsummarize pizza orders over the past week. They run the following\n aggregate()  query on the  orders  collection to fetch the\ntotals for each distinct \"status\" field: Once the operation returns, the  aggregateResult  variable references a\n Cursor . You can print the documents retrieved using the  forEach() \nmethod as shown below: The output might resemble the following: You can use the  watch()  method to monitor a collection for changes to\na collection that match certain criteria. These changes include inserted,\nupdated, replaced, and deleted documents. You can pass this method\na pipeline of aggregation commands that sequentially runs on the changed\ndata whenever write operations are executed on the collection. For a runnable example of the  watch()  method using the NodeJS driver, see\nthe  change streams  usage example. A pizza restaurant wants to receive a notification whenever a new pizza\norder comes in. To accomplish this, they create an aggregation pipeline\nto filter on insert operations and return specific fields. They pass\nthis pipeline to the  watch()  method called on the  orders \ncollection as shown below:",
            "code": [
                {
                    "lang": "javascript",
                    "value": "await myColl.find(); // no query\nawait myColl.find({}); // empty query"
                },
                {
                    "lang": "javascript",
                    "value": "const options = {\n  projection: { _id: 0, field1: 1 },\n};\n\nconst findResult = await myColl.findOne({}, options);"
                },
                {
                    "lang": "javascript",
                    "value": "await findResult.forEach(console.dir);"
                },
                {
                    "lang": "javascript",
                    "value": "[\n  { name: \"Lemony Snicket\", type: \"horseradish pizza\", qty: 1, status: \"delivered\", date: ... },\n  { name: \"Lemony Snicket\", type: \"coal-fired oven pizza\", qty: 3, status: \"canceled\", date: ...},\n  ...\n]"
                },
                {
                    "lang": "javascript",
                    "value": "    const findResult = await orders.find({\n      name: \"Lemony Snicket\",\n      date: {\n        $gte: new Date(new Date().setHours(00, 00, 00)),\n        $lt: new Date(new Date().setHours(23, 59, 59)),\n      },\n    });"
                },
                {
                    "lang": "javascript",
                    "value": "await aggregateResult.forEach(console.dir);"
                },
                {
                    "lang": "javascript",
                    "value": "[\n  { _id: 'delivering', count: 5 },\n  { _id: 'delivered', count: 37 },\n  { _id: 'created', count: 9 }\n]"
                },
                {
                    "lang": "javascript",
                    "value": "    const aggregateResult = await orders.aggregate([\n      {\n        $match: {\n          date: {\n            $gte: new Date(new Date().getTime() - 1000 * 3600 * 24 * 7),\n            $lt: new Date(),\n          },\n        },\n      },\n      {\n        $group: {\n          _id: \"$status\",\n          count: {\n            $sum: 1,\n          },\n        },\n      },\n    ]);"
                },
                {
                    "lang": "javascript",
                    "value": "    const changeStream = orders.watch([\n      { $match: { operationType: \"insert\" } },\n      {\n        $project: {\n          \"fullDocument.name\": 1,\n          \"fullDocument.address\": 1,\n        },\n      },\n    ]);\n    changeStream.on(\"change\", change => {\n      const { name, address } = change.fullDocument;\n      console.log(`New order for ${name} at ${address}.`);\n    });"
                }
            ],
            "preview": "You can use read operations to retrieve data from your MongoDB database.\nThere are multiple types of read operations that access the data in\ndifferent ways. If you want to request results based on a set of criteria\nfrom the existing set of data, you can use a find operation such as the\nfind() or findOne() methods.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud/write-operations/delete",
            "title": "Delete a Document",
            "headings": [
                "Overview",
                "Delete"
            ],
            "paragraphs": "In this section, we show you how to call the write operations to  remove \ndocuments from a collection in your MongoDB database. If you want to remove existing documents from a collection, you can\nuse  deleteOne()  to remove one document or  deleteMany()  for one or\nmore documents. These methods accept a query document that matches the\ndocuments you want to delete. You can specify the document or documents to be deleted by the\n deleteOne()  or  deleteMany()  write operations in a JSON object as\nfollows: To delete the first matching document using the  deleteOne()  method or\nto delete all matching documents using the  deleteMany()  method, pass the\ndocument as the method parameter: You can print the number of documents deleted by the operation by\naccessing the  deletedCount  field of the result for each of the\nmethod calls above as follows: Upon successful delete, these statements should print the number of documents\ndeleted by the associated operation. For fully runnable examples and additional information on the available\noptions, see our usage examples for\n deleteOne()  and\n deleteMany() .",
            "code": [
                {
                    "lang": "javascript",
                    "value": "const doc = {\n  pageViews: {\n    $gt: 10,\n    $lt: 32768\n  }\n};"
                },
                {
                    "lang": "javascript",
                    "value": "const deleteResult = await collection.deleteOne(doc);\nconst deleteManyResult = await collection.deleteMany(doc);"
                },
                {
                    "lang": "javascript",
                    "value": "console.dir(deleteResult.deletedCount);\nconsole.dir(deleteManyResult.deletedCount);"
                }
            ],
            "preview": "In this section, we show you how to call the write operations to remove\ndocuments from a collection in your MongoDB database.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud/write-operations/change-a-document",
            "title": "Change a Document",
            "headings": [
                "Overview",
                "Update",
                "Example",
                "Replace",
                "Example"
            ],
            "paragraphs": "You can change documents in a MongoDB collection using either  update \nor  replace  operations. Update operations mutate\nspecified fields in one or more documents and leave other fields and values\nunchanged. Replace operations remove all existing fields in one or more\ndocuments and substitute them with specified fields and values. To perform an update to one or more documents, create an  update\ndocument  that specifies the  update operator  (the type of update to\nperform) and the fields and values that describe the change. Update\ndocuments use the following format: The top level of an update document contains one or more of the following\nupdate operators: See the MongoDB Server manual for a  complete list of update operators\nand their usage . The update operators apply only to the fields associated with them in your\nupdate document. $set : replaces the value of a field with a specified one $inc : increments or decrements field values $rename : renames fields $unset : removes fields $mul : multiplies a field value by a specified number If you are using MongoDB Version 4.2 or later, you can use aggregation\npipelines made up of a subset of aggregation stages in update operations. For\nmore information on the aggregation stages MongoDB supports in\naggregation pipelines used in update operations, see our tutorial on building\n updates with aggregation pipelines . Consider a document with fields describing an item for sale, its price,\nand quantity available: If you apply the  $set  update operator with a new value for\n quantity , you can use the following update document: The updated document resembles the following, with an updated value in\nthe  quantity  field and all other values unchanged: If an update operation fails to match any documents in a collection, it\ndoes not make any changes. Update operations can be configured to perform\nan  upsert  which\nattempts to perform an update, but if no documents are matched, inserts\na new document with the specified fields and values. You cannot modify the  _id  field of a document nor change a field to\na value that violates a unique index constraint. See the MongoDB Server manual\nfor more information on  unique indexes . To perform a replacement operation, create a  replacement document  that\nconsists of the fields and values that you would like to use in your\n replace  operation. Replacement documents use the following format: Replacement documents are the documents that you want to take the place of\nexisting documents that match the query filters. Consider a document with fields describing an item for sale, its price,\nand quantity available: Suppose you wanted to replace this document with one that contains a\ndescription for an entirely different item. Your replacement operation might\nresemble the following: The replaced document contains the contents of the replacement document\nand the immutable  _id  field as follows: If a replace operation fails to match any documents in a collection, it\ndoes not make any changes. Replace operations can be configured to perform\nan  upsert  which\nattempts to perform the replacement, but if no documents are matched, it\ninserts a new document with the specified fields and values. You cannot modify the  _id  field of a document nor change a field to\na value that violates a unique index constraint. See the MongoDB Server manual\nfor more information on  unique indexes .",
            "code": [
                {
                    "lang": "javascript",
                    "value": "{\n   <update operator>: {\n      <field> : {\n         ...\n      },\n      <field> : {\n      }\n   },\n   <update operator>: {\n      ...\n   }\n}"
                },
                {
                    "lang": "javascript",
                    "value": "{\n   _id: 465,\n   item: \"Hand-thrown ceramic plate\",\n   price: 32.50,\n   quantity: 7,\n}"
                },
                {
                    "lang": "javascript",
                    "value": "const filter = { _id: 465 };\n\n// update the value of the 'quantity' field to 5\nconst updateDocument = {\n   $set: {\n      quantity: 5,\n   },\n};\nconst result = await collection.updateOne(filter, updateDocument);"
                },
                {
                    "lang": "javascript",
                    "value": "{\n   _id: 465,\n   item: \"Hand-thrown ceramic plate\",\n   price: 32.50,\n   quantity: 5,\n}"
                },
                {
                    "lang": "javascript",
                    "value": "{\n   <field>: {\n      <value>\n   },\n   <field>: {\n      ...\n   }\n}"
                },
                {
                    "lang": "javascript",
                    "value": "{\n   _id: 501,\n   item: \"3-wick beeswax candle\",\n   price: 18.99,\n   quantity: 10,\n}"
                },
                {
                    "lang": "javascript",
                    "value": "const filter = { _id: 501 };\n\n// replace the matched document with the replacement document\nconst replacementDocument = {\n   item: \"Vintage silver flatware set\",\n   price: 79.15,\n   quantity: 1,\n};\nconst result = await collection.replaceOne(filter, replacementDocument);"
                },
                {
                    "lang": "javascript",
                    "value": "{\n   _id: 501,\n   item: \"Vintage silver flatware set\",\n   price: 79.15,\n   quantity: 1,\n}"
                }
            ],
            "preview": "You can change documents in a MongoDB collection using either update\nor replace operations. Update operations mutate\nspecified fields in one or more documents and leave other fields and values\nunchanged. Replace operations remove all existing fields in one or more\ndocuments and substitute them with specified fields and values.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud/read-operations/text",
            "title": "Search Text",
            "headings": [
                "Overview",
                "Examples",
                "Query for Words",
                "Query By Phrase",
                "Query with Negations",
                "Sort by Relevance"
            ],
            "paragraphs": "Text search, using the  $text  query operator, lets you search string\ntype fields in your collection for words or phrases. This operator\nperforms a logical  OR  on each term separated by a space in the search\nstring. You can also specify additional options to the operator to\nhandle case sensitivity, word stemming (e.g. plural forms, tense) and stop\nwords for a supported language. This is particularly useful for\nunstructured text such as transcripts, essays, or web pages. The  $text  query operator requires that you specify the search field in\na  text index  on your collection. See the examples below for sample\ncode for creating a text index and using the  $text  query operator. Atlas Search  makes it easy\nto build fast, relevance-based search capabilities on top of your MongoDB\ndata. Try it today on\n MongoDB Atlas ,\nour fully managed database as a service. The following examples use sample data from the  movies  collection in\nthe  sample_mflix  database. In order to enable text searches on the\n title   field, create a  text index  by using the following command: We use a single field text index for the examples in this guide, but you can\ncreate a compound text index that broadens your text queries to multiple\nfields. The following command creates a text index on two fields in the\n movies  collection: You can only create  one  text index per collection. Every text search\nqueries all the fields specified in that index for matches. To learn more about text indexes, see  Text Indexes  in the Server manual. When creating a compound text index, you can specify a weight option to\nprioritize certain text fields in your index. When you execute a text\nsearch, the field weights influence how MongoDB calculates the\n text search score  for each matching\ndocument. To learn more about specifying field weights when creating a text\nindex, see the  Text Indexes \nsection in the Indexes guide. This example queries for Star Trek movies by searching for titles\ncontaining the word \"trek\". If you want to query using multiple words,\nseparate your words with spaces to query for documents that match any of\nthe search terms (logical  OR ). This operation returns the following documents: Success! The query found every document in the  movies  collection\nwith a title including the word \"trek\". Unfortunately, the search included\none unintended item: \"Trek Nation,\" which is a movie about Star Trek and not\npart of the Star Trek movie series. To solve this, we can query with a more\nspecific  phrase . To make your query more specific, try using the phrase \"star trek\"\ninstead of just the word \"trek\". To search by phrase, surround your\nmulti-word phrase with escaped quotes ( \\\"<term>\\\" ): Querying by the phrase \"star trek\" instead of just the term \"trek\"\nmatches the following documents: These results include all movies in the database that contain the phrase\n\"star trek\", which in this case results in only fictional Star Trek\nmovies. Unfortunately, though, this query returned \"Star Trek Into\nDarkness\", a movie that was not part of the original series of movies. To\nresolve this issue, we can omit that document with a  negation . To use a negated term, place a negative sign ( - ) in front of the term\nyou would like to omit from the result set. The query operation omits any\ndocuments that contain this term from the search result. Since this query\nincludes two distinct terms, separate them with a space. Querying with the negated term yields the following documents: Your query operation may return a reference to a\ncursor that contains matching documents. To learn how to\nexamine data stored in the cursor, see the\n Cursor Fundamentals page . Now that the result set reflects the desired results, you can use the\ntext search  textScore , accessed using the  $meta  operator in the query\nprojection, to order the results by relevance: Querying in this way returns the following documents in the following\norder. In general, text relevance increases as a string matches more\nterms and decreases as the unmatched portion of the string lengthens. For more information about the $text operator and its options, see the\n manual entry .",
            "code": [
                {
                    "lang": "javascript",
                    "value": "db.movies.createIndex({ title: \"text\" });"
                },
                {
                    "lang": "javascript",
                    "value": "db.movies.createIndex({ title: \"text\", plot: \"text\" });"
                },
                {
                    "lang": "javascript",
                    "value": "{ title: 'Trek Nation' }\n{ title: 'Star Trek' }\n{ title: 'Star Trek Into Darkness' }\n{ title: 'Star Trek: Nemesis' }\n{ title: 'Star Trek: Insurrection' }\n{ title: 'Star Trek: Generations' }\n{ title: 'Star Trek: First Contact' }\n{ title: 'Star Trek: The Motion Picture' }\n{ title: 'Star Trek VI: The Undiscovered Country' }\n{ title: 'Star Trek V: The Final Frontier' }\n{ title: 'Star Trek IV: The Voyage Home' }\n{ title: 'Star Trek III: The Search for Spock' }\n{ title: 'Star Trek II: The Wrath of Khan' }"
                },
                {
                    "lang": "javascript",
                    "value": "  const query = { $text: { $search: \"trek\" } };\n\n  // Return only the `title` of each matched document\n  const projection = {\n    _id: 0,\n    title: 1,\n  };\n\n  // find documents based on our query and projection\n  const cursor = movies.find(query).project(projection);"
                },
                {
                    "lang": "javascript",
                    "value": "{ title: 'Star Trek' }\n{ title: 'Star Trek Into Darkness' }\n{ title: 'Star Trek: Nemesis' }\n{ title: 'Star Trek: Insurrection' }\n{ title: 'Star Trek: Generations' }\n{ title: 'Star Trek: First Contact' }\n{ title: 'Star Trek: The Motion Picture' }\n{ title: 'Star Trek VI: The Undiscovered Country' }\n{ title: 'Star Trek V: The Final Frontier' }\n{ title: 'Star Trek IV: The Voyage Home' }\n{ title: 'Star Trek III: The Search for Spock' }\n{ title: 'Star Trek II: The Wrath of Khan' }"
                },
                {
                    "lang": "javascript",
                    "value": "  const query = { $text: { $search: \"\\\"star trek\\\"\" } };\n\n  // Return only the `title` of each matched document\n  const projection = {\n    _id: 0,\n    title: 1,\n  };\n\n  // find documents based on our query and projection\n  const cursor = movies.find(query).project(projection);"
                },
                {
                    "lang": "javascript",
                    "value": "{ title: 'Star Trek' }\n{ title: 'Star Trek: Nemesis' }\n{ title: 'Star Trek: Insurrection' }\n{ title: 'Star Trek: Generations' }\n{ title: 'Star Trek: First Contact' }\n{ title: 'Star Trek: The Motion Picture' }\n{ title: 'Star Trek VI: The Undiscovered Country' }\n{ title: 'Star Trek V: The Final Frontier' }\n{ title: 'Star Trek IV: The Voyage Home' }\n{ title: 'Star Trek III: The Search for Spock' }\n{ title: 'Star Trek II: The Wrath of Khan' }"
                },
                {
                    "lang": "javascript",
                    "value": "  const query = { $text: { $search: \"\\\"star trek\\\"  -\\\"into darkness\\\"\" } };\n\n  // Include only the `title` field of each matched document\n  const projection = {\n    _id: 0,\n    title: 1,\n  };\n\n  // find documents based on our query and projection\n  const cursor = movies.find(query).project(projection);"
                },
                {
                    "lang": "javascript",
                    "value": "{ title: 'Star Trek', score: 1.5 }\n{ title: 'Star Trek: Generations', score: 1.3333333333333333 }\n{ title: 'Star Trek: Insurrection', score: 1.3333333333333333 }\n{ title: 'Star Trek: Nemesis', score: 1.3333333333333333 }\n{ title: 'Star Trek: The Motion Picture', score: 1.25 }\n{ title: 'Star Trek: First Contact', score: 1.25 }\n{ title: 'Star Trek II: The Wrath of Khan', score: 1.2 }\n{ title: 'Star Trek III: The Search for Spock', score: 1.2 }\n{ title: 'Star Trek IV: The Voyage Home', score: 1.2 }\n{ title: 'Star Trek V: The Final Frontier', score: 1.2 }\n{ title: 'Star Trek VI: The Undiscovered Country', score: 1.2 }"
                },
                {
                    "lang": "javascript",
                    "value": "  const query = { $text: { $search: \"\\\"star trek\\\"  -\\\"into darkness\\\"\" } };\n\n  // sort returned documents by descending text relevance score\n  const sort = { score: { $meta: \"textScore\" } };\n  // Include only the `title` and `score` fields in each returned document\n  const projection = {\n    _id: 0,\n    title: 1,\n    score: { $meta: \"textScore\" },\n  };\n\n  // find documents based on our query, sort, and projection\n  const cursor = movies\n    .find(query)\n    .sort(sort)\n    .project(projection);"
                }
            ],
            "preview": "Text search, using the $text query operator, lets you search string\ntype fields in your collection for words or phrases. This operator\nperforms a logical OR on each term separated by a space in the search\nstring. You can also specify additional options to the operator to\nhandle case sensitivity, word stemming (e.g. plural forms, tense) and stop\nwords for a supported language. This is particularly useful for\nunstructured text such as transcripts, essays, or web pages.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud/write-operations/upsert",
            "title": "Insert or Update in a Single Operation",
            "headings": [
                "Overview",
                "Performing an Update",
                "Performing an Upsert"
            ],
            "paragraphs": "If your application stores and modifies data in MongoDB, you probably use\ninsert and update operations. In certain workflows, you may need to choose\nbetween an insert and update depending on whether the document exists.\nIn these cases, you can streamline your application logic by using the\n upsert  option available in the following methods: If the query filter passed to these methods does not find any matches and\nyou set the  upsert  option to  true , MongoDB inserts the update\ndocument. Let's go through an example. updateOne() replaceOne() updateMany() Suppose your application tracks the current location of food trucks,\nstoring the nearest address data in a MongoDB collection that resembles the\nfollowing: As an application user, you read about a food truck changing its regular\nlocation and want to apply the update. This update might resemble the\nfollowing: If a food truck named \"Deli Llama\" exists, the method call above updates\nthe document in the collection. However, if there are no food trucks named\n\"Deli Llama\" in your collection, no changes are made. Consider the case in which you want to add information about the food\ntruck even if it does not currently exist in your collection. Rather than\nfirst querying whether it exists to determine whether we need to insert or\nupdate the document, we can set  upsert  to  true  in our call to\n updateOne()  as follows: After you run the operation above, your collection should resemble the\nfollowing, whether the \"Deli Llama\" document existed in your collection\nbeforehand:",
            "code": [
                {
                    "lang": "javascript",
                    "value": "[\n  { name: \"Haute Skillet\", address: \"42 Avenue B\" },\n  { name: \"Lady of the Latke\", address: \"35 Fulton Rd\" },\n  ...\n]"
                },
                {
                    "lang": "javascript",
                    "value": "const query = { name: \"Deli Llama\" };\nconst update = { $set: { name: \"Deli Llama\", address: \"3 Nassau St\" }};\nconst options = {};\ncollection.updateOne(query, update, options);"
                },
                {
                    "lang": "javascript",
                    "value": "const query = { name: \"Deli Llama\" };\nconst update = { $set: { name: \"Deli Llama\", address: \"3 Nassau St\" }};\nconst options = { upsert: true };\ncollection.updateOne(query, update, options);"
                },
                {
                    "lang": "javascript",
                    "value": "[\n  { name: \"Haute Skillet\", address: \"42 Avenue B\" },\n  { name: \"Lady of the Latke\", address: \"35 Fulton Rd\" },\n  { name: \"Deli Llama\", address: \"3 Nassau St\" },\n  ...\n]"
                }
            ],
            "preview": "If your application stores and modifies data in MongoDB, you probably use\ninsert and update operations. In certain workflows, you may need to choose\nbetween an insert and update depending on whether the document exists.\nIn these cases, you can streamline your application logic by using the\nupsert option available in the following methods:",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud/write-operations/insert",
            "title": "Insert a Document",
            "headings": [
                "Overview",
                "A Note About _id",
                "Insert a Single Document",
                "Example",
                "Insert Multiple Documents",
                "Example"
            ],
            "paragraphs": "In this guide, you can learn how to insert documents into MongoDB. You can use MongoDB to retrieve, update and delete information. To\nperform any of those operations, that information, such as user profiles\nand orders, needs to exist in MongoDB. For that information to exist,\nyou need to first perform an  insert operation . An insert operation inserts a single or multiple documents in MongoDB\nusing the  insertOne() ,  insertMany()  and  bulkWrite()  methods. The following sections focus on  insertOne()  and  insertMany() . For an\nexample on how to use the  bulkWrite()  method, see our runnable  Bulk\nOperations Example . When inserting a document, MongoDB enforces one constraint on your\ndocuments by default. Each document  must  contain a unique  _id \nfield. There are two ways to manage this field: Unless you have provided strong guarantees for uniqueness, we recommend\nyou let the driver automatically generate  _id  values. For additional information about  _id , see the Server Manual Entry on\n Unique Indexes . You can manage this field yourself, ensuring each value you use is unique. You can let the driver automatically generate unique  ObjectId  values\nwith the  primary key factory . Duplicate  _id  values violate unique index constraints, resulting\nin a  WriteError . Use the  insertOne()  method when you want to insert a single\ndocument. On successful insertion, the method returns an\n InsertOneResult  instance representing the  _id  of\nthe new document. The following example creates and inserts a document using the\n insertOne()  method: Your output should look something like this: For additional information on the classes and methods mentioned in this\nsection, see the following resources: API Documentation on  insertOne() API Documentation on  InsertOneResult Server Manual Entry on  insertOne() Runnable  Insert a Document Example Use the  insertMany()  method when you want to insert multiple\ndocuments. This method inserts documents in the order specified until an\nexception occurs, if any. For example, assume you want to insert the following documents: If you attempt to insert these documents, a  WriteError  occurs at the\nthird document and the documents prior to the error get inserted into\nyour collection. On successful insertion, the method returns an\n InsertManyResult  instance representing the number of\ndocuments inserted and the  _id  of the new document. Use a try-catch block to get an acknowledgment for successfully\nprocessed documents before the error occurs: The output consists of documents MongoDB can process and should look\nsomething like this: If you look inside your collection, you see the following documents: The following example creates and adds three documents using the\n insertMany()  method: Your output should look something like this: For additional information on the classes and methods mentioned in this\nsection, see the following resources: API Documentation on  insertMany() API Documentation on  InsertManyResult API Documentation on  PkFactory Server Manual Entry on  insertMany() Runnable  Insert Multiple Documents Example",
            "code": [
                {
                    "lang": "javascript",
                    "value": "const doc = { name: \"Neapolitan pizza\", shape: \"round\" };\nconst result = await collection.insertOne(doc);\nconsole.log(\n   `A document was inserted with the _id: ${result.insertedId}`,\n);"
                },
                {
                    "lang": null,
                    "value": "A document was inserted with the _id: 60c79c0f4cc72b6bb31e3836"
                },
                {
                    "lang": "json",
                    "value": "{ \"_id\": 1, \"color\": \"red\" }\n{ \"_id\": 2, \"color\": \"purple\" }\n{ \"_id\": 1, \"color\": \"yellow\" }\n{ \"_id\": 3, \"color\": \"blue\" }"
                },
                {
                    "lang": "javascript",
                    "value": "try {\n   const docs = [\n      { \"_id\": 1, \"color\": \"red\"},\n      { \"_id\": 2, \"color\": \"purple\"},\n      { \"_id\": 1, \"color\": \"yellow\"},\n      { \"_id\": 3, \"color\": \"blue\"}\n   ];\n\n   const insertManyresult = await collection.insertMany(docs);\n   let ids = insertManyresult.insertedIds;\n\n   console.log(`${insertManyresult.insertedCount} documents were inserted.`);\n   for (let id of Object.values(ids)) {\n      console.log(`Inserted a document with id ${id}`);\n   }\n} catch(e) {\n   console.log(`A MongoBulkWriteException occurred, but there are successfully processed documents.`);\n   let ids = e.result.result.insertedIds;\n   for (let id of Object.values(ids)) {\n      console.log(`Processed a document with id ${id._id}`);\n   }\n   console.log(`Number of documents inserted: ${e.result.result.nInserted}`);\n}"
                },
                {
                    "lang": null,
                    "value": "A MongoBulkWriteException occurred, but there are successfully processed documents.\nProcessed a document with id 1\nProcessed a document with id 2\nProcessed a document with id 1\nProcessed a document with id 3\nNumber of documents inserted: 2"
                },
                {
                    "lang": "json",
                    "value": "{ \"_id\": 1, \"color\": \"red\" }\n{ \"_id\": 2, \"color\": \"purple\" }"
                },
                {
                    "lang": "javascript",
                    "value": "const docs = [\n   { name: \"Sicilian pizza\", shape: \"square\" },\n   { name: \"New York pizza\", shape: \"round\" },\n   { name: \"Grandma pizza\", shape: \"square\" }\n];\n\nconst insertManyresult = await collection.insertMany(docs);\nlet ids = insertManyresult.insertedIds;\n\nconsole.log(`${insertManyresult.insertedCount} documents were inserted.`);\n\nfor (let id of Object.values(ids)) {\n   console.log(`Inserted a document with id ${id}`);\n}"
                },
                {
                    "lang": null,
                    "value": "3 documents were inserted.\nInserted a document with id 60ca09f4a40cf1d1afcd93a2\nInserted a document with id 60ca09f4a40cf1d1afcd93a3\nInserted a document with id 60ca09f4a40cf1d1afcd93a4"
                }
            ],
            "preview": "In this guide, you can learn how to insert documents into MongoDB.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud/write-operations/embedded-arrays",
            "title": "Update Arrays in a Document",
            "headings": [
                "Overview",
                "Specifying Array Elements",
                "The First Matching Array Element",
                "Example",
                "Matching All Array Elements",
                "Example",
                "Matching Multiple Array Elements",
                "Usage",
                "Example"
            ],
            "paragraphs": "In this guide, you can learn how to use the following array update\noperators to modify an array embedded within a document: For a list of array update operators, see  Update Operators  in the Server\nManual documentation. Positional Operator :  $ All Positional Operator :  $[] Filtered Positional Operator :  $[<identifier>] Positional operators specify which array elements to update. You can use these operators to apply updates to the first element, all elements, or\ncertain elements of an array that match a criteria. To specify elements in an array with positional operators, use  dot\nnotation . Dot notation is a property access syntax for navigating BSON\nobjects. To learn more, see  dot notation . To update the first array element of each document that matches your\nquery, use the positional operator  $ . The positional operator  $  references the array matched by the query.\nYou cannot use this operator to reference a nested array. If you want to\naccess a nested array, use the  filtered positional operator . Do not use the  $  operator in an  upsert  call because the\ndriver treats  $  as a field name in the insert document. This example uses the following sample document to show how to update\nthe first matching array element: The following code shows how to increment a value in the first array\nelement that matches a query. The query matches elements in the  entries  array where the value of\n x  is a  string  type. The update increases the  y  value by\n 33  in the first matching element. After you run the update operation, the document resembles the\nfollowing: The example includes the  entries.x  field in the\nquery to match the array that the  $  operator applies an update to. If you\nomit the  entries.x  field from the query while using the\n $  operator in an update, the driver is unable to identify the\nmatching array and raises the following error: To perform the update on all of the array elements of each document that\nmatches your query, use the all positional operator  $[] . This example uses the following sample documents, which describe phone\ncall logs, to show how to update all matching array elements: The following code shows how to remove the  duration  field from\nall  calls  array entries in the document whose  date  is\n \"5/15/2023\" : After you run the update operation, the documents resemble the following: To perform an update on all embedded array elements of each document\nthat matches your query, use the filtered positional operator\n $[<identifier>] . The filtered positional operator  $[<identifier>]  specifies the\nmatching array elements in the update document. To identify which array\nelements to match, pair this operator with  <identifier>  in an\n arrayFilters  object. The  <identifier>  placeholder represents an element of the array\nfield. You must select a value for  <identifier>  that starts with a\nlowercase letter and contains only alphanumeric characters. You can use a filtered positional operator in an update operation.\nAn update operation takes a query, an update document, and\noptionally, an options object as its parameters. The following steps describe how to use a filtered positional operator\nin an update operation: Format your update document as follows: This update document contains the following placeholders: $<operator> : The array update operator <array> : The array in the document to update <identifier> : The identifier for the filtered positional operator <arrayField> : The field in the  <array>  array element to update <updateParameter> : The value that describes the update Add the matching criteria in the  arrayFilters  object. This object\nis an array of queries that specify which array elements to include\nin the update. Set this object in an  options  parameter: Pass the query, the update document, and options to an\nupdate method. The following sample code shows how to call the\n updateOne()  method with these parameters: This example uses the following sample documents, which describe\nshopping lists for specific recipes, to show how to update certain matching array elements: Suppose you want to increase the quantity of items you purchase for a\nrecipe on your  \"11/12/2023\"  grocery trip. You want to double the quantity if\nthe item meets all the following criteria: To double the  quantity  value in the matching array\nentries, use the filtered positional operator as shown in the following\ncode: The update multiplied the  quantity  value by  2  for\nitems that matched the criteria. The item  \"Sesame oil\"  did not match\nthe criteria in the  arrayFilters  object and therefore was excluded\nfrom the update. The following documents reflect these changes: The item is for the  \"Fried rice\"  recipe. The item name does not include the word  \"oil\" .",
            "code": [
                {
                    "lang": "javascript",
                    "value": "{\n  _id: ...,\n  entries: [\n    { x: false, y: 1 },\n    { x: \"hello\", y: 100 },\n    { x: \"goodbye\", y: 1000 }\n  ]\n}"
                },
                {
                    "lang": "javascript",
                    "value": "{\n  _id: ...,\n  entries: [\n    { x: false, y: 1 },\n    { x: \"hello\", y: 133 },\n    { x: \"goodbye\", y: 1000 }\n  ]\n}"
                },
                {
                    "lang": "none",
                    "value": "MongoServerError: The positional operator did not find the match needed from the query."
                },
                {
                    "lang": "javascript",
                    "value": "const query = { \"entries.x\": { $type : \"string\" } };\nconst updateDocument = {\n  $inc: { \"entries.$.y\": 33 }\n};\nconst result = await myColl.updateOne(query, updateDocument);"
                },
                {
                    "lang": "javascript",
                    "value": "{\n  _id: ...,\n  date: \"5/15/2023\",\n  calls: [\n    { time: \"10:08 am\", caller: \"Mom\", duration: 67 },\n    { time: \"4:11 pm\", caller: \"Dad\", duration: 121 },\n    { time: \"6:36 pm\", caller: \"Grandpa\", duration: 13 }\n  ]\n},\n{\n  _id: ...,\n  date: \"5/16/2023\",\n  calls: [\n    { time: \"11:47 am\", caller: \"Mom\", duration: 4 },\n  ]\n}"
                },
                {
                    "lang": "javascript",
                    "value": "{\n  _id: ...,\n  date: \"5/15/2023\",\n  calls: [\n    { time: \"10:08 am\", caller: \"Mom\" },\n    { time: \"4:11 pm\", caller: \"Dad\" },\n    { time: \"6:36 pm\", caller: \"Grandpa\" }\n  ]\n},\n{\n  _id: ...,\n  date: \"5/16/2023\",\n  calls: [\n    { time: \"11:47 am\", caller: \"Mom\", duration: 4 },\n  ]\n}"
                },
                {
                    "lang": "javascript",
                    "value": "const query = { date: \"5/15/2023\" };\nconst updateDocument = {\n  $unset: { \"calls.$[].duration\": \"\" }\n};\nconst result = await myColl.updateOne(query, updateDocument);"
                },
                {
                    "lang": "javascript",
                    "value": "{ $<operator>: { \"<array>.$[<identifier>].<arrayField>\": <updateParameter> } }"
                },
                {
                    "lang": "javascript",
                    "value": "arrayFilters: [\n  { \"<identifier>.<arrayField1>\": <updateParameter1> },\n  { \"<identifier>.<arrayField2>\": <updateParameter2> },\n  ...\n]"
                },
                {
                    "lang": "javascript",
                    "value": "await myColl.updateOne(query, updateDocument, options);"
                },
                {
                    "lang": "javascript",
                    "value": "{\n  _id: ...,\n  date: \"11/12/2023\",\n  items: [\n    { item: \"Scallions\", quantity: 3, recipe: \"Fried rice\" },\n    { item: \"Mangos\", quantity: 4, recipe: \"Salsa\" },\n    { item: \"Pork shoulder\", quantity: 1, recipe: \"Fried rice\" },\n    { item: \"Sesame oil\", quantity: 1, recipe: \"Fried rice\" }\n  ]\n},\n{\n  _id: ...,\n  date: \"11/20/2023\",\n  items: [\n    { item: \"Coffee beans\", quantity: 1, recipe: \"Coffee\" }\n  ]\n}"
                },
                {
                    "lang": "javascript",
                    "value": "{\n  _id: ...,\n  date: \"11/12/2023\",\n  items: [\n    { item: \"Scallions\", quantity: 6, recipe: \"Fried rice\" },\n    { item: \"Mangos\", quantity: 4, recipe: \"Salsa\" },\n    { item: \"Pork shoulder\", quantity: 2, recipe: \"Fried rice\" },\n    { item: \"Sesame oil\", quantity: 1, recipe: \"Fried rice\" }\n  ]\n},\n{\n  _id: ...,\n  date: \"11/20/2023\",\n  items: [\n    { item: \"Coffee beans\", quantity: 1, recipe: \"Coffee\" }\n  ]\n}"
                },
                {
                    "lang": "javascript",
                    "value": "const query = { date: \"11/12/2023\" };\nconst updateDocument = {\n  $mul: { \"items.$[i].quantity\": 2 }\n};\nconst options = {\n  arrayFilters: [\n    {\n      \"i.recipe\": \"Fried rice\",\n      \"i.item\": { $not: { $regex: \"oil\" } },\n    }\n  ]\n};\nconst result = await myColl.updateOne(query, updateDocument, options);"
                }
            ],
            "preview": "In this guide, you can learn how to use the following array update\noperators to modify an array embedded within a document:",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/bson/utf8-validation",
            "title": "UTF-8 Validation",
            "headings": [
                "Overview",
                "Specify the UTF-8 Validation Setting",
                "Set the Validation Scope"
            ],
            "paragraphs": "In this guide, you can learn how to enable or disable the Node.js driver's\n UTF-8  validation feature. UTF-8 is a character encoding specification\nthat ensures compatibility and consistent presentation across most operating\nsystems, applications, and language character sets. If you  enable  validation, the driver throws an error when it attempts to\nconvert data that contains invalid UTF-8 characters. The validation adds\nprocessing overhead since it needs to check the data. If you  disable  validation, your application avoids the validation processing\noverhead, but cannot guarantee consistent presentation of invalid UTF-8 data. The driver enables UTF-8 validation by default. It checks documents for any\ncharacters that are not encoded in a valid UTF-8 format when it transfers data\nbetween your application and MongoDB. Read the sections below to learn how to set UTF-8 validation using the\nNode.js driver. The current version of the Node.js driver automatically substitutes\ninvalid UTF-8 characters with alternate valid UTF-8 ones prior to\nvalidation when you send data to MongoDB. Therefore, the validation\nonly throws an error when the setting is enabled and the driver\nreceives invalid UTF-8 document data from MongoDB. You can specify whether the driver should perform UTF-8 validation by\ndefining the  enableUtf8Validation  setting in the options parameter\nwhen you create a client, reference a database or collection, or call a\nCRUD operation. If you omit the setting, the driver enables UTF-8 validation. See the following for code examples that demonstrate how to disable UTF-8\nvalidation on the client, database, collection, or CRUD operation: If your application reads invalid UTF-8 from MongoDB while the\n enableUtf8Validation  option is enabled, it throws a  BSONError  that\ncontains the following message: The  enableUtf8Validation  setting automatically applies to the scope of the\nobject instance on which you included it, and any other objects created by\ncalls on that instance. For example, if you include the option on the call to instantiate a database\nobject, any collection instance you construct from that object inherits\nthe setting. Any operations you call on that collection instance also\ninherit the setting. You can override the setting at any level of scope by including it when\nconstructing the object instance or when calling an operation. For example, if you disable validation on the collection object, you can\noverride the setting in individual CRUD operation calls on that\ncollection.",
            "code": [
                {
                    "lang": "javascript",
                    "value": "// disable UTF-8 validation on the client\nnew MongoClient('<connection uri>', { enableUtf8Validation: false });\n\n// disable UTF-8 validation on the database\nclient.db('<database name>', { enableUtf8Validation: false });\n\n// disable UTF-8 validation on the collection\ndb.collection('<collection name>', { enableUtf8Validation: false });\n\n// disable UTF-8 validation on a specific operation call\nawait collection.findOne({ title: 'Cam Jansen'}, { enableUtf8Validation: false });"
                },
                {
                    "lang": null,
                    "value": "Invalid UTF-8 string in BSON document"
                },
                {
                    "lang": "javascript",
                    "value": "const database = client.db('books', { enableUtf8Validation: false });\n\n// The collection inherits the UTF-8 validation disabled setting from the database\nconst collection = database.collection('mystery');\n\n// CRUD operation runs with UTF-8 validation disabled\nawait collection.findOne({ title: 'Encyclopedia Brown' });"
                },
                {
                    "lang": "javascript",
                    "value": "const collection = database.collection('mystery', { enableUtf8Validation: false });\n\n// CRUD operation runs with UTF-8 validation enabled\nawait collection.findOne({ title: 'Trixie Belden' }, { enableUtf8Validation: true });\n\n// CRUD operation runs with UTF-8 validation disabled\nawait collection.findOne({ title: 'Enola Holmes' });"
                }
            ],
            "preview": "In this guide, you can learn how to enable or disable the Node.js driver's\nUTF-8 validation feature. UTF-8 is a character encoding specification\nthat ensures compatibility and consistent presentation across most operating\nsystems, applications, and language character sets.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/crud/write-operations/pkFactory",
            "title": "Generate Custom Values for _id",
            "headings": [
                "Overview",
                "Specify a Primary Key Factory",
                "Additional Information"
            ],
            "paragraphs": "In this guide, you can learn how to use the MongoDB Node.js driver to generate your\nown  _id  values using the  primary key factory . The primary key factory allows you to create unique identifiers in your\ndocuments when you choose not to specify an  _id  during an\n insert operation . The\ndefault primary key factory generates  ObjectId  values. The driver doesn't use the primary key factory for\n upsert operations  because it's\nunable to determine whether to apply the primary key factory. If you\nspecified the primary key factory in an upsert operation and it\nperforms an insert operation, the server autogenerates an\n ObjectId  for that document. If you want to use your specified primary key factory, perform a\n find operation , then an\n update  or\n insert  operation. To specify a primary key factory, apply the  pkFactory  option to your\n MongoClient  instance. The following code snippet applies the  pkFactory  option to\ngenerate  _id  values of type  uuid : If you insert a document with an  _id  field with a different\ntype than the type specified by the primary key factory, then you\nwill have inconsistent data. For example, if you run the following insert operation on a primary\nkey factory that generates  uuid  types, your  _id  values will\ncontain both the  uuid  and  string  types: To learn more about the types, interfaces, and classes discussed in this\nsection, see the following resources: pkFactory The _id Field Insert or Update in a Single Operation Retrieve Data Change a Document Insert a Document",
            "code": [
                {
                    "lang": "javascript",
                    "value": "const { UUID } = require('bson');\n...\nconst client = new MongoClient(uri, {\n  pkFactory: { createPk: () =>  new UUID().toBinary() }\n});"
                },
                {
                    "lang": "javascript",
                    "value": "collection.insertOne({ _id: \"user1388\", ... });"
                }
            ],
            "preview": "In this guide, you can learn how to use the MongoDB Node.js driver to generate your\nown _id values using the primary key factory.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/bson/undefined-values",
            "title": "Undefined Values",
            "headings": [
                "Overview",
                "Ignore Undefined Values",
                "Set the Scope for Serializing Undefined Values"
            ],
            "paragraphs": "In this guide, you can learn to control how the driver serializes\n undefined  values. By default, the driver serializes  undefined  values\nas  null  values during write operations. To make the driver ignore fields with\n undefined  values during serialization, set the\n ignoreUndefined  setting to  true . When you specify this setting,\nthe driver  does not  serialize fields with  undefined  values. The following example inserts two documents. The first insert operation has\nthe  ignoreUndefined  setting set to  true , so the driver does not\nserialize the  salesTax  field in that operation. The second operation\ninserts a document that has the  salesTax  field with a  null  value: The documents appear in the collection as follows: You can specify the  ignoreUndefined  setting at the following levels: The  ignoreUndefined  setting automatically applies to the scope of the\nobject instance in which you specified it, as well as any other objects created\nfrom that instance. For example, if you set the  ignoreUndefined  setting when\ninstantiating a database object, any collection instance created from\nthat object inherits the setting. Furthermore, any operations that you\ncall on that collection instance also inherit the setting. The following example performs an find-and-update operation that\ninherits the  ignoreUndefined  setting from the  myDB  database\nobject. This operation does not produce any data changes because the\ndriver ignores the  gasTax  field: You can specify the  ignoreUndefined  setting again at any level to\noverride any inherited settings. For example, if you set  ignoreUndefined  to  true  on your\ncollection object, you can override the setting in individual write\noperations that you execute on that collection. The client level The database level The collection level The operation level",
            "code": [
                {
                    "lang": "javascript",
                    "value": "await myColl.insertOne(\n  {\n    state: \"Montana\",\n    salesTax: undefined,\n  },\n  { ignoreUndefined: true }\n);\n\nawait myColl.insertOne({\n  state: \"New Hampshire\",\n  salesTax: undefined,\n});"
                },
                {
                    "lang": "javascript",
                    "value": "{\n  _id: ...,\n  state: \"Montana\",\n},\n{\n  _id: ...,\n  state: \"New Hampshire\",\n  salesTax: null\n}"
                },
                {
                    "lang": "javascript",
                    "value": "const myDB = client.db(\"test\", { ignoreUndefined: true });\n\n// The collection inherits the ignoreUndefined setting\nconst myColl = myDB.collection(\"states\");\n\n// Any write operation will not serialize undefined values\nawait myColl.findOneAndUpdate(\n  { state: \"Georgia\" },\n  { $set: { gasTax: undefined } }\n);"
                },
                {
                    "lang": "javascript",
                    "value": "const myColl = myDB.collection(\"states\", { ignoreUndefined: true });\n\n// The insert operation will not serialize undefined values\nawait myColl.insertOne({\n  state: \"South Dakota\",\n  capitalGainsTax: undefined,\n});\n\n// The insert operation will serialize undefined values\nawait myColl.insertOne(\n  { state: \"Texas\", capitalGainsTax: undefined },\n  { ignoreUndefined: false }\n);"
                }
            ],
            "preview": "In this guide, you can learn to control how the driver serializes\nundefined values. By default, the driver serializes undefined values\nas null values during write operations.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/connection/connect",
            "title": "Connection Guide",
            "headings": [
                "Connection URI",
                "Atlas Connection Example",
                "Other Ways to Connect to MongoDB",
                "Connect to a MongoDB Server on Your Local Machine",
                "Connect to a Replica Set",
                "Direct Connection"
            ],
            "paragraphs": "This guide shows you how to connect to a MongoDB instance or replica set\nusing the Node.js driver. The  connection URI  is the set of instructions that the driver uses to\nconnect to a MongoDB deployment. It instructs the driver on how it should\nconnect to MongoDB and how it should behave while connected. The following\nexample shows each part of the connection URI: In this example, we use  mongodb  for the protocol, which specifies\nthe  Standard Connection String Format . If your instance or deployment has a DNS SRV record, you can use the\n DNS Seed List Connection Format  for\nyour connection string. This format offers more flexibility of\ndeployment and the ability to change the servers in rotation without\nreconfiguring clients. The next part of the connection string contains your credentials\nif you are using password-based authentication. Replace the value of  user \nwith your username and  pass  with your password. If you are using an\nauthentication mechanism that does not require a username and password, omit\nthis part of the connection URI. The next part of the connection string specifies the hostname or IP address of\nyour MongoDB instance, followed by the port number. In the example above, we use\n sample.host  as the hostname and  27017  as the port. Replace these values\nto point to your MongoDB instance. The last part of the connection string contains connection and authentication\noptions as parameters. In the example above, we set two connection options:\n maxPoolSize=20  and  w=majority . For more information on connection\noptions, skip to the  Connection Options  section. To learn how to retrieve your connection string in Atlas, see the\n Atlas driver connection guide . You must create a client to connect to a MongoDB deployment on Atlas. To create\na client, construct an instance of  MongoClient , passing in your\nURI and a  MongoClientOptions  object. Use the  serverApi  option in your  MongoClientOptions  object to\nenable the Stable API feature, which forces the server to run operations\nwith behavior compatible with the specified API version. The following code shows how you can specify the connection string and the\nStable API client option when connecting to a MongoDB deployment on Atlas and\nverify that the connection is successful: To learn more about the Stable\nAPI feature, see the  Stable API page . As each  MongoClient  represents a pool of connections to the\ndatabase, most applications only require a single instance of a\n MongoClient , even across multiple requests. To learn more about\nhow connection pools work in the driver, see the  FAQ page . If you are connecting to a single MongoDB server instance or replica set\nthat is not hosted on Atlas, see the following sections to find out how to\nconnect. To test whether you can connect to your server, replace the connection\nstring in the  Connect to MongoDB  code\nexample and run it. If you need to run a MongoDB server on your local machine for development\npurposes instead of using an Atlas cluster, you need to complete the following: After you successfully start your MongoDB server, specify your connection\nstring in your driver connection code. If your MongoDB Server is running locally, you can use the following\nconnection string: In this connection string,  <port>  is the port number on which you\nconfigured your server to listen for incoming connections. If you need to specify a different hostname or IP address, see our Server\nManual entry on  Connection Strings . Download the  Community \nor  Enterprise  version\nof MongoDB Server. Install and configure  MongoDB Server. Start the server. Always secure your MongoDB server from malicious attacks. See our\n Security Checklist  for a\nlist of security recommendations. A MongoDB replica set deployment is a group of connected instances that\nstore the same set of data. This configuration of instances provides data\nredundancy and high data availability. To connect to a replica set deployment, specify the hostname and port numbers\nof each instance, separated by a comma, and the replica set name as the value\nof the  replicaSet  parameter in the connection string. When making a connection, the driver takes the following actions by default: Discovers all replica set members when given the address of any one member. Dispatches operations to the appropriate member, such as write against the  primary . To ensure connectivity if one host is unavailable, provide the full\nlist of hosts when connecting to a replica set. To force your operations to run on the host specified in your connection\nURI, you can specify the  directConnection  connection option. If you\nspecify this option, you must use the standard connection URI format. The\ndriver does not accept the DNS seedlist connection format (SRV) when you\nspecify this option. When you specify  directConnection  and connect to a secondary member of the\nreplica set, your write operations fail because the client isn't\nconnected to the primary member. To perform read operations, you must\nenable secondary reads. See the  read preference options \nfor more information.",
            "code": [
                {
                    "lang": "javascript",
                    "value": "const { MongoClient, ServerApiVersion } = require(\"mongodb\");\n\n// Replace the placeholder with your Atlas connection string\nconst uri = \"<connection string>\";\n\n// Create a MongoClient with a MongoClientOptions object to set the Stable API version\nconst client = new MongoClient(uri,  {\n        serverApi: {\n            version: ServerApiVersion.v1,\n            strict: true,\n            deprecationErrors: true,\n        }\n    }\n);\n\nasync function run() {\n  try {\n    // Connect the client to the server (optional starting in v4.7)\n    await client.connect();\n\n    // Send a ping to confirm a successful connection\n    await client.db(\"admin\").command({ ping: 1 });\n    console.log(\"Pinged your deployment. You successfully connected to MongoDB!\");\n  } finally {\n    // Ensures that the client will close when you finish/error\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "none",
                    "value": "mongodb://localhost:<port>"
                },
                {
                    "lang": "none",
                    "value": "mongodb://host1:27017,host2:27017,host3:27017/?replicaSet=myRs"
                }
            ],
            "preview": "This guide shows you how to connect to a MongoDB instance or replica set\nusing the Node.js driver.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/connection/network-compression",
            "title": "Network Compression",
            "headings": [
                "Specify Compression Algorithms",
                "Compression Algorithm Dependencies"
            ],
            "paragraphs": "You can enable a driver option to compress messages, which reduces the amount\nof data passed over the network between MongoDB and your application. The driver supports the following compression algorithms: If you specify multiple compression algorithms, the driver selects the\nfirst one in the list supported by your MongoDB instance. Snappy : available in MongoDB 3.6 and later. Zlib : available in MongoDB 3.6 and later. To enable compression for the connection to your MongoDB instance, use one of\nthe following methods to specify the algorithms: Select the tab that matches your use case for instructions on how to specify\nthe compression algorithm: Specify compression algorithms by using the following strings: Add the parameter to the connection string. Specify the  compressors  option in your  MongoClientOptions . To enable compression by using parameters on the connection string, add\nthe  compressors  parameter and the names of the algorithms as the\nvalue. You can specify one or more compression algorithms, separating\nthem with commas: To enable compression by using  MongoClientOptions ,\npass the  compressors  option and the names of compression algorithms\nthat you want to use. You can specify one or more compression\nalgorithms, separating them with commas: \"snappy\" for  Snappy  compression \"zlib\" for  Zlib  compression To use Snappy compression, add it to your application dependencies by\nrunning the following command: You can use Zlib compression without adding any additional dependencies.",
            "code": [
                {
                    "lang": "javascript",
                    "value": "const uri =\n  \"mongodb+srv://<user>:<password>@<cluster-url>/?compressors=snappy,zlib\";\n\nconst client = new MongoClient(uri);"
                },
                {
                    "lang": "javascript",
                    "value": "const uri =\n  \"mongodb+srv://<user>:<password>@<cluster-url>\";\n\nconst client = new MongoClient(uri,\n  {\n    compressors: [\"snappy\", \"zlib\"]\n  });"
                },
                {
                    "lang": "javascript",
                    "value": "npm install --save snappy"
                }
            ],
            "preview": "You can enable a driver option to compress messages, which reduces the amount\nof data passed over the network between MongoDB and your application.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/connection/tls",
            "title": "Enable TLS on a Connection",
            "headings": [
                "Overview",
                "Enable TLS",
                "Configure Certificates",
                "Reference Certificates in a Client",
                "Create a SecureContext Object to Store Certificates",
                "Provide Certificate Filepaths",
                "Create Buffer Objects to Store Certificates",
                "SecureContext Example",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to connect to MongoDB instances with\nthe TLS security protocol. To configure your connection to use TLS, enable\nthe TLS option and provide your certificates for validation. To learn more about TLS, see the Wikipedia entry on\n Transport Layer Security . You can enable TLS on a connection to your MongoDB instance\nin the following ways: In addition to the  tls  client option, the driver provides additional\noptions to configure TLS on your connection. For  testing purposes ,\nyou can set the  tlsAllowInvalidHostnames ,\n tlsAllowInvalidCertificates , and  tlsInsecure  client options. Setting the  tlsAllowInvalidHostnames  option to  true  disables\nhostname verification, and setting the\n tlsAllowInvalidCertificates  to  true  disables certificate\nvalidation. Setting the  tlsInsecure  option to  true  disables\nboth certificate and hostname validation. For a full list of client options, see  Connection Options . Setting the  tls  option to  true  in your  MongoClientOptions  object Setting the  tls  option to  true  in your connection string A  MongoClient  instance can connect with TLS if you set  tls \nto  true  in your  MongoClientOptions  object: A  MongoClient  instance can connect with TLS if you set the\n tls  option to  true  in your connection string: If you use a DNS SRV record when connecting to MongoDB by specifying\nthe  +srv  modification in your connection string, you enable\nTLS on your connection by default. Specifying any of these options in a production environment makes\nyour application insecure and potentially\nvulnerable to expired certificates and to foreign processes posing\nas valid client instances. To successfully initiate a TLS request, an application must prove its\nidentity by referencing cryptographic certificates. To connect to\nMongoDB with TLS, your certificates must be stored as PEM\nfiles. The following list describes the components that you need to establish\na connection with TLS: For production use, your MongoDB deployment should use valid\ncertificates generated and signed by the same certificate authority.\nFor testing, you can use self-signed certificates. TLS Component Description Certificate Authority (CA) One or more certificate authorities to\ntrust when making a TLS connection. Client Certificate A digital certificate and key that allow the server to verify the identity\nof your application to establish an encrypted network connection. Certificate Key The client certificate private key file. This key is often\nincluded within the certificate file itself. Passphrase The password to decrypt the private client key if it is encrypted. To learn more about the PEM format, see the Wikipedia entry on\n Privacy-Enhanced Mail . You must reference your certificates in your  MongoClientOptions \nobject so that the server can validate them before the client connects.\nYou can reference your certificates in the following ways: Create a  SecureContext  object to store certificates  (Recommended) Provide filepath strings that point to your certificates Create  Buffer  objects to store certificates We recommend that you use the  secureContext  option to configure\nyour TLS connection.  SecureContext  objects are native to Node.js\nand allow you to keep all your TLS options in a single reusable object. To create a  SecureContext  object, import the  createSecureContext() \nmethod from the  tls  module. Next, call the  createSecureContext() \nmethod and pass the contents of your certificates in the options parameter.\nThis method returns a  SecureContext  object that you can use in your\n MongoClientOptions  object. The following code shows how to create a  SecureContext  object and\npass it to your client: To learn more about the  createSecureContext()  method and the\n tls  package, see the  Node.js TLS API documentation . For a runnable example that uses a  SecureContext  object, see\nthe  SecureContext Example . You can include the filepaths for your certificates as client options to\nretrieve your certificates while connecting with TLS. The following code shows how to provide certificate filepaths as options\nin your  MongoClient : You can pass the contents of your certificate files as  Buffer \nobjects in your client options to connect with TLS. The following code shows how to read the contents of your certificate\nfiles and pass the resulting  Buffer  objects as options in your\n MongoClient : This example shows how to create a  SecureContext  object and\na  MongoClient  instance that includes TLS options. The example\nconnects to MongoDB and executes a find query: For more information about enabling TLS on a connection, see the\nfollowing Server manual documentation: TLS/SSL (Transport Encryption) TLS/SSL Configuration for Clients MongoClientOptions MongoClient tlsAllowInvalidHostnames client option tlsAllowInvalidCertificates client option secureContext client option tlsCAFile client option tlsCertificateKeyFile client option ca client option cert client option key client option",
            "code": [
                {
                    "lang": "js",
                    "value": "const client = new MongoClient(uri, { tls: true });"
                },
                {
                    "lang": "js",
                    "value": "const uri = \"mongodb://<hostname>:<port>?tls=true\";\nconst client = new MongoClient(uri, myClientSettings);"
                },
                {
                    "lang": "js",
                    "value": "// Create a SecureContext object\nconst secureContext = tls.createSecureContext({\n  ca: fs.readFileSync(`<path to CA certificate>`),\n  cert: fs.readFileSync(`<path to public client certificate>`),\n  key: fs.readFileSync(`<path to private client key>`),\n});\n\n// Pass the SecureContext as a client option\nconst client = new MongoClient(uri, { tls: true, secureContext });"
                },
                {
                    "lang": "js",
                    "value": "// Pass filepaths as client options\nconst client = new MongoClient(uri, {\n  tls: true,\n  tlsCAFile: `<path to CA certificate>`,\n  tlsCertificateFile: `<path to public client certificate>`,\n  tlsCertificateKeyFile: `<path to private client key>`,\n});"
                },
                {
                    "lang": "js",
                    "value": "// Read file contents\nconst ca = fs.readFileSync(`<path to CA certificate>`);\nconst cert = fs.readFileSync(`<path to public client certificate>`);\nconst key = fs.readFileSync(`<path to private client key>`);\n\n// Pass Buffers as client options\nconst client = new MongoClient(uri, { tls: true, ca, cert, key });"
                },
                {
                    "lang": "js",
                    "value": "import { MongoClient } from \"mongodb\";\nimport * as fs from \"fs\";\nimport * as tls from \"tls\";\n\n// Replace the uri string with your connection string.\nconst uri = \"<connection uri>\";\n\n// Replace the filepaths with your certificate filepaths.\nconst secureContext = tls.createSecureContext({\n  ca: fs.readFileSync(`<path to CA certificate>`),\n  cert: fs.readFileSync(`<path to public client certificate>`),\n  key: fs.readFileSync(`<path to private client key>`),\n});\n\n// Create a client with the secureContext option\nconst client = new MongoClient(uri, { tls: true, secureContext });\n\nasync function run() {\n  try {\n    const db = client.db(\"myDB\");\n    const myColl = db.collection(\"myColl\");\n    const doc = await myColl.findOne({});\n    console.log(doc);\n  } finally {\n    await client.close();\n  }\n}\nrun().catch(console.dir);"
                }
            ],
            "preview": "In this guide, you can learn how to connect to MongoDB instances with\nthe TLS security protocol.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/monitoring/command-monitoring",
            "title": "Command Monitoring",
            "headings": [
                "Overview",
                "Event Subscription Example",
                "Event Descriptions",
                "Example Event Documents",
                "commandStarted",
                "commandSucceeded",
                "commandFailed"
            ],
            "paragraphs": "This guide shows you how to monitor the success or failure of commands\nsent by the driver to your MongoDB deployment. Read this guide if you need to record command status in your application\nor want to explore the information provided in these events. You can access one or more command monitoring events using the driver by\nsubscribing to them in your application. The following example demonstrates\nconnecting to a replica set and subscribing to one of the command monitoring\nevents created by the MongoDB deployment: Command monitoring is disabled by default. To enable command\nmonitoring, pass the  monitorCommands  option as  true  to\nyour  MongoClient  constructor. You can subscribe to any of the following command monitoring events: Event Name Description commandStarted Created when a command is started. commandSucceeded Created when a command succeeded. commandFailed Created when a command failed. The following sections show sample output for each type of command monitoring event.",
            "code": [
                {
                    "lang": "javascript",
                    "value": "const { MongoClient } = require(\"mongodb\");\n\n// Replace the following with your MongoDB deployment's connection\n// string.\nconst uri =\n  \"mongodb+srv://<clusterUrl>/?replicaSet=rs&writeConcern=majority\";\n\nconst client = new MongoClient(uri, { monitorCommands:true });\n\n// Replace <event name> with the name of the event you are subscribing to.\nconst eventName = \"<event name>\";\nclient.on(eventName, event => {\n  console.log(`received ${eventName}: ${JSON.stringify(event, null, 2)}`);\n});\n\nasync function run() {\n  try {\n    await client.connect();\n\n    // Establish and verify connection\n    await client.db(\"admin\").command({ ping: 1 });\n    console.log(\"Connected successfully\");\n  } finally {\n    // Ensures that the client will close when you finish/error\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "javascript",
                    "value": "CommandStartedEvent {\n  requestId: 1534,\n  databaseName: \"app\",\n  commandName: \"find\",\n  address: 'localhost:27017',\n  connectionId: 812613,\n  command: {\n    find: { firstName: \"Jane\", lastName: \"Doe\" }\n  }\n}"
                },
                {
                    "lang": "javascript",
                    "value": "CommandSucceededEvent {\n  requestId: 1534,\n  commandName: \"find\",\n  address: 'localhost:27017',\n  connectionId: 812613,\n  duration: 1586380205,\n  reply: {\n    cursor: {\n      firstBatch: [\n        {\n          _id: ObjectId(\"5e8e2ca217b5324fa9847435\"),\n          firstName: \"Jane\",\n          lastName: \"Doe\"\n        }\n      ],\n      _id: 0,\n      ns: \"app.users\"\n    },\n    ok: 1,\n    operationTime: 1586380205\n  }\n}"
                },
                {
                    "lang": "javascript",
                    "value": "CommandFailedEvent {\n  requestId: 1534,\n  commandName: \"find\",\n  address: 'localhost:27017',\n  connectionId: 812613,\n  failure: Error(\"something failed\"),\n  duration: 1586380205\n}"
                }
            ],
            "preview": "This guide shows you how to monitor the success or failure of commands\nsent by the driver to your MongoDB deployment.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/connection/connection-options",
            "title": "Connection Options",
            "headings": [],
            "paragraphs": "This section explains the MongoDB connection and authentication options\nsupported by the driver. You can pass the connection options as\nparameters of the connection URI to specify the behavior of the client. Name Accepted Values Default Value Description appname string null Specifies the app name the driver passes to the server in the client\nmetadata as part of the connection handshake. The server prints the\n appname  to the MongoDB logs upon establishing the connection.\nIt is also recorded in the slow query logs and profile collections. authMechanism string null Specifies the authentication mechanism method to use for connection to the\nserver. If you do not specify a value, the driver uses the default mechanism,\neither  SCRAM-SHA-1  or  SCRAM-SHA-256  depending on the server version. See\n authentication mechanism  for available\nauthentication mechanisms. authMechanismProperties comma separated key:value pairs, e.g. \"opt1:val1,opt2:val2\" null Specifies additional options provided for authentication, such as\nenabling hostname canonicalization for GSSAPI. authSource string null Specifies the database that connections should authenticate against. compressors comma separated list of strings, e.g. \"snappy,zlib\" null Specifies the allowed compression types for wire protocol messages\nsent to or received from the server. See  Network Compression \nfor more information. connectTimeoutMS non-negative integer 30000 Specifies the amount of time, in milliseconds, to wait to establish a single TCP\nsocket connection to the server before raising an error. Specifying\n 0  disables the connection timeout. directConnection boolean false Specifies whether to force dispatch  all  operations to the host\nspecified in the connection URI. heartbeatFrequencyMS integer greater than or equal to 500 null Specifies the interval, in milliseconds, between regular server monitoring checks. journal boolean null Specifies the default write concern  \"j\"  field for the client. See\n write concern  for more information. loadBalanced boolean null Specifies whether the driver is connecting to a load balancer. localThresholdMS non-negative integer 15 Specifies the size of the latency window, in milliseconds, on round trip time for\nselecting between suitable servers. Specifying  0  means no wait,\nmeaning the fastest available server. maxIdleTimeMS non-negative integer 0 Specifies the amount of time, in milliseconds, a connection can be idle before it's closed.\nSpecifying  0  means no minimum. maxPoolSize non-negative integer 100 Specifies the maximum number of clients or connections the driver\ncan create in its connection pool. This count includes connections\nin use. maxConnecting non-negative integer 2 Specifies the maximum number of connections a driver's connection\npool may be establishing concurrently. maxStalenessSeconds -1, or an integer greater than or equal 90 null Specifies the maximum replication lag, in wall clock time, that\na secondary can experience and still be eligible for server selection.\nSpecifying  -1  means no maximum. minPoolSize non-negative integer 0 Specifies the number of connections the driver should create and\nmaintain in the connection pool even when no operations are occurring.\nThis count includes connections in use. proxyHost string null Specifies the IPv4/IPv6 address or domain name of a SOCKS5 proxy\nserver used for connecting to MongoDB services. proxyPort non-negative integer null Specifies the port of the SOCKS5 proxy server specified in  proxyHost . proxyUsername string null Specifies the username for username/password authentication to the SOCKS5\nproxy server specified in  proxyHost . proxyPassword string null Specifies the password for username/password authentication to the SOCKS5\nproxy server specified in  proxyHost . readConcernLevel string null Specifies the default read concern for the client. See  read concern  for more information. readPreference string \"primary\" Specifies the default read preference for the client (excluding tags). See  read preference  for more information. readPreferenceTags comma-separated key:value pairs (e.g. \"dc:ny,rack:1\" and \"dc:ny)\ncan be specified multiple times, each instance of this key is a\nseparate tag set null Specifies the default read preference tags for the client. This option is\nvalid only if the read preference mode is not primary. The driver uses the order of the tags in the URI as the order\nfor the read preference. replicaSet string null Specifies the name of the replica set to connect to. retryReads boolean true Enables retryable reads. retryWrites boolean true Enables retryable writes. serverSelectionTimeoutMS non-negative integer 30000 Specifies the timeout, in milliseconds, to block for server selection\nbefore raising an error. serverSelectionTryOnce boolean true Specifies to scan the topology only once after a server selection\nfailure instead of repeatedly until the server selection times out. socketTimeoutMS non-negative integer 0 Specifies the amount of time, in milliseconds, spent attempting to send or receive on a\nsocket before timing out. Specifying  0  means no timeout. srvMaxHosts non-negative integer 0 Specifies the maximum number of SRV results to randomly select when initially\npopulating the seedlist or, during SRV polling, adding new hosts to the\ntopology. srvServiceName a valid SRV service name according to  RFC 6335 \"mongodb\" Specifies the service name to use for SRV lookup in initial DNS seedlist discovery. ssl boolean false The  ssl  is an alias for the  tls  option. timeoutMS non-negative integer unset (feature is not enabled by default) Specifies the timeout, in milliseconds, for the full execution of an operation. tls boolean false Specifies whether TLS is required for connections to the server.\nUsing a  srvServiceName  of   \"mongodb+srv\" , or specifying other\n tls  prefixed options will default  tls  to  true . tlsAllowInvalidCertificates boolean false Specifies whether the driver should error when the server\u2019s\nTLS certificate is invalid. tlsAllowInvalidHostnames boolean false Specifies whether the driver should error when there is a mismatch\nbetween the server\u2019s hostname and the hostname specified by the\nTLS certificate. tlsCAFile string null Specifies the path to a file with either a single or bundle of certificate\nauthorities to trust when making a TLS connection. tlsCertificateKeyFile string null Specifies the path to the client certificate file or the client\nprivate key file. If you need both, you must concatenate the files. tlsCertificateKeyFilePassword string null Specifies the password to decrypt the client private key to be used\nfor TLS connections. tlsInsecure boolean false Specifies to relax TLS constraints as much as possible, such as\nallowing invalid certificates or hostname mismatches. w non-negative integer or string null Specifies the default write concern  \"w\"  field for the client. waitQueueTimeoutMS non-negative integer 0 Specifies the amount of time, in milliseconds, spent attempting to check out a connection\nfrom a server's connection pool before timing out. wTimeoutMS non-negative integer null Specifies the default write concern  \"wtimeout\"  field for the client. zlibCompressionLevel integer between  -1  and  9  (inclusive) -1 Specifies the level of compression when using zlib to compress wire\nprotocol messages.  -1  signifies the default level,  0  signifies\nno compression,  1  signifies the fastest speed, and  9  signifies\nthe best compression. See  Network Compression  for more information.",
            "code": [],
            "preview": "This section explains the MongoDB connection and authentication options\nsupported by the driver. You can pass the connection options as\nparameters of the connection URI to specify the behavior of the client.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/monitoring/connection-monitoring",
            "title": "Connection Pool Monitoring",
            "headings": [
                "Overview",
                "Event Subscription Example",
                "Event Descriptions",
                "Example Event Documents",
                "connectionPoolCreated",
                "connectionPoolReady",
                "connectionPoolClosed",
                "connectionCreated",
                "connectionReady",
                "connectionClosed",
                "connectionCheckOutStarted",
                "connectionCheckOutFailed",
                "connectionCheckedOut",
                "connectionCheckedIn",
                "connectionPoolCleared"
            ],
            "paragraphs": "This guide shows you how to monitor the driver's  connection pool . A\nconnection pool is a set of open TCP connections your driver maintains\nwith a MongoDB instance. Connection pools help reduce the number of\nnetwork handshakes your application needs to perform and can help your\napplication run faster. Read this guide if you need to record connection pool events in your\napplication or want to explore the information provided in these events. You can access one or more connection pool events using the driver by\nsubscribing to them in your application. The following example demonstrates\nconnecting to a replica set and subscribing to one of the connection\npool monitoring events created by the MongoDB deployment: You can subscribe to any of the following connection pool monitoring events: Event Name Description connectionPoolCreated Created when a connection pool is created. connectionPoolReady Created when a connection pool is ready. connectionPoolClosed Created when a connection pool is closed, prior to server\ninstance destruction. connectionCreated Created when a connection is created, but not necessarily\nwhen it is used for an operation. connectionReady Created after a connection has successfully completed a\nhandshake and is ready to be used for operations. connectionClosed Created when a connection is closed. connectionCheckOutStarted Created when an operation attempts to acquire a connection for\nexecution. connectionCheckOutFailed Created when an operation fails to acquire a connection for\nexecution. connectionCheckedOut Created when an operation successfully acquires a connection for\nexecution. connectionCheckedIn Created when a connection is checked back into the pool after an operation\nis executed. connectionPoolCleared Created when a connection pool is cleared. The following sections show sample output for each type of connection\npool monitoring event.",
            "code": [
                {
                    "lang": "javascript",
                    "value": "const { MongoClient } = require(\"mongodb\");\n\n// Replace the following with your MongoDB deployment's connection\n// string.\nconst uri =\n  \"mongodb+srv://<clusterUrl>/?replicaSet=rs&writeConcern=majority\";\n\nconst client = new MongoClient(uri);\n\n// Replace <event name> with the name of the event you are subscribing to.\nconst eventName = \"<event name>\";\nclient.on(eventName, (event) =>\n  console.log(\"\\nreceived event:\\n\", event)\n);\n\nasync function run() {\n  try {\n    // Establish and verify connection\n    await client.db(\"admin\").command({ ping: 1 });\n    console.log(\"\\nConnected successfully!\\n\");\n  } finally {\n    // Ensures that the client will close when you finish/error\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "none",
                    "value": "ConnectionPoolCreatedEvent {\n  time: 2023-02-13T15:54:06.944Z,\n  address: '...',\n  options: {...}\n}"
                },
                {
                    "lang": "none",
                    "value": "ConnectionPoolReadyEvent {\n  time: 2023-02-13T15:56:38.440Z,\n  address: '...'\n}"
                },
                {
                    "lang": "none",
                    "value": "ConnectionPoolClosedEvent {\n  time: 2023-02-13T15:56:38.440Z,\n  address: '...'\n}"
                },
                {
                    "lang": "none",
                    "value": "ConnectionCreatedEvent {\n  time: 2023-02-13T15:56:38.291Z,\n  address: '...',\n  connectionId: 1\n}"
                },
                {
                    "lang": "none",
                    "value": "ConnectionReadyEvent {\n  time: 2023-02-13T15:56:38.291Z,\n  address: '...',\n  connectionId: 1\n}"
                },
                {
                    "lang": "none",
                    "value": "ConnectionClosedEvent {\n  time: 2023-02-13T15:56:38.439Z,\n  address: '...',\n  connectionId: 1,\n  reason: 'poolClosed',\n  serviceId: undefined\n}"
                },
                {
                    "lang": "none",
                    "value": "ConnectionCheckOutStartedEvent {\n  time: 2023-02-13T15:56:38.291Z,\n  address: '...',\n}"
                },
                {
                    "lang": "none",
                    "value": "ConnectionCheckOutFailedEvent {\n  time: 2023-02-13T15:56:38.291Z,\n  address: '...',\n  reason: ...\n}"
                },
                {
                    "lang": "none",
                    "value": "ConnectionCheckedOutEvent {\n  time: 2023-02-13T15:54:07.188Z,\n  address: '...',\n  connectionId: 1\n}"
                },
                {
                    "lang": "none",
                    "value": "ConnectionCheckedInEvent {\n  time: 2023-02-13T15:54:07.189Z,\n  address: '...',\n  connectionId: 1\n}"
                },
                {
                    "lang": "none",
                    "value": "ConnectionPoolClearedEvent {\n  time: 2023-02-13T15:56:38.439Z,\n  address: '...',\n  serviceId: undefined,\n  interruptInUseConnections: true,\n}"
                }
            ],
            "preview": "This guide shows you how to monitor the driver's connection pool. A\nconnection pool is a set of open TCP connections your driver maintains\nwith a MongoDB instance. Connection pools help reduce the number of\nnetwork handshakes your application needs to perform and can help your\napplication run faster.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/monitoring/cluster-monitoring",
            "title": "Cluster Monitoring",
            "headings": [
                "Overview",
                "Event Subscription Example",
                "Event Descriptions",
                "Example Event Documents",
                "serverDescriptionChanged",
                "serverHeartbeatStarted",
                "serverHeartbeatSucceeded",
                "serverHeartbeatFailed",
                "serverOpening",
                "serverClosed",
                "topologyOpening",
                "topologyClosed",
                "topologyDescriptionChanged"
            ],
            "paragraphs": "This guide shows you how to monitor topology events in a MongoDB instance,\nreplica set, or sharded cluster. The driver creates topology events, also\nknown as Server Discovery and Monitoring (SDAM) events, when there is\na change in the state of the instance or cluster that you connected to.\nFor example, the driver creates an event when you establish a new connection\nor if the cluster elects a new primary. Read this guide if you need to record topology changes in your application or\nwant to explore the information provided in these events. You can access one or more SDAM events using the driver by subscribing to them\nin your application. The following example demonstrates connecting to a\nreplica set and subscribing to one of the SDAM events created by the MongoDB\ndeployment: You can subscribe to any of the following SDAM events: Event Name Description serverOpening Created when a connection to an instance opens. serverClosed Created when a connection to an instance closes. serverDescriptionChanged Created when an instance state changes (such as from secondary to\nprimary). topologyOpening Created prior to attempting a connection to an instance. topologyClosed Created after all instance connections in the topology close. topologyDescriptionChanged Created when the topology changes, such as an election of a new\nprimary or a  mongos  proxy disconnecting. serverHeartbeatStarted Created prior to issuing a  hello  command to a MongoDB instance. serverHeartbeatSucceeded Created when the  hello  command returns successfully from a\nMongoDB instance. serverHeartbeatFailed Created when a  hello  command issued to a specific MongoDB\ninstance fails to return a successful response. The following sections show sample output for each type of SDAM event. The  type  field of the  ServerDescription  object in this event contains\none of the following possible values: Type Description Unknown Unknown instance Standalone Standalone instance Mongos Mongos proxy instance PossiblePrimary At least one server recognizes this as the primary, but is not yet\nverified by all instances. RSPrimary Primary instance RSSecondary Secondary instance RSArbiter Arbiter instance RSOther See the  RSGhost specification \nfor more details RSGhost See the  RSOther specification \nfor more details The  type  field of the  TopologyDescription  object in this event contains\none of the following possible values: Type Description Single Standalone instance ReplicaSetWithPrimary Replica set with a primary ReplicaSetNoPrimary Replica set with no primary Sharded Sharded cluster Unknown Unknown topology",
            "code": [
                {
                    "lang": "javascript",
                    "value": "const { MongoClient } = require(\"mongodb\");\n\n// Replace the following with your MongoDB deployment's connection\n// string.\nconst uri =\n  \"mongodb+srv://<clusterUrl>/?replicaSet=rs&writeConcern=majority\";\n\nconst client = new MongoClient(uri);\n\n// Replace <event name> with the name of the event you are subscribing to.\nconst eventName = \"<event name>\";\nclient.on(eventName, event => {\n  console.log(`received ${eventName}: ${JSON.stringify(event, null, 2)}`);\n});\n\nasync function run() {\n  try {\n    await client.connect();\n\n    // Establish and verify connection\n    await client.db(\"admin\").command({ ping: 1 });\n    console.log(\"Connected successfully\");\n  } finally {\n    // Ensures that the client will close when you finish/error\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "javascript",
                    "value": "ServerDescriptionChangedEvent {\n  topologyId: 0,\n  address: 'localhost:27017',\n  previousDescription: ServerDescription {\n    address: 'localhost:27017',\n    error: null,\n    roundTripTime: 0,\n    lastUpdateTime: 1571251089030,\n    lastWriteDate: null,\n    opTime: null,\n    type: 'Unknown',\n    minWireVersion: 0,\n    maxWireVersion: 0,\n    hosts: [],\n    passives: [],\n    arbiters: [],\n    tags: []\n  },\n  newDescription: ServerDescription {\n    address: 'localhost:27017',\n    error: null,\n    roundTripTime: 0,\n    lastUpdateTime: 1571251089051,\n    lastWriteDate: 2019-10-16T18:38:07.000Z,\n    opTime: { ts: Timestamp, t: 18 },\n    type: 'RSPrimary',\n    minWireVersion: 0,\n    maxWireVersion: 7,\n    maxBsonObjectSize: 16777216,\n    maxMessageSizeBytes: 48000000,\n    maxWriteBatchSize: 100000,\n    me: 'localhost:27017',\n    hosts: [ 'localhost:27017' ],\n    passives: [],\n    arbiters: [],\n    tags: [],\n    setName: 'rs',\n    setVersion: 1,\n    electionId: ObjectID,\n    primary: 'localhost:27017',\n    logicalSessionTimeoutMinutes: 30,\n    '$clusterTime': ClusterTime\n  }\n}"
                },
                {
                    "lang": "javascript",
                    "value": "ServerHeartbeatStartedEvent {\n  connectionId: 'localhost:27017'\n}"
                },
                {
                    "lang": "javascript",
                    "value": "ServerHeartbeatSucceededEvent {\n  duration: 1.939997,\n  reply:{\n    hosts: [ 'localhost:27017' ],\n    setName: 'rs',\n    setVersion: 1,\n    isWritablePrimary: true,\n    secondary: false,\n    primary: 'localhost:27017',\n    me: 'localhost:27017',\n    electionId: ObjectID,\n    lastWrite: {\n      opTime: { ts: [Timestamp], t: 18 },\n      lastWriteDate: 2019-10-16T18:38:17.000Z,\n      majorityOpTime: { ts: [Timestamp], t: 18 },\n      majorityWriteDate: 2019-10-16T18:38:17.000Z\n    },\n    maxBsonObjectSize: 16777216,\n    maxMessageSizeBytes: 48000000,\n    maxWriteBatchSize: 100000,\n    localTime: 2019-10-16T18:38:19.589Z,\n    logicalSessionTimeoutMinutes: 30,\n    minWireVersion: 0,\n    maxWireVersion: 7,\n    readOnly: false,\n    ok: 1,\n    operationTime: Timestamp,\n    '$clusterTime': ClusterTime\n  },\n  connectionId: 'localhost:27017'\n}"
                },
                {
                    "lang": "javascript",
                    "value": "ServerHeartbeatFailed {\n  duration: 20,\n  failure: MongoError('some error'),\n  connectionId: 'localhost:27017'\n}"
                },
                {
                    "lang": "javascript",
                    "value": "ServerOpeningEvent {\n  topologyId: 0,\n  address: 'localhost:27017'\n}"
                },
                {
                    "lang": "javascript",
                    "value": "ServerClosedEvent {\n  topologyId: 0,\n  address: 'localhost:27017'\n}"
                },
                {
                    "lang": "javascript",
                    "value": "TopologyOpeningEvent {\n  topologyId: 0\n}"
                },
                {
                    "lang": "javascript",
                    "value": "TopologyClosedEvent {\n  topologyId: 0\n}"
                },
                {
                    "lang": "javascript",
                    "value": "TopologyDescriptionChangedEvent {\n  topologyId: 0,\n  previousDescription: TopologyDescription {\n    type: 'ReplicaSetNoPrimary',\n    setName: null,\n    maxSetVersion: null,\n    maxElectionId: null,\n    servers: Map {\n      'localhost:27017' => ServerDescription\n    },\n    stale: false,\n    compatible: true,\n    compatibilityError: null,\n    logicalSessionTimeoutMinutes: null,\n    heartbeatFrequencyMS: 10000,\n    localThresholdMS: 15,\n    options: Object,\n    error: undefined,\n    commonWireVersion: null\n  },\n  newDescription: TopologyDescription {\n    type: 'ReplicaSetWithPrimary',\n    setName: 'rs',\n    maxSetVersion: 1,\n    maxElectionId: null,\n    servers: Map {\n      'localhost:27017' => ServerDescription\n    },\n    stale: false,\n    compatible: true,\n    compatibilityError: null,\n    logicalSessionTimeoutMinutes: 30,\n    heartbeatFrequencyMS: 10000,\n    localThresholdMS: 15,\n    options: Object,\n    error: undefined,\n    commonWireVersion: 7\n  }\n}"
                }
            ],
            "preview": "This guide shows you how to monitor topology events in a MongoDB instance,\nreplica set, or sharded cluster. The driver creates topology events, also\nknown as Server Discovery and Monitoring (SDAM) events, when there is\na change in the state of the instance or cluster that you connected to.\nFor example, the driver creates an event when you establish a new connection\nor if the cluster elects a new primary.",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/authentication/enterprise-mechanisms",
            "title": "Enterprise Authentication Mechanisms",
            "headings": [
                "Kerberos (GSSAPI/SSPI)",
                "LDAP (PLAIN)"
            ],
            "paragraphs": "In this guide, you can find sample code for connection to MongoDB with each\nauthentication mechanism available in the MongoDB Enterprise Edition:\n Kerberos (GSSAPI/SSPI)  and   LDAP (PLAIN) . The  GSSAPI  authentication mechanism uses your user principal to\nauthenticate to a Kerberos service. You can specify this authentication mechanism by performing the\nfollowing actions while specifying options on your\n connection string : The following code sample authenticates to Kerberos for UNIX using  GSSAPI . The Node.js driver supports Kerberos on UNIX using the MIT Kerberos library\nand on Windows using the SSPI API. Set the  authMechanism  parameter to  GSSAPI . Set the  SERVICE_NAME  value in the  authMechanismProperties \nparameter if using a value other than  mongodb . Specify a  SERVICE_REALM  value in the  authMechanismProperties \nparameter if a custom service realm is required. Specify a  CANONICALIZE_HOST_NAME  value in the  authMechanismProperties \nparameter if canonicalization of the hostname is required. This property can take\nthe following values: none : (Default) Does not perform hostname canonicalization forward : Performs a forward DNS lookup to canonicalize the hostname forwardAndReverse : Performs a forward DNS lookup and then a\nreverse lookup on that value to canonicalize the hostname The  gssapiServiceName  parameter is deprecated and may be removed\nin future versions of the driver. Use\n authMechanismProperties=SERVICE_NAME:<your service name>  in the\nconnection URI instead.\nSee the\n authMechanismProperties \nparameter documentation for more information. Always  URI encode  the principal using the  encodeURIComponent  method\nto ensure it is correctly parsed. The method refers to the  GSSAPI  authentication mechanism instead\nof  Kerberos  because the driver authenticates via\n GSSAPI RFC-4652  the SASL\nmechanism. The  PLAIN  authentication mechanism uses your username and password to\nauthenticate to a Lightweight Directory Access Protocol (LDAP) server. You can specify this authentication mechanism by setting the  authMechanism \nparameter to  PLAIN  and including your LDAP username and password in the\n connection string  as shown\nin the following sample code. The authentication mechanism is named  PLAIN  instead of  LDAP  since it\nauthenticates using the  PLAIN Simple Authentication and Security Layer\n(SASL) defined in RFC-4616 .",
            "code": [
                {
                    "lang": "js",
                    "value": "const { MongoClient } = require(\"mongodb\");\n\n// specify the placeholder values for your environment in the following lines\nconst clusterUrl = \"<MongoDB cluster URL>\";\nconst principal = encodeURIComponent(\"<Kerberos principal and realm>\");\nconst serviceRealm = \"<Kerberos service realm>\";\nconst canonicalizationSetting = \"<canonicalization setting>\";\nconst authMechanismProperties = `SERVICE_REALM:${serviceRealm},CANONICALIZE_HOST_NAME:${canonicalizationSetting}`;\n\nconst authMechanism = \"GSSAPI\";\n\n// Connection URI\nconst uri = `mongodb+srv://${principal}@${clusterUrl}/?authMechanism=${authMechanism}&authMechanismProperties=${authMechanismProperties}`;\n\nconst client = new MongoClient(uri);\n\n// Function to connect to the server\nasync function run() {\n  try {\n    // Connect the client to the server\n    await client.connect();\n\n    // Establish and verify connection\n    await client.db(\"admin\").command({ ping: 1 });\n    console.log(\"Connected successfully to server\");\n  } finally {\n    // Ensures that the client will close when you finish/error\n    await client.close();\n  }\n}\nrun().catch(console.dir);"
                },
                {
                    "lang": "js",
                    "value": "const { MongoClient } = require(\"mongodb\");\n\n// specify the placeholder values for your environment in the following lines\nconst clusterUrl = \"<MongoDB cluster URL>\";\nconst ldapUsername = \"<LDAP username>\";\nconst ldapPassword = \"<LDAP password>\";\nconst authMechanism = \"PLAIN\";\n\n// Connection URI\nconst uri = `mongodb+srv://${ldapUsername}:${ldapPassword}@${clusterUrl}/?authMechanism=${authMechanism}`;\n\nconst client = new MongoClient(uri);\n\n// Function to connect to the server\nasync function run() {\n  try {\n    // Connect the client to the server\n    await client.connect();\n\n    // Establish and verify connection\n    await client.db(\"admin\").command({ ping: 1 });\n    console.log(\"Connected successfully to server\");\n  } finally {\n    // Ensures that the client will close when you finish/error\n    await client.close();\n  }\n}\nrun().catch(console.dir);"
                }
            ],
            "preview": "In this guide, you can find sample code for connection to MongoDB with each\nauthentication mechanism available in the MongoDB Enterprise Edition:\nKerberos (GSSAPI/SSPI) and  LDAP (PLAIN).",
            "tags": null,
            "facets": null
        },
        {
            "slug": "fundamentals/authentication/mechanisms",
            "title": "Authentication Mechanisms",
            "headings": [
                "DEFAULT",
                "SCRAM-SHA-256",
                "SCRAM-SHA-1",
                "MONGODB-CR",
                "MONGODB-AWS",
                "X.509",
                "TLS/SSL Options"
            ],
            "paragraphs": "In this guide, you can find sample code for connection to MongoDB with each\nauthentication mechanism available in the MongoDB Community Edition:\n DEFAULT ,  SCRAM-SHA-256 ,  SCRAM-SHA-1 ,  MONGODB-CR ,\n MONGODB-AWS , and  X.509 . The  DEFAULT  authentication mechanism is a fallback setting that instructs\nthe driver to negotiate the first authentication mechanism supported by the\nserver in the following order of preference: If the  DEFAULT  option is specified, the driver first attempts to\nauthenticate using  SCRAM-SHA-256 . If the version of the MongoDB instance\ndoes not support that mechanism, the driver attempts to authenticate using\n SCRAM-SHA-1 . If the instance does not support that mechanism either,\nthe driver attempts to authenticate using  MONGODB-CR . You can specify this authentication mechanism by setting the  authMechanism \nparameter to  DEFAULT  in the\n connection string , or by omitting\nthe parameter since it is the default value. Also include your username and\npassword as shown in the code below. For more information on the challenge-response (CR) and salted\nchallenge-response authentication mechanisms (SCRAM) that MongoDB supports,\nsee the  SCRAM  section of the manual. SCRAM-SHA-256 SCRAM-SHA-1 MONGODB-CR Always  URI encode  the username and password using the\n encodeURIComponent  method to ensure they are correctly parsed. SCRAM-SHA-256  is a salted challenge-response authentication mechanism\n(SCRAM) that uses your username and password, encrypted with the  SHA-256 \nalgorithm to authenticate your user. You can specify this authentication mechanism by setting the  authMechanism \nto the value  SCRAM-SHA-256  in the\n connection string  as shown in the\nfollowing sample code. SCRAM-SHA-256  is the default authentication method for MongoDB starting\nin version 4.0 Always  URI encode  the username and password using the\n encodeURIComponent  method to ensure they are correctly parsed. SCRAM-SHA-1  is a salted challenge-response mechanism (SCRAM) that uses your\nusername and password, encrypted with the  SHA-1  algorithm to authenticate\nyour user. You can specify this authentication mechanism by setting the  authMechanism \nparameter to the value  SCRAM-SHA-1  in the\n connection string  as shown\nin the following sample code. SCRAM-SHA-1  is the default authentication method for MongoDB versions\n3.0, 3.2, 3.4, and 3.6. Always  URI encode  the username and password using the\n encodeURIComponent  method to ensure they are correctly parsed. MONGODB-CR  is a challenge-response authentication mechanism that uses your\nusername and password to authenticate your user. You can specify this option by setting the  authMechanism  parameter to value\n MONGODB-CR  in the\n connection string  as shown\nin the following sample code. Always  URI encode  the username and password using the\n encodeURIComponent  method to ensure they are correctly parsed. If you have  upgraded the authentication schema from MONGODB-CR to\nSCRAM , any  MONGODB-CR  user\nauthentication requests fail. The  MONGODB-AWS  authentication mechanism uses your Amazon Web Services\nIdentity and Access Management (AWS IAM) credentials to authenticate your\nuser. If you do not already have the  AWS signature library , install it using the following\n npm  command: To connect to a MongoDB instance with  MONGODB-AWS  authentication\nenabled, specify the  MONGODB-AWS  authentication mechanism. The driver checks for your credentials in the following sources in order: The MONGODB-AWS authentication mechanism is only available in MongoDB\nversions 4.4 and later. Connection string Environment variables AWS ECS endpoint specified in  AWS_CONTAINER_CREDENTIALS_RELATIVE_URI AWS EC2 endpoint. For more information, see  IAM Roles for Tasks . The driver only reads the credentials from the first method that it detects\nin the order as given by the preceding list. For example, if you specify\nyour AWS credentials in the connection string, the driver ignores any\ncredentials that you specified in environment variables. To authenticate to your MongoDB instance using AWS credentials stored in\nenvironment variables, you must specify the following items: The following code shows an example of specifying the  MONGODB-AWS \nauthentication mechanism with environment variables: In your connection string, specify the  MONGODB-AWS  authentication\nmechanism as the value of the  authMechanism  parameter. In your  AWS_ACCESS_KEY_ID  environment variable, specify the value\nof your AWS access key ID. In your  AWS_SECRET_ACCESS_KEY  environment variable, specify the\nvalue of your AWS secret access key. If your login requires an AWS session token, specify the value in\nyour  AWS_SESSION_TOKEN  environment variable. To connect to your MongoDB instance with a connection string, pass\nyour  AWS_ACCESS_KEY_ID  and  AWS_SECRET_ACCESS_KEY \ncredentials to the driver when you attempt to connect. If your AWS\nlogin requires a session token, include your  AWS_SESSION_TOKEN  as well. The following code shows an example of specifying the  MONGODB-AWS \nauthentication mechanism and credentials with a connection string: Always  URI encode  the username and certificate file path using the\n encodeURIComponent  method to ensure they are correctly parsed. The  X.509  authentication mechanism uses\n TLS  with X.509 certificates to\nauthenticate by retrieving the distinguished name (DN) from the\nclient certificate. You can specify this authentication mechanism by setting the following\nparameters of your  connection string : Pass the location of your client certificate file as the value of\n tlsCertificateKeyFile  as a parameter of the connection URI. The X.509 authentication mechanism is only available in MongoDB versions\n2.6 and later. Set the  authMechanism  parameter to  MONGODB-X509 Set the  tls  parameter to  true Always  URI encode  the certificate file path using the\n encodeURIComponent  method to ensure it is parsed correctly. The following table describes each of the TLS/SSL options that can be passed\nas a parameter in the connection URI. Parameter Name Type Default Value Description tls boolean false Specifies whether to use TLS/SSL connections. tlsInsecure boolean false Specifies whether to allow invalid certificates and mismatched\nhostnames. When set to  true , this is equivalent to setting\n tlsAllowInvalidCertificates  and  tlsAllowInvalidHostnames  to\n true . tlsCAFile string Path to file that contains a single or bundle of trusted certificate\nauthorities used in a TLS connection. tlsCertificateKeyFile string Path to the client certificate file or the client private key file. If\nboth are required, the two must be concatenated into a single file. tlsCertificateKeyFilePassword buffer or string String or buffer that contains the password to decrypt the client\nprivate key. tlsAllowInvalidCertificates boolean false Specifies whether the driver permits an invalid certificate to be used\nto connect. tlsAllowInvalidHostnames boolean false Specifies whether the driver should permit a mismatch between the\nserver hostname and TLS certificate hostname.",
            "code": [
                {
                    "lang": "javascript",
                    "value": "const { MongoClient } = require(\"mongodb\");\n\n// Replace the following with values for your environment.\nconst username = encodeURIComponent(\"<username>\");\nconst password = encodeURIComponent(\"<password>\");\nconst clusterUrl = \"<MongoDB cluster url>\";\n\nconst authMechanism = \"DEFAULT\";\n\n// Replace the following with your MongoDB deployment's connection string.\nconst uri =\n  `mongodb+srv://${username}:${password}@${clusterUrl}/?authMechanism=${authMechanism}`;\n\n// Create a new MongoClient\nconst client = new MongoClient(uri);\n\n// Function to connect to the server\nasync function run() {\n  try {\n    // Connect the client to the server\n    await client.connect();\n\n    // Establish and verify connection\n    await client.db(\"admin\").command({ ping: 1 });\n    console.log(\"Connected successfully to server\");\n  } finally {\n    // Ensures that the client will close when you finish/error\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "javascript",
                    "value": "const { MongoClient } = require(\"mongodb\");\n\n// Replace the following with values for your environment.\nconst username = encodeURIComponent(\"<username>\");\nconst password = encodeURIComponent(\"<password>\");\nconst clusterUrl = \"<MongoDB cluster url>\";\n\nconst authMechanism = \"SCRAM-SHA-256\";\n\n// Replace the following with your MongoDB deployment's connection string.\nconst uri =\n  `mongodb+srv://${username}:${password}@${clusterUrl}/?authMechanism=${authMechanism}`;\n\n// Create a new MongoClient\nconst client = new MongoClient(uri);\n\n// Function to connect to the server\nasync function run() {\n  try {\n    // Connect the client to the server\n    await client.connect();\n\n    // Establish and verify connection\n    await client.db(\"admin\").command({ ping: 1 });\n    console.log(\"Connected successfully to server\");\n  } finally {\n    // Ensures that the client will close when you finish/error\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "javascript",
                    "value": "const { MongoClient } = require(\"mongodb\");\n\n// Replace the following with values for your environment.\nconst username = encodeURIComponent(\"<username>\");\nconst password = encodeURIComponent(\"<password>\");\nconst clusterUrl = \"<MongoDB cluster url>\";\n\nconst authMechanism = \"SCRAM-SHA-1\";\n\n// Replace the following with your MongoDB deployment's connection string.\nconst uri =\n  `mongodb+srv://${username}:${password}@${clusterUrl}/?authMechanism=${authMechanism}`;\n\n// Create a new MongoClient\nconst client = new MongoClient(uri);\n\n// Function to connect to the server\nasync function run() {\n  try {\n    // Connect the client to the server\n    await client.connect();\n\n    // Establish and verify connection\n    await client.db(\"admin\").command({ ping: 1 });\n    console.log(\"Connected successfully to server\");\n  } finally {\n    // Ensures that the client will close when you finish/error\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "javascript",
                    "value": "const { MongoClient } = require(\"mongodb\");\n\n// Replace the following with values for your environment.\nconst username = encodeURIComponent(\"<username>\");\nconst password = encodeURIComponent(\"<password>\");\nconst clusterUrl = \"<MongoDB cluster url>\";\n\n// Replace the following with your MongoDB deployment's connection string.\nconst uri =\n  `mongodb+srv://${username}:${password}@${clusterUrl}/?authMechanism=${authMechanism}&tls=true&tlsCertificateKeyFile=${clientPEMFile}`;\n\n// Create a new MongoClient\nconst client = new MongoClient(uri);\n\n// Function to connect to the server\nasync function run() {\n  try {\n    // Connect the client to the server\n    await client.connect();\n\n    // Establish and verify connection\n    await client.db(\"admin\").command({ ping: 1 });\n    console.log(\"Connected successfully to server\");\n  } finally {\n    // Ensures that the client will close when you finish/error\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "bash",
                    "value": "npm install aws4"
                },
                {
                    "lang": "javascript",
                    "value": "const { MongoClient } = require(\"mongodb\");\n\n// Remember to specify your AWS credentials in environment variables.\nconst clusterUrl = \"<MongoDB deployment url>\";\nconst authMechanism = \"MONGODB-AWS\";\n\nlet uri =\n  `mongodb+srv://${clusterUrl}/?authSource=%24external&authMechanism=${authMechanism}`;\n\n// Create a new MongoClient.\nconst client = new MongoClient(uri);\n\nasync function run() {\n  try {\n    // Connect the client to the server.\n    await client.connect();\n\n    // Establish and verify connection.\n    await client.db(\"admin\").command({ ping: 1 });\n    console.log(\"Connected successfully to server.\");\n  } finally {\n    // Ensure that the client closes when it finishes/errors.\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "javascript",
                    "value": "const { MongoClient } = require(\"mongodb\");\n\n// Replace the following with values for your environment.\nconst accessKeyId = encodeURIComponent(\"<AWS_ACCESS_KEY_ID>\");\nconst secretAccessKey = encodeURIComponent(\"<AWS_SECRET_ACCESS_KEY>\");\nconst clusterUrl = \"<MongoDB cluster url>\";\n\nconst authMechanism = \"MONGODB-AWS\";\n\nlet uri =\n  `mongodb+srv://${accessKeyId}:${secretAccessKey}@${clusterUrl}/?authSource=%24external&authMechanism=${authMechanism}`;\n  \n// Uncomment the following lines if your AWS authentication setup requires a session token.\n// const sessionToken = encodeURIComponent(\"<AWS_SESSION_TOKEN>\");\n// uri = uri.concat(`&authMechanismProperties=AWS_SESSION_TOKEN:${sessionToken}`);\n\n// Create a new MongoClient.\nconst client = new MongoClient(uri);\n\nasync function run() {\n  try {\n    // Connect the client to the server.\n    await client.connect();\n\n    // Establish and verify connection.\n    await client.db(\"admin\").command({ ping: 1 });\n    console.log(\"Connected successfully to server.\");\n  } finally {\n    // Ensure that the client closes when it finishes/errors.\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                },
                {
                    "lang": "javascript",
                    "value": "const { MongoClient } = require(\"mongodb\");\n\n// Replace the following with values for your environment.\nconst clusterUrl = \"<MongoDB cluster url>\";\nconst clientPEMFile = encodeURIComponent(\"<path to the client pem certificate file>\");\n\nconst authMechanism = \"MONGODB-X509\";\n\n// Replace the following with your MongoDB deployment's connection string.\nconst uri =\n  `mongodb+srv://${clusterUrl}/?authMechanism=${authMechanism}&tls=true&tlsCertificateKeyFile=${clientPEMFile}`;\n\n// Create a new MongoClient\nconst client = new MongoClient(uri);\n\n// Function to connect to the server\nasync function run() {\n  try {\n    // Connect the client to the server\n    await client.connect();\n\n    // Establish and verify connection\n    await client.db(\"admin\").command({ ping: 1 });\n    console.log(\"Connected successfully to server\");\n  } finally {\n    // Ensures that the client will close when you finish/error\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n"
                }
            ],
            "preview": "In this guide, you can find sample code for connection to MongoDB with each\nauthentication mechanism available in the MongoDB Community Edition:\nDEFAULT, SCRAM-SHA-256, SCRAM-SHA-1, MONGODB-CR,\nMONGODB-AWS, and X.509.",
            "tags": null,
            "facets": null
        }
    ]
}