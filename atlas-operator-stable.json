{
    "url": "http://mongodb.com/docs/atlas/operator/stable",
    "includeInGlobalSearch": true,
    "documents": [
        {
            "slug": "ak8so-monitoring",
            "title": "Monitor Your Atlas Database Deployments",
            "headings": [],
            "paragraphs": "",
            "code": [],
            "preview": null,
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-integrate-third-party",
            "title": "Integrate with Third-Party Services",
            "headings": [
                "Prerequisites",
                "Procedure"
            ],
            "paragraphs": "You can use  Atlas Kubernetes Operator  to integrate  Atlas  with third-party services to: To learn more, see  Integrate with Third-Party Services . Receive  Atlas  alerts in various third-party services. View and analyze  performance metrics \nthat  Atlas  collects about your cluster. Currently, serverless instance metrics don't support any\nthird-party services (for example,  Datadog ). To learn more, see  Configure Access to  Atlas . You need the following public API key, private API key, and the\norganization ID information to configure  Atlas Kubernetes Operator  access to  Atlas . If you want  Atlas Kubernetes Operator  to create a new  Atlas  project,\n Create an API (Application Programming Interface) Key in an Organization . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the\n Organization Project Creator  organization role or\nhigher. If you want to work with an existing  Atlas  project,\n Create an API (Application Programming Interface) Key for a Project . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the  Project Owner \nproject role. To integrate  Atlas  with a third-party service, configure the\n AtlasProject  Custom Resource . Example: The parameters that you must specify in the\n AtlasProject  Custom Resource  depend on the third-party service\nthat you want to configure: For another example, see  Prometheus Example . To learn more about the configuration parameters available from\nthe  API (Application Programming Interface) , see the  Atlas   Third-Party Integration\nSettings . Service Settings All spec.integrations.type Datadog spec.integrations.apiKeyRef.name spec.integrations.apiKeyRef.namespace spec.integrations.region Microsoft Teams spec.integrations.microsoftTeamsWebhookURL Opsgenie spec.integrations.apiKeyRef.name spec.integrations.apiKeyRef.namespace spec.integrations.region PagerDuty spec.integrations.serviceKeyRef.name spec.integrations.serviceKeyRef.namespace Prometheus spec.integrations.enabled spec.integrations.passwordRef.name spec.integrations.passwordRef.namespace spec.integrations.scheme spec.integrations.serviceDiscovery spec.integrations.username Slack spec.integrations.apiTokenRef.name spec.integrations.apiTokenRef.namespace VictorOps spec.integrations.apiKeyRef.name spec.integrations.routingKeyRef.name spec.integrations.routingKeyRef.namespace Webhook Settings spec.integrations.secretRef.name spec.integrations.secretRef.namespace spec.integrations.url Atlas Kubernetes Operator  offers a  sample Grafana dashboard  that you can  import into Grafana .",
            "code": [
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: TestDatadogIntegration\n  connectionSecretRef:\n    name: my-atlas-key\n  projectIpAccessList:\n    - ipAddress: \"0.0.0.0/1\"\n      comment: \"Everyone has access. For test purposes only.\"\n    - ipAddress: \"128.0.0.0/1\"\n      comment: \"Everyone has access. For test purposes only.\"\n  integrations:\n    - type: \"DATADOG\"\n      apiKeyRef:\n        name: key-name\n        namespace: key-namespace\n      region: \"US\"\n EOF"
                }
            ],
            "preview": "You can use Atlas Kubernetes Operator to integrate Atlas with third-party services to:",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-configure-teams",
            "title": "Configure Teams",
            "headings": [
                "Limitations",
                "Prerequisites",
                "Procedure",
                "Create the team.",
                "Grant the team access to a project."
            ],
            "paragraphs": "Atlas Kubernetes Operator  supports  teams  for controlling access to\nyour  Atlas  projects. To manage teams with  Atlas Kubernetes Operator , specify and\nupdate the following custom resources: Each time you change any of the supported custom resources, such as updating or\nremoving a team,  Atlas Kubernetes Operator \n creates or updates  the\ncorresponding  Atlas  configuration. You can create teams at the organization level and add teams to\nprojects to grant project access roles to multiple users. Add any\nnumber of organization users to a team. Grant a team roles for specific projects. All members of a team share\nthe same project access. Organization users can belong to multiple\nteams. To add teams to a project or edit team roles, see\n Manage Access to a Project . Custom Resource Purpose AtlasTeam  Custom Resource Defines the team name and the users who belong to it. AtlasProject  Custom Resource Defines the team's access roles for this project. You\nmust set the  spec.teams.teamRef.name  field to match the\n metadata.name  of the  AtlasTeam  Custom Resource  to assign\nthe team to this project. You must assign the team to a project by configuring both the\n AtlasTeam  Custom Resource  and the  AtlasProject  Custom Resource  for\nthe team to appear in the  Atlas  UI. For other limitations that apply to teams, see\n Manage Organization Teams . To enable teams for your  Atlas Kubernetes Operator -managed\ncluster, you must: Have a running  Kubernetes  cluster with\n Atlas Kubernetes Operator   deployed . Ensure your  IP (Internet Protocol)  address is in the organization's  API (Application Programming Interface) \n access list . Follow these steps to enable teams for your  Atlas Kubernetes Operator -managed\nprojects: Create an  AtlasTeam  Custom Resource  for each team using the following\nexample. Specify a  metadata.name  so that you can reference this\nfile from the  AtlasProject  Custom Resource  and a  spec.name  so you\ncan differentiate this team from other teams in your organization. Add only users who are part of the organization. To learn more about the parameters for a team, see\nthe  AtlasTeam  Custom Resource . Example: To assign this team to a project, set the  spec.teams.teamRef.name \nfield in the  AtlasProject  Custom Resource  to match the\n metadata.name  from the previous step. In the  spec.teams.teamRef.roles  field, specify the team's\n Atlas User Roles  for this project. You can add more than one team. The following example shows two teams with\ndifferent access roles for the same project. To learn about the other parameters for a team,\nsee  AtlasProject  Custom Resource . Example:",
            "code": [
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasTeam\nmetadata:\n  name: green-leaf-team\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: \"greenLeafTeam\"\n  usernames:\n    - \"atlas.user1@example.com\"\n    - \"atlas.user2@example.com\"\n    - \"atlas.user3@example.com\"\n    - \"atlas.user4@example.com\"\n EOF"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: Test project\n  teams:\n    - teamRef:\n        name: green-leaf-team\n      roles:\n      - GROUP_OWNER\n    - teamRef:\n        name: no-leaf-team\n      roles:\n      - GROUP_CLUSTER_MANAGER\n      - GROUP_DATA_ACCESS_ADMIN\n\nEOF"
                }
            ],
            "preview": "Atlas Kubernetes Operator supports teams for controlling access to\nyour Atlas projects.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-back-up-deployment",
            "title": "Back Up Your Atlas Cluster",
            "headings": [
                "Considerations",
                "Limitations",
                "Prerequisites",
                "Procedure",
                "Create the backup policy.",
                "Create the backup schedule.",
                "Apply the backup schedule to the cluster."
            ],
            "paragraphs": "Atlas Kubernetes Operator  supports  cloud backup  for\nyour  Atlas  clusters. Cloud backup uses the native\nsnapshot capabilities of your cloud provider to support full-copy\nsnapshots and localized snapshot storage. To manage cloud backup with  Atlas Kubernetes Operator , you can specify and\nupdate the following custom resources: Each time you change any of the supported custom resources,  Atlas Kubernetes Operator \n creates or updates  the\ncorresponding  Atlas  configuration. This feature is not available for  M0  free clusters,  M2 , and\n M5  clusters. To learn more about which features are unavailable,\nsee  Atlas M0 (Free Cluster), M2, and M5 Limits . Atlas  automatically enables backups for serverless instances\nand takes snapshots every six hours. Any  Atlas Kubernetes Operator  backup custom\nresources you apply to a serverless instance will not override\nthe automatic settings. To learn more about backups for serverless instances, see\n Serverless Instance Backups . Custom Resource Purpose AtlasBackupPolicy  Custom Resource Defines the backup policy, including the frequency of backups\nand the length of snapshot retention. AtlasBackupSchedule  Custom Resource Defines the backup schedule, including the time of day that\n Atlas  backs up your database deployment, the number\nof days back in time to which you can restore, and the backup policy. AtlasDeployment  Custom Resource Defines the characteristics of a cluster. You\nmust set the  spec.backupRef.name  field to the name of\nthe configured backup schedule to enable cloud backup for\nthe cluster. Additionally, to configure continuous backup, you must set  spec.deploymentSpec.pitEnabled  to  true . Review the following considerations: You can specify one backup policy per backup schedule. You can specify one backup schedule per cluster, but\nyou can use the same backup schedule for multiple\nclusters. Atlas  determines the order of nodes to snapshot based on your\ncluster configuration. To learn more, see\n Cloud Backups . Atlas Kubernetes Operator  supports automatic  snapshot distribution .\nYou can configure this with the  spec.copySetting  field in the\n AtlasBackupSchedule  Custom Resource . Certain limitations apply to cloud backup. To learn more, see\n Back Up Your Database Deployment . To enable cloud backup for your  Atlas Kubernetes Operator -managed\ncluster, you must: Have a running  Kubernetes  cluster with\n Atlas Kubernetes Operator   deployed . Ensure your  IP (Internet Protocol)  address is in the organization's  API (Application Programming Interface) \n access list . Follow these steps to enable cloud backup for your  Atlas Kubernetes Operator -managed\nclusters: To learn more about the parameters for a backup policy, see\n AtlasBackupPolicy  Custom Resource . Example: In the  spec.policy.name  field, specify the\n metadata.name  from the\n AtlasBackupPolicy  Custom Resource  to apply your backup\npolicy. To learn more about the other parameters for a backup schedule\nsee  AtlasBackupSchedule  Custom Resource . Example: In the  spec.backupRef.name  field of the\n AtlasDeployment  Custom Resource , specify the\n metadata.name  from the\n AtlasBackupSchedule  Custom Resource  to apply your\nbackup schedule to the cluster. Example:",
            "code": [
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasBackupPolicy\nmetadata:\n  name: \"atlas-default-backuppolicy\"\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n   items:\n      frequencyType: \"weekly\"\n      frequencyInterval: 1\n      retentionUnit: \"days\"\n      retentionValue: 7\n EOF"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasBackupSchedule\nmetadata:\n  name: \"atlas-default-backupschedule\"\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  autoExportEnabled: true\n  copySettings:\n  - cloudProvider: AWS\n    frequencies:\n    - HOURLY\n    regionName: US_EAST_1\n    shouldCopyOplogs: true\n  referenceHourOfDay: 10\n  referenceMinuteOfHour: 10\n  restoreWindowDays: 2\n  policy:\n    name: atlas-default-backuppolicy\n    namespace: mongodb-atlas-system\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: my-atlas-cluster\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  backupRef:\n    name: atlas-default-backupschedule\n    namespace: mongodb-atlas-system\nEOF"
                }
            ],
            "preview": "Atlas Kubernetes Operator supports cloud backup for\nyour Atlas clusters. Cloud backup uses the native\nsnapshot capabilities of your cloud provider to support full-copy\nsnapshots and localized snapshot storage.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-unified-access",
            "title": "Set Up Unified Cloud Provider Integrations",
            "headings": [
                "Prerequisites",
                "Procedure",
                "Add the spec.cloudProviderIntegrations fields to the AtlasProject custom resource.",
                "Retrieve the project's atlasAWSAccountArn and atlasAssumedRoleExternalId.",
                "Modify your AWS (Amazon Web Services) IAM (Identity and Access Management) role trust policy.",
                "Find the IAM (Identity and Access Management) role's ARN (Amazon Resource Name) in AWS (Amazon Web Services).",
                "Authorize the IAM (Identity and Access Management) role's access using Atlas Kubernetes Operator.",
                "Check the status of the cloudProviderIntegrations."
            ],
            "paragraphs": "You can use  Atlas Kubernetes Operator  to set up unified access for an  AWS (Amazon Web Services)   IAM (Identity and Access Management)  role\nin the  AtlasProject  Custom Resource . Some  Atlas  features, including  Data Federation  and  Encryption at Rest , authenticate with  AWS (Amazon Web Services)   IAM roles .\nWhen  Atlas  accesses  AWS (Amazon Web Services)  services,\n assumes an IAM role . You can set up an assumed IAM role for your  Atlas  account to use\nwith the Atlas Administration API or Atlas UI if you have the\n Project Owner  role.  Atlas  supports unified access only\nfor  AWS (Amazon Web Services) . To learn more, see  Configure Access to  Atlas . You need the following public API key, private API key, and the\norganization ID information to configure  Atlas Kubernetes Operator  access to  Atlas . If you want  Atlas Kubernetes Operator  to create a new  Atlas  project,\n Create an API (Application Programming Interface) Key in an Organization . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the\n Organization Project Creator  organization role or\nhigher. If you want to work with an existing  Atlas  project,\n Create an API (Application Programming Interface) Key for a Project . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the  Project Owner \nproject role. Example: Specify an empty value placeholder within the\n spec.cloudProviderIntegrations.iamAssumedRoleArn \nparameter of the  AtlasProject  Custom Resource . Specify  AWS  within the\n spec.cloudProviderIntegrations.providerName \nparameter of the  AtlasProject  Custom Resource . Complete this entire procedure to configure the role for the\nempty value placeholder before adding any additional access\nroles to your  AtlasProject  custom resource. Run the command to retrieve the  atlasAWSAccountArn , which\nyou need for the next steps. Run the command to retrieve the  atlasAssumedRoleExternalId , which\nyou need for the next steps. You can use an existing  IAM (Identity and Access Management)  role or create a new  IAM (Identity and Access Management)  role\nfor unified access. Modify the trust policy for your AWS IAM role  using the following\ncustom trust policy. Replace the highlighted lines with the values you\nretrieved in a previous step. Create the AWS IAM role  using the following\ncustom trust policy. Replace the highlighted lines with the values you\nretrieved in a previous step. In the  Roles  section of the  AWS (Amazon Web Services)  Management\nConsole, click on the  IAM (Identity and Access Management)  role you edited or created for\n Atlas  access.  AWS (Amazon Web Services)  displays the  ARN (Amazon Resource Name)  in the\n Summary  section. Replace the empty value placeholder within the\n spec.cloudProviderIntegrations.iamAssumedRoleArn \nparameter of the  AtlasProject  Custom Resource  with\nthe  IAM (Identity and Access Management)  role's  AWS (Amazon Web Services)   ARN (Amazon Resource Name)  from the previous step. Example: Run the command to retrieve the status: Check for the  READY  status. If the status is  CREATED ,  Atlas  created the role but\nyou have not authorized it within  AWS (Amazon Web Services) . If the status is  EMPTY_ARN ,  Atlas  created the role\nbut you have not specified the\n spec.cloudProviderIntegrations.iamAssumedRoleArn . If the status is  READY ,  Atlas  has created the role\nand you have authorized it within  AWS (Amazon Web Services) .",
            "code": [
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: Test Project\n  projectIpAccessList:\n    - ipAddress: \"192.0.2.15\"\n      comment: \"IP address for Application\"\n  cloudProviderIntegrations:\n  - providerName: \"AWS\"\n    iamAssumedRoleArn: \"\"\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasprojects my-project -o=jsonpath='{.status.cloudProviderIntegrations.atlasAWSAccountArn.type}'"
                },
                {
                    "lang": "json",
                    "value": "arn:aws:iam::198765432109:root"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasprojects my-project -o=jsonpath='{.status.cloudProviderIntegrations.atlasAssumedRoleExternalId.type}'"
                },
                {
                    "lang": "json",
                    "value": "1a234b56-c789-0d12-345e-67f89012345a"
                },
                {
                    "lang": "json",
                    "value": "{\n   \"Version\":\"2012-10-17\",\n   \"Statement\":[\n      {\n         \"Effect\":\"Allow\",\n         \"Principal\":{\n            \"AWS\":\"<atlasAWSAccountArn>\"\n         },\n         \"Action\":\"sts:AssumeRole\",\n         \"Condition\":{\n            \"StringEquals\":{\n               \"sts:ExternalId\":\"<atlasAssumedRoleExternalId>\"\n            }\n         }\n      }\n   ]\n}\n"
                },
                {
                    "lang": "json",
                    "value": "{\n   \"Version\":\"2012-10-17\",\n   \"Statement\":[\n      {\n         \"Effect\":\"Allow\",\n         \"Principal\":{\n            \"AWS\":\"<atlasAWSAccountArn>\"\n         },\n         \"Action\":\"sts:AssumeRole\",\n         \"Condition\":{\n            \"StringEquals\":{\n               \"sts:ExternalId\":\"<atlasAssumedRoleExternalId>\"\n            }\n         }\n      }\n   ]\n}\n"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: Test Project\n  projectIpAccessList:\n    - ipAddress: \"192.0.2.15\"\n      comment: \"IP address for Application\"\n  cloudProviderIntegrations:\n  - providerName: \"AWS\"\n    iamAssumedRoleArn: \"arn:aws:iam::123456789012:role/aws-service-role/support.amazonaws.com/myRole\"\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasprojects my-project -o=jsonpath='{.status.cloudProviderIntegrations}'"
                }
            ],
            "preview": "You can use Atlas Kubernetes Operator to set up unified access for an AWS (Amazon Web Services) IAM (Identity and Access Management) role\nin the AtlasProject Custom Resource.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-x509",
            "title": "Set Up X.509 Authentication",
            "headings": [
                "Prerequisites",
                "Generate an X.509 Certificate with cert-manager",
                "Install cert-manager.",
                "Create an Issuer.",
                "Creat a certificate.",
                "Generate an X.509 Certificate with a Custom Script",
                "Run the custom script.",
                "Add the certificate to a secret.",
                "Procedure",
                "Configure a project to use the certificate.",
                "Add a database user that uses X.509 authentication."
            ],
            "paragraphs": "X.509 client certificates provide database users access to the\ndatabase deployments in your project. You can use  Atlas Kubernetes Operator  to enable\nX.509 authentication for the  AtlasProject  Custom Resource  and\nthe  AtlasDatabaseUser  Custom Resource . Options for X.509 authentication include  Atlas -managed X.509\nauthentication and self-managed X.509 authentication. To learn more\nabout self-managed X.509 authentication, see  Set Up Self-Managed X.509 Authentication . To set up X.509 authentication: Generate an X.509 certificate. Configure the  AtlasProject  Custom Resource  to use the\ncertificate. Configure the  AtlasDatabaseUser  Custom Resource  to use\n Atlas -managed or self-managed X.509 authentication. To use self-managed X.509 certificates, you must have a\nPublic Key Infrastructure to integrate with  MongoDB Atlas . To learn more, see  Configure Access to  Atlas . You need the following public API key, private API key, and the\norganization ID information to configure  Atlas Kubernetes Operator  access to  Atlas . If you want  Atlas Kubernetes Operator  to create a new  Atlas  project,\n Create an API (Application Programming Interface) Key in an Organization . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the\n Organization Project Creator  organization role or\nhigher. If you want to work with an existing  Atlas  project,\n Create an API (Application Programming Interface) Key for a Project . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the  Project Owner \nproject role. Generate an X.509 certificate with  cert-manager  or the  create_X.509.go  script. To generate an X.509 certificate with  cert-manager , do the following steps: To install cert-manager, see the\n cert-manager installation documentation . To create a cert-manager  Issuer , see the\n cert-manager configuration documentation . To learn more, see the  example . To create a certificate, see the\n cert-manager usage documentation . To learn more, see the  example . To generate an X.509 certificate with the  create_X.509.go \nscript, do the following steps: Run the  create_X.509.go  script: Example: To add the certificate to a  secret , run the following\ncommands: Example: Specify the  secret  within the\n spec.x509CertRef.name  parameter for the\n AtlasProject  Custom Resource . Example: Specify the  x509Type  parameter for the\n AtlasDatabaseUser  Custom Resource . This parameter accepts: To learn more about the configuration parameters available from\nthe  API (Application Programming Interface) , see the  Atlas   Database Users API . Example: NONE User that doesn't use X.509 authentication. MANAGED User that uses  Atlas -managed X.509. You must specify  \\$external  for the\n spec.databaseName  parameter. CUSTOMER User that uses  Self-Managed X.509 . Users created with this  x509Type \nrequire a Common Name (CN) in the  username  field. To\nlearn more, see  RFC 2253 . You must specify  \\$external  for the\n spec.databaseName  parameter.",
            "code": [
                {
                    "lang": "sh",
                    "value": "go run scripts/create_x509.go --path={pem-file-path}"
                },
                {
                    "lang": "sh",
                    "value": "go run scripts/create_x509.go --path=tmp/x509/"
                },
                {
                    "lang": "sh",
                    "value": "kubectl create secret generic {secret-name} --from-file={pem-file-directory}"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret {secret-name} atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "kubectl create secret generic my-x509-cert --from-file=./tmp/x509/cert.pem"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret my-x509-cert atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: Test Project\n  projectIpAccessList:\n    - ipAddress: \"192.0.2.15\"\n      comment: \"IP address for Application Server A\"\n    - ipAddress: \"203.0.113.0/24\"\n      comment: \"CIDR block for Application Servers B - D\"\n  x509CertRef:\n    name: my-x509-cert\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n  name: my-database-user\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  username: CN=my-x509-authenticated-user,OU=organizationalunit,O=organization\n  databaseName: \"\\$external\"\n  x509Type: \"CUSTOMER\"\n  roles:\n    - roleName: \"readWriteAnyDatabase\"\n      databaseName: \"admin\"\n  projectRef:\n    name: my-project\nEOF"
                }
            ],
            "preview": "X.509 client certificates provide database users access to the\ndatabase deployments in your project. You can use Atlas Kubernetes Operator to enable\nX.509 authentication for the AtlasProject Custom Resource and\nthe AtlasDatabaseUser Custom Resource.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "atlasdatafederation-custom-resource",
            "title": "AtlasDataFederation Custom Resource",
            "headings": [
                "Examples",
                "Parameters"
            ],
            "paragraphs": "The  AtlasDataFederation  custom resource configures a\n federated database instance  in  Atlas . When\nyou create the  AtlasDataFederation  custom resource,  Atlas Kubernetes Operator  tries\nto create or update a federated database instance in  Atlas . You can use an federated database instance to\nrun  federated queries . Atlas Kubernetes Operator  uses the  Atlas   Clusters API Resource  and  Advanced Clusters API Resource  to create a new federated database instance or\nupdate an existing federated database instance. If you specify values for fields under\n spec.serverlessSpec ,  Atlas Kubernetes Operator  uses the  Atlas \n Serverless Instance API Resource  to create or configure private endpoints for\nyour federated database instance. If you remove the  AtlasDataFederation  resource from your  Kubernetes \ncluster,  Atlas Kubernetes Operator  removes the federated database instance from  Atlas . Atlas Kubernetes Operator  doesn't support the  AtlasDataFederation  custom resource for\n Atlas  for Government. Atlas Kubernetes Operator  uses  custom resource  configuration\nfiles to manage your  Atlas  configuration, but as of  Atlas Kubernetes Operator  2.0,\ncustom resources you delete in  Kubernetes  are no longer deleted in\n Atlas . Instead,  Atlas Kubernetes Operator  simply stops managing those resources.\nFor example, if you delete an  AtlasProject  Custom Resource \nin  Kubernetes ,  Atlas Kubernetes Operator  no longer automatically deletes the corresponding project\nfrom  Atlas , preventing accidental or unexpected deletions. To learn more,\nincluding how to  revert this behavior  to\nthe default used prior to  Atlas Kubernetes Operator  2.0, see  New Default: Deletion Protection in  Atlas Kubernetes Operator  2.0 . The following example shows an  AtlasDataFederation  custom resource\nspecification with configured private endpoints: This section describes some of the key  AtlasDataFederation  custom\nresource parameters available. For a full list of available parameters, see the  Atlas   Data Federation API . Refer to these descriptions, the available examples, and the  API (Application Programming Interface) \ndocumentation to customize your specifications. Type : string Required Label that identifies the  AtlasDataFederation  Custom Resource \nthat  Atlas Kubernetes Operator  uses to add this federated database instance to a project. Type : object Required List that contains the cloud provider configurations for the federated database instance. Type : object Required Name of the cloud service provider that hosts the federated database instance. Type : string Required Unique identifier of the role that the federated database instance can use to access the\ndata stores. Type : string Required Name of the S3 data bucket that the provided role ID is authorized to\naccess. Type : object Required Information about the cloud provider region to which the federated database instance\nroutes client connections.  Atlas Kubernetes Operator  supports only  AWS (Amazon Web Services) . Type : string Required Name of the cloud service provider that hosts the federated database instance's data\nstores.  Atlas Kubernetes Operator  accepts the following values: AWS TENANT SERVERLESS Type : string Required Label that indicates the geographical location of the federated database instance's data\nstores.  Atlas Kubernetes Operator  accepts the following values: SYDNEY_AUS MUMBAI_IND FRANKFURT_DEU DUBLIN_IRL LONDON_GBR VIRGINIA_USA OREGON_USA SAOPAULO_BRA SINGAPORE_SGP Type : string Optional Label that identifies the federated database instance in  Atlas . Type : object Optional Configuration information for each data store and its mapping to\n Atlas  databases. Type : array Optional List that contains the queryable databases and collections for this\nfederated database instance. Type : array Optional List of collections and data sources that map to a  stores  data\nstore. Type : array Optional List that contains the data stores that map to a collection for this\nfederated database instance. Type : boolean Optional Flag that validates the scheme in the specified URLs. If  true ,\n Atlas Kubernetes Operator  allows the insecure  HTTP  scheme, doesn't verify the\nserver's certificate chain and hostname, and accepts any certificate\nwith any hostname presented by the server. If  false ,  Atlas Kubernetes Operator \nallows secure the  HTTPS  scheme only. Type : string Optional Human-readable label that identifies the collection in the database.\nTo create a wildcard ( * ) collection, you must omit this parameter. Type : string Optional Regex pattern to use to create a wildcard ( * ) collection. Type : string Optional Human-readable label that identifies the database, which contains the\ncollection in the cluster. You must omit this parameter to\ngenerate wildcard ( * ) collections for dynamically-generated\ndatabases. Type : string Optional Regex pattern to use to create the wildcard ( * ) database. Type : string Optional File format that  Atlas Kubernetes Operator  uses if it encounters a file without a file\nextension while searching  storeName .  Atlas Kubernetes Operator  accepts the following\nvalues: .avro .avro.bz2 .avro.gz .bson .bson.bz2 .bson.gz .bsonx .csv .csv.bz2 .csv.gz .json .json.bz2 .json.gz .orc .parquet .tsv .tsv.bz2 .tsv.gz Type : string Optional File path that controls how  Atlas Kubernetes Operator  searches for and parses files in\nthe  storeName  before mapping them to a collection. Specify  / \nto capture all files and folders from the prefix path. Type : string Optional Human-readable label that identifies the field that includes the\nprovenance of the documents in the results.  Atlas Kubernetes Operator  returns different\nfields in the results for each supported provider. Type : string Optional Human-readable label that identifies the data store that  Atlas Kubernetes Operator  maps\nto the collection. Type : array Optional URLs of the publicly-accessible data files. You can't specify URLs\nthat require authentication. Atlas Data Federation creates a partition for each\nURL. If empty or omitted, Atlas Data Federation uses the URLs from the store\nspecified in the  dataSources.storeName \nparameter. Type : string Optional Human-readable label that identifies the collection to which  Atlas Kubernetes Operator \nmaps the data in the data stores. Type : int32 Optional Maximum number of wildcard collections in the database. This only\napplies to S3 data sources. The default value is  100 . Type : string Optional Human-readable label that identifies the database to which the\nfederated database instance maps data. Type : array Optional List of aggregation pipelines that apply to the collection. This only\napplies to S3 data sources. Type : string Optional Human-readable label that identifies the view, which corresponds to\nan aggregation pipeline on a collection. Type : string Optional Aggregation pipeline stages to apply to the source collection. Type : string Optional Human-readable label that identifies the source collection for the\nview. Type : array Optional List that contains the data stores for the federated database instance. Type : string Optional Human-readable label that identifies the data store. The\n spec.storage.databases.collections.dataSources.storeName \nfield references this values as part of the mapping configuration. Type : string Conditional Provider for the store.  Atlas Kubernetes Operator  supports only  S3 . You must specify\nthis field to use a data store. Type : array Optional Collection of  AWS (Amazon Web Services)  S3 storage classes. Atlas Data Federation includes the files in\nthese storage classes in the query results.  Atlas Kubernetes Operator  accepts the\nfollowing values: STANDARD INTELLIGENT_TIERING STANDARD_IA Type : string Optional Human-readable label that identifies the  AWS (Amazon Web Services)  S3 bucket. This label\nmust exactly match the name of an S3 bucket that the federated database instance can\naccess with the configured  AWS (Amazon Web Services)   IAM (Identity and Access Management)  credentials. Type : string Optional The delimiter that separates\n spec.storage.databases.collections.dataSources.path \nsegments in the data store.  Atlas Kubernetes Operator  uses the delimiter to efficiently\ntraverse S3 buckets with a hierarchical directory structure. You can\nspecify any character supported by the S3 object keys as the\ndelimiter. For example, you can specify an underscore ( _ ) or a\nplus sign ( + ) or multiple characters, such as double underscores\n( __ ) as the delimiter. If omitted, defaults to  / . Type : boolean Optional Flag that indicates whether to use S3 tags on the files in the given\npath as additional partition attributes. If set to true,  Atlas Kubernetes Operator \nadds the S3 tags as additional partition attributes and adds new\ntop-level BSON elements associating each tag to each document. If\nomitted, defaults to  false . Type : string Optional Prefix that  Atlas Kubernetes Operator  applies when searching for files in the S3\nbucket. The data store prepends the value of prefix to the\n spec.storage.databases.collections.dataSources.path  to\ncreate the full path for files to ingest. If omitted,  Atlas Kubernetes Operator \nsearches all files from the root of the S3 bucket. Type : boolean Optional Flag that indicates whether the bucket is public. If set to  true ,\n Atlas Kubernetes Operator  doesn't use the configured  AWS (Amazon Web Services)   IAM (Identity and Access Management)  role to access the S3\nbucket. If set to  false , the configured  AWS (Amazon Web Services)   IAM (Identity and Access Management)  role must\ninclude permissions to access the S3 bucket. Type : string Optional AWS (Amazon Web Services)  region that indicates the physical location of the S3 bucket. Type : array Optional List that contains the  private endpoint  configurations for the federated database instance. Type : string Required Unique 22-character alphanumeric string starting with  vpce-  that\nidentifies the private endpoint in  AWS (Amazon Web Services) Type : string Optional Human-readable label that identifies the cloud service provider.\nAtlas Data Federation supports only  AWS . Type : string Optional Human-readable label that identifies the resource type associated\nwith this private endpoint. Atlas Data Federation supports only  DATA_LAKE . Type : string Required Name of the project to which the federated database instance belongs. You must specify\nan existing  AtlasProject  Custom Resource . Type : string Required Namespace in which the  AtlasProject  Custom Resource  specified in  spec.projectRef.name \nexists.",
            "code": [
                {
                    "lang": "",
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasDataFederation\nmetadata:\n  name: my-federated-deployment\nspec:\n  projectRef:\n    name: my-project\n    namespace: default\n  cloudProviderConfig:\n    aws:\n      roleId: 12345678\n      testS3Bucket: my-bucket\n  dataProcessRegion:\n    cloudProvider: AWS\n    region: OREGON_USA\n  name: my-fdi\n  storage:\n    databases:\n    - collections:\n      - dataSources:\n        - allowInsecure: false\n          collection: my-collection\n          collectionRegex:\n          database: my-database\n          databaseRegex:\n          defaultFormat: \".avro\"\n          path: /\n          provenanceFieldName: string\n          storeName: my-data-store\n          urls:\n          - string:\n        name: my-collection-mdb\n      maxWildcardCollections: 100\n      name: my-database-mdb\n      views:\n      - name: my-view\n        pipeline:\n        source: my-source-collection\n    stores:\n    - name: my-store\n      provider: S3\n      additionalStorageClasses:\n      - STANDARD\n      bucket: my-bucket\n      delimiter: /\n      includeTags: false\n      prefix: data-\n      public: false\n      region: US_WEST_1\n  privateEndpoints:\n  - endpointId: vpce-3bf78b0ddee411ba1\n    provider: AWS\n    type: DATA_LAKE\n  - endpointId: vpce-3bf78b0ddee411ba2\n    provider: AWS\n    type: DATA_LAKE\n"
                }
            ],
            "preview": "The AtlasDataFederation custom resource configures a\nfederated database instance in Atlas. When\nyou create the AtlasDataFederation custom resource, Atlas Kubernetes Operator tries\nto create or update a federated database instance in Atlas. You can use an federated database instance to\nrun federated queries.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "atlasbackuppolicy-custom-resource",
            "title": "AtlasBackupPolicy Custom Resource",
            "headings": [
                "Example",
                "Parameters"
            ],
            "paragraphs": "The  AtlasBackupPolicy  custom resource configures a backup policy\nthat applies to the  AtlasBackupSchedule  Custom Resource  that you\ncan apply to your  AtlasDeployment  Custom Resource . When you\ncreate the  AtlasBackupPolicy  custom resource,  Atlas Kubernetes Operator  tries to\ncreate or update a backup policy. Atlas Kubernetes Operator  does one of the following actions using the  Atlas \n Cloud Backup Schedule API Resource : If you remove the  AtlasBackupPolicy  resource from your  Kubernetes \ncluster,  Atlas  stops creating backups for your cluster. Atlas Kubernetes Operator  uses  custom resource  configuration\nfiles to manage your  Atlas  configuration, but as of  Atlas Kubernetes Operator  2.0,\ncustom resources you delete in  Kubernetes  are no longer deleted in\n Atlas . Instead,  Atlas Kubernetes Operator  simply stops managing those resources.\nFor example, if you delete an  AtlasProject  Custom Resource \nin  Kubernetes ,  Atlas Kubernetes Operator  no longer automatically deletes the corresponding project\nfrom  Atlas , preventing accidental or unexpected deletions. To learn more,\nincluding how to  revert this behavior  to\nthe default used prior to  Atlas Kubernetes Operator  2.0, see  New Default: Deletion Protection in  Atlas Kubernetes Operator  2.0 . Creates a new backup policy. Updates an existing backup policy. You must do all of the following tasks to back up a cluster: To learn more, see  Back Up Your  Atlas  Cluster . Create a backup policy. Create a\n backup schedule  and\nset the  spec.policy.name  field to the name of the\nconfigured backup policy. Set the  spec.backupRef.name  field in the\n AtlasDeployment  Custom Resource  to the name of the\nconfigured backup schedule. The following example shows an  AtlasBackupPolicy  custom resource\nthat is configured to take snapshots weekly and retain snapshots for\nseven days: This section describes some of the key  AtlasBackupPolicy  custom\nresource parameters available. For a full list of parameters available,\nsee the  Atlas \n Modify Cloud Backup Backup Policy API . Refer\nto these descriptions, the available examples, and the  API (Application Programming Interface) \ndocumentation to customize your specifications. Type : array Conditional List that contains the policy item parameters from the\n API (Application Programming Interface) . For a full list of parameters available, see the  Atlas \n Modify Cloud Backup Backup Policy API . Type : number Required Number that indicates the desired frequency of the new backup policy\nitem specified by  spec.items.frequencyType . A value of\n 1  specifies the first instance of the corresponding\n spec.items.frequencyType . This setting accepts the following frequency values: In a monthly policy item,  1  indicates that the monthly\nsnapshot occurs on the first day of the month. In a weekly policy item,  1  indicates that the weekly\nsnapshot occurs on Monday. Hourly:  1 ,  2 ,  4 ,  6 ,  8 , and  12 . Daily:  1 . Weekly:  1  through  7 , where  1  is Monday and  7  is\nSunday. Monthly:  1  through  28  and  40 , where  1  is the first\nday of the month and  40  is the last day of the month. Type : string Required String that indicates the frequency associated with the backup\npolicy item. Accepted values are:  hourly ,  daily ,  weekly ,\nor  monthly . You can't specify multiple  hourly  and  daily  backup policy\nitems. Type : string Required String that indicates the scope of the backup policy item. Together\nwith  spec.items.retentionValue , these settings define the\nlength of time to retain snapshots. Accepted values are:  days ,\n weeks , or  months . Type : string Required String that indicates the value to associate with\n spec.items.retentionUnit . Together with\n spec.items.retentionUnit , these settings define\nthe length of time to retain snapshots.",
            "code": [
                {
                    "lang": null,
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasBackupPolicy\nmetadata:\n  name: \"atlas-default-backuppolicy\"\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  items:\n    - frequencyType: \"weekly\"\n      frequencyInterval: 1\n      retentionUnit: \"days\"\n      retentionValue: 7"
                }
            ],
            "preview": "Type: array",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-private-link-dedicated",
            "title": "Manage Private Endpoints for Dedicated Clusters",
            "headings": [
                "Procedure",
                "Specify the spec.privateEndpoints parameter.",
                "Find the service names for your private endpoints.",
                "Use the AWS CLI to configure each private endpoint.",
                "Update the spec.privateEndpoints parameter.",
                "Check the status of your private endpoints using Atlas Kubernetes Operator.",
                "Retrieve the secret that Atlas Kubernetes Operator created to connect to the cluster.",
                "Specify the spec.privateEndpoints parameter.",
                "Disable private endpoint network policies.",
                "Find the service IDs and names for your private endpoints.",
                "Use the Azure CLI to configure each private endpoint.",
                "Update the spec.privateEndpoints parameter.",
                "Check the status of your private endpoints using Atlas Kubernetes Operator.",
                "Retrieve the secret that Atlas Kubernetes Operator created to connect to the cluster.",
                "Specify the spec.privateEndpoints parameter.",
                "Find the {unique-ID} for your private endpoints.",
                "Configure your private endpoints.",
                "Update the spec.privateEndpoints parameter.",
                "Check the status of your private endpoints using Atlas Kubernetes Operator.",
                "Retrieve the secret that Atlas Kubernetes Operator created to connect to the cluster."
            ],
            "paragraphs": "Atlas Kubernetes Operator  supports managing private endpoints for dedicated clusters\non the following platforms: Before you begin, see  Manage Private Endpoints . This feature is not available for  M0  free clusters,  M2 , and\n M5  clusters. To learn more about which features are unavailable,\nsee  Atlas M0 (Free Cluster), M2, and M5 Limits . AWS (Amazon Web Services)  using the  AWS PrivateLink \nfeature. Azure (Microsoft Azure)  using the  Azure Private Link \nfeature. Google Cloud  using the  Private Service Connect \nfeature. To enable clients to connect to  Atlas  dedicated clusters using\nprivate endpoints: Specify the  spec.privateEndpoints  parameter for\nthe  AtlasProject  Custom Resource . In the\n spec.privateEndpoints.provider  field, specify\n AWS . Replace the placeholder  {aws-region}  with the\n AWS region  information for\nyour private endpoints and run the following command: Atlas  creates the  VPC (Virtual Private Cloud)  resources in the region you\nselected. This might take several minutes to\ncomplete. Run the following command: Note the service name string for each private endpoint\nwithin the  status.privateEndpoints.serviceName \nfield of the  AtlasProject  Custom Resource . To create your application  VPC (Virtual Private Cloud)   interface endpoint : To learn more, see  Creating an Interface Endpoint  in the  AWS (Amazon Web Services) \ndocumentation. Copy the following command: Replace the following placeholders with the details\nabout your  AWS (Amazon Web Services)   VPC (Virtual Private Cloud) : your-application-vpc-id Unique string that identifies the peer  AWS (Amazon Web Services) \n VPC (Virtual Private Cloud) . Find this value on the  VPC (Virtual Private Cloud)  dashboard in\nyour  AWS (Amazon Web Services)  account. aws-region Label that identifies the  AWS region  of the private endpoint. service-name-string Unique string that identifies the service name\nfor your private endpoint. Find this value within\nthe  status.privateEndpoints.serviceName \nfield of the  AtlasProject  Custom Resource . your-application-subnet-ids Unique strings that identify the subnets your\n AWS (Amazon Web Services)   VPC (Virtual Private Cloud)  uses. Separate each subnet with a\nspace. Find these values on the\n Subnet   dashboard in your  AWS (Amazon Web Services) \naccount. You must specify at least one subnet. If you\ndon't,  AWS (Amazon Web Services)  won't provision a\n interface endpoint  in your  VPC (Virtual Private Cloud) . An\ninterface endpoint is required for clients\nin your  VPC (Virtual Private Cloud)  to send traffic to the private\nendpoint. Run the command with the  AWS CLI . Note the  VpcEndpointId  value in the output. Example Update the  spec.privateEndpoints  parameter for\nthe  AtlasProject  Custom Resource . Specify the\n AWS region  and replace  vpce-id  with\nthe  VpcEndpointId  values for your private endpoints and\nrun the following command: You can find the unique identifier of the peer\n AWS (Amazon Web Services)   VPC (Virtual Private Cloud)  on the  VPC (Virtual Private Cloud)  dashboard in your  AWS (Amazon Web Services)  account. Run the following command: Copy the following command: The following command requires  jq  1.6 or higher. Replace the following placeholders with the details for your\ncustom resources: my-project Specify the value of the  metadata  field of your\n AtlasProject  Custom Resource . my-atlas-cluster Specify the value of the  metadata  field of your\n AtlasDeployment  Custom Resource . my-database-user Specify the value of the  metadata  field of your\n AtlasDatabaseUser  Custom Resource . Run the command. You can use this  secret  in your application: Your connection strings will differ from the following example.\nIf you have multiple private endpoints, the secret contains\nmultiple  connectionStringPrivate  and\n connectionStringPrivateSvr  fields with the appropriate\nnumeric suffix (for example,  connectionStringPrivate1 ,\n connectionStringPrivate2 , and so on). Specify the  spec.privateEndpoints  parameter for\nthe  AtlasProject  Custom Resource . In the\n spec.privateEndpoints.provider  field, specify\n AZURE . Replace the placeholder  {azure-region}  with\nthe  Azure region \ninformation for your private endpoints and run the\nfollowing command: Atlas  creates the VNET resources in the region you\nselected. This might take several minutes to\ncomplete. Atlas  doesn't support network policies for private\nendpoints. To learn more, see the\n Manage network policies for private endpoints \nin the  Azure (Microsoft Azure)  documentation. Copy the following command: Replace the following placeholders with the details\nabout your  Azure (Microsoft Azure)  VNet: resource-group-name Human-readable label for the resource group that\ncontains the VNet that you want to use to connect\nto  Atlas . Find this value on the\n Resource Group Properties  page on your\n Azure (Microsoft Azure)  dashboard. vnet-name Human-readable label that identifies the VNet\nthat you want to use to connect to  Atlas .\nFind this value on the  Virtual\nNetwork  page on your  Azure (Microsoft Azure)  dashboard. subnet-name Human-readable label that identifies the subnet\nin your  Azure (Microsoft Azure)  VNet. Find this value on the\n Virtual Network Subnets  page on your\n Azure (Microsoft Azure)  dashboard. Run the command with the  Azure CLI . Run the following command: Note the service resouce ID and service name for each\nprivate endpoint within the\n status.privateEndpoints.serviceResourceId \nand  status.privateEndpoints.serviceName \nfields of the  AtlasProject  Custom Resource . To create your private endpoint: Copy the following command: Replace the following placeholders with the details\nabout your  Azure (Microsoft Azure)  VNet: resource-group-name Human-readable label for the resource group that\ncontains the VNet that you want to use to connect\nto  Atlas . Find this value on the\n Resource Group Properties  page on your\n Azure (Microsoft Azure)  dashboard. endpoint-name Human-readable label that identifies your private\nendpoint. Specify this now. vnet-name Human-readable label that identifies the VNet\nthat you want to use to connect to  Atlas .\nFind this value on the  Virtual\nNetwork  page on your  Azure (Microsoft Azure)  dashboard. subnet-name Human-readable label that identifies the subnet\nin your  Azure (Microsoft Azure)  VNet. Find this value on the\n Virtual Network Subnets  page on your\n Azure (Microsoft Azure)  dashboard. serviceResourceId Unique string that identifies the service\nresource for your private endpoint. Find this\nvalue within the\n status.privateEndpoints.serviceResourceId \nfield of the  AtlasProject  Custom Resource . serviceName Unique string that identifies the service name\nfor your private endpoint. Find this\nvalue within the\n status.privateEndpoints.serviceName \nfield of the  AtlasProject  Custom Resource . Run the command with the  Azure CLI . Update the  spec.privateEndpoints  parameter for\nthe  AtlasProject  Custom Resource . Specify the\nthe  Azure region , Resource ID, and\nIP address information for your private endpoints and run\nthe following command: The  Properties  page on your  Azure (Microsoft Azure) \ndashboard displays the unique identifier for the\nprivate endpoint that you created in the\n Resource ID  field. The  Overview  page on your  Azure (Microsoft Azure) \ndashboard displays the private IP address of the private\nendpoint network interface that you created in the\n Private IP  field. Run the following command: Copy the following command: The following command requires  jq  1.6 or higher. Replace the following placeholders with the details for your\ncustom resources: my-project Specify the value of the  metadata  field of your\n AtlasProject  Custom Resource . my-atlas-cluster Specify the value of the  metadata  field of your\n AtlasDeployment  Custom Resource . my-database-user Specify the value of the  metadata  field of your\n AtlasDatabaseUser  Custom Resource . Run the command. You can use this  secret  in your application: Your connection strings will differ from the following example.\nIf you have multiple private endpoints, the secret contains\nmultiple  connectionStringPrivate  and\n connectionStringPrivateSvr  fields with the appropriate\nnumeric suffix (for example,  connectionStringPrivate1 ,\n connectionStringPrivate2 , and so on). Specify the  spec.privateEndpoints  parameter for\nthe  AtlasProject  Custom Resource . In the\n spec.privateEndpoints.provider  field, specify\n GCP . Replace the placeholder  {gcp-region} \nwith the  Google Cloud Platform region \ninformation for your private endpoints and run the\nfollowing command: Atlas  creates the  VPC (Virtual Private Cloud)  resources in the region you\nselected. This might take several minutes to complete. Run the following command: Note the  {unique-id}  that follows  projects/ \nin each service attachment name. The  {unique-id}  in\nthe following example is  p-ogyvk1plka2anycnzl6znr9p . Example To edit the private endpoints and generate the necessary\nscript with the Atlas UI, see\n Configure Private Endpoints . To configure your private endpoints manually: Copy the following shell script: Replace the following placeholders with the details\nabout your  Google Cloud   VPC (Virtual Private Cloud) : google-cloud-project-id Unique ID that identifies your  Google Cloud  project.\nFind this value on the  Dashboard \npage on your  Google Cloud  platform. private-service-connect-endpoint-prefix Human-readable label that prefixes all endpoints\ncreated and identifies the endpoint group. gcp-region Label that identifies the\n Google Cloud Platform region  of the private endpoint. subnet-name Human-readable label that identifies the subnet\nin your  Google Cloud   VPC (Virtual Private Cloud) . Find this value on the\n VPC Networks  page on your  Google Cloud \ndashboard. vpc-name Human-readablle label that identifies the  VPC (Virtual Private Cloud) \nthat you want to use to connect to  Atlas .\nFind this value on the  VPC Networks \npage on your  Google Cloud  dashboard. unique-id Unique string that you noted when you returned\nthe project status. org-id Unique 24-digit hexadecimal string that\nidentifies the  Atlas   organization . Save the shell file as  setup_psc.sh  and run the\nscript from the directory where you saved the file with\nthe following command: The script creates an\n atlasEndpoints-{endpoint-name}.json  output file that\ncontains a list of IP addresses and forwarding rule\nnames. Run the following commands to format the output for\n Atlas Kubernetes Operator : The output shoud resemble the following example: Update the  spec.privateEndpoints  parameter for\nthe  AtlasProject  Custom Resource . Specify the\n Google Cloud Platform region ,  Google Cloud Project ID ,\n Private Service Endpoint Prefix , your output\ninformation, and run the following command: Run the following command: Copy the following command: The following command requires  jq  1.6 or higher. Replace the following placeholders with the details for your\ncustom resources: my-project Specify the value of the  metadata  field of your\n AtlasProject  Custom Resource . my-atlas-cluster Specify the value of the  metadata  field of your\n AtlasDeployment  Custom Resource . my-database-user Specify the value of the  metadata  field of your\n AtlasDatabaseUser  Custom Resource . Run the command. You can use this  secret  in your application: Your connection strings will differ from the following example.\nIf you have multiple private endpoints, the secret contains\nmultiple  connectionStringPrivate  and\n connectionStringPrivateSvr  fields with the appropriate\nnumeric suffix (for example,  connectionStringPrivate1 ,\n connectionStringPrivate2 , and so on).",
            "code": [
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: Test Atlas Operator Project\n  privateEndpoints:\n  - provider: \"AWS\"\n    region: \"{aws-region}\"\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasproject my-project -o yaml"
                },
                {
                    "lang": "sh",
                    "value": "aws ec2 create-vpc-endpoint --vpc-id {your-application-vpc-id} --region {aws-region} --service-name {service-name-string} --vpc-endpoint-type Interface --subnet-ids {your-application-subnet-ids}"
                },
                {
                    "lang": "sh",
                    "value": "\"VpcEndpoint\": {\n         \"VpcEndpointId\": \"vpce-XXXXXX\",\n         \"VpcEndpointType\": \"Interface\",\n         \"VpcId\": \"vpc-XXXXX\",\n         \"ServiceName\": \"com.amazonaws.vpce.{aws-region}.vpce-svc-XXXX\",\n         \"State\": \"pendingAcceptance\","
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: Test Atlas Operator Project\n  privateEndpoints:\n  - provider: \"AWS\"\n    region: \"{aws-region}\"\n    id: \"{vpce-id}\"\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasproject my-project -o yaml"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get secret {my-project}-{my-atlas-cluster}-{my-database-user} -o json | jq -r '.data | with_entries(.value |= @base64d)';"
                },
                {
                    "lang": "sh",
                    "value": "{\n  \"connectionStringPrivate\": \"mongodb://pl-0-eastus2.uzgh6.mongodb.net:1024,pl-0-eastus2.uzgh6.mongodb.net:1025,pl-0-eastus2.uzgh6.mongodb.net:1026/?ssl=truereplicaSet=atlas-18bndf-shard-0\",\n  \"connectionStringPrivateSrv\": \"mongodb+srv://cluster0-pl-0.uzgh6.mongodb.net\",\n  \"password\": \"P@@sword%\",\n  \"username\": \"theuser\"\n }"
                },
                {
                    "lang": "sh",
                    "value": "containers:\n  - name: test-app\n    env:\n    - name: \"CONNECTION_STRING\"\n      valueFrom:\n        secretKeyRef:\n          name: my-project-my-atlas-cluster-my-database-user\n          key: connectionStringPrivate"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: Test Atlas Operator Project\n  privateEndpoints:\n  - provider: \"AZURE\"\n    region: \"{azure-region}\"\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "az network vnet subnet update --resource-group {resource-group-name} --vnet-name {vnet-name} --name {subnet-name} --disable-private-endpoint-network-policies true"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasproject my-project -o yaml"
                },
                {
                    "lang": "sh",
                    "value": "az network private-endpoint create --resource-group {resource-group-name} --name {endpoint-name} --vnet-name {vnet-name} --subnet {subnet-name} --private-connection-resource-id {serviceResourceId} --connection-name {serviceName} --manual-request true"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: Test Atlas Operator Project\n  privateEndpoints:\n  - provider: \"Azure\"\n    region: \"{azure-region}\"\n    id: \"{resource-id}\"\n    ip: \"{private-ip}\"\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasproject my-project -o yaml"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get secret {my-project}-{my-atlas-cluster}-{my-database-user} -o json | jq -r '.data | with_entries(.value |= @base64d)';"
                },
                {
                    "lang": "sh",
                    "value": "{\n  \"connectionStringPrivate\": \"mongodb://pl-0-eastus2.uzgh6.mongodb.net:1024,pl-0-eastus2.uzgh6.mongodb.net:1025,pl-0-eastus2.uzgh6.mongodb.net:1026/?ssl=truereplicaSet=atlas-18bndf-shard-0\",\n  \"connectionStringPrivateSrv\": \"mongodb+srv://cluster0-pl-0.uzgh6.mongodb.net\",\n  \"password\": \"P@@sword%\",\n  \"username\": \"theuser\"\n }"
                },
                {
                    "lang": "sh",
                    "value": "containers:\n  - name: test-app\n    env:\n    - name: \"CONNECTION_STRING\"\n      valueFrom:\n        secretKeyRef:\n          name: my-project-my-atlas-cluster-my-database-user\n          key: connectionStringPrivate"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: Test Atlas Operator Project\n  privateEndpoints:\n  - provider: \"GCP\"\n    region: \"{gcp-region}\"\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasproject my-project -o yaml"
                },
                {
                    "lang": "sh",
                    "value": "\"serviceAttachmentNames\": [\n  \"projects/p-ogyvk1plka2anycnzl6znr9p/regions/us-east1/serviceAttachments/sa-us-east1-6274f45bcce0e51662a29b05-0\",\n  \"projects/p-ogyvk1plka2anycnzl6znr9p/regions/us-east1/serviceAttachments/sa-us-east1-6274f45bcce0e51662a29b05-1\",\n  \"projects/p-ogyvk1plka2anycnzl6znr9p/regions/us-east1/serviceAttachments/sa-us-east1-6274f45bcce0e51662a29b05-2\",\n  \"projects/p-ogyvk1plka2anycnzl6znr9p/regions/us-east1/serviceAttachments/sa-us-east1-6274f45bcce0e51662a29b05-3\",\n  \"projects/p-ogyvk1plka2anycnzl6znr9p/regions/us-east1/serviceAttachments/sa-us-east1-6274f45bcce0e51662a29b05-4\",\n  \"projects/p-ogyvk1plka2anycnzl6znr9p/regions/us-east1/serviceAttachments/sa-us-east1-6274f45bcce0e51662a29b05-5\"\n]"
                },
                {
                    "lang": "sh",
                    "value": "#!/bin/bash\ngcloud config set project {google-cloud-project-id}\n\nfor i in {0..5}\ndo\n  gcloud compute addresses create {private-service-connect-endpoint-prefix}-ip-$i --region={gcp-region} --subnet={subnet-name}\ndone\n\nfor i in {0..5}\ndo\n  if [ $(gcloud compute addresses describe {private-service-connect-endpoint-prefix}-ip-$i --region={gcp-region} --format=\"value(status)\") != \"RESERVED\" ]; then\n    echo \"{private-service-connect-endpoint-prefix}-ip-$i is not RESERVED\";\n  exit 1;\n  fi\ndone\n\nfor i in {0..5}\ndo\n  gcloud compute forwarding-rules create {private-service-connect-endpoint-prefix}-$i --region={gcp-region} --network={vpc-name} --address={private-service-connect-endpoint-prefix}-ip-$i --target-service-attachment=projects/{unique-ID}/regions/{gcp-region}/serviceAttachments/sa-{gcp-region}-{org-id}-$i\ndone\n\nif [ $(gcloud compute forwarding-rules list --regions={gcp-region} --format=\"csv[no-heading](name)\" --filter=\"name:{private-service-connect-endpoint-prefix}\" | wc -l) -gt 50 ]; then\n  echo \"Project has too many forwarding rules that match prefix {endpoint-name}. Either delete the competing resources or choose another endpoint prefix.\"\n  exit 2;\nfi\n\ngcloud compute forwarding-rules list --regions={gcp-region} --format=\"json(IPAddress,name)\" --filter=\"name:{private-service-connect-endpoint-prefix}\" > atlasEndpoints-{endpoint-name}.json"
                },
                {
                    "lang": "sh",
                    "value": "sh setup_psc.sh"
                },
                {
                    "lang": "sh",
                    "value": "yq e -P atlasEndpoints-{endpoint-name}.json > atlasEndpoints-user-private-endpoint.yaml"
                },
                {
                    "lang": "sh",
                    "value": "awk 'sub(\"name\",\"endpointName\")sub(\"IPAddress\",\"ipAddress\")' atlasEndpoints-user-private-endpoint.yaml"
                },
                {
                    "lang": "sh",
                    "value": "- ipAddress: 10.0.0.00\n  endpointName: {endpoint-name}-0\n- ipAddress: 10.0.0.01\n  endpointName: {endpoint-name}-1\n- ipAddress: 10.0.0.02\n  endpointName: {endpoint-name}-2\n- ipAddress: 10.0.0.03\n  endpointName: {endpoint-name}-3\n- ipAddress: 10.0.0.04\n  endpointName: {endpoint-name}-4\n- ipAddress: 10.0.0.05\n  endpointName: {endpoint-name}-5"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: Test Atlas Operator Project\n  privateEndpoints:\n  - provider: \"GCP\"\n    region: \"{gcp-region}\"\n    gcpProjectId: \"{project-id}\"\n    endpointGroupName: \"{endpoint-name}\"\n    endpoints:\n    - ipAddress: {ip-address}\n      endpointName: {endpoint-name}-0\n    - ipAddress: {ip-address}\n      endpointName: {endpoint-name}-1\n    - ipAddress: {ip-address}\n      endpointName: {endpoint-name}-2\n    - ipAddress: {ip-address}\n      endpointName: {endpoint-name}-3\n    - ipAddress: {ip-address}\n      endpointName: {endpoint-name}-4\n    - ipAddress: {ip-address}\n      endpointName: {endpoint-name}-5\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasproject my-project -o yaml"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get secret {my-project}-{my-atlas-cluster}-{my-database-user} -o json | jq -r '.data | with_entries(.value |= @base64d)';"
                },
                {
                    "lang": "sh",
                    "value": "{\n  \"connectionStringPrivate\": \"mongodb://pl-0-eastus2.uzgh6.mongodb.net:1024,pl-0-eastus2.uzgh6.mongodb.net:1025,pl-0-eastus2.uzgh6.mongodb.net:1026/?ssl=truereplicaSet=atlas-18bndf-shard-0\",\n  \"connectionStringPrivateSrv\": \"mongodb+srv://cluster0-pl-0.uzgh6.mongodb.net\",\n  \"password\": \"P@@sword%\",\n  \"username\": \"theuser\"\n }"
                },
                {
                    "lang": "sh",
                    "value": "containers:\n  - name: test-app\n    env:\n    - name: \"CONNECTION_STRING\"\n      valueFrom:\n        secretKeyRef:\n          name: my-project-my-atlas-cluster-my-database-user\n          key: connectionStringPrivate"
                }
            ],
            "preview": "Atlas Kubernetes Operator supports managing private endpoints for dedicated clusters\non the following platforms:",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-configure-custom-database-roles",
            "title": "Configure Custom Database Roles",
            "headings": [
                "Create or Update a Custom Database Role"
            ],
            "paragraphs": "You can create custom roles in  Atlas  when the\n built-in roles  don't include your\ndesired set of privileges.  Atlas  applies each database user's custom\nroles together with: You can assign multiple custom roles to each database user. Any  built-in roles  you\nassign when you  add a database user  or\n modify a database user . Any  specific privileges  you\nassign when you  add a database user  or\n modify a database user . Changes to  custom roles \nmight take up to 30 seconds to deploy in  M0  free clusters,\n M2/M5  shared clusters, and serverless instances. To create or update a custom database role, specify the\n spec.customRoles  parameters in the\n AtlasProject  Custom Resource . Example To learn more about the configuration parameters available from the\n API (Application Programming Interface) , see the  Atlas   Custom Database Roles API .",
            "code": [
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: Test Atlas Operator Project\n  connectionSecretRef:\n    name: my-atlas-key\n  customRoles:\n    - name: \"my-role\"\n      actions:\n        - name: \"my-action\"\n          resources:\n            - cluster: false\n              collection: \"my-collection\"\n              database: \"my-database\"\n      inheritedRoles:\n        - name: \"clusterMonitor\"\n          database: \"my-database\"\nEOF"
                }
            ],
            "preview": "To create or update a custom database role, specify the\nspec.customRoles parameters in the\nAtlasProject Custom Resource.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-private-link",
            "title": "Manage Private Endpoints",
            "headings": [
                "Prerequisites",
                "Procedure"
            ],
            "paragraphs": "Atlas Kubernetes Operator  supports private endpoints to connect to\ndedicated clusters, serverless instances, and federated database instances. When you use  Atlas Kubernetes Operator  to configure private links in  Atlas ,  Atlas \ncreates its own  VPC (Virtual Private Cloud)  or a Private Link service and places\ndedicated clusters or serverless instances within a region\nbehind a load balancer in the  Atlas   VPC (Virtual Private Cloud)  or  Atlas  VNet. To\nlearn more, see the  Private Endpoint Overview . To manage your private endpoints with  Atlas Kubernetes Operator , you can specify and\nupdate one of the following parameters: Each time you change the  spec  field in any of the supported custom\nresources,  Atlas Kubernetes Operator   creates or updates  the corresponding  Atlas \nconfiguration. Certain considerations and limitations apply to private endpoints. To\nlearn more, see  Configure Private Endpoints . This feature is not available for  M0  free clusters,  M2 , and\n M5  clusters. To learn more about which features are unavailable,\nsee  Atlas M0 (Free Cluster), M2, and M5 Limits . For dedicated clusters, specify the\n spec.privateEndpoints  parameter for the\n AtlasProject  Custom Resource . For serverless instances, specify the\n spec.serverlessSpec.privateEndpoints  parameter for the\n AtlasDeployment  Custom Resource . For federated database instances, specify the\n spec.privateEndpoints \nparameter for the  AtlasDataFederation  Custom Resource . To enable connections with  Atlas Kubernetes Operator  to  Atlas  using private\nendpoints, you must: Have a running  Kubernetes  cluster with  Atlas Kubernetes Operator   deployed . Have either the  Project Owner  or\n Organization Owner  role in  Atlas . Have an  AWS (Amazon Web Services)  user account with an  IAM (Identity and Access Management)  user policy that\ngrants permissions to create, modify, describe, and delete\nendpoints. For more information on controlling the use of\ninterface endpoints, see the  AWS Documentation . (Recommended) :\n Install the AWS CLI . If you have not already done so, create your  VPC (Virtual Private Cloud)  and EC2\ninstances in  AWS (Amazon Web Services) . See the  AWS documentation  for guidance. Have running  Kubernetes  cluster with  Atlas Kubernetes Operator   deployed . Have either the  Project Owner  or\n Organization Owner  role in  Atlas . Install the  Azure CLI . If you have not already done so, create your VNet and\nCompute instances in  Azure (Microsoft Azure) . See the\n Azure documentation  for guidance. Have a running  Kubernetes  cluster with  Atlas Kubernetes Operator   deployed . Have the  Project Owner  or\n Organization Owner  role in  Atlas . Have a  Google Cloud  user account with an  IAM (Identity and Access Management)  user policy and\na  Compute Network Admin \nrole that grants permissions to create, modify, and\ndelete networking resources. To learn more about\nmanaging private endpoints and connections, see the\n Google Cloud documentation . Install  the gcloud CLI . If you have not already done so, create your  VPC (Virtual Private Cloud)  and\nCompute instances in  Google Cloud . To learn more, see the\n GCP documentation . Ensure egress firewall rules permit traffic to the\ninternal IP address of the Private Service Connect endpoint. (Optional) If you enforce a security perimeter with\n VPC (Virtual Private Cloud)  service controls (VPC-SC), you must create ingress\nand egress rules to establish the connection between the\nPrivate Service Connect endpoint and  Atlas  clusters. To\nlearn more, see the  GCP documentation . Have A running  Kubernetes  cluster with  Atlas Kubernetes Operator   deployed . Have either the  Project Owner  or\n Organization Owner  role in  Atlas . Have an  AWS (Amazon Web Services)  user account with an  IAM (Identity and Access Management)  user policy that\ngrants permissions to create, modify, describe, and delete\nendpoints. For more information on controlling the use of\ninterface endpoints, see the  AWS Documentation . (Recommended) :\n Install the AWS CLI . If you have not already done so, create your  VPC (Virtual Private Cloud)  and EC2\ninstances in  AWS (Amazon Web Services) . See the  AWS documentation  for guidance. Have a running  Kubernetes  cluster with  Atlas Kubernetes Operator   deployed . Have either the  Project Owner  or\n Organization Owner  role in  Atlas . Install the  Azure CLI . If you have not already done so, create your VNet and\nCompute instances in  Azure (Microsoft Azure) . See the\n Azure documentation  for guidance. Deploy   Atlas Kubernetes Operator  on a running\n Kubernetes  cluster. Have either the  Project Owner  or\n Organization Owner  role in  Atlas . Have an  AWS (Amazon Web Services)  user account with an  IAM (Identity and Access Management)  user policy that\ngrants permissions to create, modify, describe, and delete\nendpoints. For more information on controlling the use of\ninterface endpoints, see the  AWS Documentation . (Recommended) :\n Install the AWS CLI . If you have not already done so, create your  VPC (Virtual Private Cloud)  and EC2\ninstances in  AWS (Amazon Web Services) . See the  AWS documentation  for guidance. To enable clients to connect to  Atlas  dedicated clusters or\nserverless instances using private endpoints, see the following\nprocedures: Manage Private Endpoints for Dedicated Clusters Manage Private Endpoints for Serverless Instances Manage Private Endpoints for an Federated Database Instance",
            "code": [],
            "preview": "Atlas Kubernetes Operator supports private endpoints to connect to\ndedicated clusters, serverless instances, and federated database instances.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-private-link-serverless",
            "title": "Manage Private Endpoints for Serverless Instances",
            "headings": [
                "Procedure",
                "Specify the spec.serverlessSpec.privateEndpoints parameter.",
                "Find the service names for your private endpoints.",
                "Use the AWS CLI to configure each private endpoint.",
                "Update the spec.serverlessSpec.privateEndpoints parameter.",
                "Check the status of your private endpoints using Atlas Kubernetes Operator.",
                "Retrieve the secret that Atlas Kubernetes Operator created to connect to the cluster.",
                "Specify the spec.serverlessSpec.privateEndpoints parameter.",
                "Disable private endpoint network policies.",
                "Find the service IDs and names for your private endpoints.",
                "Use the Azure CLI to configure each private endpoint.",
                "Update the spec.serverlessPrivateEndpoints parameter.",
                "Check the status of your private endpoints using Atlas Kubernetes Operator.",
                "Retrieve the secret that Atlas Kubernetes Operator created to connect to the cluster."
            ],
            "paragraphs": "Atlas Kubernetes Operator  supports managing private endpoints for\nserverless instances on the following platforms: Before you begin, see  Manage Private Endpoints . AWS (Amazon Web Services)  using the  AWS PrivateLink \nfeature. Azure (Microsoft Azure)  using the  Azure Private Link \nfeature. Serverless instances don't support Private Service Connect. If\nyou need to set up Private Service Connect, use a\n dedicated cluster . MongoDB plans to add support for more configurations and\ncapabilities on serverless instances over time. To learn which\nfeatures MongoDB plans to support for serverless instances in\nthe future, see  Serverless Instance Limits . To enable clients to connect to  Atlas  serverless instances\nusing private endpoints: Specify the  spec.serverlessSpec.privateEndpoints \nparameter for the  AtlasDeployment  Custom Resource .\nIn the  spec.serverlessSpec.privateEndpoints.name \nfield, specify a unique label to identify the private\nendpoint and run the following command: Atlas  creates the  VPC (Virtual Private Cloud)  resources. This might take\nseveral minutes to complete. Run the following command: Note the service name string for each private endpoint\nwithin the\n status.serverlessPrivateEndpoints.EndpointServiceName \nfield of the  AtlasDeployment  Custom Resource . To create your application  VPC (Virtual Private Cloud)   interface endpoint : To learn more, see  Creating an Interface Endpoint  in the  AWS (Amazon Web Services) \ndocumentation. Copy the following command: Replace the following placeholders with the details\nabout your  AWS (Amazon Web Services)   VPC (Virtual Private Cloud) : your-application-vpc-id Unique string that identifies the peer  AWS (Amazon Web Services) \n VPC (Virtual Private Cloud) . Find this value on the  VPC (Virtual Private Cloud)  dashboard in\nyour  AWS (Amazon Web Services)  account. aws-region Label that identifies the  AWS region  of the private endpoint. service-name-string Unique string that identifies the service name\nfor your private endpoint. Find this value within\nthe\n status.serverlessPrivateEndpoints.EndpointServiceName \nfield of the  AtlasDeployment  Custom Resource . your-application-subnet-ids Unique strings that identify the subnets your\n AWS (Amazon Web Services)   VPC (Virtual Private Cloud)  uses. Separate each subnet with a\nspace. Find these values on the\n Subnet   dashboard in your  AWS (Amazon Web Services) \naccount. You must specify at least one subnet. If you\ndon't,  AWS (Amazon Web Services)  won't provision a\n interface endpoint  in your  VPC (Virtual Private Cloud) . An\ninterface endpoint is required for clients\nin your  VPC (Virtual Private Cloud)  to send traffic to the private\nendpoint. Run the command with the  AWS CLI . Note the  VpcEndpointId  value in the output. Example Update the  spec.serverlessSpec.privateEndpoints \nparameter for the  AtlasDeployment  Custom Resource .\nReplace the  vpce-id  with the  VpcEndpointId  values\nfor your private endpoints and run the following command: You can find the unique identifier of the peer\n AWS (Amazon Web Services)   VPC (Virtual Private Cloud)  on the  VPC (Virtual Private Cloud)  dashboard in your  AWS (Amazon Web Services)  account. Run the following command: Copy the following command: The following command requires  jq  1.6 or higher. Replace the following placeholders with the details for your\ncustom resources: my-project Specify the value of the  metadata  field of your\n AtlasProject  Custom Resource . my-atlas-cluster Specify the value of the  metadata  field of your\n AtlasDeployment  Custom Resource . my-database-user Specify the value of the  metadata  field of your\n AtlasDatabaseUser  Custom Resource . Run the command. You can use this  secret  in your application: Your connection strings will differ from the following example.\nIf you have multiple private endpoints, the secret contains\nmultiple  connectionStringPrivate  and\n connectionStringPrivateSvr  fields with the appropriate\nnumeric suffix (for example,  connectionStringPrivate1 ,\n connectionStringPrivate2 , and so on). Specify the  spec.serverlessSpec.privateEndpoints \nparameter for the  AtlasDeployment  Custom Resource .\nIn the  spec.serverlessSpec.privateEndpoints.name \nfield, specify a unique label to identify the private\nendpoint and run the following command: Atlas  creates the VNET resources. This might take\nseveral minutes to complete. Atlas  doesn't support network policies for private\nendpoints. To learn more, see the\n Manage network policies for private endpoints \nin the  Azure (Microsoft Azure)  documentation. Copy the following command: Replace the following placeholders with the details\nabout your  Azure (Microsoft Azure)  VNet: resource-group-name Human-readable label for the resource group that\ncontains the VNet that you want to use to connect\nto  Atlas . Find this value on the\n Resource Group Properties  page on your\n Azure (Microsoft Azure)  dashboard. vnet-name Human-readable label that identifies the VNet\nthat you want to use to connect to  Atlas .\nFind this value on the  Virtual\nNetwork  page on your  Azure (Microsoft Azure)  dashboard. subnet-name Human-readable label that identifies the subnet\nin your  Azure (Microsoft Azure)  VNet. Find this value on the\n Virtual Network Subnets  page on your\n Azure (Microsoft Azure)  dashboard. Run the command with the  Azure CLI . Run the following command: Note the service resouce ID and service name for each\nprivate endpoint within the\n status.serverlessPrivateEndpoints.PrivateLinkServiceResourceId \nand  status.serverlessPrivateEndpoints.EndpointServiceName \nfields of the  AtlasDeployment  Custom Resource . To create your private endpoint: Copy the following command: Replace the following placeholders with the details\nabout your  Azure (Microsoft Azure)  VNet: resource-group-name Human-readable label for the resource group that\ncontains the VNet that you want to use to connect\nto  Atlas . Find this value on the\n Resource Group Properties  page on your\n Azure (Microsoft Azure)  dashboard. endpoint-name Human-readable label that identifies your private\nendpoint. Specify this now. vnet-name Human-readable label that identifies the VNet\nthat you want to use to connect to  Atlas .\nFind this value on the  Virtual\nNetwork  page on your  Azure (Microsoft Azure)  dashboard. subnet-name Human-readable label that identifies the subnet\nin your  Azure (Microsoft Azure)  VNet. Find this value on the\n Virtual Network Subnets  page on your\n Azure (Microsoft Azure)  dashboard. serviceResourceId Unique string that identifies the service\nresource for your private endpoint. Find this\nvalue within the\n status.serverlessPrivateEndpoints.PrivateLinkServiceResourceId \nfield of the\n AtlasDeployment  Custom Resource . serviceName Unique string that identifies the service name\nfor your private endpoint. Find this\nvalue within the\n status.serverlessPrivateEndpoints.EndpointServiceName \nfield of the\n AtlasDeployment  Custom Resource . Run the command with the  Azure CLI . Update the  spec.serverlessSpec.privateEndpoints \nparameter for the  AtlasDeployment  Custom Resource .\nSpecify the Resource ID and IP address information for\nyour private endpoints and run the following command: The  Properties  page on your  Azure (Microsoft Azure) \ndashboard displays the unique identifier for the\nprivate endpoint that you created in the\n Resource ID  field. The  Overview  page on your  Azure (Microsoft Azure) \ndashboard displays the private IP address of the private\nendpoint network interface that you created in the\n Private IP  field. Run the following command: Copy the following command: The following command requires  jq  1.6 or higher. Replace the following placeholders with the details for your\ncustom resources: my-project Specify the value of the  metadata  field of your\n AtlasProject  Custom Resource . my-atlas-cluster Specify the value of the  metadata  field of your\n AtlasDeployment  Custom Resource . my-database-user Specify the value of the  metadata  field of your\n AtlasDatabaseUser  Custom Resource . Run the command. You can use this  secret  in your application: Your connection strings will differ from the following example.\nIf you have multiple private endpoints, the secret contains\nmultiple  connectionStringPrivate  and\n connectionStringPrivateSvr  fields with the appropriate\nnumeric suffix (for example,  connectionStringPrivate1 ,\n connectionStringPrivate2 , and so on).",
            "code": [
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: atlas-deployment-serverless\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  projectRef:\n    name: my-project\n  serverlessSpec:\n    name: serverless-instance\n    tags:\n    - key: \"environment\",\n      value: \"production\"\n    providerSettings:\n      providerName: SERVERLESS\n      backingProviderName: AWS\n      regionName: US_EAST_1\n    privateEndpoints:\n    - name: \"{unique-private-endpoint-label}\"\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasdeployment atlas-deployment-serverless -o yaml"
                },
                {
                    "lang": "sh",
                    "value": "aws ec2 create-vpc-endpoint --vpc-id {your-application-vpc-id} --region {aws-region} --service-name {service-name-string} --vpc-endpoint-type Interface --subnet-ids {your-application-subnet-ids}"
                },
                {
                    "lang": "sh",
                    "value": "\"VpcEndpoint\": {\n         \"VpcEndpointId\": \"vpce-XXXXXX\",\n         \"VpcEndpointType\": \"Interface\",\n         \"VpcId\": \"vpc-XXXXX\",\n         \"ServiceName\": \"com.amazonaws.vpce.{aws-region}.vpce-svc-XXXX\",\n         \"State\": \"pendingAcceptance\","
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: atlas-deployment-serverless\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  projectRef:\n    name: my-project\n  serverlessSpec:\n    name: serverless-instance\n    tags:\n    - key: \"environment\",\n      value: \"production\"\n    providerSettings:\n      providerName: SERVERLESS\n      backingProviderName: AWS\n      regionName: US_EAST_1\n    privateEndpoints:\n    - name: \"{unique-private-endpoint-label}\"\n      cloudProviderEndpointID: \"{vpce-id}\"\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasdeployment atlas-deployment-serverless -o yaml"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get secret {my-project}-{my-atlas-cluster}-{my-database-user} -o json | jq -r '.data | with_entries(.value |= @base64d)';"
                },
                {
                    "lang": "sh",
                    "value": "{\n  \"connectionStringPrivate\": \"mongodb://pl-0-eastus2.uzgh6.mongodb.net:1024,pl-0-eastus2.uzgh6.mongodb.net:1025,pl-0-eastus2.uzgh6.mongodb.net:1026/?ssl=truereplicaSet=atlas-18bndf-shard-0\",\n  \"connectionStringPrivateSrv\": \"mongodb+srv://cluster0-pl-0.uzgh6.mongodb.net\",\n  \"password\": \"P@@sword%\",\n  \"username\": \"theuser\"\n }"
                },
                {
                    "lang": "sh",
                    "value": "containers:\n  - name: test-app\n    env:\n    - name: \"CONNECTION_STRING\"\n      valueFrom:\n        secretKeyRef:\n          name: my-project-my-atlas-cluster-my-database-user\n          key: connectionStringPrivate"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: atlas-deployment-serverless\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  projectRef:\n    name: my-project\n  serverlessSpec:\n    name: serverless-instance\n    tags:\n    - key: \"environment\",\n      value: \"production\"\n    providerSettings:\n      providerName: SERVERLESS\n      backingProviderName: AWS\n      regionName: US_EAST_1\n    privateEndpoints:\n    - name: \"{unique-private-endpoint-label}\"\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "az network vnet subnet update --resource-group {resource-group-name} --vnet-name {vnet-name} --name {subnet-name} --disable-private-endpoint-network-policies true"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasdeployment atlas-deployment-serverless -o yaml"
                },
                {
                    "lang": "sh",
                    "value": "az network private-endpoint create --resource-group {resource-group-name} --name {endpoint-name} --vnet-name {vnet-name} --subnet {subnet-name} --private-connection-resource-id {serviceResourceId} --connection-name {serviceName} --manual-request true"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: atlas-deployment-serverless\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  projectRef:\n    name: my-project\n  serverlessSpec:\n    name: serverless-instance\n    tags:\n    - key: \"environment\",\n      value: \"production\"\n    providerSettings:\n      providerName: SERVERLESS\n      backingProviderName: AWS\n      regionName: US_EAST_1\n    privateEndpoints:\n    - name: \"{unique-private-endpoint-label}\"\n      cloudProviderEndpointID: \"{resource-id}\"\n      privateEndpointIpAddress: \"{private-ip}\"\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasdeployment atlas-deployment-serverless -o yaml"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get secret {my-project}-{my-atlas-cluster}-{my-database-user} -o json | jq -r '.data | with_entries(.value |= @base64d)';"
                },
                {
                    "lang": "sh",
                    "value": "{\n  \"connectionStringPrivate\": \"mongodb://pl-0-eastus2.uzgh6.mongodb.net:1024,pl-0-eastus2.uzgh6.mongodb.net:1025,pl-0-eastus2.uzgh6.mongodb.net:1026/?ssl=truereplicaSet=atlas-18bndf-shard-0\",\n  \"connectionStringPrivateSrv\": \"mongodb+srv://cluster0-pl-0.uzgh6.mongodb.net\",\n  \"password\": \"P@@sword%\",\n  \"username\": \"theuser\"\n }"
                },
                {
                    "lang": "sh",
                    "value": "containers:\n  - name: test-app\n    env:\n    - name: \"CONNECTION_STRING\"\n      valueFrom:\n        secretKeyRef:\n          name: my-project-my-atlas-cluster-my-database-user\n          key: connectionStringPrivate"
                }
            ],
            "preview": "Atlas Kubernetes Operator supports managing private endpoints for\nserverless instances on the following platforms:",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-changelog",
            "title": "Atlas Kubernetes Operator Changelog",
            "headings": [
                "Atlas Kubernetes Operator 2.1.0",
                "Fixes",
                "New",
                "Changes",
                "Atlas Kubernetes Operator 2.0.1",
                "Breaking Changes",
                "Atlas Kubernetes Operator 2.0.0",
                "Atlas Kubernetes Operator 1.9.3",
                "Atlas Kubernetes Operator 1.9.1",
                "Fixes",
                "Atlas Kubernetes Operator 1.9.0",
                "Attention",
                "Fixes",
                "New",
                "Atlas Kubernetes Operator 1.8.2",
                "Atlas Kubernetes Operator 1.8.1",
                "Atlas Kubernetes Operator 1.8.0",
                "Atlas Kubernetes Operator 1.7.3",
                "Atlas Kubernetes Operator 1.7.2",
                "Atlas Kubernetes Operator 1.7.1",
                "Atlas Kubernetes Operator 1.7.0",
                "Atlas Kubernetes Operator 1.6.1",
                "Atlas Kubernetes Operator 1.6.0",
                "New Features",
                "Atlas Kubernetes Operator 1.5.0",
                "New Features",
                "Fixes",
                "Atlas Kubernetes Operator 1.4.1",
                "New Features",
                "Atlas Kubernetes Operator 1.4.0",
                "New Features",
                "Fixes",
                "Atlas Kubernetes Operator 1.3.0",
                "New Features",
                "Fixes",
                "Atlas Kubernetes Operator 1.2.0",
                "New Features",
                "Fixes",
                "Atlas Kubernetes Operator 1.1.0",
                "New Features",
                "Fixes",
                "Atlas Kubernetes Operator 1.0.0",
                "Breaking Changes",
                "New Features",
                "Fixes",
                "Atlas Kubernetes Operator 0.8.0",
                "Changes",
                "Bug Fixes",
                "AtlasProject Custom Resource",
                "Changes",
                "AtlasCluster Custom Resource",
                "Changes",
                "Atlas Kubernetes Operator 0.5.0",
                "Changes"
            ],
            "paragraphs": "You can find the full list of  Atlas Kubernetes Operator  releases  here . Disables the  --subobject-deletion-protection  flag due to a bug that prevents users from\nmodifying existing resources when  deletion protection  is enabled.\nYou can still use the\n --object-deletion-protection  flag to control deletion protection on a per-custom-resource basis. Adds the  terminationProtectionEnabled  property to the  deploymentSpec \nfields in the  AtlasProject  Custom Resource  to achieve feature parity with\n serverless instances  deployed with the  AtlasDeployment  Custom Resource . Adds  OIDC (OpenID Connect)  and  AWS (Amazon Web Services)  IAM authentication fields to the\n AtlasDatabaseUser  Custom Resource . To learn more, see  spec.oidcAuthType . Deprecates  cloudProviderAccess*  fields in favor of  cloudProviderIntegration* \nfields in the  AtlasProject  Custom Resource . Custom resources you delete in  Kubernetes  won't get deleted in\n Atlas . Instead,  Atlas Kubernetes Operator  stops managing those resources.\nFor example, if you delete an  AtlasProject  Custom Resource \nin  Kubernetes ,  Atlas Kubernetes Operator  no longer automatically deletes the corresponding project\nfrom  Atlas , preventing accidental or unexpected deletions. To learn more,\nincluding how to  revert this behavior  to\nthe default prior to  Atlas Kubernetes Operator  2.0.1, see  New Default: Deletion Protection in  Atlas Kubernetes Operator  2.0 . deploymentSpec  replaces  advancedDeploymentSpec  in\nthe  AtlasDeployment  custom resource. You must update your  AtlasDeployment \ncustom resource as follows: If you use  advancedDeploymentSpec , rename to  deploymentSpec .\nYou don't need to change any formatting. If you used  deploymentSpec  prior to  Atlas Kubernetes Operator  2.0.1, rewrite your\n AtlasDeployment  custom resource to match the formatting used in\n the examples . Improves snapshot distribution management by removing  replicationSpecId  from\nthe  AtlasBackupSchedule  Custom Resource  so it can be reused by multiple\ndeployments managed by  Atlas Kubernetes Operator . The  replicationSpecId  is now automatically\nset for every deployment that references it. As a result of this change, you\ncan no longer configure  replicationSpecId  and should remove it from your\n AtlasBackupSchedule  custom resource. Forces the use of  secretRef  fields for  encryptionAtRest  and  alertConfigurations \nfeatures to promote security best practices. You should now store API\nsecrets and credentials as  secrets  and reference\nthem from the  AtlasProject  Custom Resource  using the following fields: For  spec.alertConfigurations.notifications : To learn more, see  Third-Party Alert Configuration Example . For  spec.encryptionAtRest : To learn more, see  Encrypt Data Using a Key Management Service . Use  APITokenRef  instead of  APIToken Use  DatadogAPIKeyRef  instead of  DatadogAPIKey Use  FlowdockTokenAPIRef  instead of  FlowdockTokenAPI Use  OpsGenieAPIKeyRef  instead of  OpsGenieAPIKey Use  VictorOpsSecretRef  instead of  VictorOpsAPIKey  and  VictorOpsRoutingKey AWS  Use  secretRef  instead of  AccessKeyID ,  SecretAccessKey ,\n CustomerMasterKeyID , and  RoleID . Azure  Use  secretRef  instead of  SubscriptionID ,  KeyVaultName ,\n KeyIdentifier , and  Secret . GCP  Use  secretRef  instead of  ServiceAccountKey  or  KeyVersionResourceID . This release contains an issue that prevents  Atlas Kubernetes Operator  from reconciling the\n AtlasBackupSchedule  Custom Resource  when  deletion protection  is enabled.\nDon't use this version (2.0.0), and instead use  Atlas Kubernetes Operator  2.0.1. Fixes an issue that caused reconciliation to fail when you updated a\ndeployment with autoscaling enabled. Fixes missing permissions for the  AtlasFederatedAuth  Custom Resource . Validation now rejects duplicate alert configurations. Fixes a bug that duplicated projects listed in a team's status. Refactors the  IPAccessList  reconciliation flow to avoid unneeded\nrecreation. Fixes backup schedule repeatedly updating. Adds the  AtlasFederatedAuth  Custom Resource \nto configure  federated authentication  for Identity Providers that you\nalready registered in  Atlas . Supports  Atlas for Government  deployments. You\nmust configure the Gov endpoint accordingly.  Atlas Kubernetes Operator  supports only\n AWS (Amazon Web Services)  as a cloud provider for  Atlas  for Government. Supports database deployment resource tagging. To learn more, see\nthe following settings: spec.deploymentSpec.tags spec.serverlessSpec.tags Adds new arguments to serverless for continuous backups and\ntermination protection. Improves validation and handling of autoscaling reporting. Provides guidance on using third-party secret management tools with\n Atlas Kubernetes Operator  to support external key management systems. To learn how to\nconfigure external secret storage for  Atlas Kubernetes Operator , see\n Configure Secret Storage . Uses UBI micro base image instead of minimal. The micro base image is\na smaller base image with fewer dependencies. AtlasProject  Custom Resource : AtlasDeployment  Custom Resource : Fixes an issue that caused continual audit log updates in the project activity feed. Fixes an issue that caused incorrect reconciliation of  custom database roles . Fixes an issue that prevented deleting the  AtlasBackupSchedule  Custom Resource  when it was referenced by an  AtlasDeployment  Custom Resource . AtlasProject  Custom Resource : AtlasDatabaseUser  Custom Resource : Upgrades the  Atlas  client to v0.32.0. Fixes an issue where  Atlas Kubernetes Operator  could not watch  secrets \nfor  third-party integrations . Adds support for storing cloud provider credentials in secrets instead of\nthe  AtlasProject  Custom Resource  for the\n Encryption at Rest  feature. Fixes  Google Cloud  credential validation for the\n Encryption at Rest  feature. Fixes an issue where private endpoint connection strings were missing\nfrom sharded clusters. AtlasDataFederation  Custom Resource : Fixes the  aws.roleID  field for the  Encryption at Rest  feature. Supports optional secrets for  Alerts Configuration . Supports managing  Atlas Data Federation  deployments. AtlasProject  Custom Resource : Moves  leases.coordination.k8s.io  to its own proxy-role rule. Adds the  spec.settings.IsExtendedStorageSizesEnabled  parameter. Upgrades Go to 1.20. Updates the value of the  spec.export.frequencyType  parameter of\nthe  AtlasBackupSchedule  custom resource from  MONTHLY  to\n monthly . Fixes connection secret generation for different namespaces. Fixes configuration of automated cloud backup export. Fixes CVE-2023-0436: Secret logging may occur in debug mode of Atlas Operator The affected versions of MongoDB Atlas Kubernetes Operator may print sensitive information\nlike GCP service account keys and API integration secrets while DEBUG mode logging is enabled.\nThis issue affects MongoDB Atlas Kubernetes Operator versions: 1.5.0, 1.6.0, 1.6.1, 1.7.0.\nPlease note that this is reported on an EOL version of the product, and users are advised to upgrade to the latest supported version. Required Configuration: DEBUG logging is not enabled by default, and must be configured by the end-user.\nTo check the log-level of the Operator, review the flags passed in your deployment configuration\n(eg.  https://github.com/mongodb/mongodb-atlas-kubernetes/blob/main/config/manager/manager.yaml#L27 ) CVSS: 4.5 CWE-319: Cleartext Transmission of Sensitive Information AtlasProject  Custom Resource : AtlasDeployment  Custom Resource : Adds Openshift 4.12 compatibility. Supports  Kubernetes  1.25. A project can now refer to a connection secret in a\ndifferent namespace with the\n spec.connectionSecretRef.namespace  parameter. Supports multiple private endpoints per a single provider and\nregion. Supports storing all private endpoint connection strings. Fixes an issue with  Google Cloud   KMS (Key Management Service)  for the  Encryption at Rest  feature. Deprecates the  autoIndexingEnabled  field. Supports snapshot distribution. AtlasProject  Custom Resource : AtlasDeployment  Custom Resource : Fixes an issue with an IP access list. Fixes reconciliation for the  AtlasBackupSchedule  Custom Resource . AtlasProject  Custom Resource : AtlasDeployment  Custom Resource : Adds an optional  --operatorVersion  parameter. To learn more, see\n Import  Atlas  Projects into  Atlas Kubernetes Operator . Sets  finalizers  and support labels for  AtlasBackupSchedule  Custom Resource ,\n AtlasBackupPolicy  Custom Resource , and  Atlas teams \ncustom resources. Adds support for  Global Cluster \nparameters in  spec.advancedDeploymentSpec.*  and  spec.deploymentSpec.* .\nTo learn more, see  AtlasDeployment custom resource parameters .\nThese Global Cluster parameters map zones to geographic regions and allow you\nto add labels. For a full list of available parameters, see the  Atlas \n Global Clusters API . The  Atlas Kubernetes Operator  image now  supports ARM64 . AtlasProject  Custom Resource : AtlasDeployment  Custom Resource : Adds  Atlas Teams  support. Adds  serverless private endpoint \nsupport. AtlasProject  Custom Resource : AtlasDeployment  Custom Resource : Fixes an issue with connection secret creation. Fixes the minimum version of Openshift. Fixes the  InstanceSize  must match issue. Ensures private endpoints are always added to the status. Converts the  OplogMinRetentionHours  field properly. AtlasProject  Custom Resource : Updates the minimum required  Openshift  version to 4.8. Adds support for\n custom database roles \nvia the  spec.customRoles  field. AtlasProject  Custom Resource : AtlasDeployment  Custom Resource : Adds support for audit logs. You can enable auditing with the\n spec.auditing.enabled  field. For more information about\n Atlas Kubernetes Operator  auditing, see  Configure Audit Logs . Adds support for project settings via the  spec.settings \nfield. Adds support for alert configurations via the\n spec.alertConfigurations  field. Adds support for autoscaling of the  instanceSize  and\n diskSizeGB  parameters. Fixes an issue where adding an IP address with CIDR block  /32  to\nNetwork Access could leave the IP Access List inactive indefinitely. Fixes an issue where creating project integrations that require\nnamespace references could result in errors when the user provides\na namespace other than the project namespace, or does not provide a\nnamespace. AtlasProject  Custom Resource : AtlasDeployment  Custom Resource : Adds support for  network peering \nvia the  spec.networkPeers  field. Adds support for  cloud provider access \nvia the  spec.cloudProviderAccessRoles  field. Adds support for  encryption at rest \nvia the  spec.encryptionAtRest  field. Adds a test to ensure that deleting a\n CRD \ndoes not affect  AtlasDeployment  Custom Resource s with the\n mongodb.com/atlas-resource-policy: \"keep\"  annotation. Fixes a resource reconciliation issue that occured when\nyou delete an  AtlasDeployment  Custom Resource \nafter the API key has expired. Fixes an issue where you could change the  instanceSize  and\n diskSizeGB  parameters for deployments with autoscaling enabled.\nTo change the  instanceSize  and  diskSizeGB  parameters,\nyou must first disable autoscaling. Fixes an error message that returns when  Atlas Kubernetes Operator  can't delete a\nproject's backup policy or backup schedule. Upgrades Go to 1.18. Adds support for Private Endpoints backwards sync to the\n AtlasProject Custom Resource . Fixes an issue where the  AtlasDeployment Custom Resource  was not created successfully when\nthe instance size for a deployed resource changed from M10 to M40. Fixes an issue where creating an  AtlasDeployment Custom Resource  with  advancedDeploymentSpec  failed\nwith  autoscaling.diskGBEnabled  and adds a new  AdvancedAutoScalingSpec \nstruct to  AdvancedDeploymentSpecChanges . Fixes an issue where you could decrease  diskSizeGB  for deployments\nwith autoscaling enabled. To change the  diskSizeGB  parameter, you\nmust first disable autoscaling. Fixes a resource reconciliation issue where the  Atlas  API returns\nan empty object for scheduled backups. Adds support for  maintenance windows . Fixes an issue where private endpoint connection strings were missing\nfrom  Kubernetes  secrets. Fixes an issue where  Atlas Kubernetes Operator  didn't remove conditions for unused\nresources. Adds missing private endpoint fields to Pod conditions. Renames the  AtlasCluster  Custom Resource to the\n AtlasDeployment  Custom Resource . Renames  spec.clusterSpec  to  spec.deploymentSpec . Renames  spec.advancedClusterSpec  to\n spec.advancedDeploymentSpec . AtlasProject  Custom Resource : AtlasDeployment  Custom Resource : Adds log levels and JSON log output for  Atlas Kubernetes Operator . To change the\nlog level, you can provide the\n \u2014log-level=debug | info | warn | error | dpanic | panic | fatal \nflag. To change the output format, you can provide the\n \u2014log-encoder=json | console  flag. Supports  third-party integrations  including\n Prometheus integrations . Supports  GCP private endpoints . Supports  serverless instances \nvia the  spec.serverlessSpec  field. Supports  scheduled backups  for\ndatabase deployments. Supports upgrading  M0 ,  M2 , and  M5  clusters to\n M10+  clusters via the\n spec.deploymentSpec.providerSettings.instanceSizeName \nparameter. Supports  advanced options  via the\n spec.processArgs  object. Supports omitting the\n spec.deploymentSpec.providerSettings.providerName  field for\n M0 ,  M2 , and  M5  clusters. Supports omitting the\n spec.serverlessSpec.providerSettings.providerName  field for\nserverless instances. Fixes a bug where you couldn't delete the\n AtlasProject  Custom Resource  if the credentials secret was\ndeleted. Resolves missing epoch timestamps in log messages. Fixes a bug with the incorrect user-agent version. Fixes an  improper signature verification  with the\n golang.org/x/crypto/ssh  module. Upgrades the Controller Runtime to v0.11.0. Upgrades Go to 1.17. When you  install a cluster using Helm Charts , Helm doesn't exit until the cluster is\nready if you set  postInstallHook.enabled  to true. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . Supports the\n mongodb.com/atlas-reconciliation-policy=skip  annotation for\nconfiguring  Atlas Kubernetes Operator  to skip reconciliations on\n specific resources . Supports  X.509 authentication . Fixes an issue that logged errors for resource deletion. Atlas Kubernetes Operator  no longer marks the  AtlasProject  Custom Resource  as\nready until the  project IP access is successfully created . You can find the images in the following location: https://quay.io/repository/mongodb/mongodb-atlas-operator Adds the  spec.advancedClusterSpec  parameter to the\n AtlasCluster  custom\nresource. The  AtlasCluster  custom\nresource now has two main configuration options. You must specify\neither  spec.clusterSpec  or  spec.advancedClusterSpec .\nThe  spec.clusterSpec  parameter uses the\n Atlas Cluster API Resource . The\n spec.advancedClusterSpec  parameter uses the\n Atlas Advanced Cluster API Resource . To migrate an existing resource to use the  spec.clusterSpec \nstructure, you must move all fields currently under  spec.*  to\n spec.clusterSpec.*  with the exception of  spec.projectRef . This  Atlas Kubernetes Operator  trial release lets you manage  Atlas  projects,\nclusters, and database users with  Kubernetes  specifications. Introduces  Global  and  per project   Atlas  authentication\nmodes. To learn more, see  Configure Access to  Atlas . Supports installing  Atlas Kubernetes Operator  clusterwide (all the  namespaces  in the\n Kubernetes  cluster) or to its own namespace. To learn more, see\n Quick Start . Introduces the  AtlasProject  Custom Resource . Use this resource\nto create  Atlas  projects and configure their\n IP access lists . Introduces the  AtlasCluster \ncustom resource. Use this resource to create clusters in an  Atlas \nproject. Introduces the  AtlasDatabaseUser  Custom Resource  for creating\ndatabase users in an  Atlas  project. Allows you to create or update  secrets  for each database user\nand cluster. Applications can use these secrets in  Kubernetes  to connect\nto  Atlas  clusters.",
            "code": [],
            "preview": "AtlasProject Custom Resource:",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-private-link-datafederation",
            "title": "Manage Private Endpoints for an Federated Database Instance",
            "headings": [
                "Procedure",
                "Find the service name for your private endpoint.",
                "Use the AWS CLI to configure each private endpoint.",
                "Specify the spec.privateEndpoints parameter.",
                "Check the status of your private endpoints using Atlas Kubernetes Operator."
            ],
            "paragraphs": "Atlas Kubernetes Operator  supports managing private endpoints for dedicated clusters\non  AWS (Amazon Web Services)  using the  AWS PrivateLink \nfeature. Before you begin, see  Manage Private Endpoints . This feature is not available for  M0  free clusters,  M2 , and\n M5  clusters. To learn more about which features are unavailable,\nsee  Atlas M0 (Free Cluster), M2, and M5 Limits . To enable clients to connect to  Atlas  dedicated clusters using\nprivate endpoints: Use the following table to find the service name that corresponds\nto the  AWS (Amazon Web Services)  region for your private endpoint: AWS (Amazon Web Services)  Region Service Name us-east-1 com.amazonaws.vpce.us-east-1.vpce-svc-00e311695874992b4 us-west-1 com.amazonaws.vpce.us-west-2.vpce-svc-09d86b19e59d1b4bb eu-west-1 com.amazonaws.vpce.eu-west-1.vpce-svc-0824460b72e1a420e eu-west-2 com.amazonaws.vpce.eu-west-2.vpce-svc-052f1840aa0c4f1f9 eu-central-1 com.amazonaws.vpce.eu-central-1.vpce-svc-0ac8ce91871138c0d sa-east-1 com.amazonaws.vpce.sa-east-1.vpce-svc-0b56e75e8cdf50044 ap-southeast-2 com.amazonaws.vpce.ap-southeast-2.vpce-svc-036f1de74d761706e ap-south-1 com.amazonaws.vpce.ap-south-1.vpce-svc-03eb8a541f96d356d To create your application  VPC (Virtual Private Cloud)   interface endpoint : To learn more, see  Creating an Interface Endpoint  in the  AWS (Amazon Web Services) \ndocumentation. Copy the following command: Replace the following placeholders with the details\nabout your  AWS (Amazon Web Services)   VPC (Virtual Private Cloud) : your-application-vpc-id Unique string that identifies the peer  AWS (Amazon Web Services) \n VPC (Virtual Private Cloud) . Find this value on the  VPC (Virtual Private Cloud)  dashboard in\nyour  AWS (Amazon Web Services)  account. aws-region Label that identifies the  AWS region  of the private endpoint. service-name Unique string that identifies the service\nfor your private endpoint. This is the service name\nvalue you retrieved in the previous step. your-application-subnet-ids Unique strings that identify the subnets your\n AWS (Amazon Web Services)   VPC (Virtual Private Cloud)  uses. Separate each subnet with a\nspace. Find these values on the\n Subnet   dashboard in your  AWS (Amazon Web Services) \naccount. You must specify at least one subnet. If you\ndon't,  AWS (Amazon Web Services)  won't provision a\n interface endpoint  in your  VPC (Virtual Private Cloud) . An\ninterface endpoint is required for clients\nin your  VPC (Virtual Private Cloud)  to send traffic to the private\nendpoint. Run the command with the  AWS CLI . Note the  VpcEndpointId  value in the output. Example Specify the  spec.privateEndpoints  parameter for\nthe  AtlasDataFederation  Custom Resource . Replace\n vpce-id  with  the  VpcEndpointId  value from the previous\nstep and run the following command: You can find the unique identifier of the peer\n AWS (Amazon Web Services)   VPC (Virtual Private Cloud)  on the  VPC (Virtual Private Cloud)  dashboard in your  AWS (Amazon Web Services)  account. Run the following command:",
            "code": [
                {
                    "lang": "sh",
                    "value": "aws ec2 create-vpc-endpoint --vpc-id {your-application-vpc-id} --region {aws-region} --service-name {service-name} --vpc-endpoint-type Interface --subnet-ids {your-application-subnet-ids}"
                },
                {
                    "lang": "sh",
                    "value": "\"VpcEndpoint\": {\n         \"VpcEndpointId\": \"vpce-XXXXXX\u201d,\n         \"VpcEndpointType\": \"Interface\",\n         \"VpcId\": \"vpc-XXXXX\u201d,\n         \"ServiceName\": \"com.amazonaws.vpce.{aws-region}.vpce-svc-XXXX\u201d,\n         \"State\": \"pendingAcceptance\",\n         }"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDataFederation\nmetadata:\n  name: my-federated-deployment\nspec:\n  name: my-fdi\n  privateEndpoints:\n  - endpointId: {vpce-id}\n    provider: AWS\n    type: DATA_LAKE\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasdatafederation my-fdi -o yaml"
                }
            ],
            "preview": "Atlas Kubernetes Operator supports managing private endpoints for dedicated clusters\non AWS (Amazon Web Services) using the AWS PrivateLink\nfeature.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "atlasproject-custom-resource",
            "title": "AtlasProject Custom Resource",
            "headings": [
                "Example",
                "Prometheus Example",
                "Teams Example",
                "Maintenance Window Example",
                "Project Settings Example",
                "Alert Configuration Example",
                "Third-Party Alert Configuration Example",
                "Parameters"
            ],
            "paragraphs": "The  AtlasProject  custom resource configures the project in\n Atlas . When you create the  AtlasProject  custom resource,\n Atlas Kubernetes Operator  tries to create a new project in  Atlas . Atlas Kubernetes Operator  does one of the following actions: You can use the  spec.connectionSecretRef.name  parameter\nto set the connection  secret  for  the  AtlasProject  custom\nresource. This parameter overrides the default  global  connection\n secret . To  connect  to the\nAtlas Administration API,  Atlas Kubernetes Operator  reads the organization ID and\n API keys  from  Atlas Kubernetes Operator   secrets . You can also edit the  AtlasProject  custom resource specification to\nconfigure the following options: If you remove the  AtlasProject  resource from your  Kubernetes  cluster,\n Atlas Kubernetes Operator  removes the project from  Atlas . You must remove all the\nclusters in the project beforehand. Otherwise,  Atlas  rejects the\ndelete request. Atlas Kubernetes Operator  uses  custom resource  configuration\nfiles to manage your  Atlas  configuration, but as of  Atlas Kubernetes Operator  2.0,\ncustom resources you delete in  Kubernetes  are no longer deleted in\n Atlas . Instead,  Atlas Kubernetes Operator  simply stops managing those resources.\nFor example, if you delete an  AtlasProject  Custom Resource \nin  Kubernetes ,  Atlas Kubernetes Operator  no longer automatically deletes the corresponding project\nfrom  Atlas , preventing accidental or unexpected deletions. To learn more,\nincluding how to  revert this behavior  to\nthe default used prior to  Atlas Kubernetes Operator  2.0, see  New Default: Deletion Protection in  Atlas Kubernetes Operator  2.0 . Creates a new project in the organization that the connection\n secret  configures. Reuses an existing project. In this case,  Atlas Kubernetes Operator  verifies\nwhether a project with  spec.name  exists. If the project exists,\n Atlas Kubernetes Operator  skips creation. After the reconciliation,  Atlas Kubernetes Operator  updates\nthe  status.id  field with the id of the project. By default,  Atlas Kubernetes Operator  keeps connection secrets in the same  namespace \nas the  AtlasProject  Custom Resource . To store\nsecrets in another  namespace , specify the\n spec.connectionSecretRef.namespace  parameter. An  IP access list  with the\n spec.projectIpAccessList  parameter. This IP access list\ngrants network access to  Atlas  clusters in the project. Teams  with the  spec.teams  parameter. A team\nlets you grant an access role to an entire group of  Atlas  users for a\nparticular project. The  maintenance window  with\nthe  spec.maintenanceWindow  parameter. The maintenance\nwindow sets the hour and day that  Atlas  starts weekly\nmaintenance on your database deployments. Network peering  with the\n spec.networkPeers  parameter. Network peering allows you to\nconnect securely to your  AWS (Amazon Web Services) ,  Azure (Microsoft Azure) , or  Google Cloud   VPC (Virtual Private Cloud) . Encryption at rest using customer-managed keys \nwith the  spec.encryptionAtRest  parameter. Encryption at\nrest using customer-managed keys allows you to add an additional\nlayer of security by using your cloud provider's  KMS (Key Management Service)  together with\nthe MongoDB  encrypted storage engine . Private endpoints  with the\n spec.privateEndpoints  parameter. X.509 authentication  with the\n spec.x509CertRef.name  parameter. Project settings with the  spec.settings  parameter, including settings to enable and disable the following: Collection of database statistics in  cluster metrics Data explorer Performance Advisor Realtime Performance Panel Schema Advisor Project alerts configurations \nwith the  spec.alertConfigurationSyncEnabled \nand  spec.alertConfigurations  parameters. For information on how these settings interact,\nsee the  Considerations . The following example shows an  AtlasProject  custom resource\nspecification: The following example shows an  AtlasProject  custom resource\nspecification that integrates with Prometheus: To learn more, see  Integrate with Third-Party Services . Atlas Kubernetes Operator  offers a  sample Grafana dashboard  that you can  import into Grafana . The following example shows an  AtlasProject  custom resource\nspecification that gives the  green-leaf-team  the  Organization Owner \nrole for this project. The team members are defined in the\n AtlasTeam custom resource . To learn more, see  Configure Teams . The following example shows an  AtlasProject  custom resource\nspecification that sets the maintenance window to 5:00 AM every Tuesday with automatic deferral disabled: The following example shows an  AtlasProject  custom resource\nspecification that disables the collection of database statistics in\n cluster metrics ,\n data explorer ,  Performance Advisor ,  Realtime Performance Panel , and  Schema Advisor . The following example shows an  AtlasProject  custom resource\nspecification that configures an alert that triggers if the oplog\nwindow reaches less than one hour: The following example shows an  AtlasProject  custom resource\nspecification that configures an alert that sends notifications through\nSlack: This section describes the  AtlasProject  custom resource parameters: Type : string Required Name of the project created or updated in  Atlas . The name\nlength must not exceed 64 characters. The name can contain only\nletters, numbers, spaces, dashes, and underscores. Type: array of objects Optional List that contains  alert configurations \nfor this project. If you use this setting, you must also set\n spec.alertConfigurationSyncEnabled  to  true \nfor  Atlas Kubernetes Operator  to modify project alert configurations. If you omit or leave this setting empty,  Atlas Kubernetes Operator  doesn't alter the project's\nalert configurations. If creating a project,  Atlas  applies\nthe default project alert configurations. Type: string Required Event that triggers an alert that this alert configration describes. To learn about the values that  Atlas Kubernetes Operator  accepts,\nsee the request body schema for the\n Create One Alert Configuration in One Project  endpoint\nin the MongoDB Atlas Administration API documentation. Type: boolean Optional Default :  false Flag that indicates whether this alert configuration is enabled.\nIf omitted, defaults to  false . Type: array of objects Conditional List of rules that determine whether  Atlas  checks an object\nfor the alert configuration. You can filter using the matchers\narray if  spec.alertConfigurations.eventTypeName \nspecifies an event for a host, replica set, or sharded cluster. Type: string Conditional Human-readable label that identifies the parameter in the target object that  Atlas  checks.\nThe parameter must match all rules for  Atlas  to check for\nalert configurations. Atlas Kubernetes Operator  accepts the following values: Atlas Kubernetes Operator  requires this setting if you include an object in the\n spec.alertConfigurations.matchers \narray. CLUSTER_NAME HOSTNAME HOSTNAME_AND_PORT PORT REPLICA_SET_NAME SHARD_NAME TYPE_NAME Type: string Conditional Comparison operator to apply when checking the current metric value\nagainst  spec.alertConfigurations.matchers.value . Atlas Kubernetes Operator  accepts the following values: Atlas Kubernetes Operator  requires this setting if you include an object in the\n spec.alertConfigurations.matchers \narray. EQUALS CONTAINS STARTS_WITH ENDS_WITH NOT_EQUALS NOT_CONTAINS REGEX Type: string Conditional Value to match or exceed using the specified\n spec.alertConfigurations.matchers.operator . Atlas Kubernetes Operator  requires this setting if you include an object in the\n spec.alertConfigurations.matchers \narray. Type: object Conditional Threshold for the metric that, when exceeded, triggers an alert. Atlas Kubernetes Operator  requires this setting when\n spec.alertConfigurations.eventTypeName  is\n OUTSIDE_METRIC_THRESHOLD . Type: string Conditional Human-readable label that identifies the metric against\nwhich  Atlas  checks the configured\n spec.alertConfigurations.metricThreshold.threshold . To learn about the values that  Atlas Kubernetes Operator  accepts,\nsee the request body schema for the\n Create One Alert Configuration in One Project  endpoint\nin the MongoDB Atlas Administration API documentation. Atlas Kubernetes Operator  requires this setting if you include the\n spec.alertConfigurations.metricThreshold \nobject. Type: string Optional Default :  AVERAGE Atlas  computes the current metric value as an average. Atlas Kubernetes Operator  accepts only a value of  AVERAGE . Type: string Conditional Comparison operator to apply when checking the current metric value. Atlas Kubernetes Operator  accepts the following values: Atlas Kubernetes Operator  requires this setting if you include the\n spec.alertConfigurations.metricThreshold \nobject. GREATER_THAN LESS_THAN Type: integer Conditional Value of metric that, when exceeded, triggers an alert. Atlas Kubernetes Operator  requires this setting if you include the\n spec.alertConfigurations.metricThreshold \nobject. Type: string Conditional Element used to express the quantity. This value can be an\nelement of time, storage capacity, and so on Atlas Kubernetes Operator  accepts the following values: Atlas Kubernetes Operator  requires this setting if you include the\n spec.alertConfigurations.metricThreshold \nobject. BITS BYTES DAYS GIGABITS GIGABYTES HOURS KILOBITS KILOBYTES MEGABITS MEGABYTES MILLISECONDS MINUTES PETABYTES RAW SECONDS TERABYTES Type: array Conditional List that describes the notifications that  Atlas \nsends for alerts that this alert configuration describes. Type : string Conditional Name of the opaque  secret  that contains a single  password \nfield with your API token for Slack. If you want notifications through Slack, you must\nspecify this setting. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: Type : string Conditional Namespace that contains your API token for Slack. If you\nwant notifictions through Slack, you must specify this\nsetting. Type: string Conditional Human-readable label that identifies the Slack channel to which  Atlas  sends alert\nnotifications. Atlas Kubernetes Operator  requires this setting when  you set\n spec.alertConfigurations.notifications.typeName \nto  SLACK . Type : string Conditional Name of the opaque  secret  that contains a single  password \nfield with the API key for Datadog. If you want notifications\nthrough Datadog, you must specify this setting`. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: Type : string Conditional Namespace that contains your API key for Datadog. If you want\nnotifications through Datadog, you must specify this setting. Type: string Optional Default :  US Datadog region that indicates which API Uniform Resource Locator\n(URL) to use. Atlas Kubernetes Operator  accepts the following values: US EU Type: integer Optional Default :  0 Number of minutes that  Atlas  waits after it detects\nan alert condition before it sends out the first notification. Type: string Conditional Email address to which  Atlas  sends alert notifications. Atlas Kubernetes Operator  requires this setting if you set\n spec.alertConfigurations.notifications.typeName \nto  EMAIL . Atlas Kubernetes Operator  doesn't require this setting to send\nemail notifications when you set\n spec.alertConfigurations.notifications.typeName \nto one of the following values: To send emails to one  Atlas  user or group of users, set the\n spec.alertConfigurations.notifications.emailEnabled  parameter. GROUP ORG TEAM USERS Type: boolean Conditional Flag that indicates whether  Atlas  sends email notifications. Atlas Kubernetes Operator  requires this setting when you set\n spec.alertConfigurations.notifications.typeName \nto one of the following values: GROUP ORG TEAM Type: integer Optional Number of minutes to wait between successive notifications.\n Atlas  sends notifications until someone acknowledges\nthe unacknowledged alert.  Atlas Kubernetes Operator  accepts values greater\nthan or equal to  5 . PagerDuty, VictorOps, and OpsGenie notifications don't\nuse this field. Configure and manage the notification\ninterval within each of those services. Type: string Conditional Microsoft Teams Webhook Uniform Resource Locator (URL) that\n Atlas  needs to send this notification via Microsoft Teams.\nIf the URL later becomes invalid,  Atlas  sends an email to\nthe project owners. If the key remains invalid,  Atlas  removes it. Atlas Kubernetes Operator  requires this setting if you set\n spec.alertConfigurations.notifications.typeName \nto  MICROSOFT_TEAMS . Type: string Conditional Mobile phone number to which  Atlas  sends alert notifications. Atlas Kubernetes Operator  requires this setting if you set\n spec.alertConfigurations.notifications.typeName \nto  SMS . Type : string Conditional Name of the opaque  secret  that contains a single  password \nfield with the API key for Opsgenie. If you want notifications\nthrough Opsgenie, you must specify this setting. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: Type : string Conditional Namespace that contains your API key for Opsgenie. If you want\nnotifications through Opsgenie, you must specify this setting. Type: string Optional Default :  US Opsgenie region that indicates which API Uniform Resource Locator\n(URL) to use. Atlas Kubernetes Operator  accepts the following values: Atlas Kubernetes Operator  applies this setting if you set\n spec.alertConfigurations.notifications.typeName \nto  OPS_GENIE . US EU Type: array Optional List that contains the one or more organization or\nproject roles that receive the configured alert.\nIf you include this parameter,  Atlas  sends\nalerts only to users assigned the roles you specify\nin the list. If you omit this parameter,  Atlas \nsends alerts to users assigned any role. Atlas Kubernetes Operator  accepts the following values: Atlas Kubernetes Operator  applies this setting when you set\n spec.alertConfigurations.notifications.typeName \nto one of the following values: GROUP_CLUSTER_MANAGER GROUP_DATA_ACCESS_ADMIN GROUP_DATA_ACCESS_READ_ONLY GROUP_DATA_ACCESS_READ_WRITE GROUP_OWNER GROUP_READ_WRITE ORG_OWNER ORG_MEMBER ORG_GROUP_CREATOR ORG_BILLING_ADMIN ORG_READ_ONLY GROUP ORG Type : string Conditional Name of the opaque  secret  that contains a single  password \nfield with the API key for PagerDuty. If you want notifications\nthrough PagerDuty, you must specify this setting. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: Type : string Conditional Namespace that contains your API key for PagerDuty. If you want\nnotifications through PagerDuty, you must specify this setting. Type: string Optional Degree of seriousness given to this notification. Atlas Kubernetes Operator  accepts the following values: CRITICAL ERROR WARNING Type: boolean Conditional Flag that indicates whether  Atlas  sends text message\nnotifications. Atlas Kubernetes Operator  requires this setting when you set\n spec.alertConfigurations.notifications.typeName \nto one of the following values: GROUP ORG TEAM Type: string Conditional Unique 24-hexadecimal digit string that identifies one\n Atlas  team. Atlas Kubernetes Operator  requires this setting if you set\n spec.alertConfigurations.notifications.typeName \nto  TEAM . Type: string Conditional Name of the  Atlas  team that receives this notification. Atlas Kubernetes Operator  requires this setting if you set\n spec.alertConfigurations.notifications.typeName \nto  TEAM . Type: string Conditional Human-readable label that displays the alert notification type.\nThis setting is required if you specify a value for the\n spec.alertConfigurations.notifications  setting.\n Atlas  supports the following values: DATADOG EMAIL OPS-GENIE ORG PAGER_DUTY PROMETHEUS SLACK SMS TEAM USER VICTOR_OPS WEBHOOK Type: string Conditional Atlas  username of the person to whom  Atlas  sends\nnotifications. Specify only  Atlas  users who belong to\nthe project that owns the alert configuration. Atlas Kubernetes Operator  requires this setting if you set\n spec.alertConfigurations.notifications.typeName \nto  USER . Type : string Conditional Name of the opaque  secret  that contains a single  password \nfield with the API key for Splunk On-Call. If you want notifications\nthrough Splunk On-Call, you must specify this setting. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: Type : string Conditional Namespace that contains your API key for Splunk\nOn-Call. If you want notifications through Splunk\nOn-Call, you must specify this setting. Type: string Conditional Routing key that  Atlas  needs to send alert notifications\nto Splunk On-Call. If the key later becomes invalid,\n Atlas  sends an email to the project owners. If the\nkey remains invalid,  Atlas  removes it. Atlas Kubernetes Operator  requires this setting if you set\n spec.alertConfigurations.notifications.typeName \nto  VICTOR_OPS . Type: string Optional Authentication secret for a webhook-based alert. Atlas Kubernetes Operator  applies this setting if you set\n spec.alertConfigurations.notifications.typeName \nto  WEBHOOK . Type: string Conditional String that indicates your webhook URL. Atlas Kubernetes Operator  requires this setting if you set\n spec.alertConfigurations.notifications.typeName \nto  WEBHOOK . Type: object Conditional Limit that triggers an alert when exceeded. Atlas Kubernetes Operator  applies this setting if you set\n spec.alertConfigurations.eventTypeName \nto a value other than  OUTSIDE_METRIC_THRESHOLD . Type: string Conditional Comparison operator to apply when  Atlas  checks the current metric value. Atlas Kubernetes Operator  accepts the following values: Atlas Kubernetes Operator  requires this setting if you include the\n spec.alertConfigurations.threshold \nobject. GREATER_THAN LESS_THAN Type: integer Conditional Value of metric that, when exceeded, triggers an alert. Atlas Kubernetes Operator  requires this setting if you include the\n spec.alertConfigurations.threshold \nobject. Type: string Conditional Element that expresses the quantity. You can specify an\nelement of time, storage capacity, and so on. Atlas Kubernetes Operator  accepts the following values: Atlas Kubernetes Operator  requires this setting if you include the\n spec.alertConfigurations.threshold \nobject. BITS BYTES DAYS GIGABITS GIGABYTES HOURS KILOBITS KILOBYTES MEGABITS MEGABYTES MILLISECONDS MINUTES PETABYTES RAW SECONDS TERABYTES Type: boolean Optional Default :  false Flag that indicates whether  Atlas Kubernetes Operator  applies the project\nalert settings defined in  spec.alertConfigurations .\nIf you omit or set to this parameter to  false ,\n Atlas Kubernetes Operator  doesn't syncronize the project's alert\nconfigurations with the ones that you define in\nthe  AtlasProject  custom resource. For information on how this setting interacts with\n spec.withDefaultAlertsSettings ,\nsee the  Considerations . Type : boolean Optional Default :  false Flag that indicates whether to direct the auditing system to capture\nsuccessful authentication attempts for audit filters using the\n \"atype\" : \"authCheck\"  auditing event. To set this parameter to\n true , you must set  spec.auditing.enabled  to  true .\nTo learn more, see  auditAuthorizationSuccess . If you enable  auditAuthorizationSuccess ,\nyou might severely impact cluster performance. Enable\nthis option with caution. Type : string Optional JSON-formatted auditing filter. You might need to escape the\nJSON string to remove characters that could prevent parsing,\nsuch as single or double-quotes. To specify a value for this\nsetting, you must set  spec.auditing.enabled  to  true . To view example auditing filters, see\n Example Auditing Filters . To learn more about configuring\nMongoDB auditing filters, see\n Configure a Custom Auditing Filter . Type : boolean Conditional Default :  false Flag that indicates whether to enable auditing for the project. To\nspecify a value for  spec.auditing.auditFilter , or to set\n spec.auditing.auditAuthorizationSuccess  to  true , you\nmust specify this setting. To learn more, see\n Enable Audit Logs . Type : string Optional Name of the opaque  secret  that contains a single  password \nfield with the organization ID and  API keys  that  Atlas Kubernetes Operator  uses to  connect  to  Atlas .\nIf unspecified,  Atlas Kubernetes Operator  uses the default  global  secret. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: By default,  Atlas Kubernetes Operator  keeps connection secrets in the same  namespace \nas the  AtlasProject  Custom Resource . To store\nsecrets in another  namespace , specify the\n spec.connectionSecretRef.namespace  parameter. Type : string Optional Namespace  that contains the  secret  with the organization ID\nand  API keys  that  Atlas Kubernetes Operator  uses to\n connect  to  Atlas .\nIf unspecified,  Atlas Kubernetes Operator  keeps connection secrets in the same\n namespace  as the  AtlasProject  Custom Resource . Type : array Deprecated . Use  spec.cloudProviderIntegrations  instead. List that contains your  unified cloud provider access  settings. Type : string Deprecated . Use  spec.cloudProviderIntegrations.iamAssumedRoleArn  instead. Unique  AWS (Amazon Web Services)   ARN (Amazon Resource Name)  that identifies the  IAM (Identity and Access Management)  access role that\n Atlas  assumes. If you want to\n set up unified cloud provider access ,\nyou must specify this setting. Type : string Deprecated . Use  spec.cloudProviderIntegrations.providerName  instead. Cloud provider for the access role that  Atlas  assumes.  Atlas Kubernetes Operator \nsupports  AWS  for unified cloud provider access. If you want to\n set up unified cloud provider access , you must specify this setting. Type : array Optional List that contains your  unified cloud provider integration  settings. Type : string Conditional Unique  AWS (Amazon Web Services)   ARN (Amazon Resource Name)  that identifies the  IAM (Identity and Access Management)  access role that\n Atlas  assumes. If you want to\n set up unified cloud provider integrations ,\nyou must specify this setting. Type : string Conditional Cloud provider for the access role that  Atlas  assumes.  Atlas Kubernetes Operator \nsupports  AWS  for unified cloud provider integrations. If you want to\n set up unified cloud provider integrations , you must specify this setting. Type : object Optional Object that contains your custom role specifications. To learn\nmore, see  Configure Custom Database Roles . Type : string Optional Human-readable label that identifies the custom role. The specified role name can only contain letters, digits,\nunderscores, and dashes. Additionally, you cannot specify a role\nname which meets any of the following criteria: Is a name already used by an existing custom role in the\nproject Is a name of any of the  built-in roles Is  atlasAdmin Starts with  xgen- Type : array Optional List of objects that represents the individual\n privilege actions \nthat the role grants. Type : string Optional Human-readable label that identifies the privilege action. For a\ncomplete list of actions available in the Atlas Administration API, see\n /reference/custom-role-actions . Type : array Optional List of objects that indicate a database and collection\non which the action is granted, or indicates that the\naction is granted on the  cluster resource . Type : boolean Optional Flag that indicates that the action is granted on the\n cluster resource . This parameter is mutually exclusive with the\n spec.customRoles.actions.resources.collection  and\n spec.customRoles.actions.resources.db  parameters. Type : string Optional Human-readable label that identifies the collection on which the\naction is granted. If this value is an empty string, the action is\ngranted on all collections within the database specified in the\n spec.customRoles.actions.resources.db  parameter. This parameter is mutually exclusive with the\n spec.customRoles.actions.resources.cluster  parameter. Type : string Optional Human-readable label that indentifies the database on which the\naction is granted. This parameter is mutually exclusive with the\n spec.customRoles.actions.resources.cluster  parameter. Type : array Optional List of objects that represent key-value pairs that\nindicate the inherited role and the database on which the role is\ngranted. Type : string Optional Human-readable label that identifies the database on which the\ninherited role is granted. This value should be  admin  for all roles except\n read  and\n readWrite . Type : string Optional Human-readable label that identifies the inherited role. You can\nspecify another custom role or a  built-in role . Type : array Optional List that contains the configurations for\n encryption at rest using customer-managed keys  for the project. Type : object Optional List that contains the configurations to use  AWS (Amazon Web Services)   KMS (Key Management Service)  for\n encryption at rest using customer-managed keys  for the project. Type : boolean Optional Flag that indicates whether this project uses  AWS (Amazon Web Services)   KMS (Key Management Service) \nto encrypt data at rest. To enable encryption at rest using\n AWS (Amazon Web Services)   KMS (Key Management Service) , set this parameter to  true . To disable\nencryption at rest using  AWS (Amazon Web Services)   KMS (Key Management Service) , set this parameter to\n false . If you disable encryption at rest using  AWS (Amazon Web Services) \n KMS (Key Management Service) ,  Atlas Kubernetes Operator  removes the configuration details. Type : string Optional Label that indicates the  AWS region  where the customer master key exists. Type : string Optional Name of the opaque  secret  that contains your  AWS (Amazon Web Services)  credentials. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: Type : string Optional Namespace that contains your  AWS (Amazon Web Services)  credentials. If unspecified, this\nparameter defaults to the namespace of the  AtlasProject  custom\nresource. Type : object Optional List that contains the configurations to use  Azure (Microsoft Azure)  Key Vault for\n encryption at rest using customer-managed keys  for the project. Type : string Optional Azure (Microsoft Azure)  deployment location where the  Azure (Microsoft Azure)  account\ncredentials reside. Valid values include  AZURE ,\n AZURE_CHINA , and  AZURE_GERMANY . Type : string Optional Unique 36-hexadecimal character string that identifies your  Azure (Microsoft Azure) \napplication. Type : boolean Optional Flag that indicates whether this project uses  Azure (Microsoft Azure)  Key\nusing  Azure (Microsoft Azure)  key vault,  Atlas Kubernetes Operator  removes the configuration\ndetails. Type : string Optional Label that identifies the  Azure (Microsoft Azure)  resource group\nthat contains your  Azure (Microsoft Azure)  Key Vault.  Azure (Microsoft Azure) \ndisplays the resource group name on the resource\ngroup's details page. Type : string Optional Name of the opaque  secret  that contains your  Azure (Microsoft Azure) \ncredentials. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: Type : string Optional Namespace that contains your  Azure (Microsoft Azure)  credentials. If unspecified,\nthis parameter defaults to the namespace of the  AtlasProject \ncustom resource. Type : string Optional Unique 36-hexadecimal character string that identifies the\n Azure (Microsoft Azure)  Active Directory tenant within your  Azure (Microsoft Azure) \nsubscription.  Azure (Microsoft Azure)  displays the tenant ID on the tenant\nproperties page. Type : object Optional List that contains the configurations to use Google Cloud  KMS (Key Management Service)  for\n encryption at rest using customer-managed keys  for the project. Type : string Optional Flag that indicates whether this project uses Google Cloud  KMS (Key Management Service) \nto encrypt data at rest. To enable encryption at rest using\nGoogle Cloud  KMS (Key Management Service) , set this parameter to  true . To disable\nencryption at rest using Google Cloud  KMS (Key Management Service) , set this parameter to\n false . If you disable encryption at rest using Google Cloud\n KMS (Key Management Service) ,  Atlas Kubernetes Operator  removes the configuration details. Type : string Optional Name of the opaque  secret  that contains your  Google Cloud  credentials. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: Type : string Optional Namespace that contains your  Google Cloud  credentials. If unspecified,\nthis parameter defaults to the namespace of the  AtlasProject \ncustom resource. Type : array Optional List that contains your  third-party integration  settings. The parameters that you\nmust specify depend on the third-party service that you want to\nconfigure: Service Settings All spec.integrations.type Datadog spec.integrations.apiKeyRef.name spec.integrations.apiKeyRef.namespace spec.integrations.region Microsoft Teams spec.integrations.microsoftTeamsWebhookURL Opsgenie spec.integrations.apiKeyRef.name spec.integrations.apiKeyRef.namespace spec.integrations.region PagerDuty spec.integrations.serviceKeyRef.name spec.integrations.serviceKeyRef.namespace Prometheus spec.integrations.enabled spec.integrations.passwordRef.name spec.integrations.passwordRef.namespace spec.integrations.scheme spec.integrations.serviceDiscovery spec.integrations.username Slack spec.integrations.apiTokenRef.name spec.integrations.apiTokenRef.namespace VictorOps spec.integrations.apiKeyRef.name spec.integrations.routingKeyRef.name spec.integrations.routingKeyRef.namespace Webhook Settings spec.integrations.secretRef.name spec.integrations.secretRef.namespace spec.integrations.url Type : string Conditional Unique string that identifies your New Relic account. If you want to\nintegrate with New Relic, you must specify this setting. Type : string Conditional Name of the opaque  secret  that contains a single  password \nfield with the API key for Datadog, Opsgenie, or VictorOps. If you\nwant to integrate with Datadog, Opsgenie, or VictorOps, you must\nspecify this setting. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: Type : string Conditional Namespace that contains your API key for Datadog, Opsgenie, or\nVictorOps. If you want to integrate with Datadog,\nOpsgenie, or VictorOps, you must specify this setting. Type : string Conditional Name of the opaque  secret  that contains a single  password \nfield with the API token for Slack. If you want to integrate with\nSlack, you must specify this setting. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: Type : string Conditional Namespace that contains your API token for Slack. If you\nwant to integrate with Slack, you must specify this\nsetting. Type : boolean Conditional Flag that indicates whether your cluster has Prometheus enabled.\nIf you want to integrate with Prometheus, you must specify this\nsetting as  true . Type : string Conditional Name of the opaque  secret  that contains a single  password \nfield with the license key for New Relic. If you want to integrate\nwith New Relic, you must specify this setting. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: Type : string Conditional Namespace that contains your license key for New Relic. If you want\nto integrate with New Relic, you must specify this setting. Type : string Conditional String that specifies your Microsoft Teams incoming webhook  URL (Uniform Resource Locator) .\nIf you want to integrate with Mircosoft Teams, you must specify this\nsetting. Type:  string Conditional Name of the opaque  secret  that contains a single  password \nfield with the Prometheus password. If you want to integrate with\nPrometheus, you must specify this setting. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: Type:  string Conditional Namespace that contains your Prometheus password. If you want to\nintegrate with Prometheus, you must specify this setting. Type : string Conditional Name of the opaque  secret  that contains a single  password \nfield with the Insights Query Key for New Relic. If you want to\nintegrate with New Relic, you must specify this setting. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: Type : string Conditional Namespace that contains your Insights Query Key for New Relic. If\nyou want to integrate with New Relic, you must specify this setting. Type : string Conditional Default :  US String value that indicates the API URL to use for Datadog or\nOpsgenie. If you want to integrate\nwith Datadog or Opsgenie, you must specify this setting. Values for Opsgenie include  US  or  EU . Atlas  supports the following Datadog regions in the\nAtlas Administration API: Datadog uses  US1  ( US  in the Atlas Administration API) by default. To learn more about Datadog's regions, see  Datadog Sites . Atlas Administration API region Corresponding Datadog region US US1 US3 US3 US5 US5 EU EU1 Type : string Conditional Name of the opaque  secret  that contains a single  password \nfield with the routing key for VictorOps. If you want to integrate\nwith VictorOps, you must specify this setting. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: Type : string Conditional Namespace that contains your routing key for VictorOps. If you want\nto integrate with VictorOps, you must specify this setting. Type : string Conditional Name of the opaque  secret  that contains a single  password \nfield with the Webhook secret. If you want to integrate with Webhook\nSettings, you must specify this setting. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: Type : string Conditional Namespace that contains your Webhook secret. If you\nwant to integrate with Webhook Settings, you must specify this\nsetting. Type : string Conditional String that indicates the Prometheus protocol scheme configured for\nrequests. Values include  http  or  https . If you want to\nintegrate with Prometheus, you must specify this setting. Type : string Conditional Human-readable label that indicates the Prometheus service discovery\nmethod to use. Values include  file  or  http . If you want to\nintegrate with Prometheus, you must specify this setting. Type : string Conditional Name of the opaque  secret  that contains a single  password \nfield with the service key for PagerDuty. If you want to integrate\nwith PagerDuty, you must specify this setting. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: Type : string Conditional Namespace that contains your service key for PagerDuty. If you want\nto integrate with PagerDuty, you must specify this setting. Type : string Conditional String value that indicates the third-party service to integrate\nwith  Atlas . Values include: If you want to integrate with a third-party service, you must\nspecify this setting. DATADOG MICROSOFT_TEAMS NEW_RELIC OPS_GENIE PAGER_DUTY PROMETHEUS SLACK VICTOR_OPS WEBHOOK Type : string Conditional String that specifies your Webhook  URL (Uniform Resource Locator) . If you want to integrate\nwith Webhook Settings, you must specify this setting. Type : string Conditional Human-readable label that identifies the Prometheus user. If you\nwant to integrate with Prometheus, you must specify this setting. Type : string Conditional Name of the opaque  secret  that contains a single  password \nfield with the write token for New Relic. If you want to integrate\nwith New Relic, you must specify this setting. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: Type : string Conditional Namespace that contains your write token for New Relic. If you want\nto integrate with New Relic, you must specify this setting. Type : object Optional List that contains your maintenance window settings. You can specify\nthe following body parameters: Name Type Necessity Description dayOfWeek number Required Day of the week that you want the maintenance window to\nstart, as a 1-based integer. Day of Week Integer Sunday 1 Monday 2 Tuesday 3 Wednesday 4 Thursday 5 Friday 6 Saturday 7 hourOfDay number Required Hour of the day that you want the maintenance window to\nstart. This parameter uses the 24-hour clock, where midnight is\n 0  and noon is  12 . autoDeferOnceEnabled boolean Optional Flag that indicates whether you want to defer all\nmaintenance windows one week they would be triggered. Urgent maintenance activities such as security patches cannot\nwait for your chosen window.  Atlas  will start those\nmaintenance activities when needed. Once maintenance is scheduled for your cluster, you cannot change\nyour maintenance window until the current maintenance efforts have\ncompleted. Atlas  performs maintenance the same way as the maintenance\nprocedure described in the\n MongoDB Manual . This\nprocedure requires at least one\n replica set election \nduring the maintenance window per replica set. Maintenance always begins as close to the scheduled hour as\npossible, but in-progress cluster updates or unexpected system\nissues could delay the start time. Type : boolean Conditional Flag that indicates whether  Atlas  should defer all maintenance\nwindows for one week after you enable them. Type : boolean Conditional Flag that indicates whether  Atlas  should defer scheduled\nmaintenance. You must schedule maintenance before you can\nsuccessfully defer maintenance.\n spec.maintenanceWindow.defer  and\n spec.maintenanceWindow.startASAP  can't both be set to\n true  at the same time. While  spec.maintenanceWindow.defer  is set to  true ,\n Atlas Kubernetes Operator  defers scheduled maintenance every time you apply changes\nto the  AtlasProject  custom resource. If you set\n spec.maintenanceWindow.defer  to  true , you should\nchange  spec.maintenanceWindow.defer  to  false  after\nyou apply changes. Type : number Conditional One-based integer that represents the day of the week that the\nmaintenance window starts. Use the following table to find the\ninteger that corresponds to each day: If you want to configure the maintenance window for your project,\nyou must specify this setting. Day of Week Integer Sunday 1 Monday 2 Tuesday 3 Wednesday 4 Thursday 5 Friday 6 Saturday 7 Type : number Conditional Zero-based integer that represents the hour of the of the day that\nthe maintenance window starts according to a 24-hour clock. Use\n 0  for midnight and  12  for noon. If you want to configure the\nmaintenance window for your project, you must specify this setting. Type : boolean Conditional Flag that indicates whether  Atlas  should immediately start\nmaintenance.  spec.maintenanceWindow.defer  and\n spec.maintenanceWindow.startASAP  can't both be set to\n true  at the same time. While  spec.maintenanceWindow.startASAP  is set to\n true ,  Atlas Kubernetes Operator  starts maintenance every time you apply changes\nto the  AtlasProject  custom resource. If you set\n spec.maintenanceWindow.startASAP  to  true , you\nshould change  spec.maintenanceWindow.startASAP  to\n false  after you apply changes. Type : array Optional List that contains the  network peering  configurations for the project. Type : string Optional Designates the project's  AWS (Amazon Web Services)  region for  Atlas for\nGovernment  only. You can\nspecify one of the following values: NONE : If you set  regionUsageRestrictions  to  NONE , value\ndefaults to  COMMERCIAL_FEDRAMP_REGIONS_ONLY . This is the\ndefault if you omit  regionUsageRestrictions . GOV_REGIONS_ONLY : Indicates project is restricted to  AWS (Amazon Web Services) \nGovCloud regions that meet more stringent U.S. government security\nrequirements. To learn more, see the  AWS GovCloud documentation . COMMERCIAL_FEDRAMP_REGIONS_ONLY : Indicates project is\nrestricted to  AWS (Amazon Web Services)   FedRamp  Moderate\nstandard regions. Type : array Required IP access list that grants network access to  Atlas  clusters in\nthe project. You can specify the following body parameters: Parameter Type Necessity Description awsSecurityGroup string Conditional Unique identifier of the  AWS (Amazon Web Services)  security group to add to the\naccess list. Your access list entry can include only one\n awsSecurityGroup , one  cidrBlock , or one  ipAddress . You must  configure VPC peering  for your\nproject before you can add an  AWS (Amazon Web Services)  security group to an\naccess list. cidrBlock string Conditional Range of IP addresses in  CIDR (Classless Inter-Domain Routing)  notation to be added to the\naccess list. Your access list entry can include only one\n awsSecurityGroup , one  cidrBlock , or one  ipAddress . comment string Optional Comment associated with the access list entry. deleteAfterDate date Optional Timestamp in  ISO 8601  date and time format in  UTC (Coordinated Universal Time)  after which  Atlas  removes the entry from the\naccess list. The specified date must be in the future and within\none week of the time you make the  API (Application Programming Interface)  request. You cannot set  AWS (Amazon Web Services)  security groups as temporary access list\nentries. You may include an  ISO 8601  time zone designator to ensure\nthat the expiration date occurs with respect to the local\ntime in the specified time zone. ipAddress string Conditional Single IP address to be added to the access list. Mutually\nexclusive with  awsSecurityGroup  and  cidrBlock . Your access list entry can include only one\n awsSecurityGroup , one  cidrBlock , or one  ipAddress . Type : object Optional List that contains your project settings. Type : boolean Optional Flag that indicates whether your project has collection of database\nstatistics in  cluster metrics \nenabled. Type : boolean Optional Flag that indicates whether your project has  data explorer  enabled. Type : boolean Optional Flag that indicates whether to enable extended storage sizes for the\nspecified project. To learn more about enabling extended storage,\nsee  Manage Project Settings . Type : boolean Optional Flag that indicates whether your project has\n Performance Advisor  enabled. Type : boolean Optional Flag that indicates whether your project has\n Realtime Performance Panel  enabled. Type : boolean Optional Flag that indicates whether your project has  Schema Advisor  enabled. Type : array Optional List that contains the  private endpoint  configurations for the project. Type : object Optional Object that contains your team specifications. To learn more, see  Configure Teams . Type : string Conditional Human-readable label from the  AtlasTeam  Custom Resource  in the\n metadata.name  field. If you want to assign a  team \nto this project, you must specify this setting. Type : string Conditional Namespace specified in the  AtlasTeam  Custom Resource  if other than  default . Type : string Conditional Atlas User Roles  that a team uses for this project. If you want to assign a\n team  to this project, you must specify this setting. Type : boolean Optional Default :  true Flag that indicates whether  Atlas Kubernetes Operator  creates a project\nwith the  default alert configurations .\nIf omitted, defaults to  true . If you use this setting, you must also set\n spec.alertConfigurationSyncEnabled  to  true \nfor  Atlas Kubernetes Operator  to modify project alert configurations. If you set this parameter to  false  when you\ncreate a project,  Atlas  doesn't add the default\nalert configurations to your project. This setting has no effect on existing projects. For information on how this setting interacts with\n spec.alertConfigurationSyncEnabled ,\nsee the  Considerations . Type : string Optional Name of the  kubernetes.io/tls   secret  for the\n X.509 certificate . Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret:",
            "code": [
                {
                    "lang": null,
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n name: my-project\n labels:\n   \u200b\u200bapp.kubernetes.io/version: 1.6.0\nspec:\n name: Test project\n connectionSecretRef:\n   name: my-atlas-key\n   label: atlas.mongodb.com/type=credentials\n projectIpAccessList:\n   - ipAddress: \"192.0.2.15\"\n     comment: \"IP address for Application Server A\"\n   - cidrBlock: \"203.0.113.0/24\"\n     comment: \"CIDR block for Application Server B - D\""
                },
                {
                    "lang": null,
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n   \u200b\u200bapp.kubernetes.io/version: 1.6.0\nspec:\n  name: TestPrometheusIntegration\n  connectionSecretRef:\n    name: my-atlas-key\n  projectIpAccessList:\n    - ipAddress: \"0.0.0.0/1\"\n      comment: \"Everyone has access. For test purposes only.\"\n    - ipAddress: \"128.0.0.0/1\"\n      comment: \"Everyone has access. For test purposes only.\"\n  integrations:\n    - type: \"PROMETHEUS\"\n      enabled: \"true\"\n      username: \"prometheus-user\"\n      passwordRef:\n        name: \"password-name\"\n        namespace: \"password-namespace\"\n      scheme: \"http\"\n      serviceDiscovery: \"http\""
                },
                {
                    "lang": null,
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n   \u200b\u200bapp.kubernetes.io/version: 1.6.0\nspec:\n  name: Test project\n  teams:\n    - teamRef:\n        name: green-leaf-team\n      roles:\n      - ORGANIZATION_OWNER"
                },
                {
                    "lang": null,
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n name: my-project\n labels:\n   \u200b\u200bapp.kubernetes.io/version: 1.6.0\nspec:\n name: Test project\n projectIpAccessList:\n   - ipAddress: \"192.0.2.15\"\n     comment: \"IP address for Application Server A\"\nmaintenanceWindow:\n dayOfWeek: 3\n hourOfDay: 5\n autoDefer: false"
                },
                {
                    "lang": null,
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n name: my-project\n labels:\n   \u200b\u200bapp.kubernetes.io/version: 1.6.0\nspec:\n name: Test project\n projectIpAccessList:\n   - ipAddress: \"192.0.2.15\"\n     comment: \"IP address for Application Server A\"\n settings:\n   isCollectDatabaseSpecificsStatisticsEnabled: false\n   isDataExplorerEnabled: false\n   isExtendedStorageSizesEnabled: false\n   isPerformanceAdvisorEnabled: false\n   isRealtimePerformancePanelEnabled: false\n   isSchemaAdvisorEnabled: false"
                },
                {
                    "lang": null,
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n   \u200b\u200bapp.kubernetes.io/version: 1.6.0\nspec:\n  name: Test Atlas Operator Project\n  connectionSecretRef:\n    name: my-atlas-key\n  alertConfigurations:\n    - eventTypeName: \"REPLICATION_OPLOG_WINDOW_RUNNING_OUT\",\n      enabled: true,\n      notifications:\n      -  delayMin: 0\n         emailEnabled: true\n         intervalMin: 60\n         roles: [ \"GROUP_OWNER\" ]\n         smsEnabled: false\n         typeName: \"GROUP\"\n      threshold:\n         operator: \"LESS_THAN\",\n         threshold: \"1\",\n         units: \"HOURS\"\n  alertConfigurationSyncEnabled: true\n  withDefaultAlertsSettings: false"
                },
                {
                    "lang": null,
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n   \u200b\u200bapp.kubernetes.io/version: 1.6.0\nspec:\n  name: Test Atlas Operator Project\n  connectionSecretRef:\n    name: my-atlas-key\n  alertConfigurations:\n    - eventTypeName: \"REPLICATION_OPLOG_WINDOW_RUNNING_OUT\",\n      enabled: true,\n      notifications:\n      -  delayMin: 0\n         emailEnabled: true\n         intervalMin: 60\n         roles: [ \"GROUP_OWNER\" ]\n         smsEnabled: false\n         - typeName: \"SLACK\"\n           apiTokenRef:\n             name: key-name\n             namespace: key-namespace\n      threshold:\n         operator: \"LESS_THAN\",\n         threshold: \"1\",\n         units: \"HOURS\"\n  alertConfigurationSyncEnabled: true\n  withDefaultAlertsSettings: false"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                }
            ],
            "preview": "Type: string",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-network-peering",
            "title": "Configure Network Peering",
            "headings": [
                "Prerequisites",
                "Procedure",
                "Specify the spec.networkPeers parameter.",
                "Use an Existing Container",
                "Create a New Container",
                "Check for the WAITING FOR USER status.",
                "Accept the VPC (Virtual Private Cloud) peering connection in AWS (Amazon Web Services).",
                "Check the status of your VPC (Virtual Private Cloud) connection using Atlas Kubernetes Operator.",
                "Specify the spec.networkPeers parameter.",
                "Use an Existing Container",
                "Create a New Container",
                "Check the status of your VPC (Virtual Private Cloud) connection using Atlas Kubernetes Operator.",
                "Specify the spec.networkPeers parameter.",
                "Use an Existing Container",
                "Create a New Container",
                "Check for the PENDING ACCEPTANCE status.",
                "Create the VPC (Virtual Private Cloud) peering connection in Google Cloud.",
                "Check the status of your VPC (Virtual Private Cloud) connection using Atlas Kubernetes Operator."
            ],
            "paragraphs": "Atlas  doesn't support network peering\nbetween clusters you deploy in a single region on different cloud\nproviders. To manage your network peering connections with  Atlas Kubernetes Operator , you can\nspecify and update the  spec.networkPeers  parameter for the\n AtlasProject  Custom Resource . Each time you change the  spec \nfield in any of the supported custom resources,  Atlas Kubernetes Operator \n creates or updates  the\ncorresponding  Atlas  configuration. This feature is not available for  M0  free clusters,  M2 , and\n M5  clusters. To learn more,\nsee  Atlas M0 (Free Cluster), M2, and M5 Limits . This feature is not supported on Serverless instances at this time.\nTo learn more, see\n Serverless Instance Limitations . Atlas  supports network peering\nconnections for dedicated clusters hosted on  AWS (Amazon Web Services) ,  Google Cloud , and\n Azure (Microsoft Azure) , and on multi-cloud sharded clusters. Network peering establishes a private\nconnection between your  Atlas   VPC (Virtual Private Cloud)  and your cloud provider's\n VPC (Virtual Private Cloud) . The connection isolates traffic from public networks for added\nsecurity. To configure network peering using  Atlas Kubernetes Operator , you require: A running  Kubernetes  cluster with  Atlas Kubernetes Operator   deployed . The  Project Owner  or\n Organization Owner  role in  Atlas . If you have not already done so, create your  VPC (Virtual Private Cloud)  in  AWS (Amazon Web Services) . To\nlearn more, see  Get Started with Amazon VPC . A  network traffic rule  for outbound traffic. Create the following network traffic rule on your  AWS (Amazon Web Services)  security group\nattached to your resources that connect to  Atlas : Permission Direction Port Target Allow outbound 27015-27017 inclusive to your  Atlas   CIDR (Classless Inter-Domain Routing) A running  Kubernetes  cluster with  Atlas Kubernetes Operator   deployed . The  Project Owner  or\n Organization Owner  role in  Atlas . If you have not already done so, create your VNet in  Azure (Microsoft Azure) .\nTo learn more, see  Create a virtual network using the Azure portal . Azure roles required to configure a network peering connection. To learn more, see the\n Azure Permissions . A service principal for the  Atlas  peering application ID. You must complete the following steps before you create each Azure\nnetwork peering connection: For details about how  Atlas  creates\n Network Peering \nconnections with Azure  VPC (Virtual Private Cloud) s, see the  Azure  tab in\n Set Up a Network Peering Connection . Run the following Azure CLI command to create a service principal\nusing the specified  Atlas  peering application ID: You only have to do this once for each subscription. If you receive\nthe following message, the service principal with the  Atlas \npeering application ID already exists. Proceed to the next step. Copy the following example  peering-role.json  file and save it\nto your current working directory: Replace the variables in the  peering-role.json  with details\nabout the Azure VNet to which you want to create a peering\nconnection: Variable Description azureSubscriptionId Unique identifer of the Azure subscription in which the\nVNet resides. resourceGroupName Name of your Azure resource group. vnetName Name of your Azure VNet. Run the following Azure CLI command to create the role definition\nusing the  peering-role.json  file: Run the Azure CLI command shown below to assign the role you created\nto the service principal. Replace the variables with the same values you used in the\n peering-role.json  file. A running  Kubernetes  cluster with  Atlas Kubernetes Operator   deployed . The  Project Owner  or\n Organization Owner  role in  Atlas . A  Google Cloud  user account with an  IAM (Identity and Access Management)  user policy and a\n Compute Network Admin \nrole that grants permissions to create, modify, and delete\nnetworking resources. To learn more about managing private\nendpoints and connections in  Google Cloud , see\n Create and Modify Virtual Private Cloud (VPC) Networks . If you have not already done so, create your  VPC (Virtual Private Cloud)  in  Google Cloud .\nTo learn more, see the\n GCP documentation . Enable clients to connect to  Atlas  clusters using a network peering connection with the following procedure: You can configure network peering to use an existing\ncontainer or a new container. Specify the  spec.networkPeers  parameter in\nthe  AtlasProject  Custom Resource . Replace the following placeholders with your values: Placeholder Description spec.networkPeers.providerName Cloud provider name. Specify  AWS . spec.networkPeers.containerId Unique identifier for the network peering container you want\nto use. If you don't specify  containerId , you must set\n atlasCIDRblock . To learn more, see the\n Create New Container  section in this procedure. spec.networkPeers.accepterRegionName AWS region  for your  VPC (Virtual Private Cloud) . spec.networkPeers.awsAccountId Unique identifier for your  AWS (Amazon Web Services)  account.  AWS (Amazon Web Services) \ndisplays the account ID when you click\nthe account name in the top right corner of the console home page. spec.networkPeers.routeTableCidrBlock CIDR (Classless Inter-Domain Routing)  block for your  AWS (Amazon Web Services)   VPC (Virtual Private Cloud) .  AWS (Amazon Web Services)  displays\nthe  CIDR (Classless Inter-Domain Routing)  block on your  VPC (Virtual Private Cloud) 's details page. spec.networkPeers.vpcId Unique identifier for your  AWS (Amazon Web Services)   VPC (Virtual Private Cloud) .  AWS (Amazon Web Services) \ndisplays the  VPC (Virtual Private Cloud)  ID on your  VPC (Virtual Private Cloud) 's details page. Run the following command: Specify the  spec.networkPeers  parameter in\nthe  AtlasProject  Custom Resource . Replace the following placeholders with your values: Placeholder Description spec.networkPeers.providerName Cloud provider name. Specify  AWS . spec.networkPeers.atlasCidrBlock Atlas   CIDR (Classless Inter-Domain Routing)  block for which  Atlas Kubernetes Operator  creates a new\ncontainer.\nIf you don't specify  atlasCidrBlock , you must\nspecify the  containerId  of an existing container. To\nlearn more, see the  Use Existing Container \nsection in this procedure. spec.networkPeers.containerRegion (Optional)  AWS (Amazon Web Services)  region in which  Atlas Kubernetes Operator  creates a new\ncontainer. If you don't specify either a  containerRegion \nor a  containerId ,  Atlas Kubernetes Operator  creates a new container in the\nsame region as the  accepterRegionName . spec.networkPeers.accepterRegionName AWS region  for your  VPC (Virtual Private Cloud) . spec.networkPeers.awsAccountId Unique identifier for your  AWS (Amazon Web Services)  account.  AWS (Amazon Web Services) \ndisplays the account ID when you click\nthe account name in the top right corner of the console home page. spec.networkPeers.routeTableCidrBlock CIDR (Classless Inter-Domain Routing)  block for your  AWS (Amazon Web Services)   VPC (Virtual Private Cloud) .  AWS (Amazon Web Services)  displays\nthe  CIDR (Classless Inter-Domain Routing)  block on your  VPC (Virtual Private Cloud) 's details page. spec.networkPeers.vpcId Unique identifier for your  AWS (Amazon Web Services)   VPC (Virtual Private Cloud) .  AWS (Amazon Web Services) \ndisplays the  VPC (Virtual Private Cloud)  ID on your  VPC (Virtual Private Cloud) 's details page. Run the following command: Run the following command: If the  statusName  value is  WAITING FOR USER ,\nproceed\nto the next step. If the  statusName  is not\n WAITING FOR USER , wait a few minutes and try this\nstep again. To learn more, see  Accept a VPC peering connection . Run the following command again to check the status of the\n VPC (Virtual Private Cloud)  connection.  Atlas Kubernetes Operator  returns  READY  when the network peering connection is complete. You can configure network peering to use an existing\ncontainer or a new container. Specify the  spec.networkPeers  parameter in\nthe  AtlasProject  Custom Resource . Replace the following placeholders with your values: Placeholder Description spec.networkPeers.providerName Cloud provider name. Specify  AZURE . spec.networkPeers.containerId Unique identifier for the network peering container you want\nto use. If you don't specify  containerId , you must set\n atlasCIDRblock . To learn more, see the\n Create New Container  section in this procedure. spec.networkPeers.accepterRegionName Azure region  for your\n VPC (Virtual Private Cloud) . spec.networkPeers.azureSubscriptionId Unique identifier for your  Azure (Microsoft Azure)  subscription.\n Azure (Microsoft Azure) \ndisplays the subscription ID on the subscription's\ndetails page. spec.networkPeers.resourceGroupName Human-readable label that identifies the  Azure (Microsoft Azure) \nresource group that contains the  VPC (Virtual Private Cloud) .  Azure (Microsoft Azure)  displays the\nresource group name on the resource group's details page. spec.networkPeers.azureDirectoryId Unique identifier for your  Azure (Microsoft Azure)  Active\nDirectory tenant.  Azure (Microsoft Azure)  displays this as the  Tenant ID \non the tenant properties page. spec.networkPeers.vnetName Human-readable label that identifies your  Azure (Microsoft Azure) \nVNET.  Azure (Microsoft Azure) \ndisplays the VNET name on your VNET's details page. Run the following command: Specify the  spec.networkPeers  parameter in\nthe  AtlasProject  Custom Resource . Replace the following placeholders with your values: Placeholder Description spec.networkPeers.providerName Cloud provider name. Specify  AZURE . spec.networkPeers.atlasCidrBlock Atlas   CIDR (Classless Inter-Domain Routing)  block for which  Atlas Kubernetes Operator  creates a new\ncontainer.\nIf you don't specify  atlasCidrBlock , you must\nspecify the  containerId  of an existing container. To\nlearn more, see the  Use Existing Container \nsection in this procedure. spec.networkPeers.containerRegion (Optional)  Azure region  in which\n Atlas Kubernetes Operator  creates a new\ncontainer. If you don't specify either a  containerRegion \nor a  containerId ,  Atlas Kubernetes Operator  creates a new container in the\nsame region as the  accepterRegionName . spec.networkPeers.accepterRegionName Azure region  for your\n VPC (Virtual Private Cloud) . spec.networkPeers.azureSubscriptionId Unique identifier for your  Azure (Microsoft Azure)  subscription.\n Azure (Microsoft Azure) \ndisplays the subscription ID on the subscription's\ndetails page. spec.networkPeers.resourceGroupName Human-readable label that identifies the  Azure (Microsoft Azure) \nresource group that contains the  VPC (Virtual Private Cloud) .  Azure (Microsoft Azure)  displays the\nresource group name on the resource group's details page. spec.networkPeers.azureDirectoryId Unique identifier for your  Azure (Microsoft Azure)  active\ndirectory tenant.  Azure (Microsoft Azure)  displays this as the  Tenant ID \non the tenant properties page. spec.networkPeers.vnetName Human-readable label that identifies your  Azure (Microsoft Azure) \nVNET.  Azure (Microsoft Azure) \ndisplays the VNET name on your VNET's details page. Run the following command: Run the following command to check the status of the\n VPC (Virtual Private Cloud)  connection.  Atlas Kubernetes Operator  returns  READY  when the network peering connection is complete. You can configure network peering to use an existing\ncontainer or a new container. Specify the  spec.networkPeers  parameter in\nthe  AtlasProject  Custom Resource . Replace the following placeholders with your values: Placeholder Description spec.networkPeers.providerName Cloud provider name. Specify  GCP . spec.networkPeers.containerId Unique identifier for the network peering container you want\nto use. If you don't specify  containerId , you must set\n atlasCIDRblock  and  containerRegion . To learn more,\nsee the  Create New Container  section in this\nprocedure. spec.networkPeers.gcpProjectId Unique identifier for your  Google Cloud  project.  Google Cloud \ndisplays the project ID on the project's details\npage. spec.networkPeers.routeTableCidrBlock CIDR (Classless Inter-Domain Routing)  block for your  Google Cloud   VPC (Virtual Private Cloud) .  Google Cloud  displays\nthe  CIDR (Classless Inter-Domain Routing)  block on your  VPC (Virtual Private Cloud) 's details page. spec.networkPeers.networkName Human-readable label for your  Google Cloud   VPC (Virtual Private Cloud) .  Google Cloud \ndisplays the network name on your  VPC (Virtual Private Cloud) 's details page. Run the following command: Specify the  spec.networkPeers  parameter in\nthe  AtlasProject  Custom Resource . Replace the following placeholders with your values: Placeholder Description spec.networkPeers.providerName Cloud provider name. Specify  GCP . spec.networkPeers.atlasCidrBlock Atlas   CIDR (Classless Inter-Domain Routing)  block for which  Atlas Kubernetes Operator  creates a new\ncontainer.\nIf you don't specify  atlasCidrBlock , you must\nspecify the  containerId  of an existing container. To\nlearn more, see the  Use Existing Container \nsection in this procedure. spec.networkPeers.containerRegion Google Cloud region  for your\n VPC (Virtual Private Cloud) . spec.networkPeers.containerRegion Google Cloud region  in which\n Atlas Kubernetes Operator  creates a new\ncontainer. If you don't specify  containerRegion , you must\nspecify the  containerId  of an existing container. To\nlearn more, see the  Use Existing Container \nsection in this procedure. spec.networkPeers.gcpProjectId Unique identifier for your  Google Cloud  project.  Google Cloud \ndisplays the project ID on the project's details\npage. spec.networkPeers.routeTableCidrBlock CIDR (Classless Inter-Domain Routing)  block for your  Google Cloud   VPC (Virtual Private Cloud) .  Google Cloud  displays\nthe  CIDR (Classless Inter-Domain Routing)  block on your  VPC (Virtual Private Cloud) 's details page. spec.networkPeers.networkName Human-readable label for your  Google Cloud   VPC (Virtual Private Cloud) .  Google Cloud \ndisplays the network name on your  VPC (Virtual Private Cloud) 's details page. Run the following command: Run the following command: If the  status  value is  PENDING ACCEPTANCE ,\nproceed\nto the next step. If the  status  is not\n PENDING ACCEPTANCE , wait a few minutes and try this\nstep again. To learn more, see  Using VPC Network Peering . Run the following command again to check the status of the\n VPC (Virtual Private Cloud)  connection.  Atlas Kubernetes Operator  returns  READY  when the network peering connection is complete.",
            "code": [
                {
                    "lang": "sh",
                    "value": "az ad sp create --id e90a1407-55c3-432d-9cb1-3638900a9d22"
                },
                {
                    "lang": "sh",
                    "value": "Another object with the same value for property servicePrincipalNames already exists."
                },
                {
                    "lang": "json",
                    "value": "{\n  \"Name\":\"AtlasPeering/<azureSubscriptionId>/<resourceGroupName>/<vnetName>\",\n  \"IsCustom\":true,\n  \"Description\":\"Grants MongoDB access to manage peering connections on network /subscriptions/<azureSubscriptionId>/resourceGroups/<resourceGroupName>/providers/Microsoft.Network/virtualNetworks/<vnetName>\",\n  \"Actions\":[\n      \"Microsoft.Network/virtualNetworks/virtualNetworkPeerings/read\",\n      \"Microsoft.Network/virtualNetworks/virtualNetworkPeerings/write\",\n      \"Microsoft.Network/virtualNetworks/virtualNetworkPeerings/delete\",\n      \"Microsoft.Network/virtualNetworks/peer/action\"\n  ],\n  \"AssignableScopes\":[\n      \"/subscriptions/<azureSubscriptionId>/resourceGroups/<resourceGroupName>/providers/Microsoft.Network/virtualNetworks/<vnetName>\"\n  ]\n}"
                },
                {
                    "lang": "sh",
                    "value": "az role definition create --role-definition peering-role.json"
                },
                {
                    "lang": "sh",
                    "value": "az role assignment create  \\\n--role \"AtlasPeering/<azureSubscriptionId>/<resourceGroupName>/<vnetName>\" \\\n--assignee \"e90a1407-55c3-432d-9cb1-3638900a9d22\" \\\n--scope \"/subscriptions/<azureSubscriptionId>/resourceGroups/<resourceGroupName>/providers/Microsoft.Network/virtualNetworks/<vnetName>\""
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: Test Atlas Operator Project\n  networkPeers:\n  - providerName: \"AWS\"\n    containerID: \"6dc5f17280eef56a459fa3fb\"\n    accepterRegionName: \"us-east-2\"\n    awsAccountId: \"12345678\"\n    routeTableCidrBlock: \"10.0.0.0/24\"\n    vpcId: \"vpc-12345678\"\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: Test Atlas Operator Project\n  networkPeers:\n  - providerName: \"AWS\"\n    atlasCidrBlock: \"10.8.0.0/21\"\n    containerRegion: \"us-west-1\"\n    accepterRegionName: \"us-east-2\"\n    awsAccountId: \"12345678\"\n    routeTableCidrBlock: \"10.0.0.0/24\"\n    vpcId: \"vpc-12345678\"\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasprojects my-project -o=jsonpath='{.status.networkPeers.statusName}'"
                },
                {
                    "lang": "json",
                    "value": "WAITING FOR USER"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasprojects my-project -o=jsonpath='{.status.networkPeers.statusName}'"
                },
                {
                    "lang": "json",
                    "value": "READY"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\nspec:\n  name: Test Atlas Operator Project\n  networkPeers:\n  - providerName: \"AZURE\"\n    containerID: \"6dc5f17280eef56a459fa3fb\"\n    atlasCidrBlock: \"10.8.0.0/21\"\n    containerRegion: \"US_WEST\"\n    accepterRegionName: \"US_EAST_2\"\n    azureSubscriptionId: \"12345678\"\n    resourceGroupName: \"my-group\"\n    azureDirectoryId: \"x0xxx10-00x0-0x01-0xxx-x0x0x01xx100\"\n    vnetName: \"my-vnet\"\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\nspec:\n  name: Test Atlas Operator Project\n  networkPeers:\n  - providerName: \"AZURE\"\n    atlasCidrBlock: \"10.8.0.0/21\"\n    containerRegion: \"US_WEST\"\n    accepterRegionName: \"US_EAST_2\"\n    azureSubscriptionId: \"12345678\"\n    resourceGroupName: \"my-group\"\n    azureDirectoryId: \"x0xxx10-00x0-0x01-0xxx-x0x0x01xx100\"\n    vnetName: \"my-vnet\"\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasprojects my-project -o=jsonpath='{.status.networkPeers.status}'"
                },
                {
                    "lang": "json",
                    "value": "READY"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n    name: my-project\nspec:\n  name: Test Atlas Operator Project\n  networkPeers:\n  - providerName: \"GCP\"\n    containerId: \"6dc5f17280eef56a459fa3fb\"\n    gcpProjectId: \"12345678\"\n    routeTableCidrBlock: \"10.0.0.0/24\"\n    networkName: \"my-vpc\"\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n    name: my-project\nspec:\n  name: Test Atlas Operator Project\n  networkPeers:\n  - providerName: \"GCP\"\n    atlasCidrBlock: \"10.8.0.0/21\"\n    containerRegion: \"us-east1\"\n    gcpProjectId: \"12345678\"\n    routeTableCidrBlock: \"10.0.0.0/24\"\n    networkName: \"my-vpc\"\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasprojects my-project -o=jsonpath='{.status.networkPeers.status}'"
                },
                {
                    "lang": "json",
                    "value": "PENDING ACCEPTANCE"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasprojects my-project -o=jsonpath='{.status.networkPeers.status}'"
                },
                {
                    "lang": "json",
                    "value": "READY"
                }
            ],
            "preview": "Atlas doesn't support network peering\nbetween clusters you deploy in a single region on different cloud\nproviders.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "configure-ak8so-access-to-atlas",
            "title": "Configure Access to Atlas",
            "headings": [
                "Atlas Kubernetes Operator Secrets",
                "Parameters",
                "Prerequisites",
                "Procedure"
            ],
            "paragraphs": "To connect to the Atlas Administration API,  Atlas Kubernetes Operator  reads the organization\nID and  API keys  from  Atlas Kubernetes Operator \n secrets . You can also configure the following features: To learn more about creating an  Atlas  account, see\n Register a new Atlas Account . secret storage . network peering . private endpoints . Unified Cloud Provider Integrations . custom database roles . X.509 authentication Encryption at Rest . federated authentication teams . Depending on your configuration,  Atlas Kubernetes Operator  reads from one of the\nfollowing  Atlas Kubernetes Operator   secrets : Scope Location Description Global Atlas Kubernetes Operator   secret   <operator-deployment-name>-api-key \ncreated in the same  namespace  where you installed  Atlas Kubernetes Operator . Atlas Kubernetes Operator  uses this secret data to connect to the\nAtlas Administration API unless the\n AtlasProject  Custom Resource  specifies\n spec.connectionSecretRef.name . global   Atlas Kubernetes Operator   secrets  let you use one  API (Application Programming Interface)  key for\nall the projects in an organization. Any new\n AtlasProject  Custom Resource  uses the same  API (Application Programming Interface)  key for\nreduced overhead. The default name of the  Atlas Kubernetes Operator  deployment is\n mongodb-atlas-operator . So, the  secret  should be\nnamed  mongodb-atlas-operator-api-key . Project Atlas Kubernetes Operator   secret  referenced with\n spec.connectionSecretRef.name  in the\n AtlasProject  Custom Resource . By default,  Atlas Kubernetes Operator  keeps connection secrets in the same  namespace \nas the  AtlasProject  Custom Resource . To store\nsecrets in another  namespace , specify the\n spec.connectionSecretRef.namespace  parameter. Atlas Kubernetes Operator  uses this  secret  data to connect to\nthe Atlas Administration API for any\n AtlasDeployment  Custom Resource \nand  AtlasDatabaseUser  custom resource that references the\nproject. If you do not specify\n spec.connectionSecretRef.name ,  Atlas Kubernetes Operator  uses the\n global   Atlas Kubernetes Operator  secret. Atlas Kubernetes Operator   secrets  per project allow for more granular\naccess. You may want a single  API (Application Programming Interface)  key to have access to a\nsingle  Atlas  project. Both  global  and  project   secrets  require the following\ninformation: Parameter Description orgId Unique 24-digit hexadecimal string used to identify\nyour  Atlas   organization . publicAPIKey Public part of the  API key . privateAPIKey Private part of the  API key . You need the following public API key, private API key, and the\norganization ID information to configure  Atlas Kubernetes Operator  access to  Atlas . If you want  Atlas Kubernetes Operator  to create a new  Atlas  project,\n Create an API (Application Programming Interface) Key in an Organization . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the\n Organization Project Creator  organization role or\nhigher. If you want to work with an existing  Atlas  project,\n Create an API (Application Programming Interface) Key for a Project . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the  Project Owner \nproject role. To configure  Atlas Kubernetes Operator  access to  Atlas , do one of the following\nsteps. For a  global   Atlas Kubernetes Operator   secret , run the following commands: The name of the  global   Atlas Kubernetes Operator  secret must conform to\nthe predefined format. The default name of the  Atlas Kubernetes Operator  deployment\nis  mongodb-atlas-operator . So, the  secret  should be\nnamed  mongodb-atlas-operator-api-key . For a  project   Atlas Kubernetes Operator   secret , run the following commands:",
            "code": [
                {
                    "lang": "sh",
                    "value": "kubectl create secret generic mongodb-atlas-operator-api-key \\\n   --from-literal=\"orgId=<the_atlas_organization_id>\" \\\n   --from-literal=\"publicApiKey=<the_atlas_api_public_key>\" \\\n   --from-literal=\"privateApiKey=<the_atlas_api_private_key>\" \\\n   -n <operator_namespace>\n\nkubectl label secret mongodb-atlas-operator-api-key atlas.mongodb.com/type=credentials -n mongodb-atlas-system"
                },
                {
                    "lang": "sh",
                    "value": "kubectl create secret generic my-project-connection \\\n   --from-literal=\"orgId=<the_atlas_organization_id>\" \\\n   --from-literal=\"publicApiKey=<the_atlas_api_public_key>\" \\\n   --from-literal=\"privateApiKey=<the_atlas_api_private_key>\" \\\n   -n <atlas_project_namespace>\n\nkubectl label secret mongodb-atlas-operator-api-key atlas.mongodb.com/type=credentials -n mongodb-atlas-system"
                }
            ],
            "preview": "To connect to the Atlas Administration API, Atlas Kubernetes Operator reads the organization\nID and API keys from Atlas Kubernetes Operator\nsecrets. You can also configure the following features:",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "atlasfederatedauth-custom-resource",
            "title": "AtlasFederatedAuth Custom Resource",
            "headings": [
                "Examples",
                "Parameters"
            ],
            "paragraphs": "The  AtlasFederatedAuth  custom resource configures\n federated authentication \nfor your  Atlas  organization. To use this resource, you must have an existing identity\nprovider ( IdP (Identity Provider) ) linked to your  Atlas  organization.\nTo learn more, see  Configure Federated Authentication from Kubernetes . When you create the  AtlasFederatedAuth  custom resource,  Atlas Kubernetes Operator \nuses the  Federated Authentication API Resource  to  update \nthe organization configuration for the federation.\nIn the organization configuration, you specify federation settings\nfor your  Atlas  organization such as  organization  and  role mappings . Atlas Kubernetes Operator  uses  custom resource  configuration\nfiles to manage your  Atlas  configuration, but as of  Atlas Kubernetes Operator  2.0,\ncustom resources you delete in  Kubernetes  are no longer deleted in\n Atlas . Instead,  Atlas Kubernetes Operator  simply stops managing those resources.\nFor example, if you delete an  AtlasProject  Custom Resource \nin  Kubernetes ,  Atlas Kubernetes Operator  no longer automatically deletes the corresponding project\nfrom  Atlas , preventing accidental or unexpected deletions. To learn more,\nincluding how to  revert this behavior  to\nthe default used prior to  Atlas Kubernetes Operator  2.0, see  New Default: Deletion Protection in  Atlas Kubernetes Operator  2.0 . The following example shows an  AtlasFederatedAuth  custom resource\nthat configures federated authentication for an organization: The preceding example includes the  status  section,\nwhich describes the update process. To learn more,\nsee  Create and Update Process . This section describes the parameters available\nfor the  AtlasFederatedAuth  custom resource. For\ndetailed descriptions of the parameters, see the\n Atlas Federated Authentication API Resource . Refer to these descriptions, the example on this page, and the\nAPI documentation to customize your specifications. Type : string Required Name that identifies the  AtlasFederatedAuth  custom resource\nthat  Atlas Kubernetes Operator  uses to configure federated authentication\nfor the organization. Type : string Optional Namespace where you want to deploy the  AtlasFederatedAuth  custom resource. Type : boolean Required Flag that determines whether to enable federated\nauthentication for the organization. Defaults to  false . Type : string Required Name of the opaque  secret  that contains a single  password \nfield with the organization ID and  API keys  that  Atlas Kubernetes Operator  uses to  connect  to  Atlas . When you\n create the secret ,\nspecify the  orgID ,  publicApiKey , and  privateApiKey \nfields. The secret's API keys must have the  Organization Owner  role.\nYou can use the same secret from an  AtlasProject  Custom Resource \nonly if the secret has  Organization Owner  permissions. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: By default,  Atlas Kubernetes Operator  keeps connection secrets in the same  namespace \nas the  AtlasProject  Custom Resource . To store\nsecrets in another  namespace , specify the  spec.connectionSecretRef.namespace  parameter. Type : string Optional Namespace  that contains the  secret  with the organization ID\nand  API keys  that  Atlas Kubernetes Operator  uses to\n connect  to  Atlas .\nIf you omit or don't specify this parameter,  Atlas Kubernetes Operator  keeps\nconnection secrets in the same  namespace  as the\n AtlasProject  Custom Resource . Type : array of strings Optional Approved domains that restrict users who can join the organization\nbased on their email address. Type : boolean Required Flag that indicates whether domain restriction is enabled for\nthe connected organization. Defaults to  false . If you set this parameter to  true ,  Atlas  returns a list\nof users that belong to organizations outside of the federation.\nTo learn more, see  User Conflicts . Type : boolean Optional Flag that indicates whether the identity provider has debug enabled\nfor  SSO (Single Sign-On) . Defaults to  false . Type : array of strings Optional Atlas  roles that are granted to a user in this organization after\nauthenticating. For example: For a full list of accepted values, refer to the\n Federated Authentication API Resource . ORG_MEMBER ORG_READ_ONLY ORG_BILLING_ADMIN ORG_GROUP_CREATOR ORG_OWNER ORG_BILLING_READ_ONLY ORG_TEAM_MEMBERS_ADMIN Type : array of objects Optional Role mappings that are configured in this organization. Type : string Required Unique human-readable label that identifies the identity\nprovider group to which this role mapping applies. Type : array of objects Optional Atlas  roles and the unique identifiers of the groups and\norganizations associated with each role. Type : string Optional The  Atlas  project in the same organization to which to associate the\nrole. Type : string Optional Human-readable label that identifies the collection of privileges\nthat  Atlas  grants a specific API key, user, or team.\nThese roles include organization and project-level privileges. Atlas Kubernetes Operator  accepts the following values: ORG_MEMBER ORG_READ_ONLY ORG_BILLING_ADMIN ORG_GROUP_CREATOR ORG_OWNER ORG_BILLING_READ_ONLY ORG_TEAM_MEMBERS_ADMIN GROUP_AUTOMATION_ADMIN GROUP_BACKUP_ADMIN GROUP_MONITORING_ADMIN GROUP_OWNER GROUP_READ_ONLY GROUP_USER_ADMIN GROUP_BILLING_ADMIN GROUP_DATA_ACCESS_ADMIN GROUP_DATA_ACCESS_READ_ONLY GROUP_DATA_ACCESS_READ_WRITE GROUP_CHARTS_ADMIN GROUP_CLUSTER_MANAGER GROUP_SEARCH_INDEX_EDITOR",
            "code": [
                {
                    "lang": null,
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasFederatedAuth\nmetadata:\n  name: atlas-default-federated-auth\n  namespace: mongodb-atlas-system\nspec:\n  enabled: true\n  connectionSecretRef:\n    name: my-org-secret\n    namespace: mongodb-atlas-system\n  domainAllowList:\n    - my-org-domain.com\n  domainRestrictionEnabled: true\n  ssoDebugEnabled: true\n  postAuthRoleGrants:\n    - GLOBAL_AUTOMATION_ADMIN\n  roleMappings:\n    - externalGroupName: myTestGroup\n      roleAssignments:\n       - projectName: myTestProject\n         role: ORG_OWNER\nstatus:\n  conditions:\n    - type: Ready\n      status: True\n    - type: RolesReady\n      status: True\n    - type: UsersReady\n      status: True"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                }
            ],
            "preview": "The AtlasFederatedAuth custom resource configures\nfederated authentication\nfor your Atlas organization.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-secret-storage",
            "title": "Configure Secret Storage",
            "headings": [
                "Considerations",
                "Prerequisites",
                "Procedure",
                "Install the secret provisioning tool in the target cluster.",
                "Set up authentication to access secrets.",
                "Set up automatic secret provisioning.",
                "Deploy Atlas Kubernetes Operator custom resources.",
                "Test your Atlas Kubernetes Operator deployment."
            ],
            "paragraphs": "You can choose where you store sensitive information for the\ncomponents that  Atlas Kubernetes Operator  manages, but  Atlas Kubernetes Operator  must find the  Kubernetes \n secrets  it expects. You can store secrets for  Atlas Kubernetes Operator  in\nmany ways, including the following methods: This tutorial sets up an external secret storage tool for use with\n Atlas Kubernetes Operator . This tutorial focuses on \"secret-less\" setups that don't\nrequire  Atlas Kubernetes Operator  to create and store a secret to provision secrets\nto their  Kubernetes  cluster. Put sensitive information directly into  Kubernetes   secrets . All\ntutorials in the  Atlas Kubernetes Operator  documentation use  Kubernetes   secrets  by\ndefault. To use  Kubernetes   secrets , follow the steps in the\ntutorials. Put sensitive information in a Github repository following a GitOps\nflow. To store sensitive data in git securely you can use tools, such\nas  Sealed Secrets , which encrypts\nsecrets for the intended target cluster. Put sensitive information in an external secret storage tool, such as\n HashiCorp Vault  or Hyperscalers native secret management solutions.\nAn intermediary secret provisioning tool fetches sensitive info from\nthe external secret storage tool and creates  Kubernetes   secrets  from\nthe sensitive information. To learn more about the secret\nprovisioning tool, see  Considerations . The following tutorial installs or configures the following tools and\noptions: A secret provisioning tool . The secret provisioning tool\nuses one or more authentication mechanisms to retrieve the\ncredentials from the secret management service and create\n secrets  that  Atlas Kubernetes Operator  can use. This tutorial installs one\nof the following open-source secret provisioning tools: External Secrets Operator Secrets Store CSI Driver Authentication to access secrets . You can use different\nmethods to authenticate the service accounts and namespaces that can\naccess secrets in  HashiCorp Vault : Alternatively, your cloud provider's  KMS (Key Management Service)  can use native  IAM (Identity and Access Management) \nsystems to provide this authentication, which isn't covered in\nthis tutorial. To learn how to configure your cloud provider's  KMS (Key Management Service) \nfor authentication, see the following resources in the External\nSecrets Operator documentation: For  External Secrets Operator , this tutorial uses\n OIDC (OpenID Connect)   JWT (JSON Web Token)  authentication. To learn more, see\n JWT/OIDC authentication . For  Secrets Store CSI Driver , this tutorial\nuses  Kubernetes  authentication. AWS Secrets Manager Azure Key Vault Google Cloud Secret Manager Before you complete this tutorial, you need the following tools and\nconfigurations: Running service accounts for Kubernetes, Atlas Kubernetes Operator,\nand Atlas  and sufficient privileges to configure them. You need a running  Kubernetes  cluster with nodes running processors with\nthe x86-64, AMD64, or ARM64 architecture. For\nthis tutorial, the  Kubernetes  cluster is  https://kube01.internal.io \nlistening on the default port (443). To deploy the  Atlas Kubernetes Operator , run the following command. Replace\n <version>  with the latest  release number . To register for an  Atlas  account, see  Create an Atlas Account . You can access the  Atlas Kubernetes Operator  project on GitHub: https://github.com/mongodb/mongodb-atlas-kubernetes To install the Atlas Kubernetes operator using the\nAtlas CLI, run the following command: To learn more about the command syntax and parameters, see the\nAtlas CLI documentation for  atlas kubernetes operator install . Install the Atlas CLI Connect to the Atlas CLI API keys . You must  create an API key \nand configure the  API Access List . You need the following public API key, private API key, and the\norganization ID information to configure  Atlas Kubernetes Operator  access to  Atlas . If you want  Atlas Kubernetes Operator  to create a new  Atlas  project,\n Create an API (Application Programming Interface) Key in an Organization . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the\n Organization Project Creator  organization role or\nhigher. If you want to work with an existing  Atlas  project,\n Create an API (Application Programming Interface) Key for a Project . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the  Project Owner \nproject role. A secret storage vault . This tutorial uses  HashiCorp Vault , which\nis a third-party service for secret storage, running at\n https://vault.internal.io . You can use other secret storage vaults with  Atlas Kubernetes Operator  as needed,\nincluding Cloud KMS from AWS, Azure, and Google. Internal access only . To prevent exposing sensitive information\nover the public internet, the following components of the secret\nstorage solution allow internal access only: While the previous components allow internal access only,\nthey allow access to each other and allow access to anyone within your\nteam or organization. This is a best practice for security. The  HashiCorp Vault  or KMS service. The  Kubernetes  Cluster APIs service. The internal network. This tutorial uses  internal.io . Public Certificate Authorities (CAs) . You can use public CAs to\navoid managing and distributing custom CA root certificates. You can automate CA cert management and renewal by using any of the following tools: In this tutorial: ACME Lets Encrypt ZeroSSL DNS Challenges cert-manager All  internal.io  HTTPs services are internal addresses, but\ntheir HTTPS sites hold automatically renewed certificates signed by\na public CA. No mutual TLS (mTLS) is required for this integration because it\nperforms only server-side HTTPS validation. Clients can trust these service certificates without extra\ncertificate provisioning. Follow these steps to configure secret storage for  Atlas Kubernetes Operator . Select a secret provisioning tool to install it. To use  External Secrets Operator  as the secret provisioning\ntool: Run the following commands to install External Secrets Operator\nwith Helm Charts and start the service: Ensure External Secrets runs successfully: To use Secrets Store CSI Driver as the secret provisioning\ntool, follow these steps: Run the following command to install Secrets Store CSI Driver\nwith Helm Charts and start the service: Run the following command to install the Secrets Store CSI  HashiCorp Vault \nplugin with Helm Charts. You don't need to install the  HashiCorp Vault  server\nor secrets injector. Ensure Secrets Store CSI runs successfully: Ensure the  HashiCorp Vault  CSI provider runs successfully: To set up  OIDC (OpenID Connect)   JWT (JSON Web Token)  and  Kubernetes  authentication: Run the following command to enable  OIDC (OpenID Connect)   JWT (JSON Web Token)  authentication\nfor the mount path. If you set up several  Kubernetes  clusters, you must enable  OIDC (OpenID Connect)   JWT (JSON Web Token)  authentication for each cluster's mount path. Run the following command to allow unauthenticated access to the\n OIDC (OpenID Connect)  discovery URLs on the  kube01.internal.io  cluster: Run the following command to direct  HashiCorp Vault  to trust the cluster. The\nissuer for the cluster at  https://kube01.internal.io/  must\nmatch the URL in the  OIDC (OpenID Connect)  discovery document at\n .well-known/openid-configuration . Create the policies that allow access to the secrets you want to\nexpose to the cluster. The following example creates the  external-secrets  policy that\nyou specify in later steps. Run the command to create a  HashiCorp Vault  role and bind a  Kubernetes \nservice account to the role, which restricts the access of the\nservice account within the  HashiCorp Vault . The following command creates the  jwt-kube01-system  role of the\n JWT (JSON Web Token)  ( OIDC (OpenID Connect) ) type for the  vault  audience. The command\nspecifies the  sub  user claim, and the  default   Kubernetes  service\naccount in the  mongodb-atlas-system  namespace\nas the bound subject. This command ties the role to the\n external-secrets  policy set of permissions within  HashiCorp Vault . Run the command to create another role for External Secrets Operator\nto access the  default  namespace. The following command creates the  jwt-kube01-default  role of\nthe  JWT (JSON Web Token)  ( OIDC (OpenID Connect) ) type for the  vault  audience. This command\nspecifies the  sub  user claim, and the  default   Kubernetes  service\naccount in the  default  namespace as the bound subject . This\ncommand ties the role to the  external-secrets  policy set of\npermissions within  HashiCorp Vault . Ensure  OIDC (OpenID Connect)  authentication runs successfully for\nthe system service account: Atlas Kubernetes Operator  returns your  OIDC (OpenID Connect)   JWT (JSON Web Token)  credentials for the system\nservice account. Ensure  OIDC (OpenID Connect)  authentication runs successfully for\nthe default service account: Atlas Kubernetes Operator  returns your  OIDC (OpenID Connect)   JWT (JSON Web Token)  credentials for the default\nservice account. To set up  Kubernetes  authentication: Run the following command to enable  Kubernetes  authentication\nfor the mount path. If you set up several  Kubernetes  clusters, you must\nenable  Kubernetes  authentication for each cluster's mount path. When you install with Helm, it automatically configures cluster role\nbinding. Create policies that allow access to the secrets you want to\nexpose to the cluster. The following example creates the policy  vault-secret  used\nin later steps. It uses  vault , a  Kubernetes   secret  bound\nto the  HashiCorp Vault  service account that the Helm Chart CSI provider sets\nup. Run the commands to trust the  Kubernetes  cluster and use  Kubernetes \nauthentication: Run the command to create a  HashiCorp Vault  role and bind a  Kubernetes \nservice account to the role, which restricts the access of the\nservice account within the  HashiCorp Vault . The following command creates the  k8s-kube01  role at\n auth/k8s-kube01  bound to the  Kubernetes  service account in the\n default  or  mongodb-atlas-system  namespaces. This role ties\nto the  secrets-store  permissions policy within  HashiCorp Vault . The policies must exist and allow access to the secrets. The\nfollowing example policy allows access to KV v2 secrets under the  kube01/secrets-store  path: Ensure  Kubernetes  authentication runs successfully for\nthe system service account: Ensure  Kubernetes  authentication runs successfully for\nthe default account: To provision secrets with External Secrets Operator: Deploy the  SecretStore  custom resource for the  default \nservice account in the  mongodb-atlas-system  namespace: Deploy the  SecretStore  custom resource for the  default \nservice account in the  default  namespace: Deploy the  ExternalSecret  custom resource that references the\nsecret that contains the API key. You must set\n spec.target.template.metadata.labels  to\n atlas.mongodb.com/type  with the value  credentials \nfor  Atlas Kubernetes Operator  to find the secret that External Secrets Operator\ncreates. Before you run the following command, ensure that  HashiCorp Vault  has the\nsecret populated at the Kv V2 path  secret/data/kube01/external-secrets/atlas-account  with the following properties: This command creates the  Kubernetes   secret \n mongodb-atlas-operator-api-key  in the  mongodb-atlas-system \nnamespace. orgId publicApiKey privateApiKey Deploy the  ExternalSecret  custom resource that references the\nsecret that contains database user credentials. You must set\n spec.target.template.metadata.labels  to\n atlas.mongodb.com/type  with the value  credentials \nfor  Atlas Kubernetes Operator  to find the secret that External Secrets Operator\ncreates. Before you run the following command, ensure that  HashiCorp Vault  has the\nsecret populated at the Kv V2 path\n secret/data/kube01/external-secrets/db-user  with the\n password  property. Ensure the secrets return as expected when you run the\nfollowing commands: To provision secrets with Secrets Store CSI: Deploy the  SecretProviderClass  custom resource in the\n mongodb-atlas-system  namespace. You must set\n spec.secretObjects.labels  to\n atlas.mongodb.com/type  with the value  credentials \nfor  Atlas Kubernetes Operator  to find the secret that Secrets Store CSI\ncreates. Before you run the following command, ensure that  HashiCorp Vault  has the\nsecret populated at the Kv V2 path\n secret/data/kube01/external-secrets/atlas-account  with the\nfollowing properties: This command creates the  Kubernetes   secret \n mongodb-atlas-operator-api-key  in the  mongodb-atlas-system \nnamespace. orgId publicApiKey privateApiKey Run the following command to add a pod that mounts the\nrequired secrets: Deploy the  SecretProviderClass  custom resource that references\nthe secret that contains database user credentials. You must set\n spec.target.template.metadata.labels  to\n atlas.mongodb.com/type  with the value  credentials \nfor  Atlas Kubernetes Operator  to find the secret that Secrets Store CSI\ncreates. Before you run the following command, ensure that  HashiCorp Vault  has the\nsecret populated at the Kv V2 path\n secret/data/kube01/external-secrets/db-user  with the\n password  property. Run the following command to create the  secret-placeholder \nsentinel pod, which ensures the Secrets Store CSI driver fetches\nthe  dbuser  credentials and sync them to  Kubernetes : Ensure the secrets return as expected when you run the\nfollowing commands: You can now deploy  Atlas Kubernetes Operator  custom resources.  Atlas Kubernetes Operator \nauthenticates with the  Kubernetes   secrets  that reference your\n HashiCorp Vault . Adjust the  timeout  values as needed for your\ndeployments. To learn more about these custom resources, see\n Custom Resources . To test your  Atlas Kubernetes Operator  deployment, run the following command: Atlas Kubernetes Operator  returns a list of your database deployments.",
            "code": [
                {
                    "lang": "sh",
                    "value": "kubectl apply -f https://raw.githubusercontent.com/mongodb/mongodb-atlas-kubernetes/<version>/deploy/all-in-one.yaml"
                },
                {
                    "lang": "sh",
                    "value": "\natlas kubernetes operator install [options]\n"
                },
                {
                    "lang": "sh",
                    "value": "helm repo add external-secrets https://charts.external-secrets.io"
                },
                {
                    "lang": "sh",
                    "value": "helm upgrade -i --atomic \\\n-n external-secrets --create-namespace --set extraArgs.loglevel=debug \\\nexternal-secrets external-secrets/external-secrets`"
                },
                {
                    "lang": null,
                    "value": "kubectl get pod -n external-secrets -l app.kubernetes.io/name=external-secrets"
                },
                {
                    "lang": null,
                    "value": "NAME                                READY   STATUS    RESTARTS   AGE\nexternal-secrets-5779d5d6f6-2lhgd   1/1     Running   0          70s"
                },
                {
                    "lang": null,
                    "value": "helm repo add secrets-store-csi-driver https://kubernetes-sigs.github.io/secrets-store-csi-driver/charts"
                },
                {
                    "lang": null,
                    "value": "helm upgrade -i --atomic --set syncSecret.enabled=true \\\n  -n kube-system csi-secrets-store secrets-store-csi-driver/secrets-store-csi-driver"
                },
                {
                    "lang": null,
                    "value": "helm install vault hashicorp/vault \\\n--set \"server.enabled=false\" --set \"injector.enabled=false\" \\\n--set \"csi.enabled=true\""
                },
                {
                    "lang": null,
                    "value": "kubectl get pod -n kube-system -l app.kubernetes.io/name=secrets-store-csi-driver"
                },
                {
                    "lang": null,
                    "value": "NAME                                               READY   STATUS    RESTARTS   AGE\ncsi-secrets-store-secrets-store-csi-driver-6dcm8   3/3     Running   0          2m2s"
                },
                {
                    "lang": null,
                    "value": "kubectl get pods -l app.kubernetes.io/name=vault-csi-provider"
                },
                {
                    "lang": null,
                    "value": "NAME                       READY   STATUS    RESTARTS   AGE\nvault-csi-provider-j7xbr   2/2     Running   0          5m39s"
                },
                {
                    "lang": null,
                    "value": "vault auth enable -path=jwt-kube01 jwt"
                },
                {
                    "lang": null,
                    "value": "$ kubectl create clusterrolebinding oidc-reviewer  \\\n  --clusterrole=system:service-account-issuer-discovery \\\n  --group=system:unauthenticated"
                },
                {
                    "lang": null,
                    "value": "curl https://kube01.internal.io/.well-known/openid-configuration | jq .issuer\nhttps://kube01.internal.io/\nvault write auth/jwt-kube01/config jwks_url=\"https://kube01.internal.io/openid/v1/jwks\""
                },
                {
                    "lang": null,
                    "value": "echo external-secrets-policy.hcl\npath \"secret/data/kube01/external-secrets/*\" {\n  capabilities = [\"read\"]\n}"
                },
                {
                    "lang": null,
                    "value": "vault write auth/jwt-kube01/role/jwt-kube01-system role_type=\"jwt\" bound_audiences=vault \\\n  user_claim=\"sub\" bound_subject=\"system:serviceaccount:mongodb-atlas-system:default\" \\\n  policies=\"external-secrets\""
                },
                {
                    "lang": null,
                    "value": "vault write auth/jwt-kube01/role/jwt-kube01-default role_type=\"jwt\" bound_audiences=vault \\\n  user_claim=\"sub\" bound_subject=\"system:serviceaccount:default:default\" \\\n  policies=\"external-secrets\""
                },
                {
                    "lang": null,
                    "value": "export TEST_JWT_TOKEN=$(kubectl -n mongodb-atlas-system create token default --audience \"vault\")\nvault write auth/jwt-kube01/login role=jwt-kube01-system jwt=$(TEST_JWT_TOKEN)"
                },
                {
                    "lang": null,
                    "value": "export TEST_JWT_TOKEN=$(kubectl -n default create token default --audience \"vault\")\nvault write auth/jwt-kube01/login role=jwt-kube01-default jwt=$(TEST_JWT_TOKEN)"
                },
                {
                    "lang": null,
                    "value": "vault auth enable -path=jwt-kube01 kubernetes"
                },
                {
                    "lang": null,
                    "value": "echo vault-secret.yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: vault\n  annotations:\n    kubernetes.io/service-account.name: vault\ntype: kubernetes.io/service-account-token\n$ kubectl apply -f vault-secret.yaml"
                },
                {
                    "lang": null,
                    "value": "export VAULT_JWT ?= $(shell kubectl get secret/vault -o jsonpath='{.data.token}' |base64 -d)"
                },
                {
                    "lang": null,
                    "value": "vault write auth/k8s-kube01/config kubernetes_host=\"kube01.internal.io\" token_reviewer_jwt=$(VAULT_JWT)"
                },
                {
                    "lang": null,
                    "value": "vault write auth/k8s-kube01/role/k8s-kube01-role \\\n  bound_service_account_names=default,mongodb-atlas-operator \\\n  bound_service_account_namespaces=default,mongodb-atlas-system \\\n  policies=secrets-store"
                },
                {
                    "lang": null,
                    "value": "path \"secret/data/kube01/secrets-store/*\" {\n  capabilities = [\"read\"]\n}"
                },
                {
                    "lang": null,
                    "value": "export TEST_JWT_TOKEN=$( kubectl create -n mongodb-atlas-system token mongodb-atlas-operator)\nvault write auth/jwt-kube01/login role=jwt-kube01-system jwt=$(TEST_JWT_TOKEN)"
                },
                {
                    "lang": null,
                    "value": "export TEST_JWT_TOKEN=$(kubectl -n default create token default)\nvault write auth/jwt-kube01/login role=jwt-kube01-default jwt=$(TEST_JWT_TOKEN)"
                },
                {
                    "lang": null,
                    "value": "$ cat external-secrets/vault-system.yaml\napiVersion: external-secrets.io/v1beta1\nkind: SecretStore\nmetadata:\n  name: vault-store\n  namespace: mongodb-atlas-system\nspec:\n  provider:\n    vault:\n      server: \"https://vault.internal.io\"\n      path: \"secret\"\n      version: \"v2\"\n      auth:\n        jwt:\n          path: \"jwt-kube01\"\n          role: \"jwt-kube01-system\"\n          kubernetesServiceAccountToken:\n            expirationSeconds: 600\n            serviceAccountRef:\n              name: \"default\"\n              audiences:\n              - vault\n$ kubectl apply -f external-secrets/vault-system.yaml"
                },
                {
                    "lang": null,
                    "value": "$ cat external-secrets/vault-default.yaml\napiVersion: external-secrets.io/v1beta1\nkind: SecretStore\nmetadata:\n  name: vault-store\n  namespace: default\nspec:\n  provider:\n    vault:\n      server: \"https://vault.internal.io\"\n      path: \"secret\"\n      version: \"v2\"\n      auth:\n        jwt:\n          path: \"jwt-kube01\"\n          role: \"jwt-role\"\n          kubernetesServiceAccountToken:\n            expirationSeconds: 600\n            serviceAccountRef:\n              name: \"default\"\n              audiences:\n              - vault\n$ kubectl apply -f external-secrets/vault-default.yaml"
                },
                {
                    "lang": null,
                    "value": "$ cat external-secrets/atlas.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: atlas\n  namespace: mongodb-atlas-system\nspec:\n    refreshInterval: \"15s\"\n    secretStoreRef:\n      name: vault-store\n      kind: SecretStore\n    target:\n      name: mongodb-atlas-operator-api-key\n      template:\n        metadata:\n          labels:\n            atlas.mongodb.com/type: credentials\n    data:\n    - secretKey: orgId\n      remoteRef:\n        key: secret/data/kube01/external-secrets/atlas-account\n        property: orgId\n    - secretKey: publicApiKey\n      remoteRef:\n        key: secret/data/kube01/external-secrets/atlas-account\n        property: publicApiKey\n    - secretKey: privateApiKey\n      remoteRef:\n        key: secret/data/kube01/external-secrets/atlas-account\n        property: privateApiKey\n  $ kubectl apply -f external-secrets/atlas.yaml"
                },
                {
                    "lang": null,
                    "value": "$ cat external-secrets/dbuser.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: dbuser\n  namespace: default\nspec:\n    refreshInterval: \"15s\"\n    secretStoreRef:\n      name: vault-store\n      kind: SecretStore\n    target:\n      name: dbuser-password\n      template:\n        metadata:\n          labels:\n            atlas.mongodb.com/type: credentials\n    data:\n    - secretKey: password\n      remoteRef:\n        key: secret/data/kube01/external-secrets/db-user\n        property: password\n  $ kubectl apply -f external-secrets/atlas.yaml"
                },
                {
                    "lang": null,
                    "value": "$ kubectl get -n mongodb-atlas-system secrets/mongodb-atlas-operator-api-key"
                },
                {
                    "lang": null,
                    "value": "$ kubectl get -n default secrets/dbuser-password"
                },
                {
                    "lang": null,
                    "value": "$ cat secrets-store/atlas.yaml\napiVersion: secrets-store.csi.x-k8s.io/v1\nkind: SecretProviderClass\nmetadata:\n  name: atlas\n  namespace: mongodb-atlas-system\nspec:\n  provider: vault\n  secretObjects:\n  - data:\n    - key: orgId\n      objectName: atlas-org\n    - key: publicApiKey\n      objectName: atlas-pub-key\n    - key: privateApiKey\n      objectName: atlas-secret-key\n    secretName: mongodb-atlas-operator-api-key\n    type: Opaque\n    labels:\n      atlas.mongodb.com/type: credentials\n  parameters:\n    vaultAddress: https://vault.internal.io\n    vaultKubernetesMountPath: k8s-kube01\n    roleName: k8s-kube01-role\n    objects: |\n      - objectName: atlas-org\n        secretPath: secret/data/kube01/secrets-store/atlas-account\n        secretKey: orgId\n      - objectName: atlas-pub-key\n        secretPath: secret/data/kube01/secrets-store/atlas-account\n        secretKey: publicApiKey\n      - objectName: atlas-secret-key\n        secretPath: secret/data/kube01/secrets-store/atlas-account\n        secretKey: privateApiKey\n$ kubectl apply -f secrets-store/atlas.yaml"
                },
                {
                    "lang": null,
                    "value": "$ cat secrets-store/ako-patch.yaml\n  template:\n    spec:\n      containers:\n      - name: system-secret-placeholder\n        image: mongodb/atlas\n        command: [\"sleep\", \"infinity\"]\n        volumeMounts:\n        - name: secrets-store-mount\n          mountPath: \"/mnt/secrets-store\"\n          readOnly: true\n      volumes:\n        - name: secrets-store-mount\n          csi:\n            driver: secrets-store.csi.k8s.io\n            readOnly: true\n            volumeAttributes:\n              secretProviderClass: atlas\n$ kubectl apply -f secrets-store/ako-patch.yaml"
                },
                {
                    "lang": null,
                    "value": "$ cat external-secrets/dbuser.yaml\napiVersion: external-secrets.io/v1beta1\nkind: SecretProviderClass\nmetadata:\n  name: dbuser\n  namespace: default\nspec:\n  provider: vault\n  secretObjects:\n  - data:\n    - key: password\n      objectName: dbuser\n    secretName: dbuser-password\n    type: Opaque\n    labels:\n      atlas.mongodb.com/type: credentials\n parameters:\n    vaultAddress: https://vault.internal.io\n    vaultKubernetesMountPath: k8s-kube01\n    roleName: k8s-kube01-role\n    objects: |\n      - objectName: \"dbuser\"\n        secretPath: \"secret/data/kube01/secrets-store/db-user\"\n        secretKey: \"password\"\n$ kubectl apply -f secrets-store/dbuser.yaml"
                },
                {
                    "lang": null,
                    "value": "$ cat secrets-store/placeholder.yaml\nkind: Pod\napiVersion: v1\nmetadata:\n  name: secret-placeholder\nspec:\n  containers:\n  - image: mongodb/atlas\n    command: [\"sleep\", \"infinity\"]\n    name: secret-placeholder\n    volumeMounts:\n    - name: secrets-store-mount\n      mountPath: \"/mnt/secrets-store\"\n      readOnly: true\n  volumes:\n    - name: secrets-store-mount\n      csi:\n        driver: secrets-store.csi.k8s.io\n        readOnly: true\n        volumeAttributes:\n          secretProviderClass: dbuser\n$ kubectl apply -f secrets-store/placeholder.yaml"
                },
                {
                    "lang": null,
                    "value": "$ kubectl get -n mongodb-atlas-system secrets/mongodb-atlas-operator-api-key"
                },
                {
                    "lang": null,
                    "value": "$ kubectl get -n default secrets/dbuser-password"
                },
                {
                    "lang": null,
                    "value": "kubectl apply -f ako/project.yaml\nkubectl apply -f ako/deployment.yaml\nkubectl apply -f ako/user.yaml\nkubectl wait --for=condition=ready atlasdeployment/serverless-deployment --timeout=10m\nkubectl wait --for=condition=ready atlasdatabaseuser/user --timeout=10m"
                },
                {
                    "lang": null,
                    "value": "export ATLAS_DEPLOYMENT_CONN_STR=$(kubectl get secrets/test-atlas-operator-project-test-serverless-deployment-dbuser -o jsonpath='{.data.connectionStringStandardSrv}' |base64 -d)\nmongosh $(ATLAS_DEPLOYMENT_CONN_STR) --apiVersion 1 --eval \"show dbs\""
                }
            ],
            "preview": "You can choose where you store sensitive information for the\ncomponents that Atlas Kubernetes Operator manages, but Atlas Kubernetes Operator must find the Kubernetes\nsecrets it expects. You can store secrets for Atlas Kubernetes Operator in\nmany ways, including the following methods:",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "",
            "title": "Atlas Kubernetes Operator",
            "headings": [
                "What is Atlas Kubernetes Operator?",
                "What Can You Do?",
                "New Default: Deletion Protection in Atlas Kubernetes Operator 2.0",
                "Revert New Deletion Protection Default",
                "Get Hands-On Experience with Atlas Kubernetes Operator"
            ],
            "paragraphs": "Atlas Kubernetes Operator  is a new service that integrates  Atlas  resources with your\n Kubernetes  cluster. You can now deploy and manage the lifecycle of your\ncloud-native applications that need data services in a single control\nplane with secure enterprise platform integration. To learn more, see  Quick Start . Atlas Kubernetes Operator  uses  custom resource  configuration\nfiles to manage your  Atlas  configuration, but as of  Atlas Kubernetes Operator  2.0,\ncustom resources you delete in  Kubernetes  are no longer deleted in\n Atlas . Instead,  Atlas Kubernetes Operator  simply stops managing those resources.\nFor example, if you delete an  AtlasProject  Custom Resource \nin  Kubernetes ,  Atlas Kubernetes Operator  no longer automatically deletes the corresponding project\nfrom  Atlas , preventing accidental or unexpected deletions. To learn more,\nincluding how to  revert this behavior  to\nthe default used prior to  Atlas Kubernetes Operator  2.0, see  New Default: Deletion Protection in  Atlas Kubernetes Operator  2.0 . You can use  Atlas Kubernetes Operator  to manage resources in  Atlas  without leaving\n Kubernetes . You deploy  Atlas Kubernetes Operator  into  Kubernetes  clusters.  Atlas Kubernetes Operator \nmanages resources in  Atlas  based on  Kubernetes   custom resources . It ensures that the state of the projects,\ndatabase deployments, and database users in  Atlas  matches the\nconfigurations in each  AtlasProject  Custom Resource ,\n AtlasDeployment  Custom Resource , and\n AtlasDatabaseUser  Custom Resource  that you\ncreate in your  Kubernetes  cluster. Atlas Kubernetes Operator  supports many advanced features within the\n Custom Resources , such as  X509 authentication ,  private endpoints in Azure and AWS , and\n advanced multi-cloud and multi-region clusters . With  Atlas Kubernetes Operator  2.0, custom resources you delete in  Kubernetes  are no longer deleted in\n Atlas . Instead,  Atlas Kubernetes Operator  simply stops managing those resources. For example, if you delete an  AtlasProject  Custom Resource \nin  Kubernetes ,  Atlas Kubernetes Operator  no longer automatically deletes the corresponding project\nfrom  Atlas , preventing accidental or unexpected deletions. This applies to\nall  objects managed using custom resources . You can  revert this behavior  to the default\nused prior to  Atlas Kubernetes Operator  2.0 for your entire deployment or for specific custom\nresources or subobjects. Use the following tables to determine\nthe correct behavior for your deployment: Subobjects are objects that you define within another custom resource instead of\ntheir own dedicated custom resource, such as\n private endpoints  or\n IP access lists , and behave as follows: Deletion Protection No Deletion Protection New default as of  Atlas Kubernetes Operator  2.0 Default prior to  Atlas Kubernetes Operator  2.0 If you delete a custom resource or objects from a custom resource,\nthe corresponding objects remain in  Atlas  but  Atlas Kubernetes Operator  no longer\nmanages them. You can manage objects decoupled from  Atlas Kubernetes Operator  only\nfrom another interface, such as the Atlas UI. If you delete a custom resource or objects from a custom resource,\n Atlas Kubernetes Operator  deletes the corresponding objects in  Atlas , even objects\ndeployed prior to using  Atlas Kubernetes Operator . Changes to a\ncustom resource overwrite changes in  Atlas  made using another\ninterface, such as the Atlas UI. Deletion Protection for Subobjects No Deletion Protection for Subobjects New default as of  Atlas Kubernetes Operator  2.0 Default prior to  Atlas Kubernetes Operator  2.0 If you delete a subobject from a custom resource,  Atlas Kubernetes Operator  deletes the\ncorresponding subobject from  Atlas   only  if that subobject existed\nin the custom resource during the last reconciliation and matches exactly. For example, if you delete a private endpoint from the\n AtlasProject  Custom Resource ,  Atlas Kubernetes Operator  checks if it existed in the\ncustom resource during the last reconciliation and matches exactly, meaning it\nwasn't created or changed by another interface, such as the Atlas UI.\nIf it doesn't match exactly,  Atlas Kubernetes Operator  does  not  reconcile the\n AtlasProject  Custom Resource .\nFor this reason, we recommend against using the Atlas UI\nto administer  Atlas Kubernetes Operator  projects and deployments. Alert  subobjects are exceptions\nwith their own sync controls. If you delete a subobject from a custom resource,  Atlas Kubernetes Operator  deletes the\ncorresponding subobject from  Atlas   and all other subobjects of the same type ,\neven if they existed in  Atlas  prior to using  Atlas Kubernetes Operator  or were created\nor changed by another interface, such as the Atlas UI. For example, if you delete a private endpoint from the\n AtlasProject  Custom Resource ,  Atlas Kubernetes Operator  overwrites  Atlas  with\nwhat you configured in the custom resource, including overwriting any private endpoints\nyou added using the Atlas UI.\nFor this reason, we recommend against using the Atlas UI\nto administer  Atlas Kubernetes Operator  projects and deployments. Alert  subobjects are exceptions\nwith their own sync controls. You can control the new deletion protection behavior using the\n --object-deletion-protection  flag or the\n OBJECT_DELETION_PROTECTION  environment\nvariable in the  Kubernetes \n Deployment resource  that you applied when installing  Atlas Kubernetes Operator .\nThis flag and environment variable all default to  true .\nSet to  false  to revert to the behavior prior to  Atlas Kubernetes Operator  2.1. You can also control which behavior to use for individual custom resources using\nthe  atlas-resource-policy  annotations described in  Use Annotations to Skip or Override Defaults . Goal Action Create your first cluster in  Atlas  with  Atlas Kubernetes Operator . See one of the following tutorials: Quick Start Helm Charts Quick Start Configure  Atlas Kubernetes Operator  access to  Atlas . See  Configure Access to  Atlas . Manage resources. See  Custom Resources . Create and configure a federated database instance ,\nincluding  private endpoints for a federated database instance . Configure the  AtlasDataFederation  Custom Resource . Set up  X509 authentication . Configure the  AtlasProject  Custom Resource  and\n AtlasDatabaseUser  Custom Resource . Manage  private endpoints . For dedicated clusters, specify the\n spec.privateEndpoints  parameter for the\n AtlasProject  Custom Resource . For serverless instances, specify the\n spec.serverlessSpec.privateEndpoints  parameter for\nthe  AtlasDeployment  Custom Resource . For federated database instances, specify the\n spec.privateEndpoints \nparameter for the  AtlasDataFederation  Custom Resource . Set up  network peering . Configure the  AtlasProject  Custom Resource . Set up unified access for an  AWS (Amazon Web Services)   IAM (Identity and Access Management)  role. Configure the  AtlasProject  Custom Resource . Configure federated authentication for your Atlas\norganization . Configure the  AtlasFederatedAuth  Custom Resource . Create or update  custom database roles . Configure the  AtlasProject  Custom Resource . Encrypt data at rest using a key management service . Configure the  AtlasProject  Custom Resource \nand the  AtlasDeployment  Custom Resource . Set up  database auditing . Configure the  AtlasProject  Custom Resource . Set up  cloud backup . Configure the  AtlasBackupPolicy  Custom Resource ,\n AtlasBackupSchedule  Custom Resource , and\n AtlasDeployment  Custom Resource . Set up  teams . Configure the  AtlasTeam  Custom Resource  and\n AtlasProject  Custom Resource . Configure the maintenance window during which  Atlas  starts\nweekly maintenance on your database deployments. Configure the  AtlasProject  Custom Resource . Integrate with  third-party services . Configure the  AtlasProject  Custom Resource .",
            "code": [],
            "preview": "Atlas Kubernetes Operator is a new service that integrates Atlas resources with your\nKubernetes cluster. You can now deploy and manage the lifecycle of your\ncloud-native applications that need data services in a single control\nplane with secure enterprise platform integration.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-for-gov",
            "title": "Configure Atlas Kubernetes Operator for Atlas for Government",
            "headings": [
                "Prerequisites",
                "Procedure",
                "Edit the Atlas Kubernetes Operator Deployment manifest to set the target to the domain of Atlas for Government.",
                "Locate the atlas-domain setting under spec.containers.args in the file.",
                "Modify the domain to set the target to Atlas for Government.",
                "Deploy Atlas Kubernetes Operator.",
                "Set the AWS (Amazon Web Services) region for Atlas for Government."
            ],
            "paragraphs": "You can use the  Atlas Kubernetes Operator  to manage resources in  Atlas  for Government.\nThe  Atlas Kubernetes Operator  only supports managing  Atlas  for Government on  AWS (Amazon Web Services) . It\ndoesn't support Atlas Data Federation and Serverless deployments. For more\ninformation, see  Supported Features  in the  MongoDB Atlas \nfor Government documentation. This page describes how to configure the  Atlas Kubernetes Operator  to manage resources in\n Atlas  for Government. You must install the  Atlas Kubernetes Operator . If you install the  Atlas Kubernetes Operator  using\nAtlas CLI with the  --gov  flag, you can skip steps 1 - 3 in the\nfollowing procedure. If you don't specify  --gov  flag for installing\nthe  Atlas Kubernetes Operator , complete all the steps in the following procedure. To learn more about installing the  Atlas Kubernetes Operator  using the Atlas CLI, see\n Quick Start . After you install the  Atlas Kubernetes Operator , do the following: For example, to edit using  kubectl : To configure the domain, replace the value of  --atlas-domain \nwith the following  URL (Uniform Resource Locator) : Follow the procedure in the  Quick Start  to deploy\n Atlas Kubernetes Operator . Use the  spec.regionUsageRestrictions  parameter in the\n AtlasProject  custom resource to set the  AWS (Amazon Web Services)  region for\n Atlas  for Government. If you omit the\n spec.regionUsageRestrictions  parameter,\n Atlas Kubernetes Operator  restricts the project to  AWS (Amazon Web Services)   FedRamp  Moderate standard regions by\ndefault. To learn more, see\n spec.regionUsageRestrictions .",
            "code": [
                {
                    "lang": "shell",
                    "value": "kubectl edit deployments.apps -n default <your-mongodb-atlas-operator>"
                },
                {
                    "lang": "shell",
                    "value": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  ...\nspec:\n  progressDeadlineSeconds: 600\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    ...\n  strategy:\n   ...\n  template:\n    metadata:\n      ...\n    spec:\n      containers:\n      - args:\n        - --atlas-domain=https://cloud.mongodb.com/\n        - --leader-elect\n        - --health-probe-bind-address=:8081\n        - --metrics-bind-address=127.0.0.1:8080\n        - --log-level=info\n        - --log-encoder=json\n        command:\n        - /manager\n        env:\n        - name: OPERATOR_POD_NAME\n ..."
                },
                {
                    "lang": "shell",
                    "value": "https://cloud.mongodbgov.com/"
                }
            ],
            "preview": "You can use the Atlas Kubernetes Operator to manage resources in Atlas for Government.\nThe Atlas Kubernetes Operator only supports managing Atlas for Government on AWS (Amazon Web Services). It\ndoesn't support Atlas Data Federation and Serverless deployments. For more\ninformation, see Supported Features in the MongoDB Atlas\nfor Government documentation.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-alert-configurations",
            "title": "Configure Project Alerts",
            "headings": [
                "Considerations",
                "Prerequisites",
                "Procedure"
            ],
            "paragraphs": "You can use  Atlas Kubernetes Operator  to configure alerts to help\nyou monitor access to and the state of the\ndatabase deployments in your  Atlas  projects. To learn more, see  Configure Alert Settings . In your  AtlasProject  Custom Resource , use the\n spec.alertConfigurationSyncEnabled  and\n spec.withDefaultAlertsSettings  settings to\nmanage  Atlas  alert configurations. The following\ntable describes the action that  Atlas Kubernetes Operator  takes based on\nhow you configure these settings: spec.alertConfigurationSyncEnabled spec.withDefaultAlertsSettings Behavior true true Atlas Kubernetes Operator  creates a project using the default alert configuration.\nAfter  Atlas Kubernetes Operator  creates the project, the alert confgurations that\nyou define in your  AtlasProject  Custom Resource  override\nthe alert configurations on  Atlas  for your project. true false Atlas Kubernetes Operator  creates a project without adding the default alert configurations.\nAfter  Atlas Kubernetes Operator  creates the project, the alert confgurations that\nyou define in your  AtlasProject  Custom Resource  override\nthe alert configurations on  Atlas  for your project. false true Atlas Kubernetes Operator  creates a project using the default alert configuration.\n Atlas Kubernetes Operator  doesn't syncronize alert definitions on  Atlas  with those\nyou define in your  AtlasProject  Custom Resource . false false Atlas Kubernetes Operator  creates a project without adding the default alert configurations.\n Atlas Kubernetes Operator  doesn't syncronize alert definitions on  Atlas  with those\nyou define in your  AtlasProject  Custom Resource . To learn more, see  Configure Access to  Atlas . You need the following public API key, private API key, and the\norganization ID information to configure  Atlas Kubernetes Operator  access to  Atlas . If you want  Atlas Kubernetes Operator  to create a new  Atlas  project,\n Create an API (Application Programming Interface) Key in an Organization . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the\n Organization Project Creator  organization role or\nhigher. If you want to work with an existing  Atlas  project,\n Create an API (Application Programming Interface) Key for a Project . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the  Project Owner \nproject role. To configure project alerts, configure the\n AtlasProject  Custom Resource . Example: The parameters that you must specify in the\n AtlasProject  Custom Resource  depend on the alert\nthat you want to configure. To learn more about the configuration parameters available from\nthe  API (Application Programming Interface) , see  Alert Configurations .",
            "code": [
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: TestAlertConfig\n  connectionSecretRef:\n    name: my-atlas-key\n  projectIpAccessList:\n    - ipAddress: \"0.0.0.0/1\"\n      comment: \"Everyone has access. For test purposes only.\"\n    - ipAddress: \"128.0.0.0/1\"\n      comment: \"Everyone has access. For test purposes only.\"\n  alertConfigurations:\n  - eventTypeName: \"REPLICATION_OPLOG_WINDOW_RUNNING_OUT\",\n    enabled: true,\n    notifications:\n      -  delayMin: 0\n         emailEnabled: true\n         intervalMin: 60\n         roles: [ \"GROUP_OWNER\" ]\n         smsEnabled: false\n         typeName: \"GROUP\"\n      threshold:\n         operator: \"LESS_THAN\",\n         threshold: 1,\n         units: \"HOURS\"\n  alertConfigurationSyncEnabled: true\n  withDefaultAlertsSettings: false\n EOF"
                }
            ],
            "preview": "You can use Atlas Kubernetes Operator to configure alerts to help\nyou monitor access to and the state of the\ndatabase deployments in your Atlas projects.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "custom-resources",
            "title": "Custom Resources",
            "headings": [
                "Atlas Kubernetes Operator Workflow",
                "Create and Update Process",
                "Delete Process",
                "Use Annotations to Skip or Override Defaults"
            ],
            "paragraphs": "Atlas Kubernetes Operator  supports the following custom resources: Resource Description AtlasBackupPolicy  Custom Resource Configuration of a backup policy to back up your cluster\n Atlas . AtlasBackupSchedule  Custom Resource Configuration of a backup schedule to back up your cluster\n Atlas . AtlasDeployment  Custom Resource Configuration of a cluster inside some project in  Atlas . AtlasDatabaseUser  Custom Resource Configuration of a database user inside some project in\n Atlas . AtlasProject  Custom Resource Configuration of a project in  Atlas . AtlasTeam  Custom Resource Configuration of a project team in  Atlas . AtlasDataFederation  Custom Resource Configuration of a federated database instance and its private endpoints in\n Atlas . AtlasFederatedAuth  Custom Resource Configuration of federated authentication in  Atlas . Atlas Kubernetes Operator  uses  custom resource  configuration\nfiles to manage your  Atlas  configuration, but as of  Atlas Kubernetes Operator  2.0,\ncustom resources you delete in  Kubernetes  are no longer deleted in\n Atlas . Instead,  Atlas Kubernetes Operator  simply stops managing those resources.\nFor example, if you delete an  AtlasProject  Custom Resource \nin  Kubernetes ,  Atlas Kubernetes Operator  no longer automatically deletes the corresponding project\nfrom  Atlas , preventing accidental or unexpected deletions. To learn more,\nincluding how to  revert this behavior  to\nthe default used prior to  Atlas Kubernetes Operator  2.0, see  New Default: Deletion Protection in  Atlas Kubernetes Operator  2.0 . When you use  Atlas Kubernetes Operator , you can create a new  Atlas  project, or you\ncan work with an existing  Atlas  project. To learn more, see  Configure Access to  Atlas . You need the following public API key, private API key, and the\norganization ID information to configure  Atlas Kubernetes Operator  access to  Atlas . If you want  Atlas Kubernetes Operator  to create a new  Atlas  project,\n Create an API (Application Programming Interface) Key in an Organization . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the\n Organization Project Creator  organization role or\nhigher. If you want to work with an existing  Atlas  project,\n Create an API (Application Programming Interface) Key for a Project . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the  Project Owner \nproject role. Each time you change the  spec  field in any of the supported\ncustom resources, the following workflow begins in  Atlas Kubernetes Operator : Atlas Kubernetes Operator  receives an event about the changed custom resource. Atlas Kubernetes Operator  updates the  status.conditions  field to reflect that the\nresource is not ready: To connect to the Atlas Administration API,  Atlas Kubernetes Operator  reads the organization\nID and  API (Application Programming Interface)  keys from one of the following locations: spec.connectionSecretRef.name  (if specified in\nthe  AtlasProject  Custom Resource ). By default,  Atlas Kubernetes Operator  keeps connection secrets in the same  namespace \nas the  AtlasProject  Custom Resource . To store\nsecrets in another  namespace , specify the\n spec.connectionSecretRef.namespace  parameter. global   Atlas Kubernetes Operator   secret \n <operator-deployment-name>-api-key \n(if  spec.connectionSecretRef.name  is not specified). To create or update resources in  Atlas ,  Atlas Kubernetes Operator  uses the\nconnection information to make  API (Application Programming Interface)  calls to  Atlas . Sometimes  Atlas Kubernetes Operator  makes multiple  API (Application Programming Interface)  calls in  Atlas  during\nthe reconciliation of a custom resource. For example,\n AtlasProject  has an  IP Access List \nconfiguration for calling the matching  API . If any errors occur during the reconciliation,  status.conditions \nupdates to reflect the error. If the update succeeds,  status.conditions  reflects that the\nresource is ready: As of  Atlas Kubernetes Operator  2.0, when you delete a custom resource from  Kubernetes , the object\nstays in  Atlas  by default but  Atlas Kubernetes Operator \n no longer controls the object . You can\n revert this default for your entire deployment ,\nor override this default for a specific custom resource with an\n annotation  to allow  Atlas Kubernetes Operator  to delete the\ncorresponding object from  Atlas . If you override with an annotation,\nthe following workflow begins: Atlas Kubernetes Operator  receives an event about the deleted custom resource. To connect to the Atlas Administration API,  Atlas Kubernetes Operator  reads the\norganization ID\nand  API (Application Programming Interface)  keys from one of the following locations: spec.connectionSecretRef.name  (if specified in\nthe  AtlasProject  Custom Resource ). By default,  Atlas Kubernetes Operator  keeps connection secrets in the same  namespace \nas the  AtlasProject  Custom Resource . To store\nsecrets in another  namespace , specify the\n spec.connectionSecretRef.namespace  parameter. global   Atlas Kubernetes Operator   secret \n <operator-deployment-name>-api-key \n(if  spec.connectionSecretRef.name  is not specified). To delete the resource from  Atlas ,  Atlas Kubernetes Operator  uses the connection\ninformation to make  API (Application Programming Interface)  calls to  Atlas . Atlas Kubernetes Operator  removes any related objects created in  Kubernetes . For\nexample, if you remove  AtlasDatabaseUser ,  Atlas Kubernetes Operator  removes the\nrelated connection  secrets . You can use annotations to modify the  new default behaviour \nof  Atlas Kubernetes Operator . If you add the  mongodb.com/atlas-resource-policy: \"delete\"  annotation\nto a custom resource's  metadata ,  Atlas Kubernetes Operator  deletes the corresponding object in  Atlas \nwhen you delete the  Atlas Kubernetes Operator  resource. Example If you have  reverted the new delete behavior \nto the default used prior to  Atlas Kubernetes Operator  2.0, you can add the\n mongodb.com/atlas-resource-policy: \"keep\"  annotation\nto a custom resource's  metadata  so  Atlas Kubernetes Operator  won't delete the\nresource when you delete the  Atlas Kubernetes Operator  resource. If you add the  mongodb.com/atlas-reconciliation-policy: \"skip\" \nannotation to a custom resource's  metadata ,  Atlas Kubernetes Operator  doesn't start\nthe reconciliation for the resource. This annotation lets you pause the\nsync with the spec until you remove the annotation. You can use this\nannotation to make manual changes to a custom resource and avoid\n Atlas Kubernetes Operator  undoing them during a sync. When you remove this annotation,\n Atlas Kubernetes Operator  reconciles the resource and syncs it with the spec. If you add the  mongodb.com/atlas-resource-version-policy: \"allow\" \nannotation to a custom resource's  metadata ,  Atlas Kubernetes Operator  lets you use a\nresource even if its version label doesn't match the version of\n Atlas Kubernetes Operator  that you are using. If your resource version is a major version\nbehind your  Atlas Kubernetes Operator  version, the latest features might not work. Minor\nversion discrepancies are backward-compatible.",
            "code": [
                {
                    "lang": "sh",
                    "value": "conditions:\n- lastTransitionTime: \"2021-03-13T16:26:17Z\"\n  status: \"False\"\n  type: Ready"
                },
                {
                    "lang": "sh",
                    "value": "- lastTransitionTime: \"2021-03-15T14:26:44Z\"\n   message: 'POST https://cloud.mongodb.com/api/atlas/v1.0/groups/604a47de73cd8cag77239021/accessList:\n      400 (request \"INVALID_IP_ADDRESS_OR_CIDR_NOTATION\") The address 192.0.2.1dfdfd5\n      must be in valid IP address or CIDR notation.'\n   reason: ProjectIPAccessListNotCreatedInAtlas\n   status: \"False\"\n   type: IPAccessListReady"
                },
                {
                    "lang": "sh",
                    "value": "conditions:\n- lastTransitionTime: \"2021-03-13T16:26:17Z\"\n  status: \"True\"\n  type: Ready"
                },
                {
                    "lang": "yaml",
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  annotations:\n    mongodb.com/atlas-resource-policy: \"delete\""
                }
            ],
            "preview": "Atlas Kubernetes Operator supports the following custom resources:",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-configure-federated-authentication",
            "title": "Configure Federated Authentication from Kubernetes",
            "headings": [
                "Prerequisites",
                "Update an Organization Configuration"
            ],
            "paragraphs": "Atlas Kubernetes Operator  supports configuring  federated authentication  for your  Atlas  organization.\nTo configure federated authentication through  Atlas Kubernetes Operator , you must\nspecify and update the  AtlasFederatedAuth  Custom Resource . When you create the  AtlasFederatedAuth  custom resource,  Atlas Kubernetes Operator \nuses the  Federated Authentication API Resource  to  update \nthe organization configuration for the federation.\nIn the organization configuration, you specify federation settings\nfor your  Atlas  organization such as  organization  and  role mappings . Before you can use  Atlas Kubernetes Operator  to configure federated authentication,\nyou must have: An existing identity provider ( IdP (Identity Provider) ) linked to  Atlas .\nTo learn how to link an  IdP (Identity Provider)  to  Atlas , see\n Manage Identity Providers . A  secret  with  API keys  that\n Atlas Kubernetes Operator  can use to  connect  to  Atlas .\nThe API keys must have the  Organization Owner  role. To update an organization configuration\nfor your federation, specify the parameters in the\n AtlasFederatedAuth  Custom Resource . Example: To check on the status of the update process,\nrun the following command: Atlas Kubernetes Operator  returns the custom resource and includes a\nstatus section that resembles the following example: To learn about the available parameters for this resource,\nsee  AtlasFederatedAuth  Custom Resource .",
            "code": [
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasFederatedAuth\nmetadata:\n  name: atlas-default-federated-auth\n  namespace: mongodb-atlas-system\nspec:\n  enabled: true\n  connectionSecretRef:\n    name: my-org-secret\n    namespace: mongodb-atlas-system\n  domainAllowList:\n    - my-org-domain.com\n  domainRestrictionEnabled: true\n  ssoDebugEnabled: true\n  postAuthRoleGrants:\n    - GLOBAL_AUTOMATION_ADMIN\n  roleMappings:\n    - externalGroupName: myTestGroup\n      roleAssignments:\n        - projectName: myTestProject\n          role: ORG_OWNER\n\nEOF"
                },
                {
                    "lang": null,
                    "value": "kubectl get atlasfederatedauth -o yaml"
                },
                {
                    "lang": null,
                    "value": "status:\n  conditions:\n    - type: Ready\n      status: True\n    - type: RolesReady\n      status: True\n    - type: UsersReady\n      status: True"
                }
            ],
            "preview": "Atlas Kubernetes Operator supports configuring federated authentication for your Atlas organization.\nTo configure federated authentication through Atlas Kubernetes Operator, you must\nspecify and update the AtlasFederatedAuth Custom Resource.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-quick-start-helm",
            "title": "Helm Charts Quick Start",
            "headings": [
                "Prerequisites",
                "Procedure",
                "Register for an Atlas account or log in.",
                "Create API keys for your organization.",
                "Deploy Atlas Kubernetes Operator.",
                "Deploy the Atlas database deployment.",
                "Check the status of your database user.",
                "Retrieve the secret that Atlas Kubernetes Operator created to connect to the database deployment."
            ],
            "paragraphs": "You can use  Atlas Kubernetes Operator  to manage resources in  Atlas  without leaving\n Kubernetes . This tutorial demonstrates how to create your first cluster in\n Atlas  from Helm Charts with  Atlas Kubernetes Operator . To create your first cluster in  Atlas  from  Kubernetes \nconfiguration files with  Atlas Kubernetes Operator , see  Quick Start . This tutorial requires: You can access the  Atlas Kubernetes Operator  project on GitHub: A running  Kubernetes  cluster with nodes running processors with the\nx86-64, AMD64, or ARM64 architecture. https://github.com/mongodb/mongodb-atlas-kubernetes Atlas Kubernetes Operator  uses  custom resource  configuration\nfiles to manage your  Atlas  configuration, but as of  Atlas Kubernetes Operator  2.0,\ncustom resources you delete in  Kubernetes  are no longer deleted in\n Atlas . Instead,  Atlas Kubernetes Operator  simply stops managing those resources.\nFor example, if you delete an  AtlasProject  Custom Resource \nin  Kubernetes ,  Atlas Kubernetes Operator  no longer automatically deletes the corresponding project\nfrom  Atlas , preventing accidental or unexpected deletions. To learn more,\nincluding how to  revert this behavior  to\nthe default used prior to  Atlas Kubernetes Operator  2.0, see  New Default: Deletion Protection in  Atlas Kubernetes Operator  2.0 . Register a new Atlas Account  or  Log in to Your Atlas Account . Create an API (Application Programming Interface) Key in an Organization  and configure the  API\nAccess List . You need the following public API key, private API key, and the\norganization ID information to configure  Atlas Kubernetes Operator  access to\n Atlas . You need the following public API key, private API key, and the\norganization ID information to configure  Atlas Kubernetes Operator  access to  Atlas . If you want  Atlas Kubernetes Operator  to create a new  Atlas  project,\n Create an API (Application Programming Interface) Key in an Organization . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the\n Organization Project Creator  organization role or\nhigher. If you want to work with an existing  Atlas  project,\n Create an API (Application Programming Interface) Key for a Project . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the  Project Owner \nproject role. Run one of the following sets of commands: If you want  Atlas Kubernetes Operator  to watch all  namespaces  in the  Kubernetes \ncluster, run the following commands: If you want  Atlas Kubernetes Operator  to watch only its own  namespace , set the\n --watchNamespaces  flag to its own  namespace , and run the\nfollowing command: You can set the  --watchNamespaces  flag only to its\nown  namespace . Setting the  --watchNamespaces  flag to any\nother  namespace  is currently unsupported. Customize the  Atlas  project and its database users. Create a file named  install-values.yaml  and paste the\nfollowing example code, which does the following: Sets the project name to  My Project . Allows all IP addresses (0.0.0.0) to access the project. Creates a database user named  dbadmin  that has\nthe  dbAdmin  role. Creates a database user named  dbuser  that has\nthe  readWrite  role. Run the following command. The  --set  and  --values  flags in the following command\noverride the  Values.yaml  file values and default Helm Charts\nvalues with your organization ID, API keys, and  Atlas \nproject configuration. To learn more about the available parameters, see\n AtlasDeployment  Custom Resource . To create a serverless instance, see the\n serverless instance example . mongodb/atlas-deployment  references the name of a chart in the\nrepository. Run the following command to wait for the  dbadmin \ndatabase user to become ready: The  AtlasDatabaseUser  Custom Resource  waits until the\ndatabase deployment is ready. Creating a new\ndatabase deployment can take up to 10 minutes. Run the following command to retrieve the connection string\nand password for the  dbadmin  database user. Your connection\nstrings will differ from the example output. You can use the following  secret  in your application: The following command requires  jq  1.6 or higher.",
            "code": [
                {
                    "lang": "sh",
                    "value": "helm repo add mongodb https://mongodb.github.io/helm-charts\nhelm install atlas-operator --namespace=atlas-operator --create-namespace mongodb/mongodb-atlas-operator"
                },
                {
                    "lang": "sh",
                    "value": "helm install atlas-operator --namespace=atlas-operator --set watchNamespaces=atlas-operator --create-namespace mongodb/mongodb-atlas-operator"
                },
                {
                    "lang": "yaml",
                    "value": "project: # Project custom values\n  atlasProjectName: \"My Project\"\n  projectIpAccessList:\n    - ipAddress: \"0.0.0.0\"\n\nusers: # Custom database users\n  - username: dbadmin\n    databaseName: admin\n    roles:\n      - databaseName: admin-role\n        roleName: dbAdmin\n  - username: dbuser\n    databaseName: admin\n    roles:\n      - databaseName: user-role\n        roleName: readWrite"
                },
                {
                    "lang": "sh",
                    "value": "helm install atlas-deployment \\\nmongodb/atlas-deployment \\\n--namespace=my-cluster \\\n--create-namespace \\\n--set atlas.secret.orgId='<orgid>' \\\n--set atlas.secret.publicApiKey='<publicKey>' \\\n--set atlas.secret.privateApiKey='<privateApiKey>' \\\n--values install-values.yaml"
                },
                {
                    "lang": "sh",
                    "value": "kubectl wait --for=condition=ready  --timeout=10m -n my-cluster atlasdatabaseusers/atlas-deployment-dbadmin"
                },
                {
                    "lang": "sh",
                    "value": "containers:\n - name: test-app\n   env:\n     - name: \"CONNECTION_STRING\"\n       valueFrom:\n         secretKeyRef:\n           name: my-project-cluster-name-dbadmin\n           key: connectionStringStandardSrv"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get secret -n my-cluster my-project-cluster-name-dbadmin  -ojson | jq -r '.data | with_entries(.value |= @base64d)';"
                },
                {
                    "lang": "json",
                    "value": "{\n   \"connectionStringStandard\": \"mongodb://admin-user:%25SomeLong%25password$foradmin@atlas-cluster-shard-00-00.nlrvs.mongodb.net:27017,atlas-cluster-shard-00-01.nlrvs.mongodb.net:27017,atlas-cluster-shard-00-02.nlrvs.mongodb.net:27017/?ssl=true&authSource=admin&replicaSet=atlas-11q9bn-shard-0\",\n   \"connectionStringStandardSrv\": \"mongodb+srv://admin-user:%25SomeLong%25password$foradmin@atlas-cluster.nlrvs.mongodb.net\",\n   \"password\": \"%SomeLong%password$foradmin\",\n   \"username\": \"dbadmin\"\n}"
                }
            ],
            "preview": "You can use Atlas Kubernetes Operator to manage resources in Atlas without leaving\nKubernetes. This tutorial demonstrates how to create your first cluster in\nAtlas from Helm Charts with Atlas Kubernetes Operator.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-compatibility",
            "title": "Compatibility",
            "headings": [
                "Kubernetes and OpenShift Versions",
                "Supported Hardware Architectures"
            ],
            "paragraphs": "Atlas Kubernetes Operator  is compatible with the following versions of  Kubernetes  and OpenShift. Atlas Kubernetes Operator Kubernetes OpenShift Base Image 1.7.x 1.22-1.25 4.9-4.12 Red Hat UBI 8 Base Image 1.6.x 1.21, 1.22, 1.23, 1.24 4.8-4.11 Red Hat UBI 8 Base Image 1.5.x 1.21, 1.22, 1.23, 1.24 4.8-4.11 Red Hat UBI 8 Base Image Kubernetes  nodes must be running processors with the x86-64, AMD64, or ARM64 architecture.",
            "code": [],
            "preview": "Atlas Kubernetes Operator is compatible with the following versions of Kubernetes and OpenShift.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "atlasdeployment-custom-resource",
            "title": "AtlasDeployment Custom Resource",
            "headings": [
                "Examples",
                "Status Example",
                "Configuration Example",
                "Additional Options Example",
                "Serverless Instance Example",
                "Multi-Region Cluster Example",
                "Multiple Cloud Service Providers Example",
                "Parameters"
            ],
            "paragraphs": "The  AtlasDeployment  custom resource configures your MongoDB cluster\nor serverless instance in  Atlas . When you create the  AtlasDeployment \ncustom resource,  Atlas Kubernetes Operator  tries to create or update a cluster or\nserverless instance in  Atlas . Atlas Kubernetes Operator  does one of the following actions depending on the values you\nspecify in the  AtlasDeployment  custom resource: Creating or updating a cluster or serverless instance can take\nup to 10 minutes.  Atlas Kubernetes Operator  monitors the update process. You can run the following command to check on the status: The following example shows the status section of a cluster that is\nprovisioning: The  ClusterReady  status will change to  True  when the cluster\nor serverless instance is ready. With  Atlas Kubernetes Operator  2.0,  deploymentSpec  replaces  advancedDeploymentSpec  in\nthe  AtlasDeployment  custom resource. You must update your  AtlasDeployment \ncustom resource as follows: If you use  advancedDeploymentSpec , rename it to  deploymentSpec .\nYou don't need to change any formatting. If you used  deploymentSpec  prior to  Atlas Kubernetes Operator  2.0, rewrite your\n AtlasDeployment  custom resource to match the formatting used in\n the examples . Atlas Kubernetes Operator  uses  custom resource  configuration\nfiles to manage your  Atlas  configuration. As of  Atlas Kubernetes Operator  2.0,\ncustom resources you delete in  Kubernetes  are no longer deleted in\n Atlas . Instead,  Atlas Kubernetes Operator  simply stops managing those resources.\nFor example, if you delete an  AtlasProject  Custom Resource \nin  Kubernetes ,  Atlas Kubernetes Operator  no longer automatically deletes the corresponding project\nfrom  Atlas , preventing accidental or unexpected deletions. To learn more,\nincluding how to  revert this behavior  to\nthe default used prior to  Atlas Kubernetes Operator  2.0, see  New Default: Deletion Protection in  Atlas Kubernetes Operator  2.0 . If you specify values for fields under  spec.deploymentSpec ,  Atlas Kubernetes Operator \nuses the  Atlas   Clusters API Resource \nto create a new cluster or update an existing cluster. If you specify values for fields under  spec.serverlessSpec ,  Atlas Kubernetes Operator \nuses the  Atlas   Serverless Instance API Resource \nto create a new serverless instance or update an existing serverless instance. The following example shows the  AtlasDeployment  resource with a\n ClusterReady  status of  True : The following example shows an  AtlasDeployment  custom resource\nspecification configured for autoscaling multi-region clusters: The following example shows an  AtlasDeployment  custom resource\nspecification configured with some of the  additional options . The following example shows an  AtlasDeployment  custom resource\nspecification configured for a serverless instance: Clusters can span regions and cloud service providers. To learn more,\nsee  Considerations . The following example shows an  AtlasDeployment  custom\nresource specification configured for multi-region clusters: While the  Atlas   Cluster API\nResource  sends requests using the\n v1.5   Atlas   API (Application Programming Interface)  versions, the  Atlas Kubernetes Operator   apiVersion  field\nuses  v1 . In this case,  v1  refers to the version of\nthe  Kubernetes   API (Application Programming Interface) . The following example shows an  AtlasDeployment  custom resource\nspecification configured to span multiple cloud service providers: This section describes some of the key  AtlasDeployment  custom resource\nparameters available. To customize your specifications, Refer to these descriptions, the available\nexamples, and the  API (Application Programming Interface)  documentation. For the configuration parameters available for a cluster from the  API (Application Programming Interface) ,\nsee the  Atlas \n Clusters API . For a full list of available parameters for clusters,\nsee the  Atlas   Clusters API . For a full list of available parameters for serverless instances,\nsee the  Atlas   Serverless Instances API . Type : object Optional List that contains the details for the  AtlasBackupSchedule  Custom Resource \nthat you want to apply. You can specify one backup schedule per cluster. Type : string Optional metadata.name  value within the\n AtlasBackupSchedule  Custom Resource  for the backup schedule that\nyou want to apply. You can specify only one backup schedule per cluster,\nbut you can use the same backup schedule for multiple clusters. If you omit this parameter,  Atlas  doesn't apply your backup\nconfiguration to this cluster. Type : string Optional String that indicates the namespace that contains the\n AtlasBackupSchedule  Custom Resource  for the backup schedule\nthat you want to apply. Type : array Conditional List that contains the cluster parameters from the  API (Application Programming Interface) .\nFor a full list of available parameters, see the  Atlas \n Clusters API . You must specify  spec.deploymentSpec  or  spec.serverlessSpec \nin your configuration. Type : string Conditional Human-readable label that identifies cluster type to create. When should you use this parameter? Atlas  accepts: Condition Necessity You set  spec.deploymentSpec.replicationSpecs . Required You are deploying\n Global Clusters . Required You are deploying non-Global replica sets and sharded clusters. Optional Value Cluster Type REPLICASET replica set SHARDED sharded cluster GEOSHARDED global cluster Type : array Required List that contains  Global Cluster \nparameters that map zones to geographic regions. For a full list of\navailable parameters, see the  Atlas   Global\nClusters API . Type : string Required Code that represents a location that maps to a zone in your  Global\nCluster . Type : string Required Human-readable label that identifies the zone in your  Global\nCluster . Type : number Optional Capacity, in gigabytes, that indicates the host's root volume. Increase\nthis number to add capacity, up to a maximum possible value of\n 4096  (4 TB). You must specify a positive number for this value. You can't set this value for  clusters with local  NVMe SSDs . The minimum disk size for dedicated clusters is 10 GB for  AWS (Amazon Web Services)  and\n Google Cloud . If you specify this setting with a lower disk size,  Atlas \ndefaults to the minimum disk size value. If your database deployment includes  Azure (Microsoft Azure)  nodes, this value must\ncorrespond to an existing  Azure (Microsoft Azure)  disk type (8, 16, 32, 64, 128, 256,\n512, 1024, 2048, or 4096). Atlas  calculates storage charges differently depending on whether\nyou choose the default value or a custom value. If your database deployment spans cloud service providers, this\nvalue defaults to the minimum default of the providers involved. To learn more, see  Storage Capacity . If you enable autoscaling for  diskGB  in any region, you can't edit\nthis option. To learn more, see  spec.deploymentSpec.replicationSpecs.regionConfigs.autoScaling.diskGB.enabled . Atlas  has disk capacity limits on single replica sets,\nscaling up to 4 TB for higher cluster tiers. To expand\nthe total cluster storage beyond default limits, you can enable\nextended storage in the  Project Settings .\nTo accommodate further scaling in the future, we recommend that you\nenable  sharding  for long-term\nexpansion. Type : string Optional Cloud service provider that manages the customer key for this cluster.\nYou must set this value to enable encryption at rest using customer-managed\nkeys for this cluster, which provides an additional layer of encryption.\nTo learn more, see  Encrypt Data Using a Key Management Service . Atlas  accepts the following values: Value Cloud Provider AWS Amazon AWS GCP Google Cloud AZURE Microsoft Azure NONE No provider; the cluster doesn't encrypt data using\ncustomer-managed keys. Type : array Required List that contains information to create a managed namespace in a\nspecified  Global Cluster  to create. For\na full list of available parameters, see the  Atlas \n Global Clusters API . Type : string Required Human-readable label of the collection to manage in this  Global\nCluster . Type : string Required Human-readable label of the database to manage in this  Global\nCluster . Type : boolean Optional Flag that indicates whether to hash the custom shard key for\nthe specified collection. This parameter defaults to  false . To learn more, see  Hashed Shard Keys . Set to  true  to enable a custom shard key for the collection. Set to  false  to disable a custom shard key for the collection.\nIf diabled, MongoDB uses  ranged sharding . Type : boolean Optional Flag that indicates whether the custom shard key for the specified\ncollection is unique. This parameter defaults to  false . Set to  true  to enable a unique custom shard key for the collection. Set to  false  to disable a unique custom shard key for the collection. Type : integer Optional Minimum number of chunks to initially create when sharding an empty\ncollection with a  hashed shard key . To learn more, see  Shard a Global Collection . Type : boolean Optional Flag that indicates whether MongoDB Cloud should create and\ndistribute initial chunks for an empty or non-existing collection.\nThis parameter defaults to  false . Set to  true  to have MongoDB Cloud create and distribute initial chunks for an empty or non-existing collection. Set to  false  to not have MongoDB Cloud create and distribute initial chunks for an empty or non-existing collection.. Type : string Optional Version of the cluster to deploy.  Atlas  supports the\nfollowing MongoDB versions for  M10+  clusters: The following conditions produce the following results: 5.0 6.0 7.0 Condition Result You omit this parameter and you omit the\n spec.deploymentSpec.versionReleaseSystem  parameter. Atlas  deploys a cluster that runs MongoDB 7.0. You omit this parameter and you set the\n spec.deploymentSpec.versionReleaseSystem  parameter to\n LTS . Atlas  deploys a cluster that runs MongoDB 7.0. You set the\n spec.deploymentSpec.providerSettings.instanceSizeName \nparameter to  M0 ,  M2 , or  M5 . You must deploy MongoDB 7.0. You specify this parameter. Atlas  always deploys the cluster with the latest\nstable patch release of the specified version. You set the\n spec.deploymentSpec.versionReleaseSystem \nparameter to  CONTINUOUS . You must omit this parameter. Type : boolean Conditional Configuration that enables continuous cloud backup. To enable continuous\ncloud backup, you must specify  true  for this setting. Type : Object Conditional Configuration that specifies the settings for the provisioned hosts on\nwhich MongoDB runs. The available options are specific to the cloud service\nprovider. To learn more, see the  AWS ,  GCP ,\nand  Azure  cluster configuration options. If you want to create or update a cluster, you must specify this setting. Type : string Conditional Cloud service provider on which  Atlas  provisions the hosts. AWS Amazon AWS GCP Google Cloud Platform AZURE Microsoft Azure Type : string Required Atlas  provides different cluster tiers, each with a default storage\ncapacity and RAM size. The cluster you select is used for all the\ndata-bearing servers in your cluster. To learn more, see the\n AWS ,  GCP , and  Azure \ncustom storage sizes. If you change the instance size name after you deploy your\ncluster,  Atlas  changes the database deployment to the\ninstance size you specify unless it falls outside the range you\nspecify in\n spec.deploymentSpec.replicationSpecs.regionConfigs.autoScaling.compute.minInstanceSize \nand\n spec.deploymentSpec.replicationSpecs.regionConfigs.autoScaling.compute.maxInstanceSize \nwith autoscaling enabled. To learn more, see\n spec.deploymentSpec.replicationSpecs.regionConfigs.autoScaling.compute.minInstanceSize \nand\n spec.deploymentSpec.replicationSpecs.regionConfigs.autoScaling.compute.maxInstanceSize . You can change this setting to upgrade an  M0 ,  M2 , or\n M5  cluster to an  M10+  cluster. However, you can't\nupgrade an  M0 ,  M2 , or  M5  cluster to another free\nor shared cluster. For example, you can't upgrade an  M0 \ncluster to an  M5  cluster. Type : string Conditional Physical location of your MongoDB cluster. The region you\nchoose can affect network latency for clients accessing your\ndatabases. For a complete list of region name values, refer to the\ncloud provider reference pages: For multi-region clusters, see\n spec.deploymentSpec.replicationSpecs . You must set either\n spec.deploymentSpec.providerSettings.regionName  or\n spec.deploymentSpec.replicationSpecs . AWS GCP Azure Type : array of objects Conditional List that contains the configurations for your cluster regions.\nUse this parameter for multi-region clusters. You must set\neither  spec.deploymentSpec.providerSettings.regionName  or\n spec.deploymentSpec.replicationSpecs . When should you use this parameter? If you specify this parameter, you must also specify\n spec.deploymentSpec.clusterType  and\n spec.deploymentSpec.replicationSpecs.numShards . Condition Necessity Values You are deploying\n Global Clusters . Required Each object in the array represents a zone where\n Atlas  deploys your cluster's nodes. You are deploying non-Global replica sets and sharded\nclusters. Optional This array has one object representing where\n Atlas  deploys your cluster's nodes. Type : integer Conditional Positive integer that specifies the number of shards to deploy\nfor a sharded cluster. If you use the  spec.deploymentSpec.replicationSpecs \nparameter, you must set this parameter. Atlas  accepts  1  through  50 , inclusive. The default\nvalue is  1 . If you specify a value of  1  and you set\n spec.deploymentSpec.clusterType  to  SHARDED ,\n Atlas  deploys a single-shard sharded cluster. If you specify  1  and you set\n spec.deploymentSpec.clusterType  to  REPLICASET ,\n Atlas  deploys a replica set. Don't create a sharded cluster with a single shard for production\nenvironments. Single-shard sharded clusters don't provide the same\nbenefits as multi-shard configurations. Sharding Number of Nodes Type : array Required Hardware specifications for nodes set for a given region. Each\n regionConfigs  object describes the region's priority in\nelections and the number and type of MongoDB nodes that\n Atlas  deploys to the region. Each  regionConfigs  object must have either an\n analyticsSpecs  object,  electableSpecs  object, or\n readOnlySpecs  object. M0 ,  M2 , or  M5  clusters require only\n electableSpecs . Dedicated clusters can specify any of these specifications,\nbut must have at least one  electableSpecs  object within a\n replicationSpec . Every hardware specification must use the same\n instanceSize . Type : object Optional Hardware specifications for  analytics nodes  needed in the region. Analytics nodes\nhandle analytic data such as reporting queries from  BI Connector for Atlas . Analytics\nnodes are read-only and can never become the primary. If you don't specify this parameter,  Atlas  deploys no analytics\nto this region. Type : boolean Optional Flag that indicates whether this database deployment enables\ndisk autoscaling. This parameter defaults to  true . Set to  true  to enable disk autoscaling. Set to  false  to disable disk autoscaling. The maximum amount of RAM for the selected cluster tier and the oplog\nsize can limit storage auto-scaling. To learn more, see\n Customize Your Storage . Type : boolean Optional Flag that indicates whether instance size autoscaling is\nenabled. This parameter defaults to  false . Set to  true  to enable instance size autoscaling. If\nenabled, you must specify a value for  spec.deploymentSpec.replicationSpecs.regionConfigs.autoScaling.compute.maxInstanceSize . Set to  false  to disable instance size autoscaling. Type : string Conditional String that indicates the maximum instance size to which your\ndatabase deployment can automatically scale (such as  M40 ).\nYou must specify this parameter if you set  spec.deploymentSpec.replicationSpecs.regionConfigs.autoScaling.compute.enabled  to  true . If you set a maximum instance size smaller than the\ndatabase deployment's current instance size with autoscaling\nenabled,  Atlas  automatically scales the current instance\nsize to the maximum value you specify. For example, if the database deployment's current instance\nsize is  M40  and you set the maximum instance size to  M30 ,\n Atlas  automatically scales the current instance size to\n M30 . If  Atlas  changes the current instance size and you don't\nchange the\n spec.deploymentSpec.providerSettings.instanceSizeName \nin  Atlas Kubernetes Operator  to match the new instance size,  Atlas Kubernetes Operator  displays a\nwarning in the logs but doesn't prevent autoscaling. Type : string Conditional String that indicates the minimum instance size to which your\ndatabase deployment can automatically scale (such as  M10 ).\nYou must specify this parameter if you set\n spec.deploymentSpec.replicationSpecs.regionConfigs.autoScaling.compute.enabled \nto  true . If you set a minimum instance size larger than the\ndatabase deployment's current instance size with autoscaling\nenabled,  Atlas  automatically scales the current instance size\nto the minimum value you specify. For example, if the database deployment's current instance\nsize is  M10  and you set the minimum instance size to  M30 ,\n Atlas  automatically scales the current instance size to\n M30 . If  Atlas  changes the current instance size and you don't\nchange the\n spec.deploymentSpec.providerSettings.instanceSizeName \nin  Atlas Kubernetes Operator  to match the new instance size,  Atlas Kubernetes Operator  displays a\nwarning in the logs but doesn't prevent autoscaling. Type : object Optional Hardware specifications for electable nodes in the region.\nElectable nodes can become the primary and can enable\nlocal reads. If you don't specify this option,  Atlas  deploys no electable\nnodes to the region. Type : string Conditional Hardware specification for the instance sizes in this region. Each\ninstance size has a default storage and memory capacity. The instance\nsize you select applies to all the data-bearing hosts in your\ninstance size. To learn more, see the  AWS ,\n GCP , and  Azure  custom\nstorage sizes. If you deploy a sharded cluster, or  global cluster , you must choose an instance size of  M30  or\ngreater. If you have autoscaling enabled for the compute field, you can't\nedit this option. To learn more, see  spec.deploymentSpec.replicationSpecs.regionConfigs.autoScaling.compute.enabled . Type : integer Conditional Number of electable nodes for  Atlas  to deploy to the region.\nElectable nodes can become the primary and can enable\nlocal reads. The combined  electableSpecs.nodeCount  across all\n replicationSpecs.regionConfigs  objects must total\n 3 ,  5 , or  7 . You can't create electable nodes if  spec.deploymentSpec.replicationSpecs.regionConfigs.priority  is\n 0 . Type : integer Required Precedence is given to this region when a primary election\noccurs. If your  regionConfigs  has only  readOnlySpecs ,\n analyticsSpecs , or both, set this value to  0 . If you have multiple  regionConfigs  objects (your cluster is\nmulti-region or multi-cloud), they must have priorities in\ndescending order. The highest priority is  7 . If your region has set  electableSpecs.nodeCount  to  1  or\nhigher, it must have a priority of exactly one less than\nanother region in the  replicationSpecs.regionConfigs \narray unless it is the primary. The highest-priority region  must \nhave a priority of  7 . The lowest possible priority is  1 . The priority  7  region identifies the  Preferred Region  of\nthe cluster.  Atlas  places the primary node in the\n Preferred Region . Priorities  1  through  7  are\nexclusive: you can't assign a given priority to more than one\nregion per cluster. Set your highest priority region to  7 , your\nsecond-highest priority to  6 , and your third-priority\nregion to  5 . If you have no electable nodes, set this\nvalue to  0 . If you have three regions, their priorities would be  7 ,\n 6 , and  5  respectively. If you added two more regions\nfor supporting electable nodes, the priorities of those\nregions would be  4  and  3  respectively. Type : object Optional Hardware specifications for read-only nodes in the region.\nRead-only nodes can never become the primary member, but\ncan enable local reads. If you don't specify this parameter,  Atlas  deploys no read-only\nnodes to the region. Type : string Optional Human-readable label that identifies the zone in a\n Global Cluster . Provide this value\nonly if you set  spec.deploymentSpec.clusterType  to\n GEOSHARDED . Type : array Optional List that contains  tags  (key-value\npairs) to better understand, organize, and identify your\ndatabase deployments. To learn more, see\n Tags on Database Deployments . Type : string Conditional Release cadence that  Atlas  uses for this cluster.\n Atlas  accepts: CONTINUOUS :  Atlas  creates your cluster using the\nmost recent MongoDB release.  Atlas  automatically updates\nyour cluster to the latest major and rapid MongoDB releases\nas they become available. LTS :  Atlas  creates your cluster using the latest\npatch release of the MongoDB version that you specify in the\n spec.deploymentSpec.mongoDBMajorVersion  parameter.\n Atlas  automatically updates your cluster to subsequent\npatch releases of this MongoDB version.  Atlas  doesn't update\nyour cluster to newer rapid or major MongoDB releases as they\nbecome available. If omitted, defaults to  LTS . If you set this parameter to  CONTINUOUS , you must omit the\n spec.deploymentSpec.mongoDBMajorVersion  parameter. Type : object Optional Object that contains the  additional configuration\noptions  for\nyour cluster. Type : string Optional String that indicates the  default level of acknowledgment\nrequested from MongoDB for read operations  set for this cluster. MongoDB 5.0 clusters default to\n local . Type : string Optional String that indicates the  default level of acknowledgment\nrequested from MongoDB for write operations  set for this cluster. MongoDB versions 5.0 and later clusters default to\n majority . Type : boolean Optional Flag that indicates whether to fail the operation and return an\nerror when you insert or update documents where all indexed entries\nexceed 1024 bytes. If you set this to  false ,  mongod  writes\ndocuments that exceed this limit, but  doesn't  index them. This option corresponds to the\n failIndexKeyTooLong \n mongod  parameter. Type : boolean Optional Flag that indicates whether the cluster allows execution of\noperations that perform server-side executions of JavaScript. This option corresponds to modifying the\n security.javascriptEnabled  configuration file\noption for each  mongod  and  mongos  in the cluster. Type : integer Optional String that indicates the minimum  TLS (Transport Layer Security)  version that the cluster\naccepts for incoming connections. Clusters using  TLS (Transport Layer Security)  1.0 or\n1.1 should consider setting  TLS (Transport Layer Security)  1.2 as the minimum  TLS (Transport Layer Security) \nprotocol version. To learn more, see  What versions of TLS does Atlas support? . This option corresponds to the\n net.ssl.disabledProtocols   mongod \nconfiguration file option. Type : boolean Optional Flag that indicates whether the cluster disables executing any\nquery that requires a collection scan to return results. This option corresponds to the\n notablescan   mongod  parameter. Type : integer Optional Number that indicates the storage limit of a cluster's oplog\nexpressed in megabytes. A value of  null  indicates that the\ncluster uses the default oplog size that  Atlas  calculates. This option corresponds to the\n replication.oplogSizeMB \n mongod  configuration file option. Type : integer Optional Number that indicates the documents per database to sample when\ngathering schema information. This parameter corresponds to the  sampleSize \n mongosqld  option. Type : integer Optional Number that indicates the interval in seconds at which the\n mongosqld process  re-samples data\nto create its relational schema. This parameter corresponds to the  sampleRefreshIntervalSecs \n mongosqld  option. Type : string Required Name of the project where the cluster belongs. You must specify\nan existing  AtlasProject  Custom Resource . Type : array Conditional List that contains the serverless instance parameters from the\n API (Application Programming Interface) . For a full list of available parameters, see the  Atlas \n Serverless Instances API . You must specify  spec.deploymentSpec \nor  spec.serverlessSpec  in\nyour configuration. Type : array Optional List that contains the  private endpoint  configurations for the\nserverless instance. Type : Object Conditional Configuration that specifies the settings for the provisioned hosts\non which MongoDB runs. The available options are specific to the\ncloud service provider. To learn more, see the  AWS ,  GCP , and  Azure  serverless instance configuration options. If you want to create or update a serverless instance, you must\nspecify this setting. Type : string Conditional Cloud service provider on which  Atlas  provisions the host for a\nserverless instance. Atlas  accepts the following values: AWS Amazon AWS GCP Google Cloud Platform AZURE Microsoft Azure Type : string Conditional Physical location of your MongoDB serverless instance. The\nregion you choose can affect network latency for clients accessing\nyour databases. For a complete list of region name values, refer to the\ncloud provider reference pages: AWS GCP Azure Type : array Optional List that contains  tags  (key-value\npairs) to better understand, organize, and identify your\ndatabase deployments. To learn more, see\n Tags on Database Deployments . Type : array Required List that contains the connection URLs for accessing the cluster.\nThis parameter appears after you create or update a cluster. You can't use a connection URL directly.  Atlas  clusters\nrequire authentication. You must create at least one\n AtlasDatabaseUser  Custom Resource  before the application in\nyour  Kubernetes  cluster can connect to the  Atlas  cluster.\n Atlas Kubernetes Operator  creates a special  secret  for each cluster and\ndatabase user combination in the project. The application in your  Kubernetes \ncluster can use this  secret  to connect to the  Atlas \ncluster. The  spec.scopes  parameter in the  AtlasDatabaseUser \ncustom resource restricts the clusters that create the database\nuser. The following parameters are deprecated in the  Atlas \n API  and  Atlas Kubernetes Operator  does not support\nthem: replicationSpec replicationFactor",
            "code": [
                {
                    "lang": "sh",
                    "value": "kubectl get atlasdeployment -o yaml"
                },
                {
                    "lang": "sh",
                    "value": "status:\n  conditions:\n  - lastTransitionTime: \"2021-03-18T16:32:43Z\"\n    status: \"False\"\n    type: ClusterReady\n    reason: ClusterCreating\n    message: Cluster is provisioning"
                },
                {
                    "lang": null,
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: my-atlas-cluster\n  namespace: default\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  projectRef:\n    name: my-project\n  deploymentSpec:\n    name: test-cluster\n    tags:\n    - key: \"environment\",\n      value: \"production\"\n    replicationSpecs:\n      - zoneName: US-Zone\n        numShards: 3\n        regionsConfig:\n          - regionName: US_CENTRAL\n            providerName: GCP\n            backingProviderName: GCP\n            priority: 7\n            electableSpecs:\n              instanceSize: M10\n              nodeCount: 3\nstatus:\n  conditions:\n  - lastTransitionTime: \"2021-03-18T16:32:43Z\"\n    status: \"True\"\n    type: Ready\n  - lastTransitionTime: \"2021-03-18T16:32:43Z\"\n    status: \"True\"\n    type: ClusterReady\n  connectionStrings:\n    standard: mongodb://test-cluster-shard-00-00.kpc8f.mongodb.net:27017,test-cluster-shard-00-01.kpc8f.mongodb.net:27017,test-cluster-shard-00-02.kpc8f.mongodb.net:27017/?ssl=true&authSource=admin&replicaSet=atlas-1gm1pv-shard-0\n    standardSrv: mongodb+srv://test-cluster.kpc8f.mongodb.net\n  mongoDBVersion: 6.0\n  mongoURIUpdated: \"2021-03-12T12:21:41Z\"\n  observedGeneration: 1\n  stateName: IDLE"
                },
                {
                    "lang": null,
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\n  name: test-cluster-name\n  namespace: mongodb-atlas-system\nspec:\n  projectRef:\n    name: development\n  deploymentSpec:\n    autoScaling:\n      compute:\n        enabled: true\n        scaleDownEnabled: true\n    clusterType: REPLICASET\n    name: service-name\n    tags:\n    - key: \"environment\",\n      value: \"production\"\n    backupEnabled: true\n    replicationSpecs:\n      - numShards: 1\n        regionsConfig:\n         - regionName: EASTERN_US\n           providerName: GCP\n           autoscaling:\n             disk:\n               enabled: true\n             compute:\n               enabled: true\n               scaleDownEnabled: true\n               minInstanceSize: M30\n               maxInstanceSize: M40\n           analyticsSpecs:\n             instanceSize: M30\n             nodeCount: 1\n           electableSpecs:\n             instanceSize: M30\n             nodeCount: 3\n           priority: 7\n           readOnlySpecs:\n             instanceSize: M30\n             nodeCount: 1"
                },
                {
                    "lang": null,
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: my-atlas-cluster\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  projectRef:\n    name: my-project\n  deploymentSpec:\n    name: Test-cluster\n    tags:\n    - key: \"environment\",\n      value: \"production\"\n    providerSettings:\n      instanceSizeName: M10\n      providerName: AWS\n      regionName: US_EAST_1\n  processArgs:\n    javascriptEnabled: false"
                },
                {
                    "lang": null,
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: test-cluster-name\n  namespace: mongodb-atlas-system\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  projectRef:\n    name: development\n  serverlessSpec:\n    name: serverless-instance\n    tags:\n    - key: \"environment\",\n      value: \"production\"\n    providerSettings:\n      providerName: AWS\n      regionName: US_EAST_1"
                },
                {
                    "lang": null,
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: my-atlas-cluster\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  projectRef:\n    name: my-project\n  deploymentSpec:\n    clusterType: REPLICASET\n    name: tenantCluster\n    tags:\n    - key: \"environment\",\n      value: \"production\"\n    replicationSpecs:\n      - regionConfigs:\n        - electableSpecs:\n            instanceSize: M5\n          providerName: AWS\n          regionName: US_EAST_1"
                },
                {
                    "lang": null,
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: my-atlas-cluster\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  projectRef:\n    name: my-project\n  deploymentSpec:\n    clusterType: REPLICASET\n    name: tenantCluster\n    tags:\n    - key: \"environment\",\n      value: \"production\"\n    replicationSpecs:\n      - regionConfigs:\n        - electableSpecs:\n            instanceSize: M10\n            nodeCount: 3\n          providerName: AWS\n          regionName: US_EAST_1\n          priority: 7\n        - electableSpecs:\n            instanceSize: M10\n            nodeCount: 2\n          providerName: AZURE\n          regionName: US_EAST_2\n          priority: 6\n        - electableSpecs:\n            instanceSize: M10\n            nodeCount: 2\n          providerName: GCP\n          regionName: CENTRAL_US\n          priority: 5"
                }
            ],
            "preview": "Type: object",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "atlasteam-custom-resource",
            "title": "AtlasTeam Custom Resource",
            "headings": [
                "Example",
                "Parameters"
            ],
            "paragraphs": "The  AtlasTeam  custom resource defines a  team  of  Atlas \nusers.\nTo give this team access to one or more projects, you must reference the\n AtlasTeam  custom resource from the  AtlasProject  Custom Resource  and\nconfigure access roles for the team. Atlas Kubernetes Operator  does one of the following actions using the  Atlas \n Teams API Resource : Atlas Kubernetes Operator  uses  custom resource  configuration\nfiles to manage your  Atlas  configuration, but as of  Atlas Kubernetes Operator  2.0,\ncustom resources you delete in  Kubernetes  are no longer deleted in\n Atlas . Instead,  Atlas Kubernetes Operator  simply stops managing those resources.\nFor example, if you delete an  AtlasProject  Custom Resource \nin  Kubernetes ,  Atlas Kubernetes Operator  no longer automatically deletes the corresponding project\nfrom  Atlas , preventing accidental or unexpected deletions. To learn more,\nincluding how to  revert this behavior  to\nthe default used prior to  Atlas Kubernetes Operator  2.0, see  New Default: Deletion Protection in  Atlas Kubernetes Operator  2.0 . Creates a new team. Updates an existing team. The following example shows an  AtlasTeam  custom resource\nthat defines the  green-leaf-team , comprised of four users. This custom\nresource must be referenced from the  AtlasProject  Custom Resource  before\nthis team can access an  Atlas  project: This section describes the  AtlasTeam  custom resource parameters available. Type : string Required Name that the  AtlasProject  Custom Resource  uses to add this team to a project. Type : string Optional Namespace other than  default  that you want to contain the  atlasTeam \ncustom resource. If you define a custom namespace, you must add it to the\n AtlasProject  Custom Resource  in the  spec.teams.teamRef.namespace \nfield. Type : string Required Human-readable label that identifies your team. This name appears wherever you\nview, add, or edit teams to help you differentiate between multiple teams. Type : string Required List that contains the  Atlas  usernames for the members of this team.",
            "code": [
                {
                    "lang": null,
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasTeam\nmetadata:\n  name: green-leaf-team\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: \"greenLeafTeam\"\n  usernames:\n    - \"atlas.user1@example.com\"\n    - \"atlas.user2@example.com\"\n    - \"atlas.user3@example.com\"\n    - \"atlas.user4@example.com\""
                }
            ],
            "preview": "Type: string",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-get-started",
            "title": "Get Started with the Atlas Kubernetes Operator",
            "headings": [],
            "paragraphs": "",
            "code": [],
            "preview": null,
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "atlasdatabaseuser-custom-resource",
            "title": "AtlasDatabaseUser Custom Resource",
            "headings": [
                "Connection Secrets",
                "Examples",
                "Project and Clusters",
                "Database User without Scopes",
                "Database User with Scopes",
                "Database User with X.509 Authentication",
                "Database User with OIDC (OpenID Connect) Authentication",
                "Parameters"
            ],
            "paragraphs": "The  AtlasDatabaseUser  custom resource configures the database user\nin an  Atlas  project. You create database users per project, not per\ncluster. So, the  AtlasDatabaseUser  custom resource configuration\ncontains a reference to the  AtlasProject  Custom Resource . Create\nthe  AtlasProject  Custom Resource  beforehand. The following example shows a reference to the\n AtlasProject  Custom Resource : Atlas Kubernetes Operator  ensures the database user configuration in  Atlas  matches\nthe configuration in  Kubernetes . Atlas Kubernetes Operator  does one of the following actions using the  Atlas \n Database Users API : Before you create a database user, you must create an opaque\n secret  with a single  password  field to log into the  Atlas \ncluster database. The following example creates a secret: Atlas Kubernetes Operator  uses  custom resource  configuration\nfiles to manage your  Atlas  configuration, but as of  Atlas Kubernetes Operator  2.0,\ncustom resources you delete in  Kubernetes  are no longer deleted in\n Atlas . Instead,  Atlas Kubernetes Operator  simply stops managing those resources.\nFor example, if you delete an  AtlasProject  Custom Resource \nin  Kubernetes ,  Atlas Kubernetes Operator  no longer automatically deletes the corresponding project\nfrom  Atlas , preventing accidental or unexpected deletions. To learn more,\nincluding how to  revert this behavior  to\nthe default used prior to  Atlas Kubernetes Operator  2.0, see  New Default: Deletion Protection in  Atlas Kubernetes Operator  2.0 . Creates a new database user. Updates an existing user. You must create the secret in the same  namespace  where the  AtlasDatabaseUser  custom resource is located. Atlas Kubernetes Operator   watches secrets  only with the label\n atlas.mongodb.com/type=credentials  to avoid watching unnecessary\n secrets . The following example labels a secret: After  Atlas Kubernetes Operator  successfully creates or updates the database user in\n Atlas ,  Atlas Kubernetes Operator  creates or updates the connection secrets in\nthe same namespace where the  AtlasDatabaseUser  custom resource\nis located. Connection secrets contain all the information required to\nconnect to the  Atlas  clusters including the following parameters: Applications running in  Kubernetes  can use this information to connect to\n Atlas  clusters. You can mount the secrets to the application\npods as files and the application process can read these files to get\ndata. The following example shows mounting the secret as an environment\nvariable: The following example shows mounting the secret as files: By default,  Atlas Kubernetes Operator  creates the database user connection secret\nfor each cluster in the same project that the  AtlasDatabaseUser \nreferences. You can change this behavior with the\n spec.scopes  parameter. This parameter restricts the clusters\nwhere the database user gets created. The name of the connection secret\nuses the following format:\n <project_name>-<cluster_name>-<db_user_name> . Parameter Description connectionStringStandard Public  mongodb://  connection  URI (Uniform Resource Identifier) . connectionstringStandardSrv Public  mongodb+srv://  connection  URI (Uniform Resource Identifier) . username Name that identifies the database user. password Password of the database user. The following example shows an  Atlas  project and the clusters that\nreference it: The following example shows an  AtlasDatabaseUser  custom resource\nspecification with  spec.scopes  omitted: After you create this custom resource,  Atlas Kubernetes Operator  creates the following\nsecrets: p1-aws-cluster-theuser p1-gcp-cluster-theuser The following example shows an  AtlasDatabaseUser  custom resource\nspecification with  spec.scopes  set to the  Google Cloud  cluster only: After you update this custom resource,  Atlas Kubernetes Operator  removes  theuser  from\nthe  aws-cluster . It also removes the  p1-aws-cluster-theuser \nsecret from the  Kubernetes  cluster. The following example shows an  AtlasDatabaseUser  custom resource\nspecification with  X.509 authentication . The following example shows an  AtlasDatabaseUser  custom resource\nspecification with  OIDC (OpenID Connect) . This section describes some of the key  AtlasDatabaseUser  custom\nresource parameters available. For a full list of parameters available,\nsee the  Atlas   Database Users API . Refer to\nthese descriptions, the available examples, and the  API (Application Programming Interface)  documentation\nto customize your specifications. For the configuration parameters available from the  API (Application Programming Interface) , see the\n Atlas   Database Users API . Currently,  Atlas Kubernetes Operator  does not support the following parameters\navailable from the  Atlas   Database Users API : Do not specify the following parameters: Type : string Required Database  against which the\ndatabase user authenticates. Database users must provide both a\nusername and authentication database to log into MongoDB. If the database user authenticates with  SCRAM-SHA , this value must be  admin . If the database user authenticates with  X.509 ,\nthis value must be  \\$external . Type : string Conditional OIDC (OpenID Connect)  method by which the database authenticates the\nprovided  spec.username . If the database user authenticates with  OpenID Connect , this value must be  IDP_GROUP . Type : string Conditional Reference to the  secret  that contains the password. The\n SCRAM-SHA  authentication method\nrequires this parameter. Type : string Required Name of the project where the database user belongs. You must\nspecify an existing  AtlasProject  Custom Resource . Type : array Required List that contains the user's roles and the databases or collections\non which the roles apply. For a full list of parameters available,\nsee the  Atlas   Database Users API . Type : array Optional List that contains the clusters where the user gets created. Type : string Conditional Human-readable label that identifies the cluster that the database\nuser can access. You must specify this parameter if you specified\n spec.scopes . Type : string Conditional Human-readable label that identifies the resource type that the\ndatabase user can access.  Atlas Kubernetes Operator  currently supports only\n CLUSTER . You must specify this parameter if you specified\n spec.scopes . Type : string Required Human-readable label that identifies the user needed to authenticate\nto the MongoDB database or collection. If the database user authenticates with  OpenID Connect , this value must be your  Atlas   OIDC (OpenID Connect) \n IdP (Identity Provider)  followed by a forward slash  /  and your  IdP (Identity Provider)  group name. Type : string Optional X.509 method by which the database authenticates the\nprovided  spec.username . If you don't specify a value,\n Atlas  uses the default value of  NONE . This parameter accepts: NONE User that doesn't use X.509 authentication. MANAGED User that uses  Atlas -managed X.509. You must specify  \\$external  for the\n spec.databaseName  parameter. CUSTOMER User that uses  Self-Managed X.509 . Users created with this  x509Type \nrequire a Common Name (CN) in the  spec.username \nparameter. To learn more, see  RFC 2253 . You must specify  \\$external  for the\n spec.databaseName  parameter. awsIAMType ldapAuthType groupId password Specify  spec.passwordSecretRef  instead.",
            "code": [
                {
                    "lang": "sh",
                    "value": "spec:\n  projectRef:\n    name: my-project"
                },
                {
                    "lang": "sh",
                    "value": "kubectl create secret generic the-user-password --from-literal=\"password=P@@sword%\""
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "spec:\ncontainers:\n- name: test-app\n  env:\n    - name: \"CONNECTIONSTRING\"\n      valueFrom:\n        secretKeyRef:\n          name: project-cluster-basic-theuser\n          key: connectionStringStandardSrv"
                },
                {
                    "lang": "sh",
                    "value": "spec:\ncontainers:\n- name: test-app\n  volumeMounts:\n  - mountPath: /var/secrets/\n    name: theuser-connection\nvolumes:\n  - name: theuser-connection\n    secret:\n      secretName: project-cluster-basic-theuser"
                },
                {
                    "lang": "sh",
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n name: my-project\n labels:\n   app.kubernetes.io/version: 1.6.0\nspec:\n name: p1\n projectIpAccessList:\n   - ipAddress: \"192.0.2.15\"\n     comment: \"IP address for Application Server A\"\n\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n name: my-aws-cluster\n labels:\n   app.kubernetes.io/version: 1.6.0\nspec:\n name: aws-cluster\n projectRef:\n   name: my-project\n providerSettings:\n   instanceSizeName: M10\n   providerName: AWS\n   regionName: US_EAST_1\n\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n name: my-gcp-cluster\n labels:\n   app.kubernetes.io/version: 1.6.0\nspec:\n name: gcp-cluster\n projectRef:\n   name: my-project\n providerSettings:\n   instanceSizeName: M10\n   providerName: GCP\n   regionName: EASTERN_US"
                },
                {
                    "lang": "sh",
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n name: my-database-user\n labels:\n   app.kubernetes.io/version: 1.6.0\nspec:\n roles:\n   - roleName: readWriteAnyDatabase\n     databaseName: admin\n projectRef:\n   name: my-project\n username: theuser\n passwordSecretRef:\n   name: the-user-password"
                },
                {
                    "lang": null,
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n name: my-database-user\n labels:\n   app.kubernetes.io/version: 1.6.0\nspec:\n roles:\n   - roleName: \"readWriteAnyDatabase\"\n     databaseName: \"admin\"\n projectRef:\n   name: my-project\n username: theuser\n passwordSecretRef:\n   name: the-user-password\n scopes:\n   - type: CLUSTER\n     name: gcp-cluster"
                },
                {
                    "lang": "sh",
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n  name: my-database-user\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  username: CN=my-x509-authenticated-user,OU=organizationalunit,O=organization\n  databaseName: \"\\$external\"\n  x509Type: \"CUSTOMER\"\n  roles:\n    - roleName: \"readWriteAnyDatabase\"\n      databaseName: \"admin\"\n  projectRef:\n    name: my-project"
                },
                {
                    "lang": "sh",
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n  name: my-database-user\nspec:\n  roles:\n    - roleName: \"readWriteAnyDatabase\"\n      databaseName: \"admin\"\n  projectRef:\n    name: my-project\n  username: my-oidc-group-id/my-idp-group-name\n  oidcAuthType: IDP_GROUP"
                }
            ],
            "preview": "Type: string",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-configure-audit-logs",
            "title": "Configure Audit Logs",
            "headings": [
                "Required Access",
                "Enable Audit Logs",
                "Configure a Custom Auditing Filter"
            ],
            "paragraphs": "You can use  Atlas Kubernetes Operator  to configure audit logs. To learn more, see\n Set Up Database Auditing . This feature is not available for  M0  free clusters,  M2 , and\n M5  clusters. To learn more,\nsee  Atlas M0 (Free Cluster), M2, and M5 Limits . This feature is not supported on Serverless instances at this time.\nTo learn more, see\n Serverless Instance Limitations . Database auditing lets administrators track system activity for\ndeployments with multiple users.  Atlas  administrators can select\nthe actions, database users,  Atlas  roles, and LDAP groups that they\nwant to audit.  Atlas  supports  auditing \nmost of the documented  system event actions , with the following limitations: The  authCheck  event action logs authorization attempts by users\ntrying to read from and write to databases in the clusters in your\nproject.  Atlas  audits the following specific commands: Atlas  implements the  authCheck  event action as the following\nfour separate actions: To learn about how MongoDB writes audit events to disk, see\n Audit Guarantee \nin the MongoDB Manual. When an  Atlas  user performs an action in the Atlas UI on a\ncluster, both the audit logs and  mongodb.log  file log the\n mms-automation  database user as the user performing the auditable\naction. However, the  Project Activity Feed  logs the actual username of the  Atlas  user\nresponsible for the action. The  Atlas  audit logs don't track user creation or modification\nevents because  Atlas  performs these operations directly in the\n admin  database. Due to these noted limitations, you must\nuse a combination of audit logs, the  mongodb.log ,\nand the  Project Activity Feed \nto perform a full audit. authCheck Reads authCheck Writes aggregate aggregate mapReduce mapReduce distinct delete eval   1 eval   1 count findAndModify geoNear insert geoSearch update group resetError find getLastError getMore getPrevError parallelCollectionScan   1 MongoDB versions 4.2 and later don't support these commands. Event Action Description authChecksReadFailures authCheck  event action for all failed reads with the\n auditAuthorizationSuccess \nparameter set to false. This event action is the default for\nread-related event actions. authChecksReadAll authCheck  event action for all reads, both sucesses and\nfailures.\nThis event action is the same as  authChecksReadFailures , but\nwith the  auditAuthorizationSuccess \nparameter set to true. If you enable  auditAuthorizationSuccess ,\nyou might severely impact cluster performance. Enable\nthis option with caution. authChecksWriteFailures authCheck  event action for all failed writes with the\n auditAuthorizationSuccess \nparameter set to false. This event action is the default for\nwrite-related event actions. authChecksWriteAll authCheck  event action for all writes, both successes and\nfailures. This event action is the same as\n authChecksWriteFailures , but with the\n auditAuthorizationSuccess \nparameter set to true. If you enable  auditAuthorizationSuccess ,\nyou might severely impact cluster performance. Enable\nthis option with caution. To configure audit logs, you must have\n Project Owner  access to the project that\nyou want to update or  Organization Owner  access\nto the organization that contains the project that you want to update. To enable audit logs, set  spec.auditing.enabled  to  true \nin the  AtlasProject  Custom Resource . Example: To retrieve the audit logs in  Atlas , see  MongoDB Logs . To retrieve the audit logs using the API, see\n Logs . To learn about best practices for auditing the actions of temporary\ndatabase users, see  Audit Temporary Database Users . To configure a custom auditing filter, specify the\n spec.auditing.auditFilter  setting in the\n AtlasProject  Custom Resource .  To specify a value for this\nsetting, you must set  spec.auditing.enabled  to  true . Example: To learn more about the configuration parameters available from the\n API (Application Programming Interface) , see the  Atlas   Auditing . This feature is not available for  M0  free clusters,  M2 , and\n M5  clusters. To learn more,\nsee  Atlas M0 (Free Cluster), M2, and M5 Limits . This feature is not supported on Serverless instances at this time.\nTo learn more, see\n Serverless Instance Limitations . Atlas  supports specifying a JSON-formatted audit filter\nfor customizing  MongoDB Auditing . Custom audit filters lets users forgo the managed\nAtlas UI  auditing filter builder \nin favor of hand-tailored granular control of event auditing.\n Atlas  checks only that the custom filter uses valid\nJSON syntax, and doesn't validate or test the filter's functionality. The audit filter document must resolve to a query that matches one or\nmore fields in the  audit event message .\nThe filter document can use combinations of  query operators  and equality\nconditions to match the desired audit messages. To view example auditing filters, see\n Example Auditing Filters . To learn more about configuring MongoDB\nauditing filters, see  Configure Audit Filter . Atlas  uses a  rolling upgrade  strategy\nfor enabling or updating audit configuration settings across all\nclusters in the  Atlas  project. Rolling upgrades require at least\none election per replica set. To learn more about testing application resilience to replica set\nelections, see\n /tutorial/test-resilience/test-primary-failover . To learn more\nabout how  Atlas  provides high availability, see\n Atlas High Availability .",
            "code": [
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: TestAuditing\n  connectionSecretRef:\n    name: my-atlas-key\n  projectIpAccessList:\n    - ipAddress: \"0.0.0.0/1\"\n      comment: \"Everyone has access. For test purposes only.\"\n    - ipAddress: \"128.0.0.0/1\"\n      comment: \"Everyone has access. For test purposes only.\"\n  auditing:\n    enabled: true\n EOF"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: TestAuditing\n  connectionSecretRef:\n    name: my-atlas-key\n  projectIpAccessList:\n    - ipAddress: \"0.0.0.0/1\"\n      comment: \"Everyone has access. For test purposes only.\"\n    - ipAddress: \"128.0.0.0/1\"\n      comment: \"Everyone has access. For test purposes only.\"\n  auditing:\n    enabled: true\n    auditFilter: \"{\"atype\": \"authenticate\"}\"\n EOF"
                }
            ],
            "preview": "You can use Atlas Kubernetes Operator to configure audit logs. To learn more, see\nSet Up Database Auditing.",
            "tags": "audit",
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "atlasbackupschedule-custom-resource",
            "title": "AtlasBackupSchedule Custom Resource",
            "headings": [
                "Example",
                "Parameters"
            ],
            "paragraphs": "The  AtlasBackupSchedule  custom resource configures a backup\nschedule that you can apply to your\n AtlasDeployment  Custom Resource . When you\ncreate the  AtlasBackupSchedule  custom\nresource,  Atlas Kubernetes Operator  tries to create or update a backup schedule. Atlas Kubernetes Operator  does one of the following actions using the  Atlas \n Cloud Backup Schedule API Resource : If you remove the  AtlasBackupSchedule  resource from your  Kubernetes \ncluster,  Atlas  stops creating backups for your cluster. You can specify one backup schedule per cluster, but you can use\nthe same backup schedule for multiple clusters. Atlas Kubernetes Operator  uses  custom resource  configuration\nfiles to manage your  Atlas  configuration, but as of  Atlas Kubernetes Operator  2.0,\ncustom resources you delete in  Kubernetes  are no longer deleted in\n Atlas . Instead,  Atlas Kubernetes Operator  simply stops managing those resources.\nFor example, if you delete an  AtlasProject  Custom Resource \nin  Kubernetes ,  Atlas Kubernetes Operator  no longer automatically deletes the corresponding project\nfrom  Atlas , preventing accidental or unexpected deletions. To learn more,\nincluding how to  revert this behavior  to\nthe default used prior to  Atlas Kubernetes Operator  2.0, see  New Default: Deletion Protection in  Atlas Kubernetes Operator  2.0 . Creates a new backup schedule. Updates an existing backup schedule. You must do all of the following to back up a cluster: To learn more, see  Back Up Your  Atlas  Cluster . Create a  backup policy Create a backup schedule and set the\n spec.policy.name  field to the name of the configured\nbackup policy. Set the  spec.backupRef.name  field in the\n AtlasDeployment  Custom Resource  to the name of the\nconfigured backup schedule. The following example shows an  AtlasBackupSchedule  custom resource\nconfigured to take snapshots at 10:10 UTC and restore up to two days: This section describes some of the key  AtlasBackupSchedule  custom\nresource parameters available. For a full list of parameters available,\nsee the  Atlas   Modify Cloud Backup Backup Policy\nAPI . Refer\nto these descriptions, the available examples, and the  API (Application Programming Interface) \ndocumentation to customize your specifications. Type : boolean Optional Flag that specifies whether  Atlas  automatically exports cloud\nbackup snapshots to your  AWS (Amazon Web Services)  backup. Specify  true  to enable\nautomatic export of cloud backup snapshots to the  AWS (Amazon Web Services)  bucket.\nSpecify  false  to disable automatic export. Type : array Required List that contains a document for each copy setting item in the\ndesired  backup policy .\nEach copy setting item defines a\n snapshot distribution  policy. Type : object Optional Policy for automatically exporting cloud backup snapshots. Type : string Optional Unique 24-hexadecimal character string that identifies the  AWS (Amazon Web Services) \nbucket. Type : string Optional Human-readable label that indicates the rate at which the export\npolicy item occurs. Type : number Optional Number that indicates the  UTC (Coordinated Universal Time)  hour of day between  0  and\n 23 , inclusive, representing the hour of the day that  Atlas \ntakes snapshots for backup policy items. Type : number Optional Number that indicates the minutes after\n spec.referenceHourOfDay  that  Atlas  takes\nsnapshots for backup policy items. Value must be between  0 \n 59  inclusive. Type : number Optional Number that indicates the days back in time that you can restore to\nwith continuous cloud backup accuracy. Value must be a positive,\nnon-zero integer. This setting applies to continuous cloud backups only. Type : array Required List that contains the details for the\n backup policy  to\napply. Type : string Required metadata.name  value within thhe\n AtlasBackupPolicy  Custom Resource  for the backup policy that\nyou want to apply. You can specify only one backup policy per backup\nschedule. You can't use the same backup policy in multiple backup\nschedules. Type : string Required String that indicates the namespace that contains the\n AtlasBackupPolicy  Custom Resource  for the backup policy that\nyou want to apply.",
            "code": [
                {
                    "lang": null,
                    "value": "apiVersion: atlas.mongodb.com/v1\nkind: AtlasBackupSchedule\nmetadata:\n  name: atlas-default-backupschedule\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  autoExportExabled: true\n  copySettings:\n  - cloudProvider: AWS\n    frequencies:\n    - HOURLY\n    regionName: US_EAST_1\n    shouldCopyOplogs: true\n  referenceHourOfDay: 10\n  referenceMinuteOfHour: 10\n  restoreWindowDays: 2\n  policy:\n    name: atlas-default-backuppolicy\n    namespace: mongodb-atlas-system"
                }
            ],
            "preview": "Type: boolean",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-import-projects",
            "title": "Import Atlas Projects into Atlas Kubernetes Operator",
            "headings": [
                "Overview",
                "Parameters",
                "Compatibility",
                "Examples",
                "Applying the Configuration"
            ],
            "paragraphs": "If you have existing  Kubernetes  deployments and wish to start using  Atlas Kubernetes Operator ,\nyou can use the  Atlas  CLI  atlas kubernetes config generate  or\n atlas kubernetes config apply  commands to export  Atlas \nprojects, deployments, and database users. Both commands allow you to export your configuration in an\n Atlas Kubernetes Operator -compatible format for use in the  Kubernetes  or Openshift cluster on\nwhich  Atlas Kubernetes Operator  runs. The  atlas kubernetes config generate  command\nachieves this by outputting a\n YAML (Yet Another Markup Lanugage) -formatted configuration to\nyour terminal's  stdout , while the  atlas kubernetes config apply \ncommand stores the configuration in memory and sends it directly to a\ntarget  Kubernetes  cluster. Both commands generate a  .yaml -formatted configuration\nwhich includes the following  Atlas Kubernetes Operator  resources: An  AtlasDeployment  Custom Resource An  AtlasBackupSchedule  Custom Resource An  AtlasBackupPolicy  Custom Resource An  AtlasProject  Custom Resource An  AtlasDatabaseUser  Custom Resource An  AtlasTeam  Custom Resource The command takes the following parameters: Parameter Description Necessity --projectId Unique 24-digit hexadecimal string that identifies your\nproject. If omitted, defaults to the  projectId  value in\nyour  atlascli  configuration file. Required. --clusterName A comma-separated list of human-readable labels that\nidentify the clusters to export. These must be clusters in\nthe project specified in the  projectId  parameter. If\nomitted, the command exports all clusters in the specified\nproject. Optional. --includeSecrets Flag that populates an entry in the configuration file for an  Atlas \ncredentials secret. If omitted, the\ncommand creates a secret, but doesn't populate it with data.\nThe secret is rendered as plain text. Optional. --targetNamespace Kubernetes namespace to export the resources to. The command\nfills the  metadata.namespace  field of each exported  Atlas \nentity with the value of this parameter. Required. --operatorVersion Version of  Atlas Kubernetes Operator  for which to export your files. If\nomitted, the command exports files compatible with  Atlas Kubernetes Operator \nv1.5.1. Optional. The command takes the following parameters: Parameter Description Necessity --projectId Unique 24-digit hexadecimal string that identifies your\nproject. If omitted, defaults to the  projectId  value in\nyour  atlascli  configuration file. Required. --orgId Unique 24-digit hexadecimal string that identifies the\n Atlas  organization to register the project with. If\nomitted, defaults to the  orgId  value in your\n atlascli  configuration file or your  ORGID \nenvironment variable. Optional. --clusterName A comma-separated list of human-readable labels that\nidentify clusters to export. These must be clusters in the\nproject specified in the  projectId  parameter. If\nomitted, the command exports all clusters in the specified\nproject. Optional. --targetNamespace Kubernetes namespace to export the resources to. The command\nfills the  metadata.namespace  field of each exported  Atlas \nentity with the value of this parameter. Required. --operatorVersion Version of  Atlas Kubernetes Operator  for which to export your files. If\nomitted, the command exports files compatible with  Atlas Kubernetes Operator \nv1.5.1. Optional. --kubeContext Kubeconfig  context to use for connecting to the cluster. Required --kubeconfig Path to your  kubeconfig  file. Required atlascli  exports configurations from Atlas in a format that is\nversion-dependent on  Atlas Kubernetes Operator . The following table describes which\nversions of  atlascli  support which versions of  Atlas Kubernetes Operator : atlascli  version Atlas Kubernetes Operator  versions 1.4.0 1.5.0 The following examples assume a project named  sampleProject ,\nwith clusters named  sample1 ,  sample2 , and  sample3 , a\nProject ID of  63500d1139dd494b92fe4376 , and a target namespace of\n sampleNamespace . To export the entire project, including all  Atlas  deployments and\nsecrets with credentials, run the following command: To export two specific  Atlas  deployments from the project without\nsecret credentials, run the following command: In the preceding command examples, you can  apply the generated\nconfiguration to your Kubernetes or Openshift cluster  by piping\nthe output into the  kubectl apply  command. The following\ncommand example illustrates this: Alternatively, you can  save the generated configuration  by\nredirecting  stdout  to a  .yaml  file. The following command\nimports a single  Atlas  deployment from the project without\nsecret credentials and saves the output to\n myAtlasProject.yaml . To apply the generated configuration to your  Kubernetes  or Openshift\ncluster in this scenario, pass the  .yaml  file as an argument to\nthe  kubectl apply  command. To export the entire project, run the following command: To export two specific  Atlas  deployments from the project,\nrun the following command:",
            "code": [
                {
                    "lang": "sh",
                    "value": "atlas kubernetes config generate --projectId=63500d1139dd494b92fe4376 \\\n--includeSecrets --targetNamespace=sampleNamespace"
                },
                {
                    "lang": "sh",
                    "value": "atlas kubernetes config generate --projectId=63500d1139dd494b92fe4376 \\\n--clusterName=sample1,sample2 --targetNamespace=sampleNamespace"
                },
                {
                    "lang": "sh",
                    "value": "atlas kubernetes config generate --projectId=63500d1139dd494b92fe4376 \\\n--clusterName=sample1,sample2 --targetNamespace=sampleNamespace \\\n| kubectl apply -f -"
                },
                {
                    "lang": "sh",
                    "value": "atlas kubernetes config generate --projectId=63500d1139dd494b92fe4376 \\\n--clusterName=sample3 --targetNamespace=sampleNamespace \\\n> myAtlasProject.yaml"
                },
                {
                    "lang": "sh",
                    "value": "kubectl apply -f myAtlasProject.yaml"
                },
                {
                    "lang": "sh",
                    "value": "atlas kubernetes config apply --projectId=63500d1139dd494b92fe4376 \\\n--targetNamespace=sampleNamespace"
                },
                {
                    "lang": "sh",
                    "value": "atlas kubernetes config apply --projectId=63500d1139dd494b92fe4376 \\\n--clusterName=sample1,sample2 --targetNamespace=sampleNamespace\n\nIn contrast to ``atlas kubernetes config generate``, this\ncommand directly applies the generated configuration without\nany further manual operation on your part."
                }
            ],
            "preview": "If you have existing Kubernetes deployments and wish to start using Atlas Kubernetes Operator,\nyou can use the Atlas CLI atlas kubernetes config generate or\natlas kubernetes config apply commands to export Atlas\nprojects, deployments, and database users.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-quick-start",
            "title": "Quick Start",
            "headings": [
                "Prerequisites",
                "Procedure",
                "Register for an Atlas account or log in.",
                "Create API keys for your organization.",
                "Deploy Atlas Kubernetes Operator.",
                "Create a secret with your API keys and organization ID.",
                "Create the AtlasProject custom resource.",
                "Create the AtlasDeployment custom resource.",
                "Create a secret with a password to log into the Atlas cluster database.",
                "Create the AtlasDatabaseUser custom resource.",
                "Check the status of your database user.",
                "Retrieve the secret that Atlas Kubernetes Operator created to connect to the cluster."
            ],
            "paragraphs": "You can use  Atlas Kubernetes Operator  to manage resources in  Atlas  without leaving\n Kubernetes . This tutorial demonstrates how to create your first cluster\nin  Atlas  from  Kubernetes  configuration files with  Atlas Kubernetes Operator . To create your first cluster in  Atlas  from Helm Charts with\n Atlas Kubernetes Operator , see  Helm Charts Quick Start . This tutorial requires: A running  Kubernetes  cluster with nodes running processors with the\nx86-64, AMD64, or ARM64 architecture. jq  1.6 or higher You can access the  Atlas Kubernetes Operator  project on GitHub: https://github.com/mongodb/mongodb-atlas-kubernetes To install the Atlas Kubernetes operator using the\nAtlas CLI, run the following command: To learn more about the command syntax and parameters, see the\nAtlas CLI documentation for  atlas kubernetes operator install . Install the Atlas CLI Connect to the Atlas CLI Atlas Kubernetes Operator  uses  custom resource  configuration\nfiles to manage your  Atlas  configuration, but as of  Atlas Kubernetes Operator  2.0,\ncustom resources you delete in  Kubernetes  are no longer deleted in\n Atlas . Instead,  Atlas Kubernetes Operator  simply stops managing those resources.\nFor example, if you delete an  AtlasProject  Custom Resource \nin  Kubernetes ,  Atlas Kubernetes Operator  no longer automatically deletes the corresponding project\nfrom  Atlas , preventing accidental or unexpected deletions. To learn more,\nincluding how to  revert this behavior  to\nthe default used prior to  Atlas Kubernetes Operator  2.0, see  New Default: Deletion Protection in  Atlas Kubernetes Operator  2.0 . Register a new Atlas Account  or  Log in to Your Atlas Account . Create an API (Application Programming Interface) Key in an Organization  and configure the  API\nAccess List . You need the following public API key, private API key, and the\norganization ID information to configure  Atlas Kubernetes Operator  access to\n Atlas . You need the following public API key, private API key, and the\norganization ID information to configure  Atlas Kubernetes Operator  access to  Atlas . If you want  Atlas Kubernetes Operator  to create a new  Atlas  project,\n Create an API (Application Programming Interface) Key in an Organization . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the\n Organization Project Creator  organization role or\nhigher. If you want to work with an existing  Atlas  project,\n Create an API (Application Programming Interface) Key for a Project . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the  Project Owner \nproject role. In one of the following scenarios, replace  <version>  with the\nlatest  release number : If you want  Atlas Kubernetes Operator  to watch all the  namespaces  in the  Kubernetes \ncluster, run the following command: If you want  Atlas Kubernetes Operator  to watch only its  namespace , you must install\nthe configuration files from the  deploy/namespaced  directory: To create and label a  secret , run the following commands with\nyour API keys and organization ID: If you use external secret storage, you don't need to put sensitive\ninformation directly into  Kubernetes   secrets . To learn more, see\n Configure Secret Storage . Run the following command to create the\n AtlasProject  Custom Resource : The following example does not specify\n spec.connectionSecretRef.name . If unspecified,  Atlas Kubernetes Operator \nuses the default connection  secret  previously set with your\nAPI keys and organization ID. The IP address in the example,  0.0.0.0/0 , allows any client to\nconnect to the  Atlas  cluster. Do not use this IP address in\nproduction. Run the following command to create an\n AtlasDeployment  Custom Resource  and create a cluster: To create a serverless instance, see the\n serverless instance example . Replace  P@@ssword%  with your password and run the following\ncommands: If you use external secret storage, you don't need to put sensitive\ninformation directly into  Kubernetes   secrets . To learn more, see\n Configure Secret Storage . Run the following command to create the\n AtlasDatabaseUser  Custom Resource : spec.passwordSecretRef  must reference the password that\nyou created previously. Run the following command until you recieve a  True  response,\nwhich indicates the database user is ready: The  AtlasDatabaseUser  Custom Resource  waits until the\ncluster is ready. Creating a new cluster can take up to 10 minutes. Copy the following command: The following command requires  jq  1.6 or higher. Replace the following placeholders with the details for your\ncustom resources: my-project Specify the value of the  metadata  field of your\n AtlasProject  Custom Resource . my-atlas-cluster Specify the value of the  metadata  field of your\n AtlasDeployment  Custom Resource . my-database-user Specify the value of the  metadata  field of your\n AtlasDatabaseUser  Custom Resource . Run the command. You can use this  secret  in your application: Your connection strings will differ from the following example.",
            "code": [
                {
                    "lang": "sh",
                    "value": "\natlas kubernetes operator install [options]\n"
                },
                {
                    "lang": "sh",
                    "value": "kubectl apply -f https://raw.githubusercontent.com/mongodb/mongodb-atlas-kubernetes/<version>/deploy/all-in-one.yaml"
                },
                {
                    "lang": "sh",
                    "value": "kubectl apply -f https://raw.githubusercontent.com/mongodb/mongodb-atlas-kubernetes/<version>/deploy/namespaced/crds.yaml"
                },
                {
                    "lang": "sh",
                    "value": "kubectl apply -f https://raw.githubusercontent.com/mongodb/mongodb-atlas-kubernetes/<version>/deploy/namespaced/namespaced-config.yaml"
                },
                {
                    "lang": "sh",
                    "value": "kubectl create secret generic mongodb-atlas-operator-api-key \\\n    --from-literal=\"orgId=<atlas_organization_id>\" \\\n    --from-literal=\"publicApiKey=<atlas_api_public_key>\" \\\n    --from-literal=\"privateApiKey=<atlas_api_private_key>\" \\\n    -n mongodb-atlas-system"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret mongodb-atlas-operator-api-key atlas.mongodb.com/type=credentials -n mongodb-atlas-system"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: Test Atlas Operator Project\n  projectIpAccessList:\n    - ipAddress: \"0.0.0.0/0\"\n      comment: \"Allowing access to database from everywhere (only for Demo!)\"\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDeployment\nmetadata:\n  name: my-atlas-cluster\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  projectRef:\n    name: my-project\n  deploymentSpec:\n    name: \"Test-cluster\"\n    tags:\n     - key: \"environment\"\n       value: \"production\"\n    providerSettings:\n      instanceSizeName: M10\n      providerName: AWS\n      regionName: US_EAST_1\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl create secret generic the-user-password --from-literal=\"password=P@@sword%\""
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret the-user-password atlas.mongodb.com/type=credentials"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDatabaseUser\nmetadata:\n  name: my-database-user\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  roles:\n    - roleName: \"readWriteAnyDatabase\"\n      databaseName: \"admin\"\n  projectRef:\n    name: my-project\n  username: theuser\n  passwordSecretRef:\n    name: the-user-password\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasdatabaseusers my-database-user -o=jsonpath='{.status.conditions[?(@.type==\"Ready\")].status}'"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get secret {my-project}-{my-atlas-cluster}-{my-database-user} -o json | jq -r '.data | with_entries(.value |= @base64d)';"
                },
                {
                    "lang": "sh",
                    "value": "{\n   \"connectionStringStandard\": \"mongodb://theuser:P%40%40sword%25@test-cluster-shard-00-00.peqtm.mongodb.net:27017,test-cluster-shard-00-01.peqtm.mongodb.net:27017,test-cluster-shard-00-02.peqtm.mongodb.net:27017/?ssl=true&authSource=admin&replicaSet=atlas-pk82fl-shard-0\",\n   \"connectionStringStandardSrv\": \"mongodb+srv://theuser:P%40%40sword%25@test-cluster.peqtm.mongodb.net\",\n   \"password\": \"P@@sword%\",\n   \"username\": \"theuser\"\n }"
                },
                {
                    "lang": "sh",
                    "value": "containers:\n - name: test-app\n   env:\n    - name: \"CONNECTION_STRING\"\n      valueFrom:\n        secretKeyRef:\n          name: test-atlas-operator-project-test-cluster-theuser\n          key: connectionStringStandardSrv"
                }
            ],
            "preview": "You can use Atlas Kubernetes Operator to manage resources in Atlas without leaving\nKubernetes. This tutorial demonstrates how to create your first cluster\nin Atlas from Kubernetes configuration files with Atlas Kubernetes Operator.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-set-up-data-federation",
            "title": "Set Up Data Federation",
            "headings": [
                "Prerequisites",
                "Procedure",
                "Create the AWS (Amazon Web Services) IAM (Identity and Access Management) role in Atlas",
                "Modify your AWS IAM role trust policy.",
                "Create the AtlasDataFederation custom resource.",
                "Check the status of your federated database instance.",
                "Take the Next Steps"
            ],
            "paragraphs": "This tutorial demonstrates how to create a federated database instance\nin  Atlas  from  Kubernetes  configuration files with  Atlas Kubernetes Operator . The federated database instance\nin this tutorial connects an  AWS (Amazon Web Services)   S3 (Simple Storage Service)  bucket and an  Atlas \ncluster. This tutorial requires: A running  Kubernetes  cluster with  Atlas Kubernetes Operator   deployed , including an\n AtlasProject  Custom Resource . An  AWS (Amazon Web Services)  user account with permissions to modify  IAM (Identity and Access Management)  roles. The  Atlas CLI . Atlas Kubernetes Operator  uses  custom resource  configuration\nfiles to manage your  Atlas  configuration, but as of  Atlas Kubernetes Operator  2.0,\ncustom resources you delete in  Kubernetes  are no longer deleted in\n Atlas . Instead,  Atlas Kubernetes Operator  simply stops managing those resources.\nFor example, if you delete an  AtlasProject  Custom Resource \nin  Kubernetes ,  Atlas Kubernetes Operator  no longer automatically deletes the corresponding project\nfrom  Atlas , preventing accidental or unexpected deletions. To learn more,\nincluding how to  revert this behavior  to\nthe default used prior to  Atlas Kubernetes Operator  2.0, see  New Default: Deletion Protection in  Atlas Kubernetes Operator  2.0 . Run the following Atlas CLI command to create the new  AWS (Amazon Web Services) \n IAM (Identity and Access Management)  role in  Atlas . Replace the following placeholder with your value: Placeholder Description PROJECT-ID Unique 24-character hexadecimal string that identifies the\n Atlas  project to use. Note the returned field values  RoleID ,  Atlas AWS Account\nARN , and  Unique External ID : Log in to your  AWS (Amazon Web Services)  Management Console. Navigate to the  Identity and Access Management (IAM)  service. Select  Roles  from the left-side navigation. Click on the existing IAM role you wish to use for  Atlas  access\nfrom the list of roles. Select the  Trust Relationships  tab. Click the  Edit trust relationship  button. Edit the  Policy Document . Add a new  Statement  object\nwith the following content. Replace the highlighted lines with values returned in the previous step. Click the  Update Trust Policy  button. Run the following command to create the\n AtlasDataFederation  Custom Resource . The  roleId  should\nmatch the value returned for  RoleID  in the previous step and the\n spec.projectRef.name  should match the name of your\n AtlasProject  Custom Resource : Run the following command until you recieve a  True  response,\nwhich indicates the database user is ready: To configure private endpoints for your federated database instance, see  Manage Private Endpoints .",
            "code": [
                {
                    "lang": "sh",
                    "value": "atlas cloudProviders accessRoles aws create --projectId <PROJECT-ID>"
                },
                {
                    "lang": "sh",
                    "value": "AWS IAM role '<RoleID>' successfully created.\nAtlas AWS Account ARN: <AtlasAWSAccountARN>\nUnique External ID: <AtlasAssumedRoleExternalID>"
                },
                {
                    "lang": "json",
                    "value": "{\n   \"Version\":\"2012-10-17\",\n   \"Statement\":[\n      {\n         \"Effect\":\"Allow\",\n         \"Principal\":{\n            \"AWS\":\"<atlasAWSAccountArn>\"\n         },\n         \"Action\":\"sts:AssumeRole\",\n         \"Condition\":{\n            \"StringEquals\":{\n               \"sts:ExternalId\":\"<atlasAssumedRoleExternalId>\"\n            }\n         }\n      }\n   ]\n}\n"
                },
                {
                    "lang": "",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasDataFederation\nmetadata:\n  name: my-federated-deployment\nspec:\n  projectRef:\n    name: my-project\n    namespace: default\n  cloudProviderConfig:\n    aws:\n      roleId: 12345678\n      testS3Bucket: my-bucket\n  dataProcessRegion:\n    cloudProvider: AWS\n    region: OREGON_USA\n  name: my-fdi\n  storage:\n    databases:\n    - collections:\n      - dataSources:\n        - allowInsecure: false\n          collection: my-collection\n          collectionRegex:\n          database: my-database\n          databaseRegex:\n          defaultFormat: \".avro\"\n          path: /\n          provenanceFieldName: string\n          storeName: my-data-store\n          urls:\n          - string:\n        name: my-collection-mdb\n      maxWildcardCollections: 100\n      name: my-database-mdb\n      views:\n      - name: my-view\n        pipeline:\n        source: my-source-collection\n    stores:\n    - name: my-store\n      provider: S3\n      additionalStorageClasses:\n      - STANDARD\n      bucket: my-bucket\n      delimiter: /\n      includeTags: false\n      prefix: data-\n      public: false\n      region: US_WEST_1\nEOF\n"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasdatafederation my-federated-deployment -o=jsonpath='{.status.conditions[?(@.type==\"Ready\")].status}'"
                }
            ],
            "preview": "This tutorial demonstrates how to create a federated database instance\nin Atlas from Kubernetes configuration files with Atlas Kubernetes Operator. The federated database instance\nin this tutorial connects an AWS (Amazon Web Services) S3 (Simple Storage Service) bucket and an Atlas\ncluster.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "production-notes",
            "title": "Production Notes",
            "headings": [
                "Atlas Account",
                "API Keys",
                "Namespaces",
                "AWS Security Groups",
                "Deprecated Configuration Parameters",
                "Cluster Creation",
                "Connection Strings",
                "Connection Information",
                "Supported Deployment Flags"
            ],
            "paragraphs": "You can access the  Atlas Kubernetes Operator  project on GitHub: https://github.com/mongodb/mongodb-atlas-kubernetes Before you deploy  Atlas Kubernetes Operator , you must create an  Atlas  account. To\nlearn more, see  Register a new Atlas Account . To learn more, see  Configure Access to  Atlas . You need the following public API key, private API key, and the\norganization ID information to configure  Atlas Kubernetes Operator  access to  Atlas . If you want  Atlas Kubernetes Operator  to create a new  Atlas  project,\n Create an API (Application Programming Interface) Key in an Organization . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the\n Organization Project Creator  organization role or\nhigher. If you want to work with an existing  Atlas  project,\n Create an API (Application Programming Interface) Key for a Project . If your organization requires an IP\naccess list for the Atlas Administration API, you must also\n configure the API access list . You must assign the API key the  Project Owner \nproject role. You can deploy  Atlas Kubernetes Operator  to watch all the  namespaces  in the  Kubernetes \ncluster, or only its  namespace . You must  configure VPC peering  for your project\nbefore you can add an  AWS (Amazon Web Services)  security group to an access list. You\ncan't set  AWS (Amazon Web Services)  security groups as temporary access list entries. The following parameters are deprecated in the  Atlas \n API  and  Atlas Kubernetes Operator  doesn't support\nthem: replicationSpec replicationFactor Creating a new cluster can take up to 10 minutes. You can't use a connection URL directly.  Atlas  clusters\nrequire authentication. You must create at least one\n AtlasDatabaseUser  Custom Resource  before the application in\nyour  Kubernetes  cluster can connect to the  Atlas  cluster.\n Atlas Kubernetes Operator  creates a special  secret  for each cluster and\ndatabase user combination in the project. The application in your  Kubernetes \ncluster can use this  secret  to connect to the  Atlas \ncluster. The  spec.scopes  parameter in the  AtlasDatabaseUser \ncustom resource restricts the clusters that create the database\nuser. To connect to the Atlas Administration API,  Atlas Kubernetes Operator  reads the organization\nID and  API (Application Programming Interface)  keys from one of the following locations: spec.connectionSecretRef.name  (if specified in\nthe  AtlasProject  Custom Resource ). By default,  Atlas Kubernetes Operator  keeps connection secrets in the same  namespace \nas the  AtlasProject  Custom Resource . To store\nsecrets in another  namespace , specify the\n spec.connectionSecretRef.namespace  parameter. global   Atlas Kubernetes Operator   secret \n <operator-deployment-name>-api-key \n(if  spec.connectionSecretRef.name  is not specified). To create or update resources in  Atlas ,  Atlas Kubernetes Operator  uses the\nconnection information to make  API (Application Programming Interface)  calls to  Atlas . Sometimes  Atlas Kubernetes Operator  makes multiple  API (Application Programming Interface)  calls in  Atlas  during\nthe reconciliation of a custom resource. For example,\n AtlasProject  has an  IP Access List \nconfiguration for calling the matching  API . If any errors occur during the reconciliation,  status.conditions \nupdates to reflect the error. When you  deploy .\nAtlas Kubernetes Operator using  kubectl , you can add the following flags to customize your\nconfiguration: Flag Description Default Value atlas-domain Atlas URL domain name, that terminates in a slash. https://cloud.mongodb.com/ metrics-bind-address Address that the metric endpoint binds to. :8080 health-probe-bind-address Address that the probe endpoint binds to. :8081 global-api-secret-name Name of the secret that contains your Atlas API keys.\nAtlas Kubernetes Operator uses this parameter if your  AtlasProject \nconfiguration doesn't contain an API key reference. <deployment_name>-api-key , where  <deployment-name>  is\nthe name of your Atlas Kubernetes Operator deployment. leader-elect Flag that indicates whether to enable leader election for\ncontroller manager. Leader election ensures that only one\ncontroller manager is active at a time. false log-level Importance or urgency level of log entries. You can specify one\nof the following levels: debug info warn error dpanic panic fatal info log-encoder Format for log records. You can specify one of the following formats: json console json The following command sets up an Atlas Kubernetes Operator 1.8.2 deployment with the\nmetrics endpoint on port  :8084 , using a log level of  error :",
            "code": [
                {
                    "lang": "sh",
                    "value": "- lastTransitionTime: \"2021-03-15T14:26:44Z\"\n   message: 'POST https://cloud.mongodb.com/api/atlas/v1.0/groups/604a47de73cd8cag77239021/accessList:\n      400 (request \"INVALID_IP_ADDRESS_OR_CIDR_NOTATION\") The address 192.0.2.1dfdfd5\n      must be in valid IP address or CIDR notation.'\n   reason: ProjectIPAccessListNotCreatedInAtlas\n   status: \"False\"\n   type: IPAccessListReady"
                },
                {
                    "lang": "sh",
                    "value": "kubectl apply --metrics-bind-address :8084 \\\n--log-level error \\\n-f https://raw.githubusercontent.com/mongodb/mongodb-atlas-kubernetes/1.8.2/deploy/all-in-one.yaml"
                }
            ],
            "preview": "Before you deploy Atlas Kubernetes Operator, you must create an Atlas account. To\nlearn more, see Register a new Atlas Account.",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        },
        {
            "slug": "ak8so-encryption-at-rest-customer-keys",
            "title": "Encrypt Data Using a Key Management Service",
            "headings": [
                "Prerequisites",
                "Procedure",
                "Create a secret with your AWS (Amazon Web Services) credentials.",
                "Specify the spec.encryptionAtRest.awsKms parameter.",
                "Check for successful enablement of encryption at rest on your project.",
                "Enable encryption at rest using customer-managed keys for your cluster.",
                "Create a secret with your Azure (Microsoft Azure) credentials.",
                "Specify the spec.encryptionAtRest.azureKeyVault parameter.",
                "Check for successful enablement of encryption at rest on your project.",
                "Enable encryption at rest using customer-managed keys for your cluster.",
                "Create a secret with your Google Cloud credentials.",
                "Specify the spec.encryptionAtRest.googleCloudKms parameter.",
                "Check for successful enablement of encryption at rest on your project.",
                "Enable encryption at rest using customer-managed keys for your cluster."
            ],
            "paragraphs": "You can use one or more of the following customer  KMS (Key Management Service) \nproviders for encryption at rest in  Atlas : To learn more about using your  KMS (Key Management Service)  with  Atlas , see: To manage your  KMS (Key Management Service)  encryption with  Atlas Kubernetes Operator , you can\nspecify and update the  spec.encryptionAtRest  parameter for\nthe  AtlasProject  Custom Resource . Each time you change the\n spec  field in any of the supported custom resources,  Atlas Kubernetes Operator \n creates or updates  the\ncorresponding  Atlas  configuration. Serverless instances don't support this\nfeature at this time. To learn more, see\n Serverless Instance Limitations . Atlas  encrypts all cluster storage and snapshot volumes at rest\nby default. You can add another layer of security by using your\ncloud provider's  KMS (Key Management Service)  together with the MongoDB\n encrypted storage engine . AWS KMS Azure Key Vault Google Cloud KMS The key management provider doesn't need to match the cluster\ncloud service provider. Encryption at Rest using Customer Key Management . Manage Customer Keys with AWS KMS . Manage Customer Keys with Azure Key Vault . Manage Customer Keys with Google Cloud KMS . To configure encryption at rest using  AWS (Amazon Web Services)   KMS (Key Management Service)  in  Atlas Kubernetes Operator , you require: A running  Kubernetes  cluster with  Atlas Kubernetes Operator   deployed . The  Project Owner  or  Organization Owner \nrole in  Atlas . Valid key management credentials and an encryption key for\n AWS KMS . To learn more, see\n Prerequisites to Enable Customer-Managed Keys with AWS . An assumed  IAM (Identity and Access Management)  role for your  Atlas  account. To set up an\nassumed  IAM (Identity and Access Management)  role with the  Atlas Kubernetes Operator , see\n Set Up Unified Cloud Provider Integrations . To learn more about role-based\naccess for an  AWS (Amazon Web Services)  encryption key, see\n Manage Customer Keys with AWS KMS . If you switch your encryption keys to role-based access, you can't\nundo the role-based access configuration and revert to\ncredentials-based access for encryption keys on that project. To configure encryption at rest using  Azure (Microsoft Azure)  Key Vault in\n Atlas Kubernetes Operator , you require: A running  Kubernetes  cluster with  Atlas Kubernetes Operator   deployed . The  Project Owner  or  Organization Owner \nrole in  Atlas . Valid key management credentials and an encryption key for\n Azure Key Vault . To learn more, see\n Prerequisites to Enable Customer-Managed Keys with Azure . To configure encryption at rest using a Google Cloud  KMS (Key Management Service)  in  Atlas Kubernetes Operator , you require: A running  Kubernetes  cluster with  Atlas Kubernetes Operator   deployed . The  Project Owner  or  Organization Owner \nrole in  Atlas . Valid key management credentials and an encryption key for\n Google Cloud KMS . To learn more, see  Prerequisites to Enable Customer-Managed Keys with Google Cloud . Encypt your  Atlas  data using a customer-managed key with the\nfollowing procedure: Create a secret with the values for the following\nparameters: To create and label a secret, run the following\ncommands with your  AWS (Amazon Web Services)  credentials: Parameter Description CustomerMasterKeyID Unique alphanumeric string that identifies the  AWS (Amazon Web Services) \ncustomer master key that you use to encrypt and\ndecrypt the MongoDB master keys. RoleId Unique  AWS (Amazon Web Services)   ARN (Amazon Resource Name)  that identifies the  AWS (Amazon Web Services)   IAM (Identity and Access Management) \nrole with permission to manage your  AWS (Amazon Web Services)  customer\nmaster key. To find this value: AWS (Amazon Web Services)  displays the  ARN (Amazon Resource Name)  in the  Summary \nsection. Go to the  Roles  section of the  AWS (Amazon Web Services) \nManagement Console. Click the  IAM (Identity and Access Management)  role that you edited or created\nfor  Atlas  access. Add the  spec.encryptionAtRest.awsKms  object to\nthe  spec.encryptionAtRest  array in the\n AtlasProject  Custom Resource , including the\nfollowing parameters: You must use a  secret  that contains the values\nfor  AccessKeyID ,  SecretAccessKey ,  CustomerMasterKeyID ,\nand  RoleId . Parameter Description spec.encryptionAtRest.awsKms.enabled Flag that indicates whether this project uses  AWS (Amazon Web Services)   KMS (Key Management Service) \nto encrypt data at rest. To enable encryption at rest using\n AWS (Amazon Web Services)   KMS (Key Management Service) , set this parameter to  true . To disable\nencryption at rest using  AWS (Amazon Web Services)   KMS (Key Management Service) , set this parameter to\n false . If you disable encryption at rest using  AWS (Amazon Web Services) \n KMS (Key Management Service) ,  Atlas Kubernetes Operator  removes the configuration details. spec.encryptionAtRest.awsKms.region Label that indicates the  AWS region  where the customer master key exists. spec.encryptionAtRest.awsKms.secretRef.name Name of the secret that contains your  AWS (Amazon Web Services)  credentials. spec.encryptionAtRest.awsKms.secretRef.namespace Namespace that contains your  AWS (Amazon Web Services)  credentials. If\nunspecified, this parameter defaults to the namespace of the\n AtlasProject  custom resource. Run the following command: Run the following command to check whether  Atlas Kubernetes Operator  detects\nthe  AWS (Amazon Web Services)   KMS (Key Management Service)  configuration for your project. After you enable encryption at rest using customer-managed\nkeys for your project, you must enable it at the\ncluster level to encrypt data. Run the following command to add the\n spec.deploymentSpec.encryptionAtRestProvider  to your\n AtlasDeployment  Custom Resource , which enables encryption at rest using your  AWS (Amazon Web Services)  key for this\ncluster: Create a secret with the values for the following\nparameters: To create and label a secret, run the following\ncommands with your  Azure (Microsoft Azure)  credentials: Parameter Description KeyIdentifier Web address with a unique key that identifies your\n Azure (Microsoft Azure)  Key Vault. KeyVaultName Unique string that identifies the  Azure (Microsoft Azure)  Key Vault\nthat contains your key. Secret Private data associated with the  Azure (Microsoft Azure)  Key Vault\ntenant you specify in\n spec.encryptionAtRest.azureKeyVault.tenantID . SubscriptionID Unique 36-hexadecimal character string that\nidentifies your  Azure (Microsoft Azure)  subscription.  Azure (Microsoft Azure) \ndisplays the subscription ID on the subscription's\ndetails page. Add the  spec.encryptionAtRest.azureKeyVault  object to\nthe  spec.encryptionAtRest  array in the\n AtlasProject  Custom Resource , including the\nfollowing parameters: You must use a  secret  that contains the values\nfor  KeyVaultName ,  KeyIdentifier ,  Secret , and\n SubscriptionID . Parameter Description spec.encryptionAtRest.azureKeyVault.azureEnvironment Azure (Microsoft Azure)  deployment location where the  Azure (Microsoft Azure)  account\ncredentials reside. Valid values include  AZURE ,\n AZURE_CHINA , and  AZURE_GERMANY . spec.encryptionAtRest.azureKeyVault.clientID Unique 36-hexadecimal character string that\nidentifies your  Azure (Microsoft Azure)  application. spec.encryptionAtRest.azureKeyVault. \n enabled Flag that indicates whether this project uses  Azure (Microsoft Azure)  Key\nVault to encrypt data at rest. To enable encryption at rest\nusing  Azure (Microsoft Azure)  Key Vault, set this parameter to  true . To\ndisable encryption at rest using  Azure (Microsoft Azure)  Key Vault, set this\nparameter to  false . If you disable encryption at rest\nusing  Azure (Microsoft Azure)  key vault,  Atlas Kubernetes Operator  removes the configuration\ndetails. spec.encryptionAtRest.azureKeyVault.resourceGroupName Label that identifies the  Azure (Microsoft Azure)  resource group\nthat contains your  Azure (Microsoft Azure)  Key Vault.  Azure (Microsoft Azure) \ndisplays the resource group name on the resource\ngroup's details page. spec.encryptionAtRest.azureKeyVault.secretRef.name Name of the secret that contains your  Azure (Microsoft Azure)  credentials. spec.encryptionAtRest.azureKeyVault.secretRef.namespace Namespace that contains your  Azure (Microsoft Azure)  credentials. If\nunspecified, this parameter defaults to the namespace of the\n AtlasProject  custom resource. spec.encryptionAtRest.azureKeyVault. \n tenantID Unique 36-hexadecimal character string that identifies the\n Azure (Microsoft Azure)  Active Directory tenant within your  Azure (Microsoft Azure) \nsubscription.  Azure (Microsoft Azure)  displays the tenant ID on the tenant\nproperties page. Run the following command: Run the following command to check whether  Atlas Kubernetes Operator  detects\nthe  Azure (Microsoft Azure)  Key Vault configuration for your project. After you enable encryption at rest using customer-managed\nkeys for your project, you must enable it at the\ncluster level to encrypt data. Run the following command to add the\n spec.deploymentSpec.encryptionAtRestProvider  to\nyour\n AtlasDeployment  Custom Resource , which enables encryption at rest using your  Azure (Microsoft Azure)  key for this\ncluster: Create a secret with the values for the following\nparameters: The following example shows the contents of a\n ServiceAccountKey   JSON (Javascript Object Notation)  file: To create and label a secret, run the following\ncommands with your  Google Cloud  credentials: Parameter Description KeyVersionResourceID Unique resource path that displays the key version\nresource ID for your Google Cloud  KMS (Key Management Service) . ServiceAccountKey JSON (Javascript Object Notation)  file that contains the Google Cloud  KMS (Key Management Service) \ncredentials from your Google Cloud account. You must format the  JSON (Javascript Object Notation)  object properly.\nEnsure you properly indent the credential fields\nwithin the file. Add the  spec.encryptionAtRest.googleCloudKms  object to\nthe  spec.encryptionAtRest  array in the\n AtlasProject  Custom Resource , including the\nfollowing parameters: You must use a  secret  that contains the values\nfor  KeyVersionResourceID  and  ServiceAccountKey . Parameter Description spec.encryptionAtRest.googleCloudKms.enabled Flag that indicates whether this project uses Google Cloud  KMS (Key Management Service) \nto encrypt data at rest. To enable encryption at rest using\nGoogle Cloud  KMS (Key Management Service) , set this parameter to  true . To disable\nencryption at rest using Google Cloud  KMS (Key Management Service) , set this parameter to\n false . If you disable encryption at rest using Google Cloud\n KMS (Key Management Service) ,  Atlas Kubernetes Operator  removes the configuration details. spec.encryptionAtRest.googleCloudKms.secretRef.name Name of the secret that contains your  Google Cloud  credentials. spec.encryptionAtRest.googleCloudKms.secretRef.namespace Namespace that contains your  Google Cloud  credentials. If\nunspecified, this parameter defaults to the namespace of the\n AtlasProject  custom resource. Run the following command: Run the following command to check whether  Atlas Kubernetes Operator  detects\nthe Google Cloud  KMS (Key Management Service)  configuration for your project. After you enable encryption at rest using customer-managed\nkeys for your project, you must enable it at the\ncluster level to encrypt data. Run the following command to add the\n spec.deploymentSpec.encryptionAtRestProvider  to\nyour\n AtlasDeployment  Custom Resource , which enables encryption at rest using your Google Cloud key for this\ncluster:",
            "code": [
                {
                    "lang": "sh",
                    "value": "kubectl create secret generic aws-ear-creds \\\n  --from-literal=\"CustomerMasterKeyID=<customer-master-key>\" \\\n  --from-literal=\"RoleId=<aws-arn>\" \\\n  -n mongodb-atlas-system"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret aws-ear-creds atlas.mongodb.com/type=credentials -n mongodb-atlas-system"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\n  labels:\n    app.kubernetes.io/version: 1.6.0\nspec:\n  name: Test Atlas Operator Project\n  encryptionAtRest:\n    awsKms:\n      enabled: true\n      region: us-east-1\n      secretRef:\n        name: aws-ear-creds\n        namespace: mongodb-atlas-system\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasprojects my-project -o=jsonpath='{.status.conditions[?(@.type==\"EncryptionAtRestReadyType\")].status}"
                },
                {
                    "lang": "json",
                    "value": "true"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\n      apiVersion: atlas.mongodb.com/v1\n      kind: AtlasDeployment\n      metadata:\n        name: my-cluster\n      spec:\n        name: Test Atlas Operator Cluster\n        DeploymentSpec:\n          encryptionAtRestProvider: \"AWS\"\n      EOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl create secret generic azure-ear-creds \\\n  --from-literal=\"KeyIdentifier=<web-address>\" \\\n  --from-literal=\"KeyVaultName=<key-vault>\" \\\n  --from-literal=\"Secret=<secret>\" \\\n  --from-literal=\"SubscriptionID=<subscription>\" \\\n  -n mongodb-atlas-system"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret azure-ear-creds atlas.mongodb.com/type=credentials -n mongodb-atlas-system"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\nspec:\n  name: Test Atlas Operator Project\n  encryptionAtRest:\n    azureKeyVault:\n      azureEnvironment: AZURE\n      clientID: \"12345678-90ab-cdef-1234-567890abcdef\"\n      enabled: true\n      resourceGroupName: \"myResourceGroup\"\n      tenantID: \"e8e4b6ba-ff32-4c88-a9af-EXAMPLEID\"\n      secretRef:\n        name: azure-ear-creds\n        namespace: mongodb-atlas-system\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasprojects my-project -o=jsonpath='{.status.conditions[?(@.type==\"EncryptionAtRestReadyType\")].status}"
                },
                {
                    "lang": "json",
                    "value": "true"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\n      apiVersion: atlas.mongodb.com/v1\n      kind: AtlasDeployment\n      metadata:\n        name: my-cluster\n      spec:\n        name: Test Atlas Operator Cluster\n        DeploymentSpec:\n          encryptionAtRestProvider: \"AZURE\"\n      EOF"
                },
                {
                    "lang": "json",
                    "value": "{\n  \"type\": \"service_account\",\n  \"project_id\": \"my-project-common-0\",\n  \"private_key_id\": \"e120598ea4f88249469fcdd75a9a785c1bb3\\\",\n  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\\\nMIIEuwIBA(truncated)SfecnS0mT94D9\\\\n-----END PRIVATE KEY-----\\\\n\\\",\n  \"client_email\": \"my-email-kms-0@my-project-common-0.iam.gserviceaccount.com\\\",\n  \"client_id\": \"10180967717292066\",\n  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n  \"token_uri\": \"https://accounts.google.com/o/oauth2/token\",\n  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/my-email-kms-0%40my-project-common-0.iam.gserviceaccount.com\"\n  \"universe_domain\": \"googleapis.com\"\n}"
                },
                {
                    "lang": "sh",
                    "value": "kubectl create secret generic azure-ear-creds \\\n  --from-literal=\"KeyVersionResourceID=<resource-id>\" \\\n  --from-file=\"ServiceAccountKey=<your-service-account-key-files.json>\" \\\n  -n mongodb-atlas-system"
                },
                {
                    "lang": "sh",
                    "value": "kubectl label secret gcp-ear-creds atlas.mongodb.com/type=credentials -n mongodb-atlas-system"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\napiVersion: atlas.mongodb.com/v1\nkind: AtlasProject\nmetadata:\n  name: my-project\nspec:\n  name: Test Atlas Operator Project\n  encryptionAtRest:\n    googleCloudKms:\n      enabled: true\n      secretRef:\n        name: gcp-ear-creds\n        namespace: mongodb-atlas-system\nEOF"
                },
                {
                    "lang": "sh",
                    "value": "kubectl get atlasprojects my-project -o=jsonpath='{.status.conditions[?(@.type==\"EncryptionAtRestReadyType\")].status}"
                },
                {
                    "lang": "json",
                    "value": "true"
                },
                {
                    "lang": "sh",
                    "value": "cat <<EOF | kubectl apply -f -\n      apiVersion: atlas.mongodb.com/v1\n      kind: AtlasDeployment\n      metadata:\n        name: my-cluster\n        labels:\n          app.kubernetes.io/version: 1.6.0\n      spec:\n        name: Test Atlas Operator Cluster\n        DeploymentSpec:\n          encryptionAtRestProvider: \"GCP\"\n      EOF"
                }
            ],
            "preview": "You can use one or more of the following customer KMS (Key Management Service)\nproviders for encryption at rest in Atlas:",
            "tags": null,
            "facets": {
                "target_product": [
                    "atlas"
                ],
                "target_product>atlas>sub_product": [
                    "kubernetes-operator"
                ]
            }
        }
    ]
}