{
    "url": "http://mongodb.com/docs/drivers/rust/v2.7",
    "includeInGlobalSearch": false,
    "documents": [
        {
            "slug": "quick-start",
            "title": "Quick Start",
            "headings": [
                "Overview"
            ],
            "paragraphs": "This guide shows you how to create an application that uses the\nMongoDB Rust Driver to connect to a MongoDB cluster hosted on MongoDB Atlas. If\nyou prefer to connect to MongoDB using a different driver or programming\nlanguage, see our  list of official drivers . The Rust driver is a library of functions that you can use to connect\nto and communicate with MongoDB. MongoDB Atlas is a fully managed cloud database service that hosts your\nMongoDB deployments. You can create your own free (no credit card\nrequired) MongoDB Atlas deployment by following the steps in this guide. Follow the steps in this guide to connect a sample Rust application to\na MongoDB Atlas deployment.",
            "code": [],
            "preview": "This guide shows you how to create an application that uses the\nMongoDB Rust Driver to connect to a MongoDB cluster hosted on MongoDB Atlas. If\nyou prefer to connect to MongoDB using a different driver or programming\nlanguage, see our list of official drivers.",
            "tags": null,
            "facets": {
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "issues-and-help",
            "title": "Issues & Help",
            "headings": [
                "Bugs / Feature Requests",
                "Pull Requests"
            ],
            "paragraphs": "We are lucky to have a vibrant MongoDB Rust community that includes users\nwith varying levels of experience using the Rust driver. The\nquickest way to get support for general questions is through the\n MongoDB Community Forums . To learn more, visit the  support channels . If you think you found a bug or want to request a new feature in the\nRust driver, please open a case in MongoDB's issue management tool,\nJIRA, by performing the following steps: If you\u2019ve identified a security vulnerability in any official MongoDB\nproduct, please report it according to the instructions found in the\n Create a Vulnerability Report page . Visit the  MongoDB JIRA issue tracker  and click the\n signup link .\nCreate an account, and then log in to JIRA. Navigate to the  RUST JIRA project . Click  Create  to create a ticket. Please provide as much\ninformation as possible about the issue or request in the ticket. Bug reports in the RUST JIRA project are publicly viewable. We are happy to accept contributions to help improve the\nRust driver. We guide user contributions to ensure they meet\nthe standards of the codebase. Please ensure that any pull requests\ninclude documentation and tests, and confirm that they pass the\nintegration and unit tests in the source code. To get started, clone the Rust driver repository and create a\nfeature branch with the following shell commands: After making any code changes, follow the  testing guidelines  to\nensure your code passes any newly added and existing tests. Then, push\nyour changes to your branch and open a pull request in the\n Rust driver repository  on GitHub.",
            "code": [
                {
                    "lang": "bash",
                    "value": "$ git clone https://github.com/mongodb/mongo-rust-driver.git\n$ cd mongo-rust-driver\n$ git checkout -b myNewFeature"
                }
            ],
            "preview": "We are lucky to have a vibrant MongoDB Rust community that includes users\nwith varying levels of experience using the Rust driver. The\nquickest way to get support for general questions is through the\nMongoDB Community Forums.",
            "tags": null,
            "facets": {
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "whats-new",
            "title": "What's New",
            "headings": [
                "What's New in 2.7",
                "What's New in 2.6"
            ],
            "paragraphs": "Learn about new features, improvements, and fixes introduced in the\nfollowing versions of the MongoDB Rust Driver: Version 2.7 Version 2.6 The Rust driver v2.7 release includes the following features,\nimprovements, and fixes: To learn more about this release, see the\n v2.7.0 Release Highlights \non Github. Adds the  human_readable_serialization  option to the\n CollectionOptions  struct. This option instructs the\ndriver to serialize values passed to CRUD methods as a human-readable\nformat. The default value of this option is  false . If you set the value of  human_readable_serialization  to\n true , your insert operations might run more slowly. Adds the  run_cursor_command()  method to run a database command and\nretrieve the response as a  Cursor  type. To learn more, see the\n Run a Command  guide. Adds SDAM event logging when you use the  tracing-unstable  feature\nflag. Adds the following configurations for  Client  and connection management: max_connecting : an option that you can set in a  ClientOptions \nstruct to specify how many connections you can establish in\nparallel. To learn more about this option, see\n Connection Pool  in the Performance Considerations\nguide. Client::warm_connection_pool() : a method that you can use to create\nnew connections in the connection pool to provide more\npredictable performance. When you use this method, the driver\nattempts to create connections up to the number specified in the\n min_pool_size  setting. Client::shutdown() : a method that you can use to stop background\ntasks and wait for handlers to drop. This method can be helpful if\nyou use event handlers to reference external resources, as these\nhandlers might be used in tasks even after the  Client  is\nclosed. The Rust driver v2.6 release includes the following features,\nimprovements, and fixes: To learn more about this release, see the\n v2.6.0 Release Highlights \non Github. Supports AWS Identity and Access Management\n(IAM) roles for service accounts, such as Elastic Kubernetes\nService (EKS) accounts. Supports GCP-attached service accounts when using the Cloud Key\nManagement System (KMS). Supports fetching on-demand CSFLE credentials from the Azure KMS. Implements the  FromStr  trait for the  Namespace  struct.\nThis change allows you to parse a string that includes a database and\ncollection name, such as  \"testdb.testcollection\"  into a\n Namespace  instance. Includes the  server_id  in a  ConnectionInfo  struct as an\n i64  type. Removes most type constraints on values referenced by a  Cursor . Updates the  libmongocrypt  version in the driver dependencies in\norder to use the Queryable Encryption feature with equality queries.",
            "code": [],
            "preview": "Learn about new features, improvements, and fixes introduced in the\nfollowing versions of the MongoDB Rust Driver:",
            "tags": "update, new feature, deprecation, upgrade",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "",
            "title": "MongoDB Rust Driver",
            "headings": [
                "Introduction",
                "Quick Start",
                "Quick Reference",
                "What's New",
                "Usage Examples",
                "Fundamentals",
                "API",
                "FAQ",
                "Connection Troubleshooting",
                "Operation Error Handling",
                "Issues & Help",
                "Compatibility",
                "Learn",
                "Developer Hub"
            ],
            "paragraphs": "Welcome to the documentation site for the official MongoDB Rust Driver.\nYou can add the driver to your application to work with MongoDB in Rust.\nImport it by adding it to your project's  Cargo.toml  file or set up a\nrunnable project by following the Quick Start guide. Learn how to establish a connection to MongoDB Atlas and begin\nworking with data in the  Quick Start  section. See driver syntax examples for common MongoDB commands in the\n Quick Reference  section. To view a list of new features and changes in each version, see the\n What's New  section. For fully runnable code examples and explanations of common\nMongoDB operations, see  Usage Examples . Learn how to perform the following tasks using the Rust driver in the\nFundamentals section: Connect to MongoDB Specify the Stable API Version Authenticate to MongoDB Connect By Using Enterprise Authentication Mechanisms Read from and Write to MongoDB Convert Data to and from BSON Manage Databases and Collections Implement Schema Validation Perform Aggregations Create and Manage Indexes Perform a Multi-Document Transaction Create a Time Series Collection Record Driver Events Run A Database Command Optimize Driver Performance Configure Asynchronous and Synchronous Runtimes Monitor Driver Events Specify Collations to Order Results Query and Write Geospatial Data Store and Retrieve Large Files by Using GridFS For detailed information about types and methods in the MongoDB Rust Driver,\nsee the  API documentation . For answers to commonly asked questions about the MongoDB Rust Driver, see\nthe  FAQ  section. For solutions to some issues you might see when connecting to a MongoDB\ndeployment while using the MongoDB Rust Driver, see\n Connection Troubleshooting . To learn about errors you might encounter when using the MongoDB Rust Driver\nto perform MongoDB operations, see  Operation Error Handling . Learn how to report bugs, contribute to the driver, and find\nmore resources for asking questions in the\n Issues & Help  section. To learn about the versions of the MongoDB Server and the Rust language\nthat are compatible with each version of the Rust driver, see\n Compatibility . Visit the Developer Hub to learn more about the MongoDB Rust Driver. The Developer Hub provides tutorials and social engagement for\ndevelopers. To learn how to use MongoDB features with the Rust driver, see the\n Rust page  in the\nMongoDB Developer Center. To ask questions and engage in discussions with fellow developers who\nuse the Rust driver, see the  posts within the Rust tag  in the MongoDB\nCommunity Forums.",
            "code": [],
            "preview": "Welcome to the documentation site for the official MongoDB Rust Driver.\nYou can add the driver to your application to work with MongoDB in Rust.\nImport it by adding it to your project's Cargo.toml file or set up a\nrunnable project by following the Quick Start guide.",
            "tags": null,
            "facets": {
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "faq",
            "title": "FAQ",
            "headings": [
                "Why Do I Get Errors While Connecting to MongoDB?",
                "How Does Connection Pooling Work in the Rust Driver?",
                "How Do I Convert Between BSON and Rust Types?",
                "How Do I Fix Unsatisfied Trait Bounds Errors?",
                "How Do I Process a Value Wrapped in a Result or Option Enum?"
            ],
            "paragraphs": "On this page, you can find frequently asked questions and their corresponding answers. If you can't find an answer to your question on this page, see the\n Issues & Help  page for information on how to report issues. If you have trouble connecting to a MongoDB deployment, see the\n Connection Troubleshooting  guide for possible solutions. Each server in your MongoDB cluster maintains a connection pool. You can access or\nmanage the behavior of the connection pool by using an instance of a  Client . Connection pools open sockets on demand to support\nconcurrent operations in your multi-threaded application. You can configure the following connection pool features: For more information about connection pooling, see the  Connection Pool \nsection of the Performance Considerations guide. Maximum and minimum size, set by the  max_pool_size  and  min_pool_size  options Maximum number of connections that the pool creates in parallel, set by the  max_connecting \noption Maximum idle time, set by the  max_idle_time  option The Rust driver and the BSON library use the Serde framework to perform\nconversions between custom Rust types and BSON. You can add the  serde \ncrate to your  Cargo.toml  file to access the functionality of the Serde framework.\nFor instructions on adding this crate, see  serde \nin the crates registry. After you add the crate to your application, you can model the documents in a collection\nby using a custom type instead of a BSON document. The following example includes the  derive \nattribute before the  Vegetable  struct definition, which instructs the driver to\nperform the following actions when needed: You can then create a  Collection  instance with your custom struct type as its\ngeneric type parameter. The following example assigns a  Collection  instance\nparameterized with the  Vegetable  type to the  my_coll  variable: For more information about converting between BSON and Rust types, see the\n Data Modeling and Serialization  guide and the  Structuring Data with Serde in Rust  MongoDB Developer Center article. Serialize the struct, which converts the struct to BSON Deserialize BSON, which converts BSON data to your struct Trait bounds allow methods to restrict which types they accept as parameters\nand what functionality those types must implement. For example, if you define\na method that accepts a generic type parameter and prints its value, the parameter\nmust implement the  Display  trait for printing purposes. The following example\ndefines the  printer()  method and specifies that its parameter must implement\n Display : When calling a method on a data type, you might encounter an error stating that\nthe method's trait bounds are not satisfied. For example, the driver might raise\nthe following error message when you call the  try_next()  method on a  Cursor \ninstance: The  Cursor<T>  type only implements the  Stream  trait, which is required to access\nthe  try_next()  method, if the trait bounds for  T  are satisfied. Namely,  T \nmust implement the  DeserializeOwned  trait, as specified in the  Cursor  API documentation. The following example replicates the\npreceding error message by defining a custom  Actor  struct to model documents in the\n actors  collection. However, this struct does not implement the  DeserializeOwned  trait,\nand using the  try_next()  method to iterate over  Actor  instances causes an error: To resolve the trait bounds error, identify the data type over which the cursor\niterates and ensure that this data type implements the  DeserializeOwned  trait.\nYou can use the  derive  attribute to apply the required trait bound. The following example adjusts the  Actor  struct definition to implement  Deserialize : For more information about trait bounds, see the following resources: The  serde  crate provides derive macros to generate the implementation of\ncertain traits, including the  Deserialize  trait. However, this crate does not\noffer a derive macro for the  DeserializeOwned  trait. Data types that implement\n Deserialize  without lifetime restrictions automatically implement  DeserializeOwned ,\nso you can implement  Deserialize  to fulfill the  DeserializeOwned  trait bound. Cursor trait bounds question \nin the Community Forums Bounds  in the\nRust language documentation Derive \nin the Rust language documentation Rust provides the  Result  and  Option  enums as safeguards for your application\ncode. Many methods offered by the Rust driver return values wrapped in one of these\ntwo types. The  Result  enum can return the following variants: For example, the  insert_one()  method returns a  Result  type to wrap either a successful\nresponse or an error. To access the unwrapped result of  insert_one() , use the  ?  operator. If the operation is\nsuccessful, the method returns the  Ok(InsertOneResult)  variant of the  Result  enum. In this\ncase, the  ?  operator unwraps the  InsertOneResult  value and assigns it to the  insert_one_result \nvariable. If the operation is unsuccessful, the method returns the  Err(E)  enum variant, and the\n ?  operator unwraps and returns the error value. The following code demonstrates the syntax for\nusing the  ?  operator while handling an insert operation result: Alternatively, you can create a conditional to handle the unwrapped values of  InsertOneResult .\nThe following code uses the  match  keyword to process the  insert_one()  result: The  Option  enum can return the following variants: Some Rust driver methods return an  Option  type, such as the  read_concern() \nmethod. This method returns an  Option  that wraps either an empty value, if no read\nconcern exists, or a  ReadConcern  value. To access the result of  read_concern() , you can use the same  match  syntax as shown\nin the preceding example to process the  None  and  Some(T)  variants. Alternatively, you\ncan use the  if let  syntax to process only the  Some(T)  variant. The following code unwraps\nand prints the non-empty  read_concern()  return value, if it exists: For more information about the  Result  and  Option  enums, see the following\nresources in the Rust language documentation: Ok(T) : wraps the value of the result of the operation Err(E) : wraps an error value if the operation is unsuccessful None : represents an empty value returned by an operation Some(T) : wraps a non-empty return value Result Option ? Operator Concise Control Flow with if let",
            "code": [
                {
                    "lang": "rust",
                    "value": "#[derive(Serialize, Deserialize)]\nstruct Vegetable {\n   // Add struct fields here\n}"
                },
                {
                    "lang": "rust",
                    "value": "let my_coll: Collection<Vegetable> = client.database(\"db\").collection(\"vegetables\");"
                },
                {
                    "lang": "rust",
                    "value": "fn printer<T: Display>(t: T) {\n   println!(\"{}\", t);\n}"
                },
                {
                    "lang": "none",
                    "value": "error[E0599]: the method `try_next` exists for struct `mongodb::Cursor<T>`,\nbut its trait bounds were not satisfied"
                },
                {
                    "lang": "rust",
                    "value": "struct Actor {\n   name: String,\n}\n\n// Add setup code here\n\nlet my_coll: Collection<Actor> = client.database(\"db\").collection(\"actors\");\nlet mut cursor = my_coll.find(None, None).await?;\nwhile let Some(result) = cursor.try_next().await? {\n     println!(\"{:?}\", result);\n };"
                },
                {
                    "lang": "rust",
                    "value": "#[derive(Deserialize)]\nstruct Actor {\n   name: String,\n}"
                },
                {
                    "lang": "rust",
                    "value": "let insert_one_result = my_coll.insert_one(doc, None).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let insert_one_result = my_coll.insert_one(doc, None).await;\n\nmatch insert_one_result {\n   Ok(val) => {\n     println!(\"Document inserted with ID: {}\", val.inserted_id);\n   },\n   Err(err) => {\n     println!(\"Operation not successful\");\n   }\n}"
                },
                {
                    "lang": "rust",
                    "value": "if let Some(rc) = my_coll.read_concern() {\n   println!(\"Read concern: {:?}\", rc);\n}"
                }
            ],
            "preview": "On this page, you can find frequently asked questions and their corresponding answers.",
            "tags": "code example, connection error, question, help",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "usage-examples",
            "title": "Usage Examples",
            "headings": [
                "Overview",
                "How to Use the Usage Examples",
                "Load the Sample Datasets",
                "Add the Usage Example Code to Your Development Environment",
                "Replace the Connection String Placeholder",
                "Run the Usage Example Code",
                "Available Usage Examples"
            ],
            "paragraphs": "Usage examples show runnable code examples to demonstrate frequently used MongoDB\noperations. Each usage example includes the following: Description of the MongoDB operation Asynchronous and synchronous Rust code examples that you can run in\nyour environment Output printed by the code example To learn more about selecting and using different runtime APIs in the\nRust driver, see the  Asynchronous and Synchronous APIs  guide. The usage examples are designed to run operations on a MongoDB deployment that contains\nthe Atlas sample datasets. When you run the example code without the sample data, the output\nmay not match. Follow this tutorial to set up your MongoDB deployment with the sample data and run the\nexample code in your development environment. Before performing the following actions,\nensure that you create an Atlas account and deploy a cluster. For information about setting\nup an account and a cluster, see the  Get Started with Atlas Guide . After completing these steps, you can see the output described in the  Expected Output  section\nof the corresponding usage example. Follow the instructions on the  Load Sample Data  page\nto load the sample datasets into your database deployment. Copy the example code from the usage example page and paste it into a new file in\nyour preferred directory. To learn more about creating an application that uses the Rust driver, follow the\n Quick Start . In your example code, replace the  connection string  placeholder with your MongoDB\ndeployment connection string. For example, if your connection string is\n \"mongodb+srv://mongodb-example:27017\" , your connection string assignment resembles\nthe following: Run your application in your development environment. If you run your Rust applications\non the command line, run the following command: Find a Document Find Multiple Documents Insert a Document Insert Multiple Documents Update a Document Update Multiple Documents Replace a Document Delete a Document Delete Multiple Documents Count Documents List Distinct Field Values",
            "code": [
                {
                    "lang": "rust",
                    "value": "let uri = \"mongodb+srv://mongodb-example:27017\";"
                },
                {
                    "lang": "bash",
                    "value": "cargo run"
                }
            ],
            "preview": "Usage examples show runnable code examples to demonstrate frequently used MongoDB\noperations. Each usage example includes the following:",
            "tags": "set up, runnable, code example",
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals",
            "title": "Fundamentals",
            "headings": [],
            "paragraphs": "Learn how to perform the following tasks using the Rust driver in the\nFundamentals section: Connect to MongoDB Specify the Stable API Version Authenticate to MongoDB Connect By Using Enterprise Authentication Mechanisms Read from and Write to MongoDB Convert Data to and from BSON Manage Databases and Collections Implement Schema Validation Perform Aggregations Create and Manage Indexes Perform a Multi-Document Transaction Create a Time Series Collection Record Driver Events Run A Database Command Optimize Driver Performance Configure Asynchronous and Synchronous Runtimes Monitor Driver Events Specify Collations to Order Results Query and Write Geospatial Data Store and Retrieve Large Files by Using GridFS",
            "code": [],
            "preview": null,
            "tags": null,
            "facets": {
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "op-error-handling",
            "title": "Operation Error Handling",
            "headings": [
                "Overview",
                "Error Type",
                "Connection Errors",
                "Write Error Types",
                "Write Concern Error",
                "Write Error"
            ],
            "paragraphs": "This page describes errors you might encounter when\nusing the MongoDB Rust Driver to perform MongoDB operations. Once you\nunderstand the types of operation errors that the driver raises, you can take\nappropriate actions to either handle them or correct the error-causing code. This page addresses only operation error handling. If you encounter\nany other issues with MongoDB or the driver, visit the following\nresources: Connection Troubleshooting  for potential solutions to\nissues you might encounter when connecting to a MongoDB deployment Issues & Help  page for\ninformation about reporting bugs, contributing to the driver, and\nfinding more resources MongoDB Community Forums  for\nquestions, discussions, or general technical support If the driver encounters an error while performing an operation, it\nreturns an error of the  Error  type. The  Error  type contains the  kind  field, which describes the type of\nerror that occurred. The  kind  field has a value of enum  ErrorKind . The  ErrorKind  enum has\nvariants for different kinds of errors, including the following: For example, if you attempt to perform an insert operation that\nduplicates an  _id  field value that is already in the collection,\nthe driver returns an  Error  instance and prints the following error\nmessage: In the preceding error message, the value of the  kind  field is\n Write . To learn more about this type of error, see the  Write\nError Types  section of this guide. InvalidArgument : you provided an invalid argument to a method Authentication : the driver encountered an error during authentication ServerSelection : the client couldn't select a server for the operation Write : an error occurred during a write operation Transaction : an error occurred during a transaction A concurrent operation error might clear the connection pool,\ninterrupting your connection to the server. In this\nsituation, the driver raises an  Error  type in which the value of the\n kind  field is  ConnectionPoolCleared . The error message describes\nthe reason that the concurrent operation failed. To learn how to adjust your connection pool to address this error, see\n Tuning Your Connection Pool Settings  in the Server manual. Depending on the circumstances that produce the error, the driver may\nadd a  RetryableWriteError  label to the error, as shown in the\nfollowing error message: This label indicates that the error is write-retryable, which means that\nthe driver makes one retry attempt. When the driver experiences an error while performing a write operation,\nit raises an  Error  instance with a  kind  field value of  Write .\nThe body of the  Write  variant is the enum  WriteFailure , which\ntakes a value of type  WriteError  or\n WriteConcernError . The driver raises a  WriteConcernError  error when you perform a write\noperation and the driver cannot satisfy the specified write concern. For\nexample, if you specify a write concern of  majority  for\noperations on a replica set with three nodes, the driver returns\nthis error if the write operation propagates only to one node. To learn more about write concerns, see  Write Concern  in the Server manual. The driver raises a  WriteError  error for any errors that it\nencounters when performing a write operation that are not related to\nsatisfying the write concern. Because there are many causes for this\nerror, the  WriteError  type contains fields that describe the type of\nwrite error and reason for the error. For example, the driver raises a  WriteError  error if you attempt to\ninsert a document into a collection that violates the collection's\nschema validation rules. Suppose the collection has a rule where the\nvalue of the  quantity  field must be an  int  type. If you\nattempt to insert a document where the value of  quantity  is\n \"three\" , the driver prints the following error message: In the preceding error message, the  message  field describes the\nreason for the error, and the  details  field provides specific\ndetails about the failing operation. To address this error, you must\neither revise the document to adhere to the schema validation rules or\nbypass validation. To learn more about schema validation, see the guide on\n Schema Validation .",
            "code": [
                {
                    "lang": "none",
                    "value": "Error: Error { kind: Write(WriteError(WriteError { code: 11000,\ncode_name: None, message: \"E11000 duplicate key error collection:\ndb.test_coll index: _id_ dup key: { _id: 1 }\", details: None })), labels:\n{}, wire_version: None, source: None }"
                },
                {
                    "lang": "none",
                    "value": "Error { kind: ConnectionPoolCleared { message: \"Connection pool for\nlocalhost:27017 cleared because another operation failed with: Kind:\nI/O error: timed out, labels: {}\" }, labels: {\"RetryableWriteError\"},\nwire_version: None, source: None }"
                },
                {
                    "lang": "none",
                    "value": "Error: Error { kind: Write(WriteError(WriteError { code: 121, code_name:\nNone, message: \"Document failed validation\", details:\nSome(Document({\"failingDocumentId\": Int32(1), \"details\":\nDocument({\"operatorName\": String(\"$jsonSchema\"), \"title\":\nString(\"Numerical Validation\"), \"schemaRulesNotSatisfied\":\nArray(...)})})) })), labels: {},\nwire_version: None, source: None }"
                }
            ],
            "preview": "This page describes errors you might encounter when\nusing the MongoDB Rust Driver to perform MongoDB operations. Once you\nunderstand the types of operation errors that the driver raises, you can take\nappropriate actions to either handle them or correct the error-causing code.",
            "tags": null,
            "facets": {
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "connection-troubleshooting",
            "title": "Connection Troubleshooting",
            "headings": [
                "Server Connection Errors",
                "Check the Connection String",
                "Configure the Firewall",
                "Check the Number of Connections",
                "Authentication Errors",
                "Check the Credentials Formatting",
                "Verify the Authentication Mechanism",
                "Verify User Is in Authentication Database",
                "DNS Resolution Errors",
                "Check Database Deployment Availability",
                "Check the Network Addresses"
            ],
            "paragraphs": "This page only addresses connection issues. If you encounter any other issues\nwith MongoDB or the driver, visit the following resources: Operation Error Handling  for recommendations on how to handle\ndifferent error types that the driver raises during operations Issues & Help  page for\ninformation about reporting bugs, contributing to the driver, and\nfinding more resources MongoDB Community Forums  for\nquestions, discussions, or general technical support The  Frequently Asked Questions (FAQ)  section for\ncommon questions and corresponding answers about the\nRust driver To learn more about specifying multiple hosts in a replica set, see the\n Connect to a Replica Set  section of the\nConnection Guide. Client maxPoolSize 100 maxIdleTimeMS To learn more about how connection pools work in the driver, see\n How Does Connection Pooling Work in the Rust Driver? \non the FAQ page. For more information about connection strings,\nsee the  Create a Connection String  guide. Alternatively, you can specify your authentication credentials in a\n Credential  struct. To learn more about authentication, see the  Authentication Mechanisms  guide. This page offers potential solutions to issues that you might encounter\nwhen using the MongoDB Rust Driver to connect to a MongoDB deployment. This page only addresses connection issues. If you encounter any other issues\nwith MongoDB or the driver, visit the following resources: Operation Error Handling  for recommendations on how to handle\ndifferent error types that the driver raises during operations Issues & Help  page for\ninformation about reporting bugs, contributing to the driver, and\nfinding more resources MongoDB Community Forums  for\nquestions, discussions, or general technical support The  Frequently Asked Questions (FAQ)  section for\ncommon questions and corresponding answers about the\nRust driver When an issue occurs when you attempt to connect to a server, the Rust driver\nreturns an error message. If this error resembles the following message, it\nindicates that the driver cannot connect to a MongoDB deployment: The following sections describe methods that might help resolve the issue. Verify that the hostname and port number in the connection string are both\naccurate. In the sample error message, the hostname is  127.0.0.1  and the\nport is  27017 . The default port value for an instance of MongoDB Server is\n 27017 , but you can configure MongoDB to listen on another port. When connecting to a replica set, include all the replica set hosts in\nyour connection string. Separate each of the hosts in the connection\nstring with a comma. This enables the driver to establish a connection if\none of the hosts is unreachable. To learn more about specifying multiple hosts in a replica set, see the\n Connect to a Replica Set  section of the\nConnection Guide. If your MongoDB deployment is hosted behind a firewall, ensure the port\non which MongoDB listens is open in the firewall. If your deployment\nlistens on the default network port, ensure that port  27017  is\nopen in the firewall. If your deployment listens on a different port,\nensure that port is open on the firewall. Do not open a firewall port unless you are sure that it is the one\nthat your MongoDB deployment listens on. Each  Client  instance supports a maximum number of concurrent open\nconnections in its connection pool. The configuration parameter  maxPoolSize \ndefines this value and is set to  100  by default. If the\nnumber of open connections is equal to  maxPoolSize , the server waits until\na connection becomes available. If this wait time exceeds the  maxIdleTimeMS \nvalue, the driver responds with an error. To learn more about how connection pools work in the driver, see\n How Does Connection Pooling Work in the Rust Driver? \non the FAQ page. The Rust driver may be unable connect to a MongoDB deployment if\nthe authorization is not configured correctly. In these cases, the driver\nraises an error message similar to the following message: The following sections describe methods that may help resolve the issue. One of the most common causes of authentication issues is invalid\ncredentials formatting in the MongoDB connection string. If your connection string contains a username and password, ensure that\nthey are correctly formatted. For more information about connection strings,\nsee the  Create a Connection String  guide. If your username or password includes any of the following characters, you\nmust  percent-encode  it: Use your percent-encoded username and password in your connection string. Ensure that your credentials and authentication mechanism are correct. You can\nspecify your authentication credentials in the options of your connection string. Alternatively, you can specify your authentication credentials in a\n Credential  struct. To learn more about authentication, see the  Authentication Mechanisms  guide. When using a username and password-based authentication method,\nthe username must be defined in the authentication database. The default authentication database is the  admin  database.\nTo use a different database for authentication, specify the\n authSource  option in the connection string. The following example instructs MongoDB to use the  users  database\nas the authentication database: The Rust driver may be unable to resolve your DNS connection. When this\nhappens, you might receive an error message similar to the following message: If the driver reports this error, try the methods in the following sections\nto resolve the issue. If you are connecting to MongoDB Atlas and your driver cannot find the DNS\nhost of the Atlas database deployment, the database deployment might be paused\nor deleted. Ensure that the database deployment exists in Atlas. If the cluster is paused,\nyou can resume the cluster in the Atlas UI or the\n Atlas command line interface . To learn how to resume a cluster, see\n Resume One Cluster \nin the Atlas documentation. Verify that the network addresses or hostnames in your connection string\nare accurate. If your deployment is hosted on MongoDB Atlas, you can follow the\n Connect to Your Cluster \ntutorial to find your Atlas connection string.",
            "code": [
                {
                    "lang": "none",
                    "value": "Error: Error { kind: ServerSelection { message: \"Server selection timeout:\nNo available servers. Topology: { Type: Unknown, Servers: [ { Address:\n127.0.0.1:27017, Type: Unknown, Error: Kind: I/O error: Connection refused\n(os error 61), labels: {} } ] }\" }, labels: {}, wire_version: None, source:\nNone }"
                },
                {
                    "lang": "none",
                    "value": "Error: Error { kind: Authentication { message: \"SCRAM failure: bad auth :\nauthentication failed\" }, labels: {}, wire_version: None, source: Some(Error\n{ kind: Command(CommandError { code: 8000, code_name: \"AtlasError\", message:\n\"bad auth : authentication failed\", topology_version: None }),\nlabels: {}, wire_version: None, source: None }) }"
                },
                {
                    "lang": "rust",
                    "value": "let uri = \"mongodb://<username>:<password>@<hostname>:<port>/?authSource=users\";\nlet client = Client::with_uri_str(uri).await?;"
                },
                {
                    "lang": "none",
                    "value": "Error: Error { kind: DnsResolve { message: \"sample message. type:\nSRV class: IN\" }, labels: {}, wire_version: None, source: None }"
                },
                {
                    "lang": "none",
                    "value": "Error: Error { kind: ServerSelection { message: \"Server selection timeout:\nNo available servers. Topology: { Type: Unknown, Servers: [ { Address:\n127.0.0.1:27017, Type: Unknown, Error: Kind: I/O error: Connection refused\n(os error 61), labels: {} } ] }\" }, labels: {}, wire_version: None, source:\nNone }"
                },
                {
                    "lang": "none",
                    "value": "Error: Error { kind: Authentication { message: \"SCRAM failure: bad auth :\nauthentication failed\" }, labels: {}, wire_version: None, source: Some(Error\n{ kind: Command(CommandError { code: 8000, code_name: \"AtlasError\", message:\n\"bad auth : authentication failed\", topology_version: None }),\nlabels: {}, wire_version: None, source: None }) }"
                },
                {
                    "lang": "none",
                    "value": ": / ? # [ ] @"
                },
                {
                    "lang": "rust",
                    "value": "let uri = \"mongodb://<username>:<password>@<hostname>:<port>/?authSource=users\";\nlet client = Client::with_uri_str(uri).await?;"
                },
                {
                    "lang": "none",
                    "value": "Error: Error { kind: DnsResolve { message: \"sample message. type:\nSRV class: IN\" }, labels: {}, wire_version: None, source: None }"
                }
            ],
            "preview": "When an issue occurs when you attempt to connect to a server, the Rust driver\nreturns an error message. If this error resembles the following message, it\nindicates that the driver cannot connect to a MongoDB deployment:",
            "tags": "code example, disconnected, deployment",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "usage-examples/replace",
            "title": "Replace a Document",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can replace a document in a collection by calling the  replace_one()  method on a\n Collection  instance. Pass the following parameters to the  replace_one()  method: The  replace_one()  method returns an  UpdateResult  type that contains\ninformation about the results of the replace operation, such as the\nnumber of modified documents. To learn more about the  replace_one()  method, see the\n Replace a Document  section of the Modify Documents guide. Query filter, which specifies the criteria to match Replacement document, which contains the fields and values that will\nreplace the first matched document This example replaces a document in the  restaurants  collection of\nthe  sample_restaurants  database. The example uses a  Restaurant \nstruct that has  name ,  borough , and  cuisine  fields to model\ndocuments in the collection. The following code replaces a document in which the value of the\n name  field is  \"Landmark Coffee Shop\"  with a new document. MongoDB\nreplaces the first document that matches the query filter. Select the  Asynchronous  or  Synchronous  tab to\nsee the corresponding code for each runtime:",
            "code": [
                {
                    "lang": "rust",
                    "value": "use std::env;\nuse mongodb::{ bson::doc, Client, Collection };\nuse serde::{ Deserialize, Serialize };\n\n#[derive(Serialize, Deserialize, Debug)]\nstruct Restaurant {\n    borough: String,\n    cuisine: String,\n    name: String,\n}\n\n#[tokio::main]\nasync fn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n\n    let client = Client::with_uri_str(uri).await?;\n    let my_coll: Collection<Restaurant> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let filter = doc! { \"name\": \"Landmark Coffee Shop\" };\n    let replacement = Restaurant {\n        borough: \"Brooklyn\".to_string(),\n        cuisine: \"Caf\u00e9/Coffee/Tea\".to_string(),\n        name: \"Harvest Moon Caf\u00e9\".to_string(),\n    };\n\n    let res = my_coll.replace_one(filter, replacement, None).await?;\n    println!(\"Replaced documents: {}\", res.modified_count);\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "console",
                    "value": "Replaced documents: 1"
                },
                {
                    "lang": "rust",
                    "value": "use std::env;\nuse mongodb::{ bson::doc, sync::{ Client, Collection } };\nuse serde::{ Deserialize, Serialize };\n\n#[derive(Serialize, Deserialize, Debug)]\nstruct Restaurant {\n    borough: String,\n    cuisine: String,\n    name: String,\n}\n\nfn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n\n    let client = Client::with_uri_str(uri)?;\n    let my_coll: Collection<Restaurant> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let filter = doc! { \"name\": \"Landmark Coffee Shop\" };\n    let replacement = Restaurant {\n        borough: \"Brooklyn\".to_string(),\n        cuisine: \"Caf\u00e9/Coffee/Tea\".to_string(),\n        name: \"Harvest Moon Caf\u00e9\".to_string(),\n    };\n\n    let res = my_coll.replace_one(filter, replacement, None)?;\n    println!(\"Replaced documents: {}\", res.modified_count);\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "console",
                    "value": "Replaced documents: 1"
                }
            ],
            "preview": "You can replace a document in a collection by calling the replace_one() method on a\nCollection instance.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "quick-reference",
            "title": "Quick Reference",
            "headings": [],
            "paragraphs": "On this page, you can see examples that use the Rust driver to\nperform several common MongoDB tasks. Each row of the following table\ndescribes the task, shows the driver syntax to execute the task, and\nincludes links to the related reference and API documentation. The Rust driver offers an asynchronous runtime for executing async\napplications. Additionally, the driver supports a blocking synchronous\nruntime. For each MongoDB task listed in the following table, you can see\nexamples that use both the asynchronous and synchronous APIs. To learn more about asynchronous and synchronous runtimes, see the  Asynchronous and Synchronous APIs \nguide. Command Syntax Async Runtime Sync Runtime Async Runtime Sync Runtime Async Runtime Sync Runtime Async Runtime Sync Runtime Async Runtime Sync Runtime Async Runtime Sync Runtime Async Runtime Sync Runtime Async Runtime Sync Runtime Async Runtime Sync Runtime Async Runtime Sync Runtime Async Runtime Sync Runtime Async Runtime Sync Runtime Async Runtime Sync Runtime Async Runtime Sync Runtime Async Runtime Sync Runtime Async Runtime Sync Runtime Async Runtime Sync Runtime Async Runtime Sync Runtime",
            "code": [
                {
                    "lang": "rust",
                    "value": "let result = collection.find_one(\n    doc! { \"title\": \"Peter Pan\" },\n    None\n).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let result = collection.find_one(\n    doc! { \"title\": \"Peter Pan\" },\n    None\n)?;"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"year\": 1925 };\nlet mut cursor = collection.find(filter, None).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"year\": 1925 };\nlet mut cursor = collection.find(filter, None)?;"
                },
                {
                    "lang": "rust",
                    "value": "let doc = doc! { \n    \"title\": \"Mistress America\", \"type\": \"movie\" \n};\n\nlet result = collection.insert_one(doc, None).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let doc = doc! { \n    \"title\": \"Mistress America\", \"type\": \"movie\" \n};\n\nlet result = collection.insert_one(doc, None)?;"
                },
                {
                    "lang": "rust",
                    "value": "let docs = vec![\n    doc! { \"title\": \"Friends With Money\", \"runtime\": 88 },\n    doc! { \"title\": \"Please Give\", \"runtime\": 90 },\n    doc! { \"title\": \"You Hurt My Feelings\", \"runtime\": 93 },\n];\n\nlet result = collection.insert_many(docs, None).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let docs = vec![\n    doc! { \"title\": \"Friends With Money\", \"runtime\": 88 },\n    doc! { \"title\": \"Please Give\", \"runtime\": 90 },\n    doc! { \"title\": \"You Hurt My Feelings\", \"runtime\": 93 },\n];\n\nlet result = collection.insert_many(docs, None)?;"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"title\": \"Burn After Reading\"};\nlet update =\n    doc! {\n        \"$set\": doc!{ \"num_mflix_comments\": 1 }\n};\n\nlet result = collection.update_one(\n      filter, update, None\n).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"title\": \"Burn After Reading\"};\nlet update =\n    doc! {\n        \"$set\": doc!{ \"num_mflix_comments\": 1 }\n};\n\nlet result = collection.update_one(\n      filter, update, None\n)?;"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"rated\": \"PASSED\"};\nlet update =\n    doc! {\n        \"$set\": doc!{ \"rated\": \"Not Rated\" }\n};\n\nlet result = collection.update_many(\n      filter, update, None\n).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"rated\": \"PASSED\"};\nlet update =\n    doc! {\n        \"$set\": doc!{ \"rated\": \"Not Rated\" }\n};\n\nlet result = collection.update_many(\n      filter, update, None\n)?;"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"title\": \"\u00e8 Nous la Libert\u00e8\" };\nlet replacement =\n    doc! {\n    \"title\": \"\u00c0 nous la libert\u00e9\",\n    \"type\": \"movie\",\n    \"directors\": vec! [ \"Ren\u00e9 Clair\" ]\n};\n\nlet result = collection.replace_one(\n      filter, replacement, None\n).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"title\": \"\u00e8 Nous la Libert\u00e8\" };\nlet replacement =\n    doc! {\n    \"title\": \"\u00c0 nous la libert\u00e9\",\n    \"type\": \"movie\",\n    \"directors\": vec! [ \"Ren\u00e9 Clair\" ]\n};\n\nlet result = collection.replace_one(\n      filter, replacement, None\n)?;"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"title\": \"Search and Destroy\" };\nlet result = collection.delete_one(filter, None).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"title\": \"Search and Destroy\" };\nlet result = collection.delete_one(filter, None)?;"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \n    \"year\": doc! { \"$lt\": 1920 } \n};\n\nlet result = collection.delete_many(filter, None).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \n    \"year\": doc! { \"$lt\": 1920 } \n};\n\nlet result = collection.delete_many(filter, None)?;"
                },
                {
                    "lang": "rust",
                    "value": "let mut cursor = collection.find(\n    doc! { \"$and\": vec!\n        [\n            doc! { \"metacritic\": doc! { \"$gt\": 90 } },\n            doc! { \"directors\": vec! [ \"Martin Scorsese\" ] }\n        ] },\n    None\n).await?;\n\nwhile let Some(result) = cursor.try_next().await? {\n    println!(\"{}\", result);\n};"
                },
                {
                    "lang": "rust",
                    "value": "let cursor = collection.find(\n    doc! { \"$and\": vec!\n        [\n            doc! { \"metacritic\": doc! { \"$gt\": 90 } },\n            doc! { \"directors\": vec! [ \"Martin Scorsese\" ] }\n        ] },\n    None\n)?;\n\nfor result in cursor {\n  println!(\"{}\", result?);\n}"
                },
                {
                    "lang": "rust",
                    "value": "let cursor = collection.find(\n    doc! { \"title\": \"Secrets & Lies\" }, None\n).await?;\n\nlet results: Vec<Document> = cursor.try_collect().await?;"
                },
                {
                    "lang": "rust",
                    "value": "let cursor = collection.find(\n    doc! { \"title\": \"Secrets & Lies\" }, None\n)?;\n\nlet results: Vec<Result<Document>> = cursor.collect();"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! {\n    \"languages\": vec! [ \"Mandarin\" ]\n};\n\nlet result = collection.count_documents(filter, None).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! {\n    \"languages\": vec! [ \"Mandarin\" ]\n};\n\nlet result = collection.count_documents(filter, None)?;"
                },
                {
                    "lang": "rust",
                    "value": "let field_name = \"title\";\nlet filter = doc! {\n    \"directors\": vec! [ \"Sean Baker\" ]\n};\n\nlet results = collection.distinct(\n      field_name, filter, None\n).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let field_name = \"title\";\nlet filter = doc! {\n    \"directors\": vec! [ \"Sean Baker\" ]\n};\n\nlet results = collection.distinct(\n      field_name, filter, None\n)?;"
                },
                {
                    "lang": "rust",
                    "value": "let opts: FindOptions = FindOptions::builder()\n    .limit(5)\n    .build();\n\nlet filter = doc! { \"awards.wins\": 25};\nlet mut cursor = collection.find(filter, opts).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let opts: FindOptions = FindOptions::builder()\n    .limit(5)\n    .build();\n\nlet filter = doc! { \"awards.wins\": 25};\nlet mut cursor = collection.find(filter, opts)?;"
                },
                {
                    "lang": "rust",
                    "value": "let opts: FindOptions = FindOptions::builder()\n    .skip(1)\n    .build();\n\nlet filter = doc! { \"runtime\": 100 };\nlet mut cursor = collection.find(filter, opts).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let opts: FindOptions = FindOptions::builder()\n    .skip(1)\n    .build();\n\nlet filter = doc! { \"runtime\": 100 };\nlet mut cursor = collection.find(filter, opts)?;"
                },
                {
                    "lang": "rust",
                    "value": "let opts: FindOptions = FindOptions::builder()\n    .sort(doc! { \"imdb.rating\": 1 })\n    .build();\n\nlet filter = doc! {\n    \"directors\": vec! [ \"Nicole Holofcener\" ]\n};\n\nlet mut cursor = collection.find(filter, opts).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let opts: FindOptions = FindOptions::builder()\n    .sort(doc! { \"imdb.rating\": 1 })\n    .build();\n\nlet filter = doc! {\n    \"directors\": vec! [ \"Nicole Holofcener\" ]\n};\n\nlet mut cursor = collection.find(filter, opts)?;"
                },
                {
                    "lang": "rust",
                    "value": "let opts: FindOptions = FindOptions::builder()\n    .projection(doc! { \"title\": 1, \"metacritic\": 1, \"_id\": 0 })\n    .build();\n\nlet filter = doc! { \"year\": 2015 };\nlet mut cursor = collection.find(filter, opts).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let opts: FindOptions = FindOptions::builder()\n    .projection(doc! { \"title\": 1, \"metacritic\": 1, \"_id\": 0 })\n    .build();\n\nlet filter = doc! { \"year\": 2015 };\nlet mut cursor = collection.find(filter, opts)?;"
                },
                {
                    "lang": "rust",
                    "value": "let index: IndexModel = IndexModel::builder()\n    .keys(doc! { \"title\": 1 })\n    .build();\n\nlet result = collection.create_index(index, None).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let index: IndexModel = IndexModel::builder()\n    .keys(doc! { \"title\": 1 })\n    .build();\n\nlet result = collection.create_index(index, None)?;"
                }
            ],
            "preview": "On this page, you can see examples that use the Rust driver to\nperform several common MongoDB tasks. Each row of the following table\ndescribes the task, shows the driver syntax to execute the task, and\nincludes links to the related reference and API documentation.",
            "tags": null,
            "facets": {
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "usage-examples/deleteOne",
            "title": "Delete a Document",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can delete a document from a collection by calling the  delete_one()  method on a  Collection \ninstance. Pass a query filter to the  delete_one()  method to match the document you want to\ndelete from the collection. If multiple documents match the query filter, MongoDB\ndeletes the first matching document according to their  natural order  in the\ndatabase or according to the sort order specified in a  DeleteOptions \ninstance. The  delete_one()  method returns a  DeleteResult \ntype. This type contains information about the result of the delete operation, such as\nthe total number of documents deleted. To learn more about delete operations, see the  Delete Documents  guide. This example deletes a document that matches a query filter from the  restaurants \ncollection in the  sample_restaurants  database. This example uses a query filter that matches documents in which the value of the\n name  field is  \"Haagen-Dazs\"  and the  borough  field is  \"Brooklyn\" . MongoDB\ndeletes the first document that matches the query filter. Select the  Asynchronous  or  Synchronous  tab to\nsee the corresponding code for each runtime:",
            "code": [
                {
                    "lang": "rust",
                    "value": "use mongodb::{ \n    bson::{ Document, doc }, \n    Client, \n    Collection \n};\n\n#[tokio::main]\nasync fn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n    let client = Client::with_uri_str(uri).await?;\n\n    let my_coll: Collection<Document> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let filter =\n        doc! { \"$and\": [\n           doc! { \"name\": \"Haagen-Dazs\" },\n           doc! { \"borough\": \"Brooklyn\" }\n       ]\n    };\n\n    let result = my_coll.delete_one(filter, None).await?;\n\n    println!(\"Deleted documents: {}\", result.deleted_count);\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "console",
                    "value": "Deleted documents: 1"
                },
                {
                    "lang": "rust",
                    "value": "use mongodb::{ \n    bson::{ Document, doc }, \n    sync::{ Client, Collection } \n};\n\nfn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n    let client = Client::with_uri_str(uri)?;\n\n    let my_coll: Collection<Document> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let filter =\n        doc! { \"$and\": [\n           doc! { \"name\": \"Haagen-Dazs\" },\n           doc! { \"borough\": \"Brooklyn\" }\n       ]\n    };\n\n    let result = my_coll.delete_one(filter, None)?;\n\n    println!(\"Deleted documents: {}\", result.deleted_count);\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "console",
                    "value": "Deleted documents: 1"
                }
            ],
            "preview": "You can delete a document from a collection by calling the delete_one() method on a Collection\ninstance.",
            "tags": "runnable, code example, write operation",
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "usage-examples/insertMany",
            "title": "Insert Multiple Documents",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can insert multiple documents into a collection by calling the\n insert_many()  method\non a  Collection  instance. Pass a vector containing one or more documents to the  insert_many()  method\nto insert them into your collection. These documents must be instances of the type\nthat you parameterized your  Collection  instance with. For example, if you\nparameterized your collection with the  MyStruct  struct, pass a vector of  MyStruct \ninstances as a parameter to the  insert_many()  method. The  insert_many()  method returns an  InsertManyResult \ntype that references the  _id  values of the inserted documents. To learn more about inserting documents into a collection, see the\n Insert Documents  guide. To insert a single document, consider using the  insert_one()  method instead. For a\nrunnable code example that uses this method, see the  Insert a Document \nusage example. This example inserts documents into the  restaurants  collection of the\n sample_restaurants  database. The example uses a  Restaurant  struct containing\n name  and  cuisine  fields to model the documents being inserted into the\ncollection. This example passes a vector of documents as a parameter to the  insert_many() \nmethod. Select the  Asynchronous  or  Synchronous  tab to\nsee the corresponding code for each runtime:",
            "code": [
                {
                    "lang": "rust",
                    "value": "use mongodb::{ \n    bson::doc,\n    Client,\n    Collection \n};\nuse serde::{ Deserialize, Serialize };\n\n#[derive(Serialize, Deserialize, Debug)]\nstruct Restaurant {\n    name: String,\n    cuisine: String,\n}\n\n#[tokio::main]\nasync fn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n    let client = Client::with_uri_str(uri).await?;\n\n    let my_coll: Collection<Restaurant> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let docs = vec! [\n        Restaurant {\n            name: \"While in Kathmandu\".to_string(),\n            cuisine: \"Nepalese\".to_string(),\n        },\n        Restaurant {\n            name: \"Cafe Himalaya\".to_string(),\n            cuisine: \"Nepalese\".to_string(),\n        }\n    ];\n    \n    let insert_many_result = my_coll.insert_many(docs, None).await?;\n    println!(\"Inserted documents with _ids:\");\n    for (_key, value) in &insert_many_result.inserted_ids {\n        println!(\"{}\", value);\n    }\n        \n    Ok(())\n}"
                },
                {
                    "lang": "console",
                    "value": "Inserted documents with _ids:\nObjectId(\"...\")\nObjectId(\"...\")"
                },
                {
                    "lang": "rust",
                    "value": "use mongodb::{\n    bson::doc,\n    sync::{Client, Collection}\n};\nuse serde::{ Deserialize, Serialize };\n\n#[derive(Serialize, Deserialize, Debug)]\nstruct Restaurant {\n    name: String,\n    cuisine: String,\n}\n\nfn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n    let client = Client::with_uri_str(uri)?;\n\n    let my_coll: Collection<Restaurant> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let docs = vec! [\n        Restaurant {\n            name: \"While in Kathmandu\".to_string(),\n            cuisine: \"Nepalese\".to_string(),\n        },\n        Restaurant {\n            name: \"Cafe Himalaya\".to_string(),\n            cuisine: \"Nepalese\".to_string(),\n        }\n    ];\n    \n    let insert_many_result = my_coll.insert_many(docs, None)?;\n    println!(\"Inserted documents with _ids:\");\n    for (_key, value) in &insert_many_result.inserted_ids {\n        println!(\"{}\", value);\n    }\n\n    Ok(())\n}"
                },
                {
                    "lang": "console",
                    "value": "Inserted documents with _ids:\nObjectId(\"...\")\nObjectId(\"...\")"
                }
            ],
            "preview": "You can insert multiple documents into a collection by calling the\ninsert_many() method\non a Collection instance.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "usage-examples/updateOne",
            "title": "Update a Document",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can update a document in a collection by calling the  update_one()  method on a\n Collection  instance. Pass the following parameters to the  update_one()  method: The  update_one()  method returns an  UpdateResult  type that contains\ninformation about the results of the update operation, such as the\nnumber of modified documents. To learn more about the  update_one()  method, see the\n Update Documents  section of the Modify Documents guide. Query filter, which specifies the criteria to match Update document, which specifies the updates to make to the first\nmatched document This example updates a document in the  restaurants  collection of\nthe  sample_restaurants  database. The following code adds the  price  field to a document in which the\nvalue of the  name  field is  \"Spice Market\" . MongoDB\nupdates the first document that matches the query filter. Select the  Asynchronous  or  Synchronous  tab to\nsee the corresponding code for each runtime:",
            "code": [
                {
                    "lang": "rust",
                    "value": "use std::env;\nuse mongodb::{\n    bson::{ Document, doc },\n    Client,\n    Collection\n};\n\n#[tokio::main]\nasync fn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n\n    let client = Client::with_uri_str(uri).await?;\n    let my_coll: Collection<Document> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let filter = doc! { \"name\": \"Spice Market\" };\n    let update = doc! { \"$set\": doc! {\"price\": \"$$$\"} };\n\n    let res = my_coll.update_one(filter, update, None).await?;\n    println!(\"Updated documents: {}\", res.modified_count);\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "console",
                    "value": "Updated documents: 1"
                },
                {
                    "lang": "rust",
                    "value": "use std::env;\nuse mongodb::{\n    bson::{ Document, doc },\n    sync::{ Client, Collection }\n};\n\nfn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n\n    let client = Client::with_uri_str(uri)?;\n    let my_coll: Collection<Document> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let filter = doc! { \"name\": \"Spice Market\" };\n    let update = doc! { \"$set\": doc! {\"price\": \"$$$\"} };\n\n    let res = my_coll.update_one(filter, update, None)?;\n    println!(\"Updated documents: {}\", res.modified_count);\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "console",
                    "value": "Updated documents: 1"
                }
            ],
            "preview": "You can update a document in a collection by calling the update_one() method on a\nCollection instance.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "usage-examples/findOne",
            "title": "Find a Document",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can retrieve a single document from a collection by calling the  find_one()  method on a  Collection  instance. Pass a query filter to the  find_one()  method to return one document in the collection\nthat matches the filter. If multiple documents match the query filter, this method returns\nthe first matching document according to their  natural order  in the database or\naccording to the sort order specified in a  FindOneOptions  instance. The  find_one()  method returns an  Option<T> \ntype, where  T  is the type with which you parameterized your  Collection \ninstance. To learn more about retrieving documents, see the  Retrieve Data  guide. This example retrieves a document that matches a query filter from the  restaurants \ncollection in the  sample_restaurants  database. The example populates a  Restaurant \nstruct with data from the retrieved document. This example uses a query filter that matches documents in which the value of the\n name  field is  \"Tompkins Square Bagels\" . MongoDB retrieves the\nfirst document that matches the query filter. Select the  Asynchronous  or  Synchronous  tab to\nsee the corresponding code for each runtime:",
            "code": [
                {
                    "lang": "rust",
                    "value": "use mongodb::{ \n    bson::doc,\n    Client,\n    Collection\n};\nuse serde::{ Deserialize, Serialize };\n\n#[derive(Serialize, Deserialize, Debug)]\nstruct Restaurant {\n    name: String,\n    cuisine: String,\n}\n\n#[tokio::main]\nasync fn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n    let client = Client::with_uri_str(uri).await?;\n\n    let my_coll: Collection<Restaurant> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let result = my_coll.find_one(\n        doc! { \"name\": \"Tompkins Square Bagels\" },\n        None\n    ).await?;\n\n    println!(\"{:#?}\", result);\n\n    Ok(())\n}\n\n"
                },
                {
                    "lang": "console",
                    "value": "Some(\n    Restaurant {\n        name: \"Tompkins Square Bagels\",\n        cuisine: \"American\",\n    },\n)"
                },
                {
                    "lang": "rust",
                    "value": "use mongodb::{\n    bson::doc,\n    sync::{Client, Collection}\n};\nuse serde::{ Deserialize, Serialize };\n\n#[derive(Serialize, Deserialize, Debug)]\nstruct Restaurant {\n    name: String,\n    cuisine: String,\n}\n\nfn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n    let client = Client::with_uri_str(uri)?;\n\n    let my_coll: Collection<Restaurant> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let result = my_coll.find_one(\n        doc! { \"name\": \"Tompkins Square Bagels\" },\n        None\n    )?;\n\n    println!(\"{:#?}\", result);\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "console",
                    "value": "Some(\n    Restaurant {\n        name: \"Tompkins Square Bagels\",\n        cuisine: \"American\",\n    },\n)"
                }
            ],
            "preview": "You can retrieve a single document from a collection by calling the find_one() method on a Collection instance.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "usage-examples/count",
            "title": "Count Documents",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can count the number of documents in a collection by calling one of\nthe following methods on a  Collection  instance: Each method returns the count as a  u64  instance. count_documents() :\ncounts the number of documents that match a query filter. To learn\nmore about creating query filters, see the  Specify a Query \nguide. estimated_document_count() :\nestimates the total number of documents in a collection by using\ncollection metadata. If you don't pass a filter to the  count_documents()  method,\nMongoDB counts the total number of documents in the collection. This example counts documents in the  restaurants  collection of the\n sample_restaurants  database. The following code first uses the  estimated_document_count()  method\nto count the total number of documents in the collection. Then, the\nexample uses the  count_documents()  method to count the number of\ndocuments that match a query filter. The filter matches documents in which\nthe value of the  name  field includes the string  \"Sunset\" : Select the  Asynchronous  or  Synchronous  tab to\nsee the corresponding code for each runtime:",
            "code": [
                {
                    "lang": "rust",
                    "value": "use std::env;\nuse mongodb::{ bson::doc, Client, Collection };\nuse bson::Document;\n\n#[tokio::main]\nasync fn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n\n    let client = Client::with_uri_str(uri).await?;\n    let my_coll: Collection<Document> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let ct = my_coll.estimated_document_count(None).await?;\n    println!(\"Number of documents: {}\", ct);\n\n    let ct = my_coll.count_documents(doc! { \"name\": doc! { \"$regex\": \"Sunset\" } }, None).await?;\n    println!(\"Number of matching documents: {}\", ct);\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "console",
                    "value": "// Your values might differ\nNumber of documents: 25216\nNumber of matching documents: 10"
                },
                {
                    "lang": "rust",
                    "value": "use std::env;\nuse mongodb::{\n    bson::{ Document, doc },\n    sync::{ Client, Collection }\n};\n\nfn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n\n    let client = Client::with_uri_str(uri)?;\n    let my_coll: Collection<Document> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let ct = my_coll.estimated_document_count(None)?;\n    println!(\"Number of documents: {}\", ct);\n\n    let ct = my_coll.count_documents(doc! { \"name\": doc! { \"$regex\": \"Sunset\" } }, None)?;\n    println!(\"Number of matching documents: {}\", ct);\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "console",
                    "value": "// Your values might differ\nNumber of documents: 25216\nNumber of matching documents: 10"
                }
            ],
            "preview": "You can count the number of documents in a collection by calling one of\nthe following methods on a Collection instance:",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "usage-examples/distinct",
            "title": "List Distinct Field Values",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can list the distinct values of a document field in a collection by\ncalling the  distinct() \nmethod on a  Collection  instance. For example, if documents in a\ncollection contain the  date  field, you can use the  distinct() \nmethod to find all the possible values for that field in the collection. Pass a field name as a parameter to the  distinct()  method to return\nthe distinct values for that field. You can also pass a query filter as\na parameter to find distinct field values from only a subset of matched\ndocuments. To learn more about creating query filters, see the\n Specify a Query  guide. The  distinct()  method returns the list of distinct values as a  Vec<Bson> \ntype, a vector of  Bson  values. This example finds distinct values for a field in the\n restaurants  collection of the  sample_restaurants  database. This example finds distinct values of the  borough  field in\nthe subset of documents in which the value of the  cuisine  field\nis  \"Turkish\" . Select the  Asynchronous  or  Synchronous  tab to\nsee the corresponding code for each runtime:",
            "code": [
                {
                    "lang": "rust",
                    "value": "use std::env;\nuse mongodb::{ \n    bson::{ Document, doc },\n    Client,\n    Collection };\n\n#[tokio::main]\nasync fn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n\n    let client = Client::with_uri_str(uri).await?;\n    let my_coll: Collection<Document> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let filter = doc! { \"cuisine\": \"Turkish\" };\n    let boroughs = my_coll.distinct(\"borough\", filter, None).await?;\n\n    println!(\"List of field values for 'borough':\");\n    for b in boroughs.iter() {\n        println!(\"{:?}\", b);\n    }\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "console",
                    "value": "List of field values for 'borough':\nString(\"Brooklyn\")\nString(\"Manhattan\")\nString(\"Queens\")\nString(\"Staten Island\")"
                },
                {
                    "lang": "rust",
                    "value": "use std::env;\nuse mongodb::{ \n    bson::{ Document, doc },\n    sync::{ Client, Collection }\n};\n\nfn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n\n    let client = Client::with_uri_str(uri)?;\n    let my_coll: Collection<Document> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let filter = doc! { \"cuisine\": \"Turkish\" };\n    let boroughs = my_coll.distinct(\"borough\", filter, None)?;\n\n    println!(\"List of field values for 'borough':\");\n    for b in boroughs.iter() {\n        println!(\"{:?}\", b);\n    }\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "console",
                    "value": "List of field values for 'borough':\nString(\"Brooklyn\")\nString(\"Manhattan\")\nString(\"Queens\")\nString(\"Staten Island\")"
                }
            ],
            "preview": "You can list the distinct values of a document field in a collection by\ncalling the distinct()\nmethod on a Collection instance. For example, if documents in a\ncollection contain the date field, you can use the distinct()\nmethod to find all the possible values for that field in the collection.",
            "tags": "runnable, code example, read operation",
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "usage-examples/updateMany",
            "title": "Update Multiple Documents",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can update multiple documents in a collection by calling the  update_many()  method on a\n Collection  instance. Pass the following parameters to the  update_many()  method: The  update_many()  method returns an  UpdateResult  type that contains\ninformation about the results of the update operation, such as the\nnumber of modified documents. To learn more about the  update_many()  method, see the\n Update Documents  section of the Modify Documents guide. Query filter, which specifies the criteria to match Update document, which specifies the updates to make to all matching\ndocuments This example updates a document in the  restaurants  collection of\nthe  sample_restaurants  database. The following code adds the  near_me  field to documents in which the\nvalue of the  address.street  field is  \"Sullivan Street\"  and the\n borough  field is  \"Manhattan\" . Select the  Asynchronous  or  Synchronous  tab to\nsee the corresponding code for each runtime:",
            "code": [
                {
                    "lang": "rust",
                    "value": "use std::env;\nuse mongodb::{ bson::doc, Client, Collection };\nuse bson::Document;\n\n#[tokio::main]\nasync fn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n\n    let client = Client::with_uri_str(uri).await?;\n    let my_coll: Collection<Document> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let filter =\n        doc! { \n            \"address.street\": \"Sullivan Street\", \n            \"borough\": \"Manhattan\" \n        };\n    let update = doc! { \"$set\": doc! { \"near_me\": true } };\n\n    let res = my_coll.update_many(filter, update, None).await?;\n    println!(\"Updated documents: {}\", res.modified_count);\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "console",
                    "value": "// Your values might differ\nUpdated documents: 22"
                },
                {
                    "lang": "rust",
                    "value": "use std::env;\nuse mongodb::{\n    bson::{ Document, doc },\n    sync::{ Client, Collection } \n};\n\nfn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n\n    let client = Client::with_uri_str(uri)?;\n    let my_coll: Collection<Document> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let filter =\n        doc! { \n        \"address.street\": \"Sullivan Street\", \n        \"borough\": \"Manhattan\" \n    };\n    let update = doc! { \"$set\": doc! { \"near_me\": true } };\n\n    let res = my_coll.update_many(filter, update, None)?;\n    println!(\"Updated documents: {}\", res.modified_count);\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "console",
                    "value": "// Your values might differ\nUpdated documents: 22"
                }
            ],
            "preview": "You can update multiple documents in a collection by calling the update_many() method on a\nCollection instance.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "usage-examples/insertOne",
            "title": "Insert a Document",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can insert a document into a collection by calling the  insert_one()  method on a\n Collection  instance. You must insert a document of the same type that you parameterized your\n Collection  instance with. For example, if you parameterized your\ncollection with the  MyStruct  struct, pass a  MyStruct \ninstance as a parameter to the  insert_one()  method to insert a\ndocument. To learn more about specifying a type parameter, see the\n Collection Parameterization  section\nof the Databases and Collections guide. The  insert_one()  method returns an  InsertOneResult  type that contains the\n _id  field of the newly inserted document. To learn more about the  insert_one()  method, see the\n Insert Documents  guide. This example inserts a document into the  restaurants  collection of\nthe  sample_restaurants  database. The example uses a  Restaurant \nstruct that has  name ,  borough , and  cuisine  fields to model\ndocuments in the collection. The following code creates a  Restaurant  instance and inserts it into\nthe collection. Select the  Asynchronous  or  Synchronous  tab to\nsee the corresponding code for each runtime:",
            "code": [
                {
                    "lang": "rust",
                    "value": "use std::env;\nuse mongodb::{ bson::doc, Client, Collection };\nuse serde::{ Deserialize, Serialize };\n\n#[derive(Serialize, Deserialize, Debug)]\nstruct Restaurant {\n    borough: String,\n    cuisine: String,\n    name: String,\n}\n\n#[tokio::main]\nasync fn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n\n    let client = Client::with_uri_str(uri).await?;\n    let my_coll: Collection<Restaurant> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let doc = Restaurant {\n        name: \"Sea Stone Tavern\".to_string(),\n        cuisine: \"Greek\".to_string(),\n        borough: \"Queens\".to_string(),\n    };\n\n    let res = my_coll.insert_one(doc, None).await?;\n    println!(\"Inserted a document with _id: {}\", res.inserted_id);\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "console",
                    "value": "Inserted a document with _id: ObjectId(\"...\")"
                },
                {
                    "lang": "rust",
                    "value": "use std::env;\nuse mongodb::{ bson::doc, sync::{ Client, Collection } };\nuse serde::{ Deserialize, Serialize };\n\n#[derive(Serialize, Deserialize, Debug)]\nstruct Restaurant {\n    borough: String,\n    cuisine: String,\n    name: String,\n}\n\nfn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n\n    let client = Client::with_uri_str(uri)?;\n    let my_coll: Collection<Restaurant> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let doc = Restaurant {\n        name: \"Sea Stone Tavern\".to_string(),\n        cuisine: \"Greek\".to_string(),\n        borough: \"Queens\".to_string(),\n    };\n\n    let res = my_coll.insert_one(doc, None)?;\n    println!(\"Inserted a document with _id: {}\", res.inserted_id);\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "console",
                    "value": "Inserted a document with _id: ObjectId(\"...\")"
                }
            ],
            "preview": "You can insert a document into a collection by calling the insert_one() method on a\nCollection instance.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "usage-examples/find",
            "title": "Find Multiple Documents",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can query for multiple documents in a collection by calling the\n find()  method on a\n Collection  instance. Pass a query filter to the  find()  method to return documents in the collection\nthat match the filter. If you do not include a filter, MongoDB returns all the\ndocuments in the collection. The  find()  method returns a  Cursor \ntype, which you can iterate through to retrieve individual documents. To\nlearn more about using cursors, see the  Access Data by Using a Cursor  guide. To learn more about retrieving documents,\nsee the  Retrieve Data  guide, and to learn more about\ncreating query filters, see the  Specify a Query  guide. This example retrieves documents that match a query filter from the  restaurants \ncollection in the  sample_restaurants  database. The example populates\ninstances of the  Restaurant  struct with data from the retrieved\ndocuments. The following code uses a query filter that matches documents in which the value\nof the  cuisine  field is  \"French\" . Select the  Asynchronous  or  Synchronous  tab to\nsee the corresponding code for each runtime:",
            "code": [
                {
                    "lang": "rust",
                    "value": "use mongodb::{ \n    bson::doc,\n    Client,\n    Collection\n};\nuse futures::TryStreamExt;\nuse serde::{ Deserialize, Serialize };\n\n#[derive(Serialize, Deserialize, Debug)]\nstruct Restaurant {\n    name: String,\n    cuisine: String,\n}\n\n#[tokio::main]\nasync fn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n    let client = Client::with_uri_str(uri).await?;\n\n    let my_coll: Collection<Restaurant> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let mut cursor = my_coll.find(\n        doc! { \"cuisine\": \"French\" },\n        None\n    ).await?;\n\n    while let Some(doc) = cursor.try_next().await? {\n        println!(\"{:?}\", doc);\n    }\n\n    Ok(())\n}\n\n\n"
                },
                {
                    "lang": "console",
                    "value": "// Results truncated\n...\nRestaurant { name: \"Cafe Un Deux Trois\", cuisine: \"French\" }\nRestaurant { name: \"Calliope\", cuisine: \"French\" }\n..."
                },
                {
                    "lang": "rust",
                    "value": "use mongodb::{\n    bson::doc,\n    sync::{Client, Collection}\n};\nuse serde::{ Deserialize, Serialize };\n\n#[derive(Serialize, Deserialize, Debug)]\nstruct Restaurant {\n    name: String,\n    cuisine: String,\n}\n\nfn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n    let client = Client::with_uri_str(uri)?;\n\n    let my_coll: Collection<Restaurant> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let mut cursor = my_coll.find(\n        doc! { \"cuisine\": \"French\" },\n        None\n    )?;\n    \n    for result in cursor {\n        println!(\"{:?}\", result?);\n      }\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "console",
                    "value": "// Results truncated\n...\nRestaurant { name: \"Cafe Un Deux Trois\", cuisine: \"French\" }\nRestaurant { name: \"Calliope\", cuisine: \"French\" }\n..."
                }
            ],
            "preview": "You can query for multiple documents in a collection by calling the\nfind() method on a\nCollection instance.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "usage-examples/deleteMany",
            "title": "Delete Multiple Documents",
            "headings": [
                "Example"
            ],
            "paragraphs": "You can delete multiple documents from a collection in a single operation\nby calling the  delete_many() \nmethod on a  Collection  instance. Pass a query filter to the  delete_many()  method to delete documents in the\ncollection that match the filter. If you do not include a filter, MongoDB deletes\nall the documents in the collection. The  delete_many()  method returns a  DeleteResult \ntype. This type contains information about the delete operation, such as the total\nnumber of documents deleted. To learn more about delete operations, see the  Delete Documents  guide. To delete all documents in a collection, consider calling the  drop() \nmethod on a  Collection  instance. To learn more about the  drop() \nmethod, see the  Drop a Collection  section of the Databases and\nCollections guide. This example deletes all documents that match a query filter from the  restaurants \ncollection in the  sample_restaurants  database. This example passes a query filter as a parameter to the  delete_many()  method.\nThe filter matches documents in which the value of the  borough  field is  \"Manhattan\" \nand the value of the  address.street  field is  \"Broadway\" . Select the  Asynchronous  or  Synchronous  tab to\nsee the corresponding code for each runtime:",
            "code": [
                {
                    "lang": "rust",
                    "value": "use mongodb::{\n    bson::{ Document, doc },\n    Client,\n    Collection\n};\n\n#[tokio::main]\nasync fn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n    let client = Client::with_uri_str(uri).await?;\n\n    let my_coll: Collection<Document> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let filter =\n        doc! { \"$and\": [\n           doc! { \"borough\": \"Manhattan\" },\n           doc! { \"address.street\": \"Broadway\" }\n       ]\n    };\n\n    let result = my_coll.delete_many(filter, None).await?;\n\n    println!(\"Deleted documents: {}\", result.deleted_count);\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "console",
                    "value": "// Your values might differ\nDeleted documents: 615"
                },
                {
                    "lang": "rust",
                    "value": "use mongodb::{ \n    bson::{ Document, doc }, \n    sync::{ Client, Collection } \n};\n\nfn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n    let client = Client::with_uri_str(uri)?;\n\n    let my_coll: Collection<Document> = client\n        .database(\"sample_restaurants\")\n        .collection(\"restaurants\");\n\n    let filter =\n        doc! { \"$and\": [\n           doc! { \"borough\": \"Manhattan\" },\n           doc! { \"address.street\": \"Broadway\" }\n       ]\n    };\n\n    let result = my_coll.delete_many(filter, None)?;\n\n    println!(\"Deleted documents: {}\", result.deleted_count);\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "console",
                    "value": "// Your values might differ\nDeleted documents: 615"
                }
            ],
            "preview": "You can delete multiple documents from a collection in a single operation\nby calling the delete_many()\nmethod on a Collection instance.",
            "tags": "runnable, code example, write operation",
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/monitoring",
            "title": "Monitoring",
            "headings": [],
            "paragraphs": "Cluster Monitoring : monitor changes\nin your cluster configuration Command Monitoring : monitor command\nexecution Connection Pool Monitoring :\nmonitor changes in the connection pool",
            "code": [],
            "preview": null,
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/database-collection",
            "title": "Databases and Collections",
            "headings": [
                "Overview",
                "Access a Database",
                "List Databases",
                "Drop a Database",
                "Access a Collection",
                "Collection Parameterization",
                "Create a Collection",
                "List Collections",
                "Drop a Collection",
                "Additional Information"
            ],
            "paragraphs": "In this guide, you can learn how to use the Rust driver to access\nand manage MongoDB databases and collections. MongoDB organizes data in a hierarchal structure. A MongoDB\ndeployment contains one or more  databases , and each database\ncontains one or more  collections . In each collection, MongoDB stores\ndata as  documents  that contain field-and-value pairs. To learn more about the document data format,\nsee  Documents  in the Server manual. You can access a database by retrieving a  Database  instance from your client. You can use\na  Database  instance to perform database-level operations and access\ncollections that the database contains. Call one of the following methods on a  Client  instance to create a  Database : If you pass the name of a nonexistent database to the  database()  or\n database_with_options()  methods, the driver still returns a\n Database  instance. When you insert any data into collection in this\ndatabase, the server creates it. The following example uses the  database()  method to access a\ndatabase called  test_db : database() : retrieve a database by its name database_with_options() : set\noptions ( DatabaseOptions ) while retrieving a\ndatabase by its name default_database() : access the\ndefault database specified for your  Client  instance To specify the default database for your client, set the\n default_database  field of your  ClientOptions  struct. If you\ndo not set this field, the driver gets the default database from the\n defaultauthdb  component of your connection string. To see a list of your deployment's databases, call the\n list_database_names()  method on\nyour  Client  instance. This\nmethod returns a  Vec<String>  type, a vector containing the database\nnames as strings. To see detailed information about each database, call the  list_databases() \nmethod on your  Client  instance. This method returns a\n Vec<DatabaseSpecification>  type. The  DatabaseSpecification  type\ncontains fields describing each database, such as its size and whether\nit contains data. The following example shows how to print a list of databases by using\nthe  list_database_names()  method: Dropping a database permanently deletes all the data in that database's\ncollections. To drop a database, call the  drop()  method\non your  Database  instance. The following code shows\nhow to drop a database referenced by the  db  variable: Dropping a database permanently deletes all\ndocuments in the database's collections and all indexes on those collections.\nAfter you drop a database, you cannot access or restore any of its data. You can access a collection by retrieving a  Collection  instance from your database. You\ncan use a  Collection  instance to perform data operations,\ncreate aggregations, and manage indexes. Call one of the following\nmethods on a  Database  instance to retrieve a  Collection : If you pass the name of a nonexistent collection to the  collection()  or\n collection_with_options()  methods, the driver still returns a\n Collection  instance. When you insert any data into this\ncollection, the server creates it. To learn how to explicitly\ncreate a collection, see the  Create a Collection  section of this guide. This example uses the  collection_with_options()  method to\nperform the following actions: To learn more about write concerns, see  Write Concern  in\nthe Server manual. collection() : retrieve a collection by its name collection_with_options() : set\noptions ( CollectionOptions ) while accessing a\ncollection by its name Access a collection called  coll_xyz  from a database referenced by\nthe  db  variable Set a write preference on the collection in the  CollectionOptions  type You must parameterize your  Collection  instance by specifying what\ndata type you want to serialize the collection's\ndata into. When you call a method on a  Collection  instance that is\nparameterized with a specific type, the method accepts or returns\ninstances of this type. The following example shows equivalent ways of parameterizing a\ncollection with the  Document  type: If you do not parameterize your  Collection  instance, the compiler\ninfers the generic type when you perform a CRUD operation with a\nspecified data type in the same scope. We recommend that you parameterize your  Collection  instance with a\ncustom type that models your data instead of the  Document  type.\nYou can avoid repetitive serialization and validation by defining a\ntype that models your specific data. To learn more about serialization in the Rust driver, see the\nguide on  Data Modeling and Serialization . You can explicitly create a collection by calling the\n create_collection()  method on a\n Database  instance. This method takes the collection name and an\noptional  CreateCollectionOptions  type as\nparameters. You can use a  Collection  instance to perform data\noperations, create aggregations, and manage indexes. The following code shows how to create a collection called  coll_abc \nwithin a database referenced by the  db  variable: When creating a collection, you can implement schema validation to\nmaintain a consistent document schema and control whether any write\noperations can bypass the validation rules. To learn how to enable this\nfeature, see the guide on  Schema Validation . To see the names of the collections in a database, call the\n list_collection_names()  method on your  Database  instance. This\nmethod returns a  Vec<String>  type, a vector containing the\ncollection names as strings. To see detailed information about each collection, call the  list_collections() \nmethod on your  Database  instance. This method returns a\n Vec<CollectionSpecification>  type. The  CollectionSpecification  type\ncontains fields describing each collection, such as its type and settings. The following example shows how to print the names of the collections in\na database referenced by the  db  variable by using the\n list_collection_names()  method: Dropping a collection permanently deletes all the data in that\ncollection. To drop a collection, call the  drop()  method\non your  Collection  instance. The following code shows\nhow to drop a collection referenced by the  my_coll  variable: Dropping a collection from your database permanently deletes all\ndocuments within that collection and all indexes on that collection.\nAfter you drop a collection, you cannot access or restore any of its data. For more information about the concepts in this guide, see the following documentation: Insert Documents  guide Databases and Collections \nin the Server manual Documents  in the Server manual",
            "code": [
                {
                    "lang": "rust",
                    "value": "let db = client.database(\"test_db\");"
                },
                {
                    "lang": "rust",
                    "value": "let db_list = client.list_database_names(doc! {}, None).await?;\nprintln!(\"{:?}\", db_list);"
                },
                {
                    "lang": "console",
                    "value": "[\"admin\", \"local\", \"test_db\", ...]"
                },
                {
                    "lang": "rust",
                    "value": "db.drop(None).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let wc = WriteConcern::builder().journal(true).build();\nlet coll_opts = CollectionOptions::builder().write_concern(wc).build();\nlet my_coll: Collection<Document> = db.collection_with_options(\"coll_xyz\", coll_opts);"
                },
                {
                    "lang": "rust",
                    "value": "let my_coll: Collection<Document> = client.database(\"test_db\").collection(\"coll_xyz\");\nlet my_coll = client.database(\"test_db\").collection::<Document>(\"coll_xyz\");"
                },
                {
                    "lang": "rust",
                    "value": "db.create_collection(\"coll_abc\", None).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let coll_list = db.list_collection_names(doc! {}).await?;\nprintln!(\"{:?}\", coll_list);"
                },
                {
                    "lang": "console",
                    "value": "[\"my_coll\", \"coll_xyz\", ...]"
                },
                {
                    "lang": "rust",
                    "value": "my_coll.drop(None).await?;"
                }
            ],
            "preview": "In this guide, you can learn how to use the Rust driver to access\nand manage MongoDB databases and collections.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/crud",
            "title": "CRUD Operations",
            "headings": [],
            "paragraphs": "CRUD (create, read, update, and delete) operations enable you to work\nwith data stored in MongoDB. Learn how to perform CRUD operations in the\nfollowing sections: Compound operations combine functionalities of read and write\noperations. To learn more about these methods, see\nthe  Compound Operations  guide. Read Operations : find and return\ndocuments. Write Operations : insert, modify,\nor delete documents.",
            "code": [],
            "preview": "CRUD (create, read, update, and delete) operations enable you to work\nwith data stored in MongoDB. Learn how to perform CRUD operations in the\nfollowing sections:",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/enterprise-auth",
            "title": "Enterprise Authentication Mechanisms",
            "headings": [
                "Overview",
                "Authenticate to LDAP (PLAIN)",
                "Example",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to authenticate to MongoDB using the\nauthentication mechanisms available in the MongoDB Enterprise\nEdition. When you connect to MongoDB, you can use an authentication\nmechanism to establish trust between the driver and the server. The Rust driver supports authenticating to a Lightweight\nDirectory Access Protocol (LDAP) server by using the\n LDAP (PLAIN)  enterprise authentication mechanism. To select a specific authentication mechanism, specify the\nmechanism, your credentials, and other necessary information\nin the options of your connection string or in a  Credential  struct. The driver does not support the GSSAPI/Kerberos authentication\nmechanism, but you can use other methods to authenticate this way. To\nlearn more about these methods, see  Kerberos Authentication  in the Server manual. To authenticate to MongoDB by using mechanisms available in\nthe MongoDB Community Edition, see the guide on  Authentication Mechanisms . To learn more about connecting to a MongoDB deployment, see the\n Connection Guide . You can authenticate to a Lightweight Directory Access Protocol (LDAP) server\nby using your directory server username and password. The name of the authentication mechanism is  PLAIN  instead of LDAP\nbecause the mechanism uses the PLAIN Simple Authentication and\nSecurity Layer (SASL) defined in  RFC-4616 . This authentication mechanism sends your password to the server in\nplaintext. Use this mechanism only after enabling TLS\non your connection to improve security and reduce vulnerabilities in\nyour application. To learn more, see  TLS/SSL (Transport Encryption)  in the Server manual. To specify the  PLAIN  authentication mechanism, set the\n mechanism  field of your  Credential  struct to\n AuthMechanism::Plain . This example specifies the\nauthentication mechanism by using the following placeholders: Alternatively, you can authenticate by using a connection string URI by\nsetting the value of the  authMechanism  connection string option to  PLAIN .\nThis example shows how to specify the  PLAIN  authentication mechanism in\na connection string URI by using the following placeholders: username : Your LDAP username password : Your LDAP password Because your credentials are stored outside of MongoDB, you must use the\n $external  database for authentication. The  source  field of\nthe  Credential  struct defaults to  $external , so you can omit\nthis field. username : Your LDAP username password : Your LDAP password hostname : The network address of your MongoDB server To learn more about the concepts in this guide, see the following documentation: MongoDB Server Support for LDAP Proxy Authentication  in the Server manual Connection Options  guide Connection Strings  in the\nServer manual To learn more about the methods and types mentioned in this\nguide, see the following API documentation: Credential ClientOptions Client with_options()",
            "code": [
                {
                    "lang": "rust",
                    "value": "let uri = \"mongodb://<username>:<password>@<hostname>/?authSource=$external&authMechanism=PLAIN\";"
                },
                {
                    "lang": "rust",
                    "value": "let plain_cred = Credential::builder()\n    .username(\"<username>\".to_string())\n    .password(\"<password>\".to_string())\n    .mechanism(AuthMechanism::Plain)\n    .source(\"$external\".to_string())\n    .build();\n\nclient_options.credential = Some(plain_cred);\nlet client = Client::with_options(client_options)?;"
                }
            ],
            "preview": "In this guide, you can learn how to authenticate to MongoDB using the\nauthentication mechanisms available in the MongoDB Enterprise\nEdition. When you connect to MongoDB, you can use an authentication\nmechanism to establish trust between the driver and the server.",
            "tags": "enterprise edition, verify credentials, code example",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/schema-validation",
            "title": "Schema Validation",
            "headings": [
                "Overview",
                "JSON Schema Validation",
                "Implement Schema Validation",
                "Example",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to use the Rust driver to implement\n schema validation  for your MongoDB collections. To implement schema validation, you must provide a JSON schema that consists\nof a set of a validation rules. If you implement schema validation, the\nserver only allows you to run write operations that follow the validation\nrules. Use schema validation to restrict data types and value ranges of\ndocument fields in a specified collection. You can define schema validation rules when creating a collection by using\ndriver methods, or you can add them to an existing collection by using the\n collMod  MongoDB command. This guide only describes how to enable schema\nvalidation when creating a collection. To learn more about enabling schema\nvalidation on existing collections, see  collMod \nin the Server manual. Before creating a collection with schema validation rules, you must define a\nJSON schema. The JSON schema is a JSON object that contains key-value pairs specifying\nthe validation rules for your collection. At the top level, this object must\ninclude a  $jsonSchema  object. The  $jsonSchema  object includes the\nfollowing fields: For a full list of JSON schema object fields, see  JSON Schema  in the Server manual. title : sets an optional description for the schema. required : specifies a list of required fields for each document in\nyour collection. properties : sets property requirements for individual fields. You can implement schema validation by passing your schema and related options\nin an instance of  CreateCollectionOptions  to the  create_collection() \nmethod. You can build a  CreateCollectionOptions  instance by using the\n CreateCollectionOptions::builder()  method. Call the following  CreateCollectionOptions::builder()  functions to specify\nthe validation options for the new collection: The Rust driver implements the Builder design pattern for the\ncreation of many different types, including  CreateCollectionOptions .\nYou can use each type's  builder()  method to construct an options\ninstance by chaining option builder functions one at a time. Method Description validator() Specifies validation rules for a collection by passing a JSON schema. For more information, see the  JSON Schema Validation \nsection on this page. validation_level() Specifies which insert and update operations are subject to the validation\nrules. Possible values:  ValidationLevel::Off ,\n ValidationLevel::Strict ,  ValidationLevel::Moderate . validation_action() Specifies whether the driver throws an error or a warning if you insert documents\nthat don't follow the validation rules. Possible values:  ValidationAction::Error ,  ValidationAction::Warn . This example creates a collection called  survey_answers  with the\nfollowing validation specifications: The following documents follow the validation rules and can be successfully\ninserted: However, if you attempt to insert the following document, the server\nraises an error because the value of  answer  does not match any of\nthe valid options: The  validator()  method receives a JSON schema specifying that the\n answer  field in each document must have a value of  \"yes\"  or\n \"no\" . The  validation_action()  method specifies whether the driver raises an\n Error  when a write operation violates a validation rule. The  validation_level()  method specifies that the validation is\n Moderate , so the validation rules apply only to inserts and\nupdates on existing valid documents. To bypass a collection's validation rules, set the  bypass_document_validation \nfield to  true  in the write method's options parameter. This ignores any validation\nrules on the collection and any exemptions of them defined by the  validation_level . To see an example of how to specify this setting in the options for the\n insert_one()  method, see the  Modify insert_one Behavior  section of the Insert Documents guide. To learn more about the MongoDB Server operations mentioned on this page,\nsee the following documentation in the Server manual: Validation operations for the collMod command Schema Validation Specify JSON Schema Validation To learn more about setting validation levels and actions, see the\nfollowing API documentation: To learn more about any other methods or types referenced in this\nguide, see the following documentation: validation_level \nfor the  validation_level()  helper method ValidationLevel  for possible  validation_level  values validation_action \nfor the  validation_action()  helper method ValidationAction  for possible  validation_action  values create_collection() CreateCollectionOptions validator",
            "code": [
                {
                    "lang": "json",
                    "value": "{\n  \"_id\": { ... },\n  \"question\": \"Do you like to exercise?\",\n  \"answer\": \"yes\"\n},\n{\n  \"_id\": { ... },\n  \"question\": \"Do you like to play computer games?\",\n  \"answer\": \"no\"\n}"
                },
                {
                    "lang": "rust",
                    "value": "let validator =\n    doc! {\n        \"$jsonSchema\": doc! {\n           \"bsonType\": \"object\",\n           \"title\": \"Answer Value Validation\",\n           \"properties\": doc! {\n              \"answer\": doc! {\n                 \"enum\": vec! [ \"yes\", \"no\" ],\n              }\n           }\n        }\n    };\nlet validation_opts = CreateCollectionOptions::builder()\n    .validator(validator)\n    .validation_action(Some(ValidationAction::Error))\n    .validation_level(Some(ValidationLevel::Moderate))\n    .build();\n\ndb.create_collection(\"survey_answers\", validation_opts).await?;"
                },
                {
                    "lang": "json",
                    "value": "{\n  \"_id\": { ... },\n  \"question\": \"Do you like to exercise?\",\n  \"answer\": \"depends on my mood\"\n}"
                },
                {
                    "lang": "none",
                    "value": "Error: Error { kind: Write(WriteError(WriteError { code: 121, code_name:\nNone, message: \"Document failed validation\", details:\nSome(Document({\"failingDocumentId\":\nObjectId(\"...\"), \"details\":\nDocument({\"operatorName\": String(\"$jsonSchema\"), \"title\": String(\"Answer\nValue Validation\"), ... })})) })), ... }"
                }
            ],
            "preview": "In this guide, you can learn how to use the Rust driver to implement\nschema validation for your MongoDB collections.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/geo",
            "title": "Search Geospatially",
            "headings": [
                "Overview",
                "Store Geospatial Data",
                "GeoJSON",
                "Positions",
                "Types",
                "Legacy Coordinate Pairs",
                "Geospatial Indexes",
                "2dsphere",
                "2d",
                "Geospatial Queries",
                "Query Operators",
                "Query by Proximity Example",
                "Query Within a Range Example",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to search  geospatial data  by using the\nRust driver. Geospatial data represents a geographic location on the surface\nof the Earth or on a Euclidean plane. Examples of geospatial data include: This guide includes the following sections: Locations of movie theaters Borders of countries Routes of bicycle rides Dog exercise areas in New York City Points on a graph Store Geospatial Data  describes the data formats you can use to\nrepresent geospatial data Geospatial Indexes  describes how to create an index on fields\nstoring geospatial data Geospatial Queries  describes how to query geospatial\ndata stored in indexed fields Additional Information  provides links to resources and\nAPI documentation for types and methods mentioned in this guide All geospatial data in MongoDB is stored in one of the following formats: GeoJSON, a format that represents geospatial data on an Earth-like\nsphere Legacy Coordinate Pair, a format that represents geospatial data\non a Euclidean plane Use GeoJSON to store data that represents geospatial information on\nan Earth-like sphere. GeoJSON is composed of one or more  positions \nand a  type . A position represents a single place on Earth and exists in code as an array\ncontaining the following values: The following code represents the  position  of the MongoDB Headquarters in\nNew York City, NY: Longitude in the first position Latitude in the second position GeoJSON orders coordinates as  longitude  first and  latitude  second.\nThis conflicts with geographic coordinate system conventions, which generally list\nlatitude first and longitude second. Ensure that you reformat your coordinates to\nalign with GeoJSON standards. Your GeoJSON object's type determines the geometric shape it represents. Geometric shapes are\nmade up of positions. The following list describes common GeoJSON types and how to specify them with positions: To learn more about the GeoJSON types that you can use in MongoDB, see the\n GeoJSON  page in the Server manual. Point : a single position. For example, the following  Point  represents the location of\nthe MongoDB Headquarters: LineString : an array of two or more positions that forms a series of line\nsegments. A  LineString  can represent a path, route, border, or any other linear\ngeospatial data. For example, the following  LineString  represents a segment of\n the Great Wall of China : Polygon : an array of positions in which the first and last\nposition are the same and enclose some space. For example, the following\n Polygon  represents  the land within Vatican City : Use legacy coordinate pairs to represent geospatial data on a two-dimensional\nEuclidean plane. The following code specifies a legacy coordinate pair that represents the\nlocation of Washington, D.C.: To learn more about legacy coordinate pairs, see\n Legacy Coordinate Pairs \nin the Server manual. Before querying geospatial data, you must create an index that corresponds\nto the data format. The following index types enable geospatial queries: The following sections on  2dsphere  and  2d  indexes include code examples\nthat use the  theaters  collection in the  sample_mflix  database from the\nAtlas sample data. 2dsphere  for GeoJSON data 2d  for legacy coordinate pairs To learn more about creating an index, see the  Indexes  guide. For instructions on importing the Atlas sample data, see the  Load Sample Data  page. To query data stored in the GeoJSON format, add the field containing\nboth the  type  and  coordinates  fields to a  2dsphere  index. The\nfollowing example creates a  2dsphere  index on the  location.geo  field: To query data stored as legacy coordinate pairs, add the field containing\nlegacy coordinate pairs to a  2d  index. The following example creates a\n 2d  index on the  location.geo.coordinates  field: After creating a  2dsphere  or  2d  index on fields containing geospatial data, you\ncan perform geospatial queries that access those fields. To query geospatial data, create a query filter with a field name and a geospatial query\noperator. You can specify options for certain geospatial query operators to limit\nthe documents returned. The following sections on geospatial queries include code examples that use the  theaters \ncollection in the  sample_mflix  database from the Atlas sample data. Assume that\nthe  theaters  collection has a  2dsphere  index on the  location.geo  field. To learn more about querying data, see the  Specify a Query  guide. For instructions on importing the Atlas sample data, see the  Load Sample Data  page. To query your geospatial data, use one of the following query operators: When using the  $near  operator, you can specify the following distance operators: When using the  $geoWithin  operator, you can specify the following shape operators: $near $geoWithin $nearSphere $geoIntersects   (requires a 2dsphere index) $minDistance $maxDistance $box $polygon $center $centerSphere To learn more about geospatial query operators, see  Geospatial Query Operators  in the Server manual. The following example queries for documents in which the  location.geo  field\nstores a location within 1000 meters of the MongoDB Headquarters in New York City, NY.\nThe code returns documents in ascending order of their distance from the MongoDB Headquarters. The following example queries for documents in which the  location.geo  field\nstores a location within the Chicago area. The example creates a vector called  chicago \nthat stores four coordinates representing the bounds of the geographic search area. To learn more about find operations, see the  Retrieve Data  guide. To learn more about working with geospatial data, see the following Server manual pages: Geospatial Data GeoJSON To learn more about the methods and types mentioned in this\nguide, see the following API documentation: create_index() IndexModel find()",
            "code": [
                {
                    "lang": "rust",
                    "value": "let coords = vec! [-73.986805, 40.7620853];"
                },
                {
                    "lang": "rust",
                    "value": "let point = doc! {\"name\": \"MongoDB HQ\", \"location\": doc! {\n        \"type\": \"Point\",\n        \"coordinates\": vec! [-73.986805, 40.7620853],\n    }\n};"
                },
                {
                    "lang": "rust",
                    "value": "let line = doc! {\"name\": \"Great Wall of China\", \"location\": doc! {\n        \"type\": \"LineString\",\n        \"coordinates\": vec! [\n            vec! [116.572, 40.430],\n            vec! [116.570, 40.434],\n            vec! [116.567, 40.436],\n            vec! [116.566, 40.441]\n        ],\n    }\n};"
                },
                {
                    "lang": "rust",
                    "value": "let polygon = doc! {\"name\": \"Vatican City\", \"location\": doc! {\n    \"type\": \"Polygon\",\n    \"coordinates\": vec![\n        vec! [\n            vec! [12.458, 41.906],\n            vec! [12.458, 41.901],\n            vec! [12.450, 41.901],\n            vec! [12.450, 41.906],\n            vec! [12.458, 41.906],\n            ]\n        ],\n    }\n};"
                },
                {
                    "lang": "rust",
                    "value": "let capital = vec! [-77.0369, 38.9072];"
                },
                {
                    "lang": "rust",
                    "value": "let index = IndexModel::builder()\n    .keys(doc! { \"location.geo\": \"2dsphere\" })\n    .build();\n\nlet idx = my_coll.create_index(index, None).await?;\nprintln!(\"Created index:\\n{}\", idx.index_name);"
                },
                {
                    "lang": "none",
                    "value": "Created index:\nlocation.geo_\"2dsphere\""
                },
                {
                    "lang": "rust",
                    "value": "let index = IndexModel::builder()\n    .keys(doc! { \"location.geo.coordinates\": \"2d\" })\n    .build();\n\nlet idx = my_coll.create_index(index, None).await?;\nprintln!(\"Created index:\\n{}\", idx.index_name);"
                },
                {
                    "lang": "none",
                    "value": "Created index:\nlocation.geo.coordinates_\"2d\""
                },
                {
                    "lang": "rust",
                    "value": "let mongodb = vec! [-73.986805, 40.7620853];\nlet query = doc! {\"location.geo\": \n    doc! { \"$near\": {\n        \"$geometry\": {\n            \"type\": \"Point\", \"coordinates\": mongodb,\n            },\n        \"$maxDistance\": 1000,\n        }\n    }\n};\n\nlet mut cursor = my_coll.find(query, None).await?;\nwhile let Some(doc) = cursor.try_next().await? {\n    println!(\"{}\", doc);\n}"
                },
                {
                    "lang": "none",
                    "value": "{ \"_id\":{...},\"theaterId\":1908,\"location\":{\"address\":{...},\"geo\":{\"type\":\"Point\",\"coordinates\":[-73.983487,40.76078] } } }\n{ \"_id\":{...},\"theaterId\":1448,\"location\":{\"address\":{...},\"geo\":{\"type\":\"Point\",\"coordinates\":[-73.982094,40.769882] } } }"
                },
                {
                    "lang": "rust",
                    "value": "let chicago = doc! {\n    \"type\": \"Polygon\",\n    \"coordinates\": vec![\n        vec![\n            vec![-87.851, 41.976],\n            vec![-87.851, 41.653],\n            vec![-87.651, 41.653],\n            vec![-87.651, 41.976],\n            vec![-87.851, 41.976],\n        ]\n    ]\n};\n\nlet query = doc! {\"location.geo\":\n    doc! { \"$geoWithin\": { \"$geometry\": chicago }}\n};\n\nlet mut cursor = my_coll.find(query, None).await?;\nwhile let Some(doc) = cursor.try_next().await? {\n    println!(\"{}\", doc);\n}\n"
                },
                {
                    "lang": "none",
                    "value": "{ \"_id\":{...},\"theaterId\":322,\"location\":{\"address\":{...},\"geo\":{ \"type\":\"Point\",\"coordinates\":[-87.849403, 41.90707] } } }\n{ \"_id\":{...},\"theaterId\":2960,\"location\":{\"address\":{...},\"geo\":{ \"type\":\"Point\",\"coordinates\":[-87.811262, 41.847938] } } }\n{ \"_id\":{...},\"theaterId\":323,\"location\":{\"address\":{...},\"geo\":{ \"type\":\"Point\",\"coordinates\":[-87.653557, 41.912025] } } }\n{ \"_id\":{...},\"theaterId\":320,\"location\":{\"address\":{...},\"geo\":{ \"type\":\"Point\",\"coordinates\":[-87.805817, 41.847572] } } }\n{ \"_id\":{...},\"theaterId\":814,\"location\":{\"address\":{...},\"geo\":{ \"type\":\"Point\",\"coordinates\":[-87.670631, 41.919514] } } }"
                }
            ],
            "preview": "In this guide, you can learn how to search geospatial data by using the\nRust driver. Geospatial data represents a geographic location on the surface\nof the Earth or on a Euclidean plane.",
            "tags": "code example, geographic, map, distance",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/stable-api",
            "title": "Stable API",
            "headings": [
                "Overview",
                "Specify an API Version",
                "API Version Specification Example",
                "Modify Behavior",
                "Stable API Options Example",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "To use the Stable API feature, you must connect to a deployment running MongoDB Server version 5.0 or later. Use the Stable API feature only if all the MongoDB\nservers you are connecting to support this feature. In this guide, you can learn how to specify  Stable API \ncompatibility when connecting to a MongoDB instance or replica set. The Stable API feature forces the server to run operations with\nbehaviors that are compatible with the  API version  you specify. An API\nversion defines the expected behavior of the operations it covers and\nthe format of server responses. The operations and the server responses\nmay differ depending on the API version you specify. When you use the Stable API feature with an official MongoDB driver, you\ncan update your driver or server without worrying about backward\ncompatibility issues of the commands covered by the Stable API. To learn more about the commands that the server covers, see\n Stable API  in the Server manual. To specify an API version, define a  ServerApi  struct and set the\n server_api  field of your  ClientOptions  instance to this struct.\nThe  ServerApi  struct contains the API version and options.\nTo learn more about setting options, see the  Modify Behavior  section of this guide. After you specify an API version, the client runs only operations that\nare compatible with that version. The MongoDB Rust Driver supports only Stable API version 1. The following example sets the Stable API version when instantiating a  Client \nand connects to a server. You can modify the behavior of the Stable API feature by setting fields\nin the  ServerApi  struct. While you can set the fields in a  ServerApi  struct manually, you can use\nthe builder design pattern to define the struct more efficiently. The Rust driver implements the Builder design pattern for the\ncreation of many different types, including the  ServerApi  struct.\nYou can use each type's  builder()  method to construct an options\ninstance by chaining option builder functions one at a time. Field Description version strict deprecation_errors This example enables the Stable API feature with the following specifications: Uses Stable API version 1 Returns errors for features that aren't part of version 1 Returns errors for deprecated features To learn more about connecting to your MongoDB instance or replica set,\nsee the  Connection Guide . To learn more about the methods and types mentioned in this\nguide, see the following API documentation: Client ClientOptions ServerApi ServerApiVersion with_options()",
            "code": [
                {
                    "lang": "rust",
                    "value": "let server_api = ServerApi::builder().version(ServerApiVersion::V1).build();\nclient_options.server_api = Some(server_api);\n\nlet client = Client::with_options(client_options)?;"
                },
                {
                    "lang": "rust",
                    "value": "let mut client_options = ClientOptions::parse(uri)?;\n\nlet server_api = ServerApi::builder()\n    .version(ServerApiVersion::V1)\n    .strict(true)\n    .deprecation_errors(true)\n    .build();\nclient_options.server_api = Some(server_api);\n\nlet client = Client::with_options(client_options)?;"
                }
            ],
            "preview": "In this guide, you can learn how to specify Stable API\ncompatibility when connecting to a MongoDB instance or replica set.",
            "tags": "set options, versioned api, code example",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "compatibility",
            "title": "Compatibility",
            "headings": [
                "MongoDB Compatibility",
                "Compatibility Table Legend",
                "Language Compatibility"
            ],
            "paragraphs": "The following compatibility table specifies the versions of the\nMongoDB Rust Driver you can use with each version of MongoDB. The first column lists the driver version. MongoDB ensures compatibility between the MongoDB Server and the drivers\nfor three years after the server version's end of life (EOL) date. To learn\nmore about the MongoDB release and EOL dates, see\n MongoDB Software Lifecycle Schedules . Icon Explanation \u2713 All features are supported. \u229b The Driver version will work with the MongoDB version, but not all\nnew MongoDB features are supported. No mark The Driver version is not tested with the MongoDB version. The Rust driver is not compatible with MongoDB Server versions\nolder than 3.6. Rust Driver Version MongoDB 7.0 MongoDB 6.0 MongoDB 5.0 MongoDB 4.4 MongoDB 4.2 MongoDB 4.0 MongoDB 3.6 2.8  \u229b \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 2.7  \u229b \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 2.6  \u229b \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 2.5  \u229b \u229b \u2713 \u2713 \u2713 \u2713 \u2713 2.4  \u229b \u229b \u2713 \u2713 \u2713 \u2713 \u2713 2.3  \u229b \u229b \u2713 \u2713 \u2713 \u2713 \u2713 2.2  \u229b \u229b \u2713 \u2713 \u2713 \u2713 \u2713 2.1  \u229b \u229b \u2713 \u2713 \u2713 \u2713 \u2713 2.0  \u229b \u229b \u2713 \u2713 \u2713 \u2713 \u2713 This Rust driver version does not support\n OCSP . This Rust driver version does not support Decimal128\nor  OCSP . This Rust driver version does not support Decimal128,\n Client-Side Field Level Encryption ,\n GridFS , or\n OCSP . This Rust driver version does not support Decimal128,\n Client-Side Field Level Encryption ,\n GridFS ,\n OCSP ,\nor  change streams . This Rust driver version does not support Decimal128,\n Client-Side Field Level Encryption ,\n GridFS ,\n OCSP ,\n change streams ,\n Causal Consistency , or\n Serverless Instances . For more information on how to read the compatibility tables, see the guide on\n MongoDB Compatibility Tables . The MongoDB Rust Driver requires Rust 1.60.0 or later.",
            "code": [],
            "preview": "The following compatibility table specifies the versions of the\nMongoDB Rust Driver you can use with each version of MongoDB.",
            "tags": null,
            "facets": {
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/performance",
            "title": "Performance Considerations",
            "headings": [
                "Overview",
                "Client Lifecycle",
                "Connection Pool",
                "Configure Maximum Pool Size",
                "Configure Concurrent Connection Options",
                "Configure Maximum Idle Time",
                "Parallelism",
                "Runtime",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to optimize the performance of the\nRust driver. To connect to MongoDB, you must create a  Client  instance. Your  Client \ninstance automatically handles most aspects of connection, such as\ndiscovering server topology, monitoring your connection, and maintaining\nan internal connection pool. This guide describes best practices for\nconfiguring and using your  Client  instance. This guide includes the following sections: Client Lifecycle  describes\nbest practices for creating and managing a  Client  instance Connection Pool  describes\nhow connection pooling works in the driver Parallelism  provides sample code\nfor running parallel, asynchronous tasks Runtime  describes how to manage\nruntimes by using functionalities of the  tokio  and  async_std  crates Additional Information \nprovides links to resources and API documentation for types\nand methods mentioned in this guide We recommend that you reuse your client across sessions and operations.\nYou can use the same  Client  instance to perform multiple tasks, as\nthe  Client  type is safe for concurrent use by multiple threads.\nCreating a new  Client  instance for each request results in slower\nperformance. The following code creates a method that accepts a pointer to an\nexisting  Client  instance, which allows you to perform many requests\nby using the same client: Every  Client  instance has a built-in connection pool for each server\nin your MongoDB topology. Connection pools open sockets on demand to\nsupport concurrent requests to MongoDB in your application. The default configuration for a  Client  works for most applications.\nThe following code shows how to create a client with default connection\nsettings: Alternatively, you can tune the connection pool to best fit the needs of your\napplication and optimize performance. For more information on how to customize\nyour connection settings, see the following subsections of this guide: Configure Maximum Pool Size Configure Concurrent Connection Options Configure Maximum Idle Time To learn more about configuring a connection pool, see\n Tuning Your Connection Pool Settings  in the Server manual. The maximum size of each connection pool is set by the  max_pool_size \noption, which defaults to  10 . If the number of in-use connections to\na server reaches the value of  max_pool_size , the next request to\nthat server waits until a connection becomes available. In addition to the sockets needed to support your application's requests,\neach  Client  instance opens two more sockets per server\nin your MongoDB topology for monitoring the server's state.\nFor example, a client connected to a three-node replica set opens six\nmonitoring sockets. If the application uses the default setting for\n max_pool_size  and only queries the primary (default) node, then\nthere can be at most 16 total connections in the connection pool. If the\napplication uses a read preference to query the secondary nodes, those\nconnection pools grow and there can be 36 total connections. To support high numbers of concurrent MongoDB requests\nwithin one process, you can increase the value of the  max_pool_size \noption. The following code demonstrates how to specify a value for\n max_pool_size  when instantiating a  Client : Connection pools are rate-limited. The  max_connecting  option\ndetermines the number of connections that the pool can create in\nparallel at any time. For example, if the value of  max_connecting  is\n 2 , the default value, the third request that attempts to concurrently\ncheck out a connection succeeds only when one of the following cases occurs: You can set the minimum number of concurrent connections to\neach server with the  min_pool_size  option, which defaults to  0 .\nThe driver initializes the connection pool with this number of sockets. If\nsockets are closed and the total number of sockets, both in use and\nidle, drops below the minimum, the connection pool opens more sockets until the\nminimum is reached. The following code sets the  max_connecting  and  min_pool_size  options when\ninstantiating a  Client : The connection pool finishes creating a connection and the number of\nconnections in the pool is less than or equal to the value of  max_pool_size . An existing connection is checked back into the pool. The driver's ability to reuse existing connections improves due to\nrate limits on connection creation. You can set the maximum amount of time that a connection can\nremain idle in the pool by setting the  max_idle_time  option.\nOnce a connection has been idle for the duration specified in\n max_idle_time , the connection pool removes and replaces that\nconnection. This option defaults to  0 , or no limit. When the  Client::shutdown()  method is called at any point in your\napplication, the driver closes all idle sockets and closes all sockets\nthat are in use as they are returned to the pool. Calling  Client::shutdown() \ncloses only inactive sockets, so you cannot interrupt or terminate\nany ongoing operations by using this method. The driver closes these\nsockets only when the process completes. The following code sets the value of the  max_idle_time  option to\n 90  seconds when instantiating a  Client : If you can run parallel data operations, you can optimize performance by\nrunning asynchronous, concurrent tasks. The following code uses the\n spawn()  method from the  tokio::task  module to create separate,\nconcurrent tasks to perform insert operations: A  Client  instance is bound to the instance of the  tokio  or\n async-std  runtime in which you created it. If you use a  Client \ninstance to perform operations on a different runtime, you might\nexperience unexpected behavior or failures. If use the  test  helper macro from the  tokio  or\n async_std  crate to test your application, you might accidentally run\noperations on a different runtime than intended. This is because these\nhelper macros create a new runtime for each test. However, you can use\none of the following strategies to avoid this issue: This example follows the first strategy and creates a global runtime used only for testing.\nIn the following code, the  test_list_dbs()  method uses a client that\nmanually connects to this runtime to list databases in the deployment: Implementing the second strategy, the following code creates a new\n Client  instance for each test run with  tokio::test ,\nensuring that there are no unintended interactions between runtimes: Attach the runtime to the  Client  instance without using the  test  helper macros. Create a new  Client  instance for every  async  test. To learn more about connecting to MongoDB, see the\n Connection Guide . To learn more about the available runtimes for the Rust driver, see\nthe guide on  Asynchronous and Synchronous APIs . Client() ClientOptions spawn()  in\nthe  tokio::task  module tokio::runtime  module",
            "code": [
                {
                    "lang": "rust",
                    "value": "// ... Create a client earlier in your code\n\nasync fn make_request(client: &Client) -> Result<(), Box<dyn Error>> {\n    // Use the client to perform operations\n    Ok(())\n}\n"
                },
                {
                    "lang": "rust",
                    "value": "let client = Client::with_uri_str(\"<connection string>\").await?;"
                },
                {
                    "lang": "rust",
                    "value": "let mut client_options = ClientOptions::parse_async(\"<connection string>\").await?;\nclient_options.max_pool_size = Some(20);\n\nlet client = Client::with_options(client_options)?;"
                },
                {
                    "lang": "rust",
                    "value": "let mut client_options = ClientOptions::parse_async(\"<connection string>\").await?;\nclient_options.max_connecting = Some(3);\nclient_options.min_pool_size = Some(1);\n\nlet client = Client::with_options(client_options)?;"
                },
                {
                    "lang": "rust",
                    "value": "let mut client_options = ClientOptions::parse_async(\"<connection string>\").await?;\nclient_options.max_idle_time = Some(Duration::new(90, 0));\n\nlet client = Client::with_options(client_options)?;"
                },
                {
                    "lang": "rust",
                    "value": "let client = Client::with_uri_str(\"<connection string>\").await?;\nlet data = doc! { \"title\": \"1984\", \"author\": \"George Orwell\" };\n\nfor i in 0..5 {\n    let client_ref = client.clone();\n    let data_ref = data.clone();\n\n    task::spawn(async move {\n        let collection = client_ref\n            .database(\"items\")\n            .collection::<Document>(&format!(\"coll{}\", i));\n\n        collection.insert_one(data_ref, None).await\n    });\n}\n"
                },
                {
                    "lang": "rust",
                    "value": "use tokio::runtime::Runtime;\nuse once_cell::sync::Lazy;\n\nstatic CLIENT_RUNTIME: Lazy<(Client, Runtime)> = Lazy::new(|| {\n    let rt = Runtime::new().unwrap();\n    let client = rt.block_on(async {\n        Client::with_uri_str(\"<connection string>\").await.unwrap()\n    });\n    (client, rt)\n});\n\n#[test]\nfn test_list_dbs() -> Result<(), Box<dyn Error>> {\n    let (client, rt) = &*CLIENT_RUNTIME;\n    rt.block_on(async {\n        client.list_database_names(None, None).await\n    })?;\n    Ok(())\n}\n"
                },
                {
                    "lang": "rust",
                    "value": "#[tokio::test]\nasync fn test_list_dbs() -> Result<(), Box<dyn Error>> {\n    let client = Client::with_uri_str(\"<connection string>\").await?;\n    client.list_database_names(None, None).await?;\n    Ok(())\n}\n"
                }
            ],
            "preview": "In this guide, you can learn how to optimize the performance of the\nRust driver. To connect to MongoDB, you must create a Client instance. Your Client\ninstance automatically handles most aspects of connection, such as\ndiscovering server topology, monitoring your connection, and maintaining\nan internal connection pool. This guide describes best practices for\nconfiguring and using your Client instance.",
            "tags": "code example, optimization, speed, memory",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/tracing-logging",
            "title": "Tracing & Logging",
            "headings": [
                "Overview",
                "Enable Tracing and Logging",
                "Implement Tracing",
                "Implement Logging",
                "Additional Information"
            ],
            "paragraphs": "In this guide, you can learn how to use the Rust driver to configure\n tracing  and  logging  for your application. Tracing and logging\nare two frameworks for observing your application. Logging allows you to\nview a discrete, event-based log of driver activities, while tracing\nprovides a continuous view. In the Rust driver, the functionalities of tracing and logging do not\ndiffer greatly. However, when you enable tracing, the driver emits messages in a\nmore structured format, which can make it more convenient for your application to\nconsume event messages programmatically. Tracers and loggers log messages at a severity, or verbosity, level that you\ncan specify. By enabling one of these components in your application,\nyou can receive information about your application's activities at\ndifferent levels of detail. To learn more about logging severity levels, see the Wikipedia entry on\nthe  Syslog standard for message logging . The driver implements the  tracing \ncrate to enable the driver to emit messages for driver events. To enable tracing, logging, or both, you must add the  tracing \ndependency and the  tracing-unstable  feature flag to your  mongodb \ndependency in your  Cargo.toml  file: The following table describes components that you can emit events\nagainst and their corresponding targets: To specify the logging component and severity level, you can set the\n RUST_LOG  environment variable when you compile and run your\napplication. Specify the logging component by setting the value of\n RUST_LOG  to one of the targets provided in the preceding table and\nincluding a severity level. The following code shows a command to execute a program that records\nconnection events at the  debug  level: The following sections describe how to consume events using either\n tracing  or  logging . Because the  tracing  crate does not have a 1.0 version\nrelease, you can consider the functionality to be unstable. Component Target Description Command mongodb::command Events describe commands sent to the database and whether they\nsucceed or fail. Server selection mongodb::server_selection Events describe the driver's process of selecting a server in a\nMongoDB deployment. Connection mongodb::connection Events describe the behavior of driver connection pools and the\nconnections they contain. To enable tracing, you must also add the  tracing-subscriber \ndependency to your  Cargo.toml  file. The following code shows a\nsample dependencies list that contains the driver dependencies and the\n tracing-subscriber  crate: Then, in your application, you must register a type implementing the\n tracing::Subscriber  trait to consume events with tracing. The\nfollowing code shows how to register a tracing subscriber that uses the\nspecifications of the  RUST_LOG  environment variable: If you run your application and trace against commands at the  debug \nlevel, the driver emits messages whenever you execute an operation. The\nfollowing code shows the command for this tracing specification: With  debug  level tracing specified, when you perform a write\noperation, the driver generates trace messages: To learn more about registering a subscriber, see the  tracing \n documentation . To enable logging, you must also add the  log  or  log-always  feature\nflag to the  tracing  dependency in your  Cargo.toml  file. You\nmust also add a dependency for a logging crate, such as  env_logger : Then, in your application, you must register a global logger to consume\nevents with logging. The following code shows how to register a logger\nthat uses the specifications of the  RUST_LOG  environment variable: If you run your application and log against connections at the  debug \nlevel, the driver emits messages whenever you open, use, and close a\nconnection. The following code shows the command for this logging\nspecification: With  debug  level tracing specified, when you open and use a connection,\nthe driver generates log messages: To learn more about the  log  and  log-always  flags, see the\n tracing   documentation . To learn more about the third-party logging crate  env_logger , see\nits  documentation . To see examples of other ways to configure the logger,\nvisit the  env_logger   GitHub repository . To learn more about setting client options, see the\nguide on  Connection Options . In addition to logging, you can enable monitoring in your\napplication. To learn more, see the  Monitoring  guides.",
            "code": [
                {
                    "lang": "none",
                    "value": "[dependencies]\ntracing = \"0.1.37\"\n\n[dependencies.mongodb]\nversion = \"2.7.1\"\nfeatures = [\"tracing-unstable\"]"
                },
                {
                    "lang": "bash",
                    "value": "$ RUST_LOG='mongodb::connection=debug' cargo run"
                },
                {
                    "lang": "none",
                    "value": "[dependencies]\ntracing = \"0.1.37\"\ntracing-subscriber = \"0.3.17\"\n\n[dependencies.mongodb]\nversion = \"2.7.1\"\nfeatures = [\"tracing-unstable\"]"
                },
                {
                    "lang": "bash",
                    "value": "$ RUST_LOG='mongodb::command=debug' cargo run"
                },
                {
                    "lang": "rust",
                    "value": "tracing_subscriber::fmt::init();"
                },
                {
                    "lang": "rust",
                    "value": "let my_coll = client.database(\"db\").collection(\"test_coll\");\nmy_coll.insert_one(doc! { \"x\" : 1 }, None).await?;"
                },
                {
                    "lang": "console",
                    "value": "2023-07-21T17:37:13.587794Z DEBUG mongodb::command: Command started topologyId=\"...\" command=\"{\\\"insert\\\":\\\"test_coll\\\", ...}\" databaseName=\"test\" commandName=\"insert\" requestId=12 driverConnectionId=1 serverConnectionId=133839 serverHost=\"...\" serverPort=27017\n2023-07-21T17:37:13.630401Z DEBUG mongodb::command: Command succeeded topologyId=\"...\" reply=\"{\\\"n\\\":1, ...}\" commandName=\"insert\" requestId=12 driverConnectionId=1 serverConnectionId=133839 serverHost=\"...\" serverPort=27017 durationMS=42"
                },
                {
                    "lang": "none",
                    "value": "[dependencies]\ntracing = { version = \"0.1.37\", features = [\"log\"] }\nenv_logger = \"0.10.0\"\n\n[dependencies.mongodb]\nversion = \"2.7.1\"\nfeatures = [\"tracing-unstable\"]"
                },
                {
                    "lang": "bash",
                    "value": "$ RUST_LOG='mongodb::connection=debug' cargo run"
                },
                {
                    "lang": "rust",
                    "value": "env_logger::init();"
                },
                {
                    "lang": "rust",
                    "value": "let my_coll = client.database(\"db\").collection(\"test_coll\");\nmy_coll.insert_one(doc! { \"x\" : 1 }, None).await?;"
                },
                {
                    "lang": "console",
                    "value": "[2023-07-21T18:13:00Z DEBUG mongodb::connection] Connection pool created topologyId=\"...\" serverHost=\"...\" serverPort=27017\n[2023-07-21T18:13:00Z DEBUG mongodb::connection] Connection pool created topologyId=\"...\" serverHost=\"...\" serverPort=27017\n[2023-07-21T18:13:00Z DEBUG mongodb::connection] Connection pool created topologyId=\"...\" serverHost=\"...\" serverPort=27017\n[2023-07-21T18:13:00Z DEBUG mongodb::connection] Connection pool ready topologyId=\"...\" serverHost=\"...\" serverPort=27017\n[2023-07-21T18:13:00Z DEBUG mongodb::connection] Connection checkout started topologyId=\"...\" serverHost=\"...\" serverPort=27017\n[2023-07-21T18:13:00Z DEBUG mongodb::connection] Connection created topologyId=\"...\" serverHost=\"...\" serverPort=27017 driverConnectionId=1\n..."
                }
            ],
            "preview": "In this guide, you can learn how to use the Rust driver to configure\ntracing and logging for your application. Tracing and logging\nare two frameworks for observing your application. Logging allows you to\nview a discrete, event-based log of driver activities, while tracing\nprovides a continuous view.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/authentication",
            "title": "Authentication Mechanisms",
            "headings": [
                "Overview",
                "SCRAM-Based Mechanisms",
                "SCRAM-SHA-256",
                "SCRAM-SHA-1",
                "MONGODB-AWS Mechanism",
                "MONGODB-X509 Mechanism",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to use the authentication\nmechanisms available in the MongoDB Community Edition. When you connect\nto MongoDB, you can use an authentication mechanism to establish trust\nbetween the driver and the server. This guide describes the following authentication mechanisms: To select a specific authentication mechanism, you can specify the\nmechanism, your credentials, and other necessary information\nin the options of your connection string or in a  Credential  struct. In this guide, the examples demonstrate how to configure\nauthentication in a  Credential  struct. To learn more about the connection string options for authentication,\nsee the  Authentication Options  section\nof the Connection String URI Format guide in the Server manual. To learn how to authenticate to MongoDB by using a Lightweight\nDirectory Access Protocol (LDAP) server, see the guide on\n Enterprise Authentication Mechanisms . To learn more about connecting to a MongoDB deployment, see the\n Connection Guide . SCRAM-Based Mechanisms MONGODB-AWS Mechanism MONGODB-X509 Mechanism Salted challenge response authentication mechanism (SCRAM) refers to a\ngroup of authentication mechanisms that use a username and\npassword to authenticate to a server. MongoDB supports the following SCRAM-based authentication mechanisms: SCRAM-SHA-256 : an authentication mechanism that\nuses your username and password, encrypted with the  SHA-256 \nalgorithm SCRAM-SHA-1 : an authentication mechanism that\nuses your username and password, encrypted with the  SHA-1 \nalgorithm If you do not specify an authentication mechanism, the server\nattempts to validate credentials by using the default authentication\nmechanism, a SCRAM-based mechanism that varies depending on the\nversion of the server that you are connecting to. The  SCRAM-SHA-256  mechanism is the default authentication\nmechanism for MongoDB Server versions 4.0 and later. To use the default authentication mechanism, omit only the\n mechanism  field when you instantiate your  Credential  struct.\nThis example uses the following placeholders: username : Your username password : Your password db : The authentication database associated with the user To specify the  SCRAM-SHA-256  authentication mechanism, set the\n mechanism  field of your  Credential  struct to\n AuthMechanism::ScramSha256 . This example specifies the\nauthentication mechanism by using the following placeholders: username : Your username password : Your password db : The authentication database associated with the user To specify the  SCRAM-SHA-1  authentication mechanism, set the\n mechanism  field of your  Credential  struct to\n AuthMechanism::ScramSha1 . This example specifies the\nauthentication mechanism by using the following placeholders: username : Your username password : Your password db : The authentication database associated with the user The  MONGODB-AWS  authentication mechanism uses your Amazon Web Services\nIdentity and Access Management (AWS IAM) credentials to authenticate your\nuser. To use this authentication mechanism, you must add the  aws-auth \nfeature flag to your  mongodb  dependency in your project's\n Cargo.toml  file. The following shows an example of what your\n mongodb  dependency feature list must include to enable the\n MONGODB-AWS  authentication mechanism: The driver obtains the credentials only from the first source in which\nthey are found. The driver checks for your credentials from the following\nsources in the following order: For example, if you specify your AWS credentials in your connection string, the\ndriver uses those credentials and ignores any that you might have\nspecified in environment variables. Select from the  Credential Struct ,  Environment\nVariables , and  Web Identity Token File  tabs below for\ncode samples that demonstrate how to set your AWS IAM credentials in\nthe corresponding ways. To use the  MONGODB-AWS  authentication mechanism in the\nRust driver, your application must meet the following\nrequirements: You are connected to MongoDB Server version 4.4 or later. You are using the  tokio  asynchronous runtime. Credential  struct or connection string. Environment variables. Web identity token file. AWS ECS endpoint specified in the  AWS_CONTAINER_CREDENTIALS_RELATIVE_URI \nenvironment variable. AWS EC2 endpoint. For more information, see  IAM Roles for Tasks \nin the AWS documentation. To specify the  MONGODB-AWS  authentication mechanism, set the\n mechanism  field of your  Credential  struct to\n AuthMechanism::MongoDbAws . This example specifies the\nauthentication mechanism by using the following placeholders: If you are using temporary credentials, create a document that\ncontains the value of your AWS session token, and then set the\n mechanism_properties  field of the  Credential  struct to\nthis document. If you are not using temporary credentials, omit\nline 9 of the following example: access key ID : Your AWS access key ID secret access key : Your AWS secret access key db : The authentication database associated with the user You can obtain temporary AWS IAM credentials from a Security\nToken Service (STS) Assume Role request. Learn more about\nthis process in the  AssumeRole AWS documentation . To store your AWS credentials in environment variables, run the\nfollowing commands in your shell: If you are not using an AWS session token, omit the line\nthat sets the  AWS_SESSION_TOKEN  environment variable. Set the  mechanism  option in your\n Credential  struct to  AuthMechanism::MongoDbAws . The driver\nreads your AWS IAM credentials from your environment variables.\nThe following code shows how to define a  Credential  struct\nwith AWS authentication specified and connect to MongoDB: You can use the OpenID Connect (OIDC) token obtained from a web\nidentity provider to authenticate to Amazon Elastic Kubernetes\nService (EKS) or other services. To use an OIDC token, create a\nfile that contains your token, then define an environment variable\nwhose value is the absolute path to the token file as shown in the\nfollowing shell command: Set the  mechanism  option in your\n Credential  struct to  AuthMechanism::MongoDbAws . The driver\nreads your AWS IAM credentials from the token file.\nThe following code shows how to define a  Credential  struct\nwith AWS authentication specified and connect to MongoDB: The  MONGODB-X509  authentication mechanism uses Transport Level Security (TLS)\nwith X.509 certificates to authenticate your user, which is identified\nby the relative distinguished names (RDNs) of your client certificate. When you specify this authentication mechanism, the server authenticates\nthe connection by reading the following files: To specify the  MONGODB-X509  authentication mechanism, set the\n mechanism  field of your  Credential  struct to\n AuthMechanism::MongoDbX509 . This example specifies the\nauthentication mechanism by using the following placeholders: The following code shows how to reference your certificates in your\nconnection string, specify the  MONGODB-X509  authentication mechanism, and\nconnect to MongoDB: A certificate authority (CA) file, which contains one or more\ncertificate authorities to trust when making a TLS connection A certificate key file, which references the client certificate private key path to CA certificate : The filepath for your CA file path to private client key : The filepath for your certificate key file db : The authentication database associated with the user To learn more about authenticating to MongoDB, see\n Authentication  in the Server manual. To learn more about managing users of your MongoDB deployment, see\n Users  in the Server manual. To learn more about the methods and types mentioned in this\nguide, see the following API documentation: Credential ClientOptions Client Client::with_options() ClientOptions::parse()",
            "code": [
                {
                    "lang": "rust",
                    "value": "let uri = \"<connection string>\";\nlet mut client_options = ClientOptions::parse_async(uri).await?;\n\nlet default_cred = Credential::builder()\n    .username(\"<username>\".to_string())\n    .password(\"<password>\".to_string())\n    .source(\"<db>\".to_string())\n    .build();\n\nclient_options.credential = Some(default_cred);\nlet client = Client::with_options(client_options)?;"
                },
                {
                    "lang": "rust",
                    "value": "let uri = \"<connection string>\";\nlet mut client_options = ClientOptions::parse_async(uri).await?;\n\nlet scram_sha_256_cred = Credential::builder()\n    .username(\"<username>\".to_string())\n    .password(\"<password>\".to_string())\n    .mechanism(AuthMechanism::ScramSha256)\n    .source(\"<db>\".to_string())\n    .build();\n\nclient_options.credential = Some(scram_sha_256_cred);\nlet client = Client::with_options(client_options)?;"
                },
                {
                    "lang": "rust",
                    "value": "let uri = \"<connection string>\";\nlet mut client_options = ClientOptions::parse_async(uri).await?;\n\nlet scram_sha_1_cred = Credential::builder()\n    .username(\"<username>\".to_string())\n    .password(\"<password>\".to_string())\n    .mechanism(AuthMechanism::ScramSha1)\n    .source(\"<db>\".to_string())\n    .build();\n\nclient_options.credential = Some(scram_sha_1_cred);\nlet client = Client::with_options(client_options)?;"
                },
                {
                    "lang": "none",
                    "value": "[dependencies.mongodb]\nversion = \"2.7.1\"\nfeatures = [ \"aws-auth\", ... ]"
                },
                {
                    "lang": "rust",
                    "value": "let uri = \"<connection string>\";\nlet mut client_options = ClientOptions::parse_async(uri).await?;\n\nlet aws_cred = Credential::builder()\n    .username(\"<access key ID>\".to_string())\n    .password(\"<secret access key>\".to_string())\n    .source(\"<db>\".to_string())\n    .mechanism(AuthMechanism::MongoDbAws)\n    .mechanism_properties(doc!(\"AWS_SESSION_TOKEN\": \"<session token>\"))\n    .build();\n\nclient_options.credential = Some(aws_cred);\nlet client = Client::with_options(client_options)?;"
                },
                {
                    "lang": "bash",
                    "value": "export AWS_ACCESS_KEY_ID=<access key ID>\nexport AWS_SECRET_ACCESS_KEY=<secret access key>\nexport AWS_SESSION_TOKEN=<session token>"
                },
                {
                    "lang": "rust",
                    "value": "let uri = \"<connection string>\";\nlet mut client_options = ClientOptions::parse_async(uri).await?;\n\nlet aws_cred = Credential::builder().mechanism(AuthMechanism::MongoDbAws).build();\n\nclient_options.credential = Some(aws_cred);\nlet client = Client::with_options(client_options)?;"
                },
                {
                    "lang": "bash",
                    "value": "export AWS_WEB_IDENTITY_TOKEN_FILE=<absolute path to OIDC token file>"
                },
                {
                    "lang": "rust",
                    "value": "let uri = \"<connection string>\";\nlet mut client_options = ClientOptions::parse_async(uri).await?;\n\nlet aws_cred = Credential::builder().mechanism(AuthMechanism::MongoDbAws).build();\n\nclient_options.credential = Some(aws_cred);\nlet client = Client::with_options(client_options)?;"
                },
                {
                    "lang": "rust",
                    "value": "let uri = format!(\n    \"mongodb://<hostname>:<port>/?tlsCAFile={tlsCAFile}&tlsCertificateKeyFile={tlsCertificateKeyFile}\",\n    tlsCAFile = \"<path to CA certificate>\",\n    tlsCertificateKeyFile = \"<path to private client key>\"\n);\nlet mut client_options = ClientOptions::parse_async(uri).await?;\nlet x509_cred = Credential::builder().mechanism(AuthMechanism::MongoDbAws).build();\n\nclient_options.credential = Some(x509_cred);\nlet client = Client::with_options(client_options)?;"
                }
            ],
            "preview": "In this guide, you can learn how to use the authentication\nmechanisms available in the MongoDB Community Edition. When you connect\nto MongoDB, you can use an authentication mechanism to establish trust\nbetween the driver and the server.",
            "tags": "validate credentials, protocols, code example",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/runtimes",
            "title": "Asynchronous and Synchronous APIs",
            "headings": [
                "Overview",
                "Configure the Asynchronous Runtime",
                "Tokio Runtime Example",
                "Configure the Synchronous API",
                "Synchronous Code Example",
                "Use Both Asynchronous and Synchronous APIs",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn about the Rust driver's  asynchronous \nand  synchronous  APIs.\nThis guide explains how to enable the available APIs and structure your code to use each. The Rust driver supports  tokio  and  async-std , two popular asynchronous runtime crates.\nBy default, the driver uses the  tokio  asynchronous runtime, but you can select a specific runtime\nby adding feature flags to the  mongodb  dependency in your  Cargo.toml  file. The driver also includes a synchronous API for use cases that require blocking, or when parallelism is not necessary.\nYou can select the synchronous API by adding feature flags to the  mongodb  dependency in your  Cargo.toml  file. The driver uses the  tokio  runtime by default.\nYou can explicitly choose a runtime by adding the  \"tokio-runtime\"  or  \"async-std-runtime\" \nfeature flags to the  mongodb  dependency. Select from the following tabs to see how to add feature flags for each corresponding crate: For more information on installing the driver and adding feature flags,\nsee the  Download and Install  step of the Quick Start. The following code uses the  task  module from the  tokio  crate\nto create separate, concurrent tasks for multiple data operations: The driver also provides a blocking, synchronous API.\nTo use the synchronous API, add the either the  \"sync\"  or  \"tokio-sync\"  feature flag\nto the  mongodb  dependency. Select from the following tabs to see how to add feature flags for each corresponding crate: When using the synchronous API, use types from the  mongodb::sync  module to perform operations.\nThe following code uses the  sync  module to insert data into a collection using the synchronous API.\nWhen the  insert_one  method runs inside the  for  loop, the driver waits for each request to complete before continuing. You can use both asynchronous and synchronous APIs in the same application.\nFor example, to enable both  tokio  runtimes, you can add the  tokio  dependency to your dependencies list, and add the\n \"tokio-sync\"  flag to the  mongodb  dependency: For more information about the concepts in this guide, see the following pages: Performance Considerations Asynchronous Programming in Rust To learn more about the methods and types mentioned in this\nguide, see the following API documentation: Client sync",
            "code": [
                {
                    "lang": "toml",
                    "value": "[dependencies.mongodb]\nversion = \"2.7.1\"\nfeatures = [\"tokio-runtime\"]"
                },
                {
                    "lang": "toml",
                    "value": "[dependencies.mongodb]\nversion = \"2.7.1\"\ndefault-features = false\nfeatures = [\"async-std\"]"
                },
                {
                    "lang": "rust",
                    "value": "let client = Client::with_uri_str(\"<connection string>\").await?;\nlet some_data = doc! { \"title\": \"1984\", \"author\": \"George Orwell\" };\n\nfor i in 0..5 {\n    let client_ref = client.clone();\n    let somedata_ref = some_data.clone();\n\n    task::spawn(async move {\n        let collection = client_ref\n            .database(\"items\")\n            .collection::<Document>(&format!(\"coll{}\", i));\n\n        collection.insert_one(somedata_ref, None).await\n    });\n}\n"
                },
                {
                    "lang": "toml",
                    "value": "[dependencies.mongodb]\nversion = \"2.7.1\"\ndefault-features = false\nfeatures = [\"sync\"]"
                },
                {
                    "lang": "toml",
                    "value": "[dependencies.mongodb]\nversion = \"2.7.1\"\ndefault-features = false\nfeatures = [\"tokio-sync\"]"
                },
                {
                    "lang": "rust",
                    "value": "use mongodb::sync::Client;\n\nfn main() {\n    let client = Client::with_uri_str(\"<connection string>\")?;\n    let some_data = doc! { \"title\": \"1984\", \"author\": \"George Orwell\" };\n\n    for i in 0..5 {\n        let client_ref = client.clone();\n        let somedata_ref = some_data.clone();\n\n        let collection = client_ref\n            .database(\"items\")\n            .collection::<Document>(&format!(\"coll{}\", i));\n\n        collection.insert_one(somedata_ref, None);\n    }\n}\n"
                },
                {
                    "lang": "toml",
                    "value": "[dependencies]\nfutures = \"0.3.28\"\ntokio = {version = \"1.32.0\", features = [\"full\"]}\n\n[dependencies.mongodb]\nversion = \"2.7.1\"\nfeatures = [\"tokio-sync\"]"
                }
            ],
            "preview": "In this guide, you can learn about the Rust driver's asynchronous\nand synchronous APIs.\nThis guide explains how to enable the available APIs and structure your code to use each.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/transactions",
            "title": "Transactions",
            "headings": [
                "Overview",
                "Methods",
                "Example",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to use the Rust driver to perform\n transactions . Transactions allow you to perform a series of operations\nthat change data only if the entire transaction is committed.\nIf any operation in the transaction does not succeed, the driver stops the\ntransaction and discards all data changes before they ever become\nvisible. This feature is called  atomicity . In MongoDB, transactions run within logical sessions. A\nsession is a grouping of related read or write operations that you\nwant to run sequentially. Sessions enable causal consistency for a group\nof operations and allow you to run operations in an  ACID-compliant \ntransaction, which is a transaction that meets an expectation of\natomicity, consistency, isolation, and durability. MongoDB guarantees\nthat the data involved in your transaction operations remains\nconsistent, even if the operations encounter unexpected errors. When using the Rust driver, you can create a new session from a\n Client  instance as a  ClientSession  type. You can improve your\napp's performance by reusing your client for multiple sessions and\ntransactions instead of instantiating a new client each time. Use a  ClientSession  only in operations running on the\n Client  that created it. Using a  ClientSession  with a\ndifferent  Client  results in operation errors. Create a  ClientSession  by using the  start_session()  method on your\n Client  instance. You can then modify the session state using the\nmethods provided by the  ClientSession  type. The following table\ndescribes these methods: Method Description start_transaction() commit_transaction() abort_transaction() with_transaction() To run MongoDB tasks within transactions, you must use the\n _with_session()  suffixed methods. These methods accept a\n ClientSession  instance as a parameter. For example, to delete a document, you can generally use the\n delete_one()  method. However, to delete a document within\na transaction, you must use the  delete_one_with_session() \nmethod and pass the session as a parameter. The following code defines the  insert_media()  callback function that\ninserts data into the  books  and  films  collections: The following code completes the following actions to perform the\ntransaction: If you require more control over your transactions, see the  ClientSession API\ndocumentation \nto find an example that shows how to manually create and commit a transaction. Creates a session from the client by using the  start_session()  method. Uses the  with_transaction()  method to start a transaction and run\nthe  insert_media()  callback function within the transaction. To learn more about the concepts mentioned in this guide, see the\nfollowing pages in the Server manual: To learn more about ACID compliance, see the  What are ACID\nProperties in Database Management Systems? \narticle on the MongoDB website. To learn more about insert operations, see the\n Insert Documents  guide. Transactions Server Sessions Read Isolation, Consistency, and Recency To learn more about the methods and types mentioned in this\nguide, see the following API documentation: ClientSession start_session() start_transaction() commit_transaction() abort_transaction() with_transaction() TransactionOptions",
            "code": [
                {
                    "lang": "rust",
                    "value": "async fn insert_media(session: &mut ClientSession) -> Result<(), Error> {\n    let books_coll = session\n        .client()\n        .database(\"db\")\n        .collection::<Document>(\"books\");\n\n    let films_coll = session\n        .client()\n        .database(\"db\")\n        .collection::<Document>(\"films\");\n\n    books_coll.insert_one_with_session(\n        doc! { \n            \"name\": \"Sula\", \n            \"author\": \"Toni Morrison\"\n        },\n        None,\n        session\n    ).await?;\n\n    films_coll.insert_one_with_session(\n        doc! { \"name\": \"Nostalgia\", \"year\": 1983 },\n        None,\n        session\n    ).await?;\n\n    Ok(())\n}"
                },
                {
                    "lang": "rust",
                    "value": "let mut session = client.start_session(None).await?;\nsession\n    .with_transaction((), |session, _| insert_media(session).boxed(), None)\n    .await?;\nprintln!(\"Successfully committed transaction!\");"
                },
                {
                    "lang": "console",
                    "value": "Successfully committed transaction!"
                }
            ],
            "preview": "In this guide, you can learn how to use the Rust driver to perform\ntransactions. Transactions allow you to perform a series of operations\nthat change data only if the entire transaction is committed.\nIf any operation in the transaction does not succeed, the driver stops the\ntransaction and discards all data changes before they ever become\nvisible. This feature is called atomicity.",
            "tags": "code example, ACID compliance, multi-document",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/connections",
            "title": "Connections",
            "headings": [
                "Overview"
            ],
            "paragraphs": "Learn how to use the Rust driver to configure your application's\nconnection to a MongoDB deployment in the following sections: To learn how to authenticate to MongoDB, see the following guides: Connection Guide Connection Options Enable Network Compression Enable and Configure TLS Authentication Mechanisms Enterprise Authentication Mechanisms",
            "code": [],
            "preview": "Learn how to use the Rust driver to configure your application's\nconnection to a MongoDB deployment in the following sections:",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/time-series",
            "title": "Time Series Collections",
            "headings": [
                "Overview",
                "Create a Time Series Collection",
                "Example",
                "Query a Time Series Collection",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to use the Rust driver to create\nand interact with  time series collections . Time series collections\nefficiently store chronological sequences of measurements over a period\nof time. Each document in a time series collection contains the\nfollowing pieces of information: The following table describes some sample situations for which data could be\nstored in a time series collection. Each row describes the situation,\nthe measured quantity, and the metadata in each document: This guide includes the following sections: Quantity that is being measured over time Metadata that describes the measurement Timestamp for the measurement Situation Measured Quantity Metadata Recording monthly sales by industry Revenue in USD Company, country Tracking weather changes Precipitation level Location, sensor type Recording fluctuations in housing prices Monthly rent price Location, currency Create a Time Series Collection  describes\nthe syntax for creating a time series collection and provides example code Query a Time Series Collection  describes how to\nperform operations on time series collections Additional Information \nprovides links to resources and API documentation for types\nand methods mentioned in this guide To create a time series collection, perform the following actions: To create and interact with time series collections, you must be\nconnected to a deployment running MongoDB 5.0 or later. Create a  TimeseriesOptions  instance that specifies properties of\nyour time series collection. Create a  CreateCollectionOptions  instance and set the value of\nthe  timeseries  field to your  TimeseriesOptions  instance. Pass the  CreateCollectionOptions  instance to the\n create_collection()  method. You must also pass the collection\nname as a parameter. This example creates the  sept2023  time series collection in the\n precipitation  database with the following configuration: To verify that you successfully created the time series collection, run\nthe  list_collections()  method on the database and print the results: time_field  is set to  \"precipitation_mm\" meta_field  is set to  \"location\" granularity  is set to minutes You can use the same syntax and conventions to query a time series\ncollection as you use when performing read or aggregation operations on\nother collections. To find more information about these operations, see\nthe  Additional Information  section. To learn more about the concepts mentioned in this guide, see the\nfollowing Server manual entries: To learn more about creating collections, see the guide on\n Databases and Collections . To learn more about performing read operations, see the guides in the\n Read Operations  category. Time Series Create and Query a Time Series Collection Set Granularity for Time Series Data To learn more about the methods and types mentioned in this\nguide, see the following API documentation: TimeseriesOptions CreateCollectionOptions create_collection() TimeseriesGranularity list_collections() CollectionSpecification",
            "code": [
                {
                    "lang": "rust",
                    "value": "let db = client.database(\"precipitation\");\n\nlet ts_opts = TimeseriesOptions::builder()\n    .time_field(\"precipitation_mm\".to_string())\n    .meta_field(Some(\"location\".to_string()))\n    .granularity(Some(TimeseriesGranularity::Minutes))\n    .build();\n\nlet coll_opts = CreateCollectionOptions::builder()\n    .timeseries(ts_opts)\n    .build();\n\ndb.create_collection(\"sept2023\", coll_opts).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let mut coll_list = db.list_collections(None, None).await?;\nwhile let Some(c) = coll_list.try_next().await? {\n    println!(\"{:#?}\", c);\n}"
                },
                {
                    "lang": "console",
                    "value": "CollectionSpecification {\n    name: \"sept2023\",\n    collection_type: Timeseries,\n    options: CreateCollectionOptions {\n        ...\n        timeseries: Some(\n            TimeseriesOptions {\n                time_field: \"precipitation_mm\",\n                meta_field: Some(\n                    \"location\",\n                ),\n                granularity: Some(\n                    Minutes,\n                ),\n            },\n        ),\n        ...\n    },\n    ...\n}"
                }
            ],
            "preview": "In this guide, you can learn how to use the Rust driver to create\nand interact with time series collections. Time series collections\nefficiently store chronological sequences of measurements over a period\nof time. Each document in a time series collection contains the\nfollowing pieces of information:",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/collations",
            "title": "Collations",
            "headings": [
                "Overview",
                "MongoDB Collations",
                "Specify a Collation",
                "Example",
                "Set a Collation on a Collection",
                "Create Collection with a Collation Example",
                "Collation Ordering Demonstration",
                "Set a Collation on an Index",
                "Example",
                "Set a Collation on an Operation",
                "Example",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to use  collations  to order your find or\naggregation operation results by string values. A collation is a set of character\nordering conventions that correspond to a specific language and locale. This guide includes the following sections: MongoDB Collations  describes how MongoDB sorts string values according\nto the default collation and custom collations Specify a Collation  describes how to create a  Collation  struct instance Set a Collation on a Collection  describes how to set the collation for a\nnew collection Set a Collation on an Index  describes how to set the collation for an index Set a Collation on an Operation  describes how to apply a collation to certain CRUD operations Additional Information  provides links to resources and API documentation\nfor types and methods mentioned in this guide MongoDB sorts strings using  binary collation  by default. This collation method\nuses the ASCII standard character values to compare and order strings. Certain\nlanguages and locales have specific character ordering conventions that differ from\nthe ASCII standard. For example, in Canadian French, the right-most accented character determines\nthe ordering for strings when the other characters are the same. Consider the\nfollowing Canadian French words: When using the default binary collation, MongoDB sorts the words in the following order: In this sort order, \"cot\u00e9\" is placed before \"c\u00f4te\" because the ASCII standard positions the\ncharacter \"o\" before the character \"\u00f4\". When using the Canadian French collation, MongoDB sorts the words in the following order: In this sort order, \"cot\u00e9\" is placed after \"c\u00f4te\" because Canadian French collation rules position\nthe character \"e\" before the character \"\u00e9\". To learn more about the ASCII standard, see the  ASCII  Wikipedia page. cote cot\u00e9 c\u00f4te c\u00f4t\u00e9 You can define a collation by specifying a collation locale and other options in a  Collation \nstruct instance. To begin building a  Collation  instance, call the  Collation::builder() \nmethod. The following table describes the builder methods that you can use to set fields of a  Collation \ninstance. You must use the  locale()  method to build a valid  Collation  struct, but all other\nbuilder methods are optional: The Rust driver implements the Builder design pattern for the\ncreation of many different types, including  Collation . You can\nuse the  builder()  method to construct an instance of each type\nby chaining option builder methods. Method Possible Values Description strength() CollationStrength::Primary ,\n CollationStrength::Secondary ,\n CollationStrength::Tertiary ,\n CollationStrength::Quaternary ,\n CollationStrength::Identical Specifies the level of comparison to perform case_first() CollationCaseFirst::Upper ,\n CollationCaseFirst::Lower ,\n CollationCaseFirst::Off Specifies the sort order of case differences during tertiary level comparisons alternate() CollationAlternate::NonIgnorable ,\n CollationAlternate::Shifted Specifies whether the driver considers whitespace and punctuation as base characters\nduring string comparison normalization() true ,  false Specifies whether the driver performs text normalization for string values The following example specifies a  Collation  instance and sets the collation locale to  \"en_US\" : When you create a new collection, you can define the collation for future operations\ncalled on that collection. Set the collation by using the  collation()  function\nwhen creating a  CreateCollectionOptions  instance. Then, call the  create_collection() \nmethod with your options instance as a parameter. This example specifies a collation according to the  \"fr\" , or French, locale conventions\nand applies the collation to a new collection called  books . The  strength  field is set to\n CollationStrength::Primary  to ignore differences in diacritics. If you run an operation that supports collations on the  books  collection, the operation\nuses the collation specified in the preceding  Create Collection with a Collation Example . Assume the  books  collection contains the following documents: The following example uses the  find()  method to return all documents in which the value\nof the  name  field alphabetically precedes  \"Infinite Jest\" : If you don't specify a collation for the  books  collection, the  find()  method follows\ndefault binary collation rules to determine the  name  values that precede  \"Infinite Jest\" .\nThese rules place words beginning with \"\u00c7\" after those beginning with \"I\". So, when the\npreceding find operation follows binary collation rules, the document in which the  name  value is\n \"\u00c7a\"  does not match the filter criteria. To learn how to insert documents into a collection, see the  Insert Documents \nguide. When you create a new index on a collection, you can define the collation for operations\nthat are covered by the index. To run an operation that uses the index and its collation, your\noperation and index must specify the same collation. Set the index collation by using the  collation()  function to build an  IndexOptions  instance.\nThen, pass your  IndexOptions  as an argument to an  IndexModel  builder function, and pass your\n IndexModel  as an argument to the  create_index()  method. To learn more about indexes and covered queries, see the  Indexes  guide. The following example uses the  create_index()  method to create an ascending index on the\n name  field and specifies a new collation corresponding to the  \"en_US\"  locale: Operations that read, update, and delete documents from a collection can use collations.\nApplying a collation to an operation overrides any collation previously defined for a\ncollection or index. If you apply a collation to an operation that differs from an index's collation, you\ncannot use that index. As a result, the operation may not perform as efficiently as one that\nis covered by an index. For more information on the disadvantages of sorting operations\nnot covered by an index, see  Using Indexes to Sort Query Results \nin the Server manual. This example performs the following actions: If you run the preceding find operation without setting the  numeric_ordering  option to  true ,\nthe driver compares  length  values as strings and orders the string value  \"1000\"  before the\nvalues  \"474\"  and  \"918\" . In this case, the preceding find operation returns all documents in\nthe  books  collection. Sets the  numeric_ordering  collation option to  true , which ensures that values are sorted in\nnumerical order rather than alphabetical order Specifies a collation in a  FindOptions  instance, which overrides the collection's collation Uses the  find()  method to return documents in which the value of the  length  field is greater\nthan  \"1000\" To learn more about the  find()  method, see the  Retrieve Data  guide. To learn more about collations, see the following Server manual pages: Collation Collation Locales and Default Parameters To learn more about any of the methods or types mentioned in this guide, see the\nfollowing API documentation: Collation create_collection() CreateCollectionOptions create_index() IndexOptions IndexModel find() FindOptions",
            "code": [
                {
                    "lang": "none",
                    "value": "cote\ncot\u00e9\nc\u00f4te\nc\u00f4t\u00e9"
                },
                {
                    "lang": "none",
                    "value": "cote\nc\u00f4te\ncot\u00e9\nc\u00f4t\u00e9"
                },
                {
                    "lang": "rust",
                    "value": "let collation = Collation::builder()\n    .locale(\"en_US\")\n    .build();"
                },
                {
                    "lang": "rust",
                    "value": "let collation = Collation::builder()\n    .locale(\"fr\")\n    .strength(CollationStrength::Primary)\n    .build();\n\nlet opts = CreateCollectionOptions::builder()\n    .collation(collation)\n    .build();\n\nlet result = my_db.create_collection(\"books\", opts).await?;"
                },
                {
                    "lang": "json",
                    "value": "{ \"name\" : \"Emma\", \"length\" : \"474\" }\n{ \"name\" : \"Les Mis\u00e9rables\", \"length\": \"1462\" }\n{ \"name\" : \"Infinite Jest\", \"length\" : \"1104\" }\n{ \"name\" : \"Cryptonomicon\", \"length\" : \"918\" }\n{ \"name\" : \"\u00c7a\", \"length\" : \"1138\" }"
                },
                {
                    "lang": "rust",
                    "value": "let query = doc! { \"name\": doc! { \"$lt\": \"Infinite Jest\" } };\nlet mut cursor = my_coll.find(query, None).await?;\n\nwhile let Some(doc) = cursor.try_next().await? {\n   println!(\"{}\", doc);\n}"
                },
                {
                    "lang": "none",
                    "value": "{ \"name\": \"Emma\", \"length\": 474 }\n{ \"name\": \"Cryptonomicon\", \"length\": 918 }\n{ \"name\" : \"\u00c7a\", \"length\" : \"1138\" }"
                },
                {
                    "lang": "rust",
                    "value": "let collation = Collation::builder()\n    .locale(\"en_US\")\n    .build();\n\nlet index_opts = IndexOptions::builder()\n    .collation(collation)\n    .build();\n\nlet index = IndexModel::builder()\n    .keys(doc! { \"name\": 1 })\n    .options(index_opts)\n    .build();\n\nlet result = my_coll.create_index(index, None).await?;\nprintln!(\"Created index: {}\", result.index_name);"
                },
                {
                    "lang": "none",
                    "value": " Created index: name_1"
                },
                {
                    "lang": "rust",
                    "value": "let collation = Collation::builder()\n    .locale(\"en_US\")\n    .numeric_ordering(true)\n    .build();\n\nlet opts = FindOptions::builder()\n    .collation(collation)\n    .build();\n\nlet filter = doc! { \"length\": doc! { \"$gt\": \"1000\" } };\nlet mut cursor = my_coll.find(filter, opts).await?;\n\nwhile let Some(result) = cursor.try_next().await? {\n    println!(\"{}\", result);\n};"
                },
                {
                    "lang": "none",
                    "value": "{ \"name\" : \"Les Mis\u00e9rables\", \"length\": \"1462\" }\n{ \"name\" : \"Infinite Jest\", \"length\" : \"1104\" }\n{ \"name\" : \"\u00c7a\", \"length\" : \"1138\" }"
                }
            ],
            "preview": "In this guide, you can learn how to use collations to order your find or\naggregation operation results by string values. A collation is a set of character\nordering conventions that correspond to a specific language and locale.",
            "tags": "string ordering, code example, french language",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/indexes",
            "title": "Indexes",
            "headings": [
                "Overview",
                "Query Coverage and Performance",
                "Operational Considerations",
                "Index Types",
                "Single Field Indexes",
                "Example",
                "Compound Indexes",
                "Example",
                "Multikey Indexes (Array Field Indexes)",
                "Example",
                "Clustered Indexes",
                "Example",
                "Text Indexes",
                "Example",
                "Geospatial Indexes",
                "Example",
                "Unique Indexes",
                "Example",
                "Remove an Index",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to use the Rust driver to create\nand manage  indexes . Indexes are special data structures that improve\nquery performance in MongoDB. If you perform a query on a collection without any indexes, MongoDB\nscans every document to find matches. These collection scans are slow\nand can negatively affect the performance of your application. When you\ncreate an index that covers your query, MongoDB limits the number of\ndocuments it inspects to find matches, which results in improved\nperformance. You can use indexes in update operations, delete operations, and\nsome aggregation pipeline stages. To learn more about using indexes\nin aggregations, see  Improve Performance with Indexes and Document Filters \nin the Server manual. The following table describes the elements that you can include in a\nMongoDB query: When your query elements reference fields that are all included in the\nsame index, MongoDB can return results directly from the index.\nThese queries are called  covered queries . To learn how to ensure that your index covers your query, see\n Covered Query  in\nthe Server manual. Element Description Query Options Projection Sort Your sort criteria must match or invert the order of the index. Suppose a collection has the following index on the  name  field\nin ascending order (A-Z) and the  age  field in descending order (9-0): MongoDB uses this index when you sort documents in either\nof the following configurations: If you specify the same sort order for both fields, MongoDB does not\nuse the index and instead performs an in-memory sort. name  ascending,  age  descending name  descending,  age  ascending To improve your query performance, create indexes on fields that appear\noften in your queries. However, it is a good practice to track index\nmemory and disk usage for capacity planning, because each index consumes\ndisk space and memory. Additionally, if a write operation updates an\nindexed field, MongoDB also must update the relevant index. MongoDB supports dynamic schemas, so your application can query\nagainst fields with unknown or variable names. If you are connected to\nMongoDB Server version 4.2 or later, you can create wildcard indexes to\nsupport these queries. To learn more about this index type, see\n Wildcard Indexes \nin the Server manual. MongoDB supports multiple index types to support your queries. The\nfollowing sections describe common index types and show how to create\neach index type in a collection. You can use the  create_index()  and\n create_indexes()  methods to create indexes in a collection. The\n create_index()  method takes an  IndexModel  struct parameter that\nyou can construct by using the type's  builder()  method. To view a full list of index types, see\n Index Types  in the Server manual. The examples in this guide use collections from the Atlas sample\ndata. To learn how to import this data, see the  Load Sample\nData  tutorial in the Atlas documentation. A single field index holds a reference to a document field. This index improves the performance of single field queries and sorts.\nIt also supports TTL indexes that automatically remove documents from a\ncollection after a certain amount of time. To learn more about TTL\nindexes, see  TTL indexes  in the Server manual. When you create a new collection, MongoDB automatically creates a\n unique , single field index on the  _id  field. The following code creates an ascending index on the\n city  field in the  sample_training.zips  collection: A compound index holds a reference to multiple document fields. This index improves the performance of queries and sorts on multiple\nfields. When you create a compound index, you must specify a direction for\neach of the indexed fields. You can create a multikey index by using the same syntax for creating a\n single field index . The following code creates a compound index on the\n city  and  pop  fields in the  sample_training.zips  collection: A multikey index holds a reference to an array-valued field. This index\nimproves the performance of queries on array fields. You can create a multikey index by using the same syntax for creating a\n single field index . The following code creates a multikey index on the\n tags  field in the  sample_training.posts  collection: Clustered indexes improve the performance of insert, update, and delete\noperations on clustered collections. Clustered collections store\ndocuments ordered by the clustered index key value. To learn more about\nthese collections, see  Clustered Collections  in the Server manual. You can create a clustered index only when creating a collection.\nTo create a clustered collection, perform the following steps: You must set the following fields of the  ClusteredIndex  struct: To create a  ClusteredIndex  instance that automatically uses the\nrequired values, you can call the type's  default()  method. Create a  ClusteredIndex  instance. Set the  ClusteredIndex  instance as the value of the\n clustered_index  field of a  CreateCollectionOptions  instance. Pass the options to the  create_collection()  method. The  key  field, which specifies the key pattern. The value of this\nfield must be  { _id: 1 } . The  unique  field, which specifies the uniqueness of the index. The\nvalue of this field must be  true . The following code creates a clustered index with default configuration on the\n _id  field when creating a new collection called  items  in the\n sample_training  database: A text index supports text search queries on string content. This index\nreferences a field with a string value or a string array value.\nMongoDB supports text search for several languages. When you create a\ntext index, you can specify the default language as an option. A collection can only contain one text index. To create a\ntext index on multiple text fields, you can create a  compound\nindex . When you run a text search after creating a\ncompound index, the search operation runs on all the text fields\nin the compound index. Text indexes are different from Atlas full text search indexes. To\nlearn more about Atlas Search indexes, see the  Atlas Search\ndocumentation . The following code creates a text index on the  body  field in the\n sample_training.posts  collection. The code sets an option to specify\n \"spanish\"  as the default language for the text index: MongoDB supports queries containing geospatial coordinate data by using\n 2dsphere  indexes. You can create a  2dsphere  index on a field\nwith GeoJSON object values. This index type supports the following tasks: Queries on geospatial data to find inclusion, intersection, and proximity Calculation of distances on a Euclidean plane You cannot create two geospatial indexes on the same field. The following sample document in the  sample_mflix.theaters \ncollection contains the field  location.geo . This field has a GeoJSON\npoint value: The following code creates a geospatial  2dsphere  index on the\n location.geo  field in the  sample_mflix.theaters  collection: A unique index ensures that the indexed fields do not store duplicate\nvalues. By default, MongoDB creates a unique, single field index on the\n _id  field when you create a collection. To create a unique index, specify the field or combination of fields\nthat you want to maintain uniqueness for and set the  unique  option\nto  true . The following code shows how to set the  unique  field to  true  in an\n IndexOptions  instance and pass these options when creating an\n IndexModel : You can remove, or drop, any indexes from a collection except the\ndefault unique index on the  _id  field. To remove an index, pass the\nname of the index to the  drop_index()  method. The following example removes an index called  city_1  from the\n sample_training.zips  collection: You can remove all the indexes on a collection except for the\n _id  index at once by using the  drop_indexes()  method. To learn more about designing data models and creating appropriate\nindexes for your application, see  Indexing Strategies  and  Operational Factors and Data\nModels  in the Server manual. To learn about performing read operations, see the guides in the\n Read Operations  category. To learn more about the concepts mentioned in this guide, see the\nfollowing Server documentation: Single Field Indexes TTL Indexes Compound Indexes Multikey Indexes Text Indexes Compound Text Indexes Geospatial Queries GeoJSON Objects Unique Indexes Clustered Collections To learn more about the methods and types mentioned in this\nguide, see the following API documentation: create_index() create_indexes() IndexModel IndexOptions ClusteredIndex CreateCollectionOptions drop_index() drop_indexes()",
            "code": [
                {
                    "lang": "none",
                    "value": "name_1_age_-1"
                },
                {
                    "lang": "rust",
                    "value": "let index = IndexModel::builder()\n    .keys(doc! { \"city\": 1 })\n    .build();\n\nlet idx = my_coll.create_index(index, None).await?;\nprintln!(\"Created index:\\n{}\", idx.index_name);"
                },
                {
                    "lang": "console",
                    "value": "Created index:\ncity_1"
                },
                {
                    "lang": "rust",
                    "value": "let index = IndexModel::builder()\n    .keys(doc! { \"city\": 1, \"pop\": -1 })\n    .build();\n\nlet idx = my_coll.create_index(index, None).await?;\nprintln!(\"Created index:\\n{}\", idx.index_name);"
                },
                {
                    "lang": "console",
                    "value": "Created index:\ncity_1_pop_-1"
                },
                {
                    "lang": "rust",
                    "value": "let index = IndexModel::builder()\n    .keys(doc! { \"tags\": 1 })\n    .build();\n\nlet idx = my_coll.create_index(index, None).await?;\nprintln!(\"Created index:\\n{}\", idx.index_name);"
                },
                {
                    "lang": "console",
                    "value": "Created index:\ntags_1"
                },
                {
                    "lang": "rust",
                    "value": "let db = client.database(\"sample_training\");\nlet cl_idx = ClusteredIndex::default();\nlet opts = CreateCollectionOptions::builder()\n    .clustered_index(cl_idx)\n    .build();\n\ndb.create_collection(\"items\", opts).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let idx_opts = IndexOptions::builder()\n    .default_language(\"spanish\".to_string())\n    .build();\n\nlet index = IndexModel::builder()\n    .keys(doc! { \"body\": \"text\" })\n    .options(idx_opts)\n    .build();\n\nlet idx = my_coll.create_index(index, None).await?;\nprintln!(\"Created index:\\n{}\", idx.index_name);"
                },
                {
                    "lang": "console",
                    "value": "Created index:\nbody_\"text\""
                },
                {
                    "lang": "javascript",
                    "value": "{\n  \"_id\": ...,\n  \"theaterId\": ...,\n  \"location\": {\n    \"address\": ...,\n    \"geo\": {\n      \"type\": \"Point\",\n      \"coordinates\": [\n        -93.24565,\n        44.85466\n      ]\n    }\n  }\n}"
                },
                {
                    "lang": "rust",
                    "value": "let index = IndexModel::builder()\n    .keys(doc! { \"location.geo\": \"2dsphere\" })\n    .build();\n\nlet idx = my_coll.create_index(index, None).await?;\nprintln!(\"Created index:\\n{}\", idx.index_name);"
                },
                {
                    "lang": "console",
                    "value": "Created index:\nlocation.geo_\"2dsphere\""
                },
                {
                    "lang": "rust",
                    "value": "let opts = IndexOptions::builder().unique(true).build();\nlet index = IndexModel::builder()\n    .keys(doc! { \"_id\": -1 })\n    .options(opts)\n    .build();"
                },
                {
                    "lang": "rust",
                    "value": "my_coll.drop_index(\"city_1\".to_string(), None).await?;"
                }
            ],
            "preview": "In this guide, you can learn how to use the Rust driver to create\nand manage indexes. Indexes are special data structures that improve\nquery performance in MongoDB.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/serialization",
            "title": "Data Modeling and Serialization",
            "headings": [
                "Overview",
                "Generic Type Parameter",
                "Custom Data Model",
                "Custom Struct Example",
                "Multiple Parameterizations",
                "Custom Serialization",
                "Serialize a String as an ObjectId",
                "Serialize a DateTime as a String",
                "Serialize a u32 as an f64",
                "Other Attributes and Modules",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn about how the Rust driver handles conversions\nbetween BSON and Rust types. The process of converting a Rust type to\nBSON is called  serialization , while the reverse process is called\n deserialization . The Rust language uses a static type system, but BSON has a dynamic\nschema. To handle conversions between Rust types and BSON, the driver and the\n bson  library integrate functionality from the Serde framework. To\nlearn how to install the  serde  crate, see  serde  at the  crates.io  crate registry. By implementing functionality from the  serde  crate into your\napplication, you can use custom Rust types such as structs and enums\nto model your data. This guide includes the following sections: Generic Type Parameter  describes\ncollection parameterization and data modeling Custom Data Model  describes how to\ndefine custom Rust types to model data in your collections Custom Serialization  describes how\nto modify default serialization and deserialization behavior by using\nattributes and provides examples Additional Information \nprovides links to resources and API documentation for types\nand methods mentioned in this guide When you create a  Collection  instance, you must specify a generic\ntype parameter to represent the type of data that models the documents\nin your collection. To learn more about specifying a generic type parameter,\nsee the  Collection Parameterization section  of the guide on Databases and Collections. We recommend that you define and use a custom type to model your\ncollection's data instead of using the  Document  type. You can use any Rust data type that implements the  Serialize  and\n Deserialize  traits from the  serde  crate as the generic type\nparameter for a  Collection  instance. To implement the  Serialize \nand  Deserialize  traits, you must include the following  derive \nattribute before defining a Rust type: The following code defines a sample  Vegetable  struct that implements\nthe  serde  serialization traits: The following code accesses the  vegetables  collection with\n Vegetable  as its generic type parameter: Because the  Collection  instance is parameterized with the\n Vegetable  struct, you can perform CRUD operations with this type.\nThe following code inserts a  Vegetable  instance into the collection: If your collection contains multiple schemas, you can define a custom\ntype to model each data type and create clones of the original\n Collection  instance for each type. You can create clones of a\n Collection  instance by using the  clone_with_type()  method. Suppose you originally parameterized a collection with a struct\ncalled  Square , but you later realize that you want to insert a different\ntype of data, modeled by the  Circle  struct, into the collection.\nThe following code parameterizes a collection with the  Square  type,\nthen creates a clone of the collection that is parameterized with the\n Circle  type: You can modify the default serialization and deserialization behavior of\nthe Rust driver by using  attributes  from the  serde  crate.\nAttributes are optional pieces of metadata attached to fields of\nstructs or variants of enums. The  serde  crate provides the  serialize_with  and\n deserialize_with  attributes, which take helper functions as values.\nThese helper functions customize serialization and deserialization on\nspecific fields and variants. To specify an attribute on a field,\ninclude the attribute before the field definition: In the following sections, you can find examples that use helper\nfunctions from the  bson  library to achieve common serialization tasks. To\nsee a full list of these helper functions, see the  serde_helpers API\ndocumentation . You might want to represent the  _id  field in a document as a\nhexadecimal string in your struct. To convert the hexadecimal string to\nthe  ObjectId  BSON type, use the\n serialize_hex_string_as_object_id  helper function as the value of\nthe  serialize_with  attribute. The following example attaches the\n serialize_with  attribute to the  _id  field so that the driver\nserializes the hexadecimal string as an  ObjectId  type: To see how the driver serializes a sample  Order  struct to BSON,\nselect from the following  Struct  and  BSON  tabs: You might want to represent a  DateTime  field value in a document as\nan ISO-formatted string in BSON. To specify this conversion, use the\n serialize_bson_datetime_as_rfc3339_string  helper function as the value of\nthe  serialize_with  attribute attached to the field with a\n DateTime  value. The following example attaches the\n serialize_with  attribute to the  delivery_date  field so that the\ndriver serializes the  DateTime  value to a string: To see how the driver serializes a sample  Order  struct to BSON,\nselect from the following  Struct  and  BSON  tabs: You might want to represent a  u32  field value in a document as\nan  f64 , or  Double , type in BSON. To specify this conversion, use the\n serialize_u32_as_f64  helper function as the value of\nthe  serialize_with  attribute attached to the field with a  u32 \nvalue. The following example attaches the\n serialize_with  attribute to the  quantity  field so that the\ndriver serializes the  u32  value to a  Double  type: The BSON  Double  representation of a  u32  value appears\nthe same as the original value. In addition to helper functions, the  bson  library provides modules\nthat handle both serialization and deserialization. To select a module\nto use on a specific field or variant, set the value of the  with \nattribute to the name of the module: For a full list of these modules, see the  serde_helpers API\ndocumentation . The  serde  crate provides many other attributes to customize\nserialization. The following list describes some common attributes and\ntheir functionality: For a full list of  serde  attributes, see the  serde Attributes\nAPI Documentation . rename : serialize and deserialize a field with a specified name instead of the\nRust struct or variant name skip : do not serialize or deserialize the specified field default : if no value is present during deserialization, use the\ndefault value from  Default::default() To learn more about BSON types, see  BSON Types  in the Server manual. For more examples that demonstrate  serde  functionality, see the\n Structuring Data with Serde in Rust  Developer Center\narticle. To learn more about the Serde framework, see the  Serde documentation . To learn more about the methods and types mentioned in this\nguide, see the following API documentation: collection() clone_with_type() serialize_with \nSerde attribute deserialize_with \nSerde attribute with  Serde attribute",
            "code": [
                {
                    "lang": "rust",
                    "value": "#[derive(Serialize, Deserialize)]"
                },
                {
                    "lang": "rust",
                    "value": "#[derive(Serialize, Deserialize)]\nstruct Vegetable {\n    name: String,\n    category: String,\n    tropical: bool,\n}"
                },
                {
                    "lang": "rust",
                    "value": "let my_coll: Collection<Vegetable> = client\n    .database(\"db\")\n    .collection(\"vegetables\");"
                },
                {
                    "lang": "rust",
                    "value": "let calabash = Vegetable {\n    name: \"calabash\".to_string(),\n    category: \"gourd\".to_string(),\n    tropical: true,\n};\n\nmy_coll.insert_one(calabash, None).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let shapes_coll: Collection<Square> = client\n    .database(\"db\")\n    .collection(\"shapes\");\n// ... perform some operations with Square\n\nlet shapes_coll: Collection<Circle> = shapes_coll.clone_with_type();\n// ... perform some operations with Circle"
                },
                {
                    "lang": "rust",
                    "value": "#[derive(Serialize, Deserialize)]\nstruct MyStruct {\n    #[serde(serialize_with = \"<helper function>\")]\n    field1: String,\n    // ... other fields\n}"
                },
                {
                    "lang": "rust",
                    "value": "#[derive(Serialize, Deserialize)]\nstruct Order {\n    #[serde(serialize_with = \"serialize_hex_string_as_object_id\")]\n    _id: String,\n    item: String,\n}"
                },
                {
                    "lang": "rust",
                    "value": "let order = Order {\n    _id: \"6348acd2e1a47ca32e79f46f\".to_string(),\n    item: \"lima beans\".to_string(),\n};"
                },
                {
                    "lang": "json",
                    "value": "{\n  \"_id\": { \"$oid\": \"6348acd2e1a47ca32e79f46f\" },\n  \"item\": \"lima beans\"\n}"
                },
                {
                    "lang": "rust",
                    "value": "#[derive(Serialize, Deserialize)]\nstruct Order {\n    item: String,\n    #[serde(serialize_with = \"serialize_bson_datetime_as_rfc3339_string\")]\n    delivery_date: DateTime,\n}"
                },
                {
                    "lang": "rust",
                    "value": "let order = Order {\n    item: \"lima beans\".to_string(),\n    delivery_date: DateTime::now(),\n};"
                },
                {
                    "lang": "json",
                    "value": "{\n  \"_id\": { ... },\n  \"item\": \"lima beans\",\n  \"delivery_date\": \"2023-09-26T17:30:18.181Z\"\n}"
                },
                {
                    "lang": "rust",
                    "value": "#[derive(Serialize, Deserialize)]\nstruct Order {\n    item: String,\n    #[serde(serialize_with = \"serialize_u32_as_f64\")]\n    quantity: u32,\n}"
                },
                {
                    "lang": "rust",
                    "value": "#[derive(Serialize, Deserialize)]\nstruct MyStruct {\n    #[serde(with = \"<module>\")]\n    field1: u32,\n    // ... other fields\n}"
                }
            ],
            "preview": "In this guide, you can learn about how the Rust driver handles conversions\nbetween BSON and Rust types. The process of converting a Rust type to\nBSON is called serialization, while the reverse process is called\ndeserialization.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/run-command",
            "title": "Run a Command",
            "headings": [
                "Overview",
                "Execute a Command",
                "Response",
                "Command Example",
                "Output",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to use the Rust driver\nto run a database command. You can use database commands to perform a\nvariety of administrative and diagnostic tasks, such as fetching server\nstatistics, initializing a replica set, or running an aggregation pipeline. This guide includes the following sections: Execute a Command  describes the syntax\nand behavior of the  run_command()  and  run_cursor_command()  methods Response  describes the information\nthat the command execution methods return Command Example  provides a command\nexample and describes the output for the command Additional Information \nprovides links to resources and API documentation for types\nand methods mentioned in this guide The driver provides wrapper methods for many database commands.\nWe recommend using driver methods instead of executing database\ncommands when possible. To perform administrative tasks, use the  MongoDB Shell \ninstead of the Rust driver. Calling the  db.runCommand() \nmethod inside the shell is the preferred way to issue database\ncommands, as it provides a consistent interface between the shell and\ndrivers. To run a database command, you must specify the command and any relevant\nparameters in a command document, then pass the command document to a\ncommand execution method. The Rust driver provides the following methods\nto run database commands: The following code shows how you can use the  run_command() \nmethod to run the  hello  command, which returns information about\nthe current member's role in the replica set, on a database: The  checkMetadataConsistency  command returns multiple result\ndocuments. You can use the  run_cursor_command()  method to run\nthis command and collect the results, as shown in the following code: To find a link to a full list of database commands and corresponding\nparameters, see the  Additional Information section . run_command() , which returns the command response as a\n Document  type. You can use this method with any database command. run_cursor_command() , which returns the command response as an iterable\n Cursor  type. You can use this method only if your database command\nreturns multiple result documents. The  run_command()  and  run_cursor_command()  methods do not\nobey the read preference you might have set on your  Database \nobject elsewhere in your code. By default, they use the  primary \nread preference. You can set a read preference for command execution by\npassing an options object to either method. The following code shows\nhow to specify a read preference in a  SelectionCriteria  instance\nand pass it as an option to the  run_command()  method: The  run_cursor_command()  method takes a\n RunCursorCommandOptions  instance as a parameter. You can set the\n selection_criteria  field of this struct to select a read preference. For more information on read preference options, see  Read\nPreference  in the Server manual. The  run_command()  method returns a  Document  object that contains\nthe response from the database after the command has been executed. The\n run_cursor_command()  returns a  Cursor  that references multiple\nresult documents. Each database command performs a different function, so the response\ncontent can vary depending on the command executed. However, every\nresponse contains a document with the following fields: Field Description <command result> Fields specific to the database command. For example,\n count  returns the  n  field and  explain  returns the\n queryPlanner  field. ok Whether the command has succeeded ( 1 )\nor failed ( 0 ). operationTime The logical time of the operation. MongoDB uses the\nlogical time to order operations. To learn more about logical time, see our blog post about the\n Global Logical Clock . $clusterTime A document that contains the signed cluster time. Cluster time is a\nlogical time used for the ordering of operations. This document contains the following fields: clusterTime , the timestamp of the highest known cluster time for the member signature , a document that contains the hash of the cluster time and the ID\nof the key used to sign the cluster time The following code shows how you can use the  run_command()  method to run\nthe  explain  command for a  count  operation on the  flowers \ncollection of the  plants  database. The  explain  command runs in the\n \"queryPlanner\"  verbosity mode: The output includes fields explaining the\nexecution of the  count  operation, such as the winning plan, which is\nthe plan selected by the query optimizer, and any rejected\nplans. The output also contains information about the execution of the\n explain  command: For more information about the concepts in this guide, see the following\ndocumentation in the Server manual: db.runCommand() Database Commands hello Command explain Command run_command() run_cursor_command() SelectionCriteria RunCursorCommandOptions ReadPreference",
            "code": [
                {
                    "lang": "rust",
                    "value": "let result = my_db.run_command(doc! { \"hello\": 1 }, None).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let cursor = my_db\n    .run_cursor_command(doc! { \"checkMetadataConsistency\": 1 }, None)\n    .await?;"
                },
                {
                    "lang": "rust",
                    "value": "let command_options = SelectionCriteria::ReadPreference(\n    ReadPreference::Primary\n);\nlet result = my_db.run_command(command_doc, command_options).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let my_db = client.database(\"plants\");\nlet count_command = doc! { \"count\": \"flowers\" };\nlet explain_command =\n    doc! {\n    \"explain\": count_command,\n    \"verbosity\": \"queryPlanner\"\n};\n\nlet result = my_db.run_command(explain_command, None).await?;"
                },
                {
                    "lang": "json",
                    "value": "{\n    \"$clusterTime\": {\n        \"clusterTime\": {\n            \"T\": 1673969525,\n            \"I\": 24\n        },\n        \"signature\": {...}\n    },\n    \"command\": {\n        \"$db\": \"plants\",\n        \"count\": \"flowers\"\n    },\n    \"explainVersion\": \"1\",\n    \"ok\": 1,\n    \"operationTime\": {\n        \"T\": 1673969525,\n        \"I\": 24\n    },\n    \"queryPlanner\": {\n        \"indexFilterSet\": false,\n        \"maxIndexedAndSolutionsReached\": false,\n        \"maxIndexedOrSolutionsReached\": false,\n        \"maxScansToExplodeReached\": false,\n        \"namespace\": \"plants.flowers\",\n        \"rejectedPlans\": [],\n        \"winningPlan\": {\n            \"stage\": \"RECORD_STORE_FAST_COUNT\"\n        }\n    },\n    \"serverInfo\": {...},\n    \"serverParameters\": {\n        \"internalDocumentSourceGroupMaxMemoryBytes\": 104857600,\n        ...\n    }\n}"
                }
            ],
            "preview": "In this guide, you can learn how to use the Rust driver\nto run a database command. You can use database commands to perform a\nvariety of administrative and diagnostic tasks, such as fetching server\nstatistics, initializing a replica set, or running an aggregation pipeline.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/aggregation",
            "title": "Aggregation",
            "headings": [
                "Overview",
                "Analogy",
                "Compare Aggregation and Find Operations",
                "Server Limitations",
                "Examples",
                "Age Insights by Genre",
                "Group by Time Component",
                "Calculate Popular Genres",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to perform aggregation operations in\nthe Rust driver. Aggregation operations process data in your MongoDB collections based on\nspecifications you can set in an  aggregation pipeline . An aggregation\npipeline consists of one or more  stages . Each stage performs an\noperation based on its expression operators. After the driver executes\nthe aggregation pipeline, it returns an aggregated result. This guide includes the following sections: Compare Aggregation and Find Operations \ndescribes the functionality differences between aggregation and find operations Server Limitations  describes the\nserver limitations on memory usage for aggregation operations Examples  provides examples of aggregations\nfor different use cases Additional Information \nprovides links to resources and API documentation for types\nand methods mentioned in this guide Aggregation operations function similarly to car factories with assembly\nlines. The assembly lines have stations with specialized tools to\nperform specific tasks. For example, when building a car, the assembly\nline begins with the frame. Then, as the car frame moves through the\nassembly line, each station assembles a separate part. The result is a\ntransformed final product, the finished car. The assembly line represents the  aggregation pipeline , the individual\nstations represent the  aggregation stages , the specialized tools\nrepresent the  expression operators , and the finished product\nrepresents the  aggregated result . The following table lists the different tasks you can perform with find\noperations, compared to what you can achieve with aggregation\noperations. The aggregation framework provides expanded functionality\nthat allows you to transform and manipulate your data. Find Operations Aggregation Operations When performing aggregation operations, consider the following\nlimitations: Returned documents must not violate the  BSON document size\nlimit  of 16 megabytes. Pipeline stages have a memory limit of 100 megabytes by default. If\nrequired, you may exceed this limit by setting the  allow_disk_use \nfield in your  AggregateOptions . The  $graphLookup  operator\nhas a strict memory limit of 100 megabytes and ignores\nthe  allow_disk_use  setting. The examples in this section use the following sample documents. Each\ndocument represents a user profile on a book review website and contains\ninformation about their name, age, genre interests, and date that they\nwere last active on the website: The following example calculates the average, minimum, and maximum age of users\ninterested in each genre. The aggregation pipeline contains the following stages: An  $unwind  stage to separate each array entry in the\n genre_interests  field into a new document. A  $group  stage to group documents by the value of the\n genre_interests  field. This stage finds the average, minimum, and\nmaximum user age by using the  $avg ,  $min , and  $max  operators. The following example finds how many users were last active in each\nmonth. The aggregation pipeline contains the following stages: A  $project  stage to extract the month from the  last_active \nfield as a number into the  month_last_active  field. A  $group  stage to group documents by the  month_last_active \nfield and count the number of documents for each month. A  $sort  stage to set an ascending sort on the month. The following example finds the three most popular genres based on how\noften they appear in users' interests. The aggregation pipeline contains the following stages: An  $unwind  stage to separate each array entry in the\n genre_interests  field into a new document. A  $group  stage to group documents by the  genre_interests \nfield and count the number of documents for each genre. A  $sort  stage to set a descending sort on the genre popularity. A  $limit  stage to show only the first three genres. To learn more about the concepts mentioned in this guide, see the\nfollowing Server manual entries: To learn more about the behavior of the  aggregate()  method, see the\n Aggregation Operations  section of the\nRetrieve Data guide. Expression Operators Aggregation Pipeline Aggregation Stages Operator Expressions Aggregation Pipeline Limits To learn more about the methods and types mentioned in this\nguide, see the following API documentation: aggregate() AggregateOptions",
            "code": [
                {
                    "lang": "json",
                    "value": "{ \"name\": \"Sonya Mehta\", \"age\": 23, \"genre_interests\": [\"fiction\", \"mystery\", \"memoir\"], \"last_active\": { \"$date\": \"2023-05-13T00:00:00.000Z\" } },\n{ \"name\": \"Selena Sun\", \"age\": 45, \"genre_interests\": [\"fiction\", \"literary\", \"theory\"], \"last_active\": { \"$date\": \"2023-05-25T00:00:00.000Z\" } },\n{ \"name\": \"Carter Johnson\", \"age\": 56, \"genre_interests\": [\"literary\", \"self help\"], \"last_active\": { \"$date\": \"2023-05-31T00:00:00.000Z\" } },\n{ \"name\": \"Rick Cortes\", \"age\": 18, \"genre_interests\": [\"sci-fi\", \"fantasy\", \"memoir\"], \"last_active\": { \"$date\": \"2023-07-01T00:00:00.000Z\" } },\n{ \"name\": \"Belinda James\", \"age\": 76, \"genre_interests\": [\"literary\", \"nonfiction\"], \"last_active\": { \"$date\": \"2023-06-11T00:00:00.000Z\" } },\n{ \"name\": \"Corey Saltz\", \"age\": 29, \"genre_interests\": [\"fiction\", \"sports\", \"memoir\"], \"last_active\": { \"$date\": \"2023-01-23T00:00:00.000Z\" } },\n{ \"name\": \"John Soo\", \"age\": 16, \"genre_interests\": [\"fiction\", \"sports\"], \"last_active\": { \"$date\": \"2023-01-03T00:00:00.000Z\" } },\n{ \"name\": \"Lisa Ray\", \"age\": 39, \"genre_interests\": [\"poetry\", \"art\", \"memoir\"], \"last_active\": { \"$date\": \"2023-05-30T00:00:00.000Z\" } },\n{ \"name\": \"Kiran Murray\", \"age\": 20, \"genre_interests\": [\"mystery\", \"fantasy\", \"memoir\"], \"last_active\": { \"$date\": \"2023-01-30T00:00:00.000Z\" } },\n{ \"name\": \"Beth Carson\", \"age\": 31, \"genre_interests\": [\"mystery\", \"nonfiction\"], \"last_active\": { \"$date\": \"2023-08-04T00:00:00.000Z\" } },\n{ \"name\": \"Thalia Dorn\", \"age\": 21, \"genre_interests\": [\"theory\", \"literary\", \"fiction\"], \"last_active\": { \"$date\": \"2023-08-19T00:00:00.000Z\" } },\n{ \"name\": \"Arthur Ray\", \"age\": 66, \"genre_interests\": [\"sci-fi\", \"fantasy\", \"fiction\"], \"last_active\": { \"$date\": \"2023-11-27T00:00:00.000Z\" } }"
                },
                {
                    "lang": "rust",
                    "value": "let age_pipeline = vec![\n    doc! { \"$unwind\": doc! { \"path\": \"$genre_interests\" } },\n    doc! { \"$group\": doc! {\n        \"_id\": \"$genre_interests\",\n        \"avg_age\": doc! { \"$avg\": \"$age\" },\n        \"min_age\": doc! { \"$min\": \"$age\" },\n        \"max_age\": doc! { \"$max\": \"$age\" }\n    } }\n];\n\nlet mut results = my_coll.aggregate(age_pipeline, None).await?;\nwhile let Some(result) = results.try_next().await? {\n    let doc = bson::from_document(result)?;\n    println!(\"* {}\", doc);\n}"
                },
                {
                    "lang": "console",
                    "value": "* { \"_id\": \"memoir\", \"avg_age\": 25.8, \"min_age\": 18, \"max_age\": 39 }\n* { \"_id\": \"sci-fi\", \"avg_age\": 42, \"min_age\": 18, \"max_age\": 66 }\n* { \"_id\": \"fiction\", \"avg_age\": 33.333333333333336, \"min_age\": 16, \"max_age\": 66 }\n* { \"_id\": \"nonfiction\", \"avg_age\": 53.5, \"min_age\": 31, \"max_age\": 76 }\n* { \"_id\": \"self help\", \"avg_age\": 56, \"min_age\": 56, \"max_age\": 56 }\n* { \"_id\": \"poetry\", \"avg_age\": 39, \"min_age\": 39, \"max_age\": 39 }\n* { \"_id\": \"literary\", \"avg_age\": 49.5, \"min_age\": 21, \"max_age\": 76 }\n* { \"_id\": \"fantasy\", \"avg_age\": 34.666666666666664, \"min_age\": 18, \"max_age\": 66 }\n* { \"_id\": \"mystery\", \"avg_age\": 24.666666666666668, \"min_age\": 20, \"max_age\": 31 }\n* { \"_id\": \"theory\", \"avg_age\": 33, \"min_age\": 21, \"max_age\": 45 }\n* { \"_id\": \"art\", \"avg_age\": 39, \"min_age\": 39, \"max_age\": 39 }\n* { \"_id\": \"sports\", \"avg_age\": 22.5, \"min_age\": 16, \"max_age\": 29 }"
                },
                {
                    "lang": "rust",
                    "value": "let last_active_pipeline = vec![\n    doc! { \"$project\": { \"month_last_active\" : doc! { \"$month\" : \"$last_active\" } } },\n    doc! { \"$group\": doc! { \"_id\" : doc! {\"month_last_active\": \"$month_last_active\"} ,\n    \"number\" : doc! { \"$sum\" : 1 } } },\n    doc! { \"$sort\": { \"_id.month_last_active\" : 1 } }\n];\n\nlet mut results = my_coll.aggregate(last_active_pipeline, None).await?;\nwhile let Some(result) = results.try_next().await? {\n    let doc = bson::from_document(result)?;\n    println!(\"* {}\", doc);\n}"
                },
                {
                    "lang": "console",
                    "value": "* { \"_id\": { \"month_last_active\": 1 }, \"number\": 3 }\n* { \"_id\": { \"month_last_active\": 5 }, \"number\": 4 }\n* { \"_id\": { \"month_last_active\": 6 }, \"number\": 1 }\n* { \"_id\": { \"month_last_active\": 7 }, \"number\": 1 }\n* { \"_id\": { \"month_last_active\": 8 }, \"number\": 2 }\n* { \"_id\": { \"month_last_active\": 11 }, \"number\": 1 }"
                },
                {
                    "lang": "rust",
                    "value": "let popularity_pipeline = vec![\n    doc! { \"$unwind\" : \"$genre_interests\" },\n    doc! { \"$group\" : doc! { \"_id\" : \"$genre_interests\" , \"number\" : doc! { \"$sum\" : 1 } } },\n    doc! { \"$sort\" : doc! { \"number\" : -1 } },\n    doc! { \"$limit\": 3 }\n];\n\nlet mut results = my_coll.aggregate(popularity_pipeline, None).await?;\nwhile let Some(result) = results.try_next().await? {\n    let doc = bson::from_document(result)?;\n    println!(\"* {}\", doc);\n}"
                },
                {
                    "lang": "console",
                    "value": "* { \"_id\": \"fiction\", \"number\": 6 }\n* { \"_id\": \"memoir\", \"number\": 5 }\n* { \"_id\": \"literary\", \"number\": 4 }"
                }
            ],
            "preview": "In this guide, you can learn how to perform aggregation operations in\nthe Rust driver.",
            "tags": "pipeline, code example",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/connections/connection-guide",
            "title": "Connection Guide",
            "headings": [
                "Overview",
                "Connection URI",
                "Parts of a Connection URI",
                "MongoDB Client",
                "Client Creation Methods",
                "Connection Example",
                "Other Ways to Connect to MongoDB",
                "Connect to a MongoDB Server on Your Local Machine",
                "Connect to a Replica Set",
                "Direct Connection"
            ],
            "paragraphs": "In this guide, you can learn how to connect to a MongoDB instance or\nreplica set deployment by using the Rust driver. This guide includes the following sections: Connection URI  describes connection URIs\nand their constituent parts MongoDB Client  describes the  Client  type and\nways to create a client from a connection string Connection Example  provides\nexamples that show how to connect to MongoDB by using an Atlas\nconnection string Other Ways to Connect to MongoDB \ndescribes ways to connect to MongoDB deployments that are not hosted\non Atlas A  connection URI , also known as a connection string, tells the\ndriver how to connect to MongoDB and how to behave while connected. The following example explains each part of a sample connection URI: In this example, we use  mongodb  for the protocol, which specifies the\n Standard Connection String Format .\nYou can also use the  DNS Seed List Connection Format  if you\nwant more flexibility in your deployment and the ability to change the\nservers in rotation without reconfiguring clients. If you are using password-based authentication, the part of the\nconnection string after the protocol contains your username and\npassword. Replace the placeholder for  user  with your username and\n pass  with your password. If you are using an authentication\nmechanism that does not require a username and password, omit\nthis part of the connection URI. The part of the connection string after the credentials specifies the\nhostname or IP address and port of your MongoDB instance. In the\npreceding example, we use  sample.host  as the hostname and  27017 \nas the port. Replace these values to point to your MongoDB instance. The last part of the connection string specifies connection and authentication\noptions. In the example, we set two connection options:\n maxPoolSize=20  and  w=majority . To learn more about setting connection options, see the guide on\n Connection Options . To connect to MongoDB, you must create a  Client  instance. A\nclient manages your connections and runs database commands. You can improve performance by reusing your client across sessions and operations.\nYou can use the same  Client  instance to perform multiple tasks, instead of\ncreating a new one each time. The  Client  type is safe for\nconcurrent use by multiple threads or async tasks. You can create a client that uses your connection string and other\nclient options by passing a  ClientOptions  object to the  with_options() \nmethod. To specify your connection URI, pass it to the  parse() \nmethod of  ClientOptions . To set any other\noptions, set the relevant field of the  ClientOptions  struct. If you do not specify any client options, create a client by passing your\nconnection string to the  Client::with_uri_str()  method. To learn more about creating a client, see the API documentation for  Client  and  with_options() . You can set the Stable API version as an option to avoid\nbreaking changes when you upgrade to a new server version. To learn more about the Stable API feature, see the\n Stable API  guide. The following code shows how you can create a client that uses an Atlas\nconnection string and the Stable API version, connect to MongoDB, and\nverify that the connection is successful. Select from the\n Asynchronous API  or  Synchronous API  tabs below for corresponding\nconnection code samples. To learn more about asynchronous and synchronous runtimes, see the\n Asynchronous and Synchronous APIs  guide. Follow the  Quick Start guide \nto retrieve your Atlas connection string. To learn about connecting to Atlas Serverless, see the\n Serverless Instance Limitations page  to identify the minimum driver version\nyou need. If you must connect to a single MongoDB server instance or replica set\nthat is not hosted on Atlas, see the following sections to find out how to\nconnect. If you must run the MongoDB Server on your local machine for development\npurposes, you must complete the following: After you successfully start the MongoDB Server, connect to your local\ninstance by performing the following steps: Follow the  Install MongoDB  tutorial to\ninstall the MongoDB Server on your machine. Select the appropriate\ninstallation tutorial for your machine and operating system. After you complete the installation, start the server. Always secure your server from malicious attacks. See the\n Security Checklist  for a\nlist of security recommendations. Replace the connection string stored in the  uri  variable in the\n preceding example  with the\nconnection string for your local MongoDB instance. If your MongoDB Server is running locally, you can use the following\nconnection string to connect to MongoDB: In this connection string,  <port>  is the port number you\nconfigured your server to listen for incoming connections. Run the connection code. If the code executes successfully, you should see\nthe following output in your console: To learn more about connection strings and custom formats, see\n Connection Strings  in the\nServer manual. A MongoDB replica set deployment is a group of connected instances, or nodes,\nwhere the nodes store the same set of data. This configuration of instances\nprovides data redundancy and high data availability. To connect to a replica set deployment, specify the hostname and port numbers\nof each instance, separated by commas, and the replica set name as the value\nof the  replicaSet  parameter in the connection string. In the following example, the hostnames are  host1 ,  host2 , and\n host3 , and the port numbers are all  27017 . The replica set name\nis  myRS . The following code shows the connection URI for the replica\nset with these specifications: When connecting to a replica set, the driver takes the following actions by default: Discovers all replica set members when given the address of any one member. Dispatches operations to the appropriate member, such as instructions\nto write against the  primary  node. To learn more about the replica\nset primary, see  Replica Set Primary  in the Server manual. You are only required to specify one host to connect to a replica set.\nHowever, to ensure connectivity when the specified host\nis unavailable, provide the full list of hosts. To force operations on the host designated in the connection URI,\nspecify the  directConnection  option. Direct connections display the\nfollowing behavior: They don't support SRV strings. They fail on writes when the specified host is not the primary. They require you to  specify a secondary read preference  when the\nspecified host isn't the primary member. To learn more about these\nreplica set members, see  Replica Set Secondary Members  in the Server manual.",
            "code": [
                {
                    "lang": "rust",
                    "value": "use mongodb::{ bson::doc, options::{ ClientOptions, ServerApi, ServerApiVersion }, Client };\n\n#[tokio::main]\nasync fn main() -> mongodb::error::Result<()> {\n    // Replace the placeholder with your Atlas connection string\n    let uri = \"<connection string>\";\n    let mut client_options = ClientOptions::parse_async(uri).await?;\n\n    // Set the server_api field of the client_options object to Stable API version 1\n    let server_api = ServerApi::builder().version(ServerApiVersion::V1).build();\n    client_options.server_api = Some(server_api);\n\n    // Create a new client and connect to the server\n    let client = Client::with_options(client_options)?;\n\n    // Send a ping to confirm a successful connection\n    client.database(\"admin\").run_command(doc! { \"ping\": 1 }, None).await?;\n    println!(\"Pinged your deployment. You successfully connected to MongoDB!\");\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "rust",
                    "value": "use mongodb::{ bson::doc, options::{ ClientOptions, ServerApi, ServerApiVersion }, sync::Client };\n\nfn main() -> mongodb::error::Result<()> {\n    // Replace the placeholder with your Atlas connection string\n    let uri = \"<connection string>\";\n    let mut client_options = ClientOptions::parse(uri)?;\n\n    // Set the server_api field of the client_options object to Stable API version 1\n    let server_api = ServerApi::builder().version(ServerApiVersion::V1).build();\n    client_options.server_api = Some(server_api);\n\n    // Create a new client and connect to the server\n    let client = Client::with_options(client_options)?;\n\n    // Send a ping to confirm a successful connection\n    client.database(\"admin\").run_command(doc! { \"ping\": 1 }, None)?;\n    println!(\"Pinged your deployment. You successfully connected to MongoDB!\");\n\n    Ok(())\n}\n"
                },
                {
                    "lang": "none",
                    "value": "mongodb://localhost:<port>"
                },
                {
                    "lang": "none",
                    "value": "Pinged your deployment. You successfully connected to MongoDB!"
                },
                {
                    "lang": "none",
                    "value": "mongodb://host1:27017,host2:27017,host3:27017/?replicaSet=myRS"
                }
            ],
            "preview": "In this guide, you can learn how to connect to a MongoDB instance or\nreplica set deployment by using the Rust driver.",
            "tags": "access deployment, code example, authentication",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/gridfs",
            "title": "GridFS",
            "headings": [
                "Overview",
                "How GridFS Works",
                "Reference a GridFS Bucket",
                "Upload Files",
                "Download Files",
                "Retrieve File Information",
                "Rename Files",
                "Delete Files",
                "Delete a GridFS Bucket",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to store and retrieve large files in\nMongoDB by using  GridFS . GridFS is a specification that describes how\nto split files into chunks during storage and reassemble them during retrieval.\nThe Rust driver implementation of GridFS manages the operations and\norganization of the file storage. Use GridFS if the size of your file exceeds the BSON document size limit of\n16 MB. GridFS also helps you access files without loading the entire file into\nmemory. For more detailed information about whether GridFS is suitable for your\nuse case, see the  GridFS  page in the Server manual. To learn more about GridFS, navigate to the following sections in this guide: How GridFS Works Reference a GridFS Bucket Upload Files Download Files Retrieve File Information Rename Files Delete Files Delete a GridFS Bucket Additional Information GridFS organizes files in a  bucket , which is a group of MongoDB collections\ncontaining file chunks and descriptive information. Buckets contain the\nfollowing collections, named according to the convention defined in the GridFS\nspecification: When you create a new GridFS bucket, the Rust driver performs the following\nactions: You can create a reference to a GridFS bucket by following the steps in the  Reference a GridFS Bucket \nsection of this page. However, the driver does not create a new GridFS bucket and its\nindexes until the first write operation. For more information on GridFS indexes, see the\n GridFS Indexes  page in the Server manual. When storing a file in a GridFS bucket, the Rust driver creates the following documents: The following diagram describes how GridFS splits files when uploading to a bucket: When retrieving files, GridFS fetches the metadata from the  files  collection in the\nspecified bucket and uses the information to reconstruct the file from documents in the\n chunks  collection. You can read the file into memory or output it to a stream. chunks , which stores the binary file chunks files , which stores the file metadata Creates the  chunks  and  files  collections, prefixed with the default bucket\nname  fs , unless you specify a different name Creates an index on each collection to ensure efficient retrieval of files and related\nmetadata One document in the  files  collection that stores a unique file ID, file name, and other\nfile metadata One or more documents in the  chunks  collection that store the content of the file, which\nthe driver splits into smaller pieces Before storing files in a GridFS bucket, create a bucket reference or get a reference to\nan existing bucket. The following example calls the  gridfs_bucket()  method on a database instance, which\ncreates a reference to either a new or existing GridFS bucket: You can specify a custom bucket name and other options in a  GridFsBucketOptions \nstruct instance. To begin building a  GridFsBucketOptions  instance, call the\n GridFsBucketOptions::builder()  method. The following table describes the builder methods that you can use to set fields of a\n GridFsBucketOptions  instance: The following example specifies options in a  GridFsBucketOptions  instance to configure a custom\nbucket name and a five-second time limit for write operations: The Rust driver implements the Builder design pattern for the\ncreation of many different types, including  GridFsBucketOptions . You\ncan use the  builder()  method to construct an instance of each type\nby chaining option builder methods. Method Possible Values Description chunk_size_bytes() Any  u32  value Specifies the chunk size used to break the file into chunks, which is 255 KB by default read_concern() ReadConcernLevel::Local ,\n ReadConcernLevel::Majority ,\n ReadConcernLevel::Linearizable ,\n ReadConcernLevel::Available ,\n ReadConcernLevel::Snapshot Specifies the bucket's read concern, which is set to the database's read concern by default You can upload a file to a GridFS bucket by opening an upload stream and\nwriting your file to the stream. Call the  open_upload_stream()  method on\nyour bucket instance to open the stream. This method returns an instance of\n GridFsUploadStream  to which you can write the file contents. To upload\nthe file contents to the  GridFsUploadStream , call the  write_all()  method\nand pass your file bytes as a parameter. The following example uses an upload stream to upload a file called  \"example.txt\" \nto a GridFS bucket: The  GridFsUploadStream  struct implements the  futures_io::AsyncWrite  trait.\nTo use the  AsyncWrite  write methods, such as  write_all() , import the\n AsyncWriteExt  module into your application file with the following use\ndeclaration: You can download a file from a GridFS bucket by opening a download stream and\nreading from the stream. Call the  open_download_stream()  method on\nyour bucket instance, specifying the desired file's  _id  value as a parameter.\nThis method returns an instance  GridFsDownloadStream  from which you can access\nthe file. To read the file from the  GridFsDownloadStream , call the  read_to_end() \nmethod and pass a vector as a parameter. The following example uses a download stream to download a file with an  _id  value\nof   3289  from a GridFS bucket: The  GridFsDownloadStream  struct implements the  futures_io::AsyncRead  trait.\nTo use the  AsyncRead  read methods, such as  read_to_end() , import the\n AsyncReadExt  module into your application file with the following use\ndeclaration: The GridFS streaming API cannot load partial chunks. When a download\nstream needs to pull a chunk from MongoDB, it pulls the entire chunk\ninto memory. The 255 KB default chunk size is usually sufficient, but\nyou can reduce the chunk size to reduce memory overhead. You can retrieve information about the files stored in the  files  collection of\nthe GridFS bucket. Each file is stored as an instance of the  FilesCollectionDocument \ntype, which includes the following fields that represent file information: Call the  find()  method on a GridFS bucket instance to retrieve\nfiles from the bucket. The method returns a cursor instance\nfrom which you can access the results. The following example retrieves and prints the length of each file in a GridFS bucket: _id : the file ID length : the file size chunk_size_bytes : the size of the file's chunks upload_date : the file's upload date and time filename : the name of the file metadata : a document that stores user-specified metadata To learn more about the  find()  method, see the  Retrieve Data \nguide. To learn more about retrieving data from a cursor, see the  Access Data by Using a Cursor \nguide. You can update the name of a GridFS file in your bucket by calling the  rename()  method\non a bucket instance. Pass the target file's  _id  value and the new file name as\nparameters to the  rename()  method. The following example updates the  filename  field of the file containing an  _id  value\nof  3289  to  \"new_file_name\" : The  rename()  method only supports updating the name of one file at\na time. To rename multiple files, retrieve a list of files matching the\nfile name from the bucket, extract the  _id  field from the files you\nwant to rename, and pass each value in separate calls to the  rename() \nmethod. You can use the  delete()  method to remove a file from your bucket. To remove a\nfile, call  delete()  on your bucket instance and pass the file's  _id  value\nas a parameter. The following example deletes the file in which the value of the  _id  field is\n 3289 : The  delete()  method only supports deleting one file at a time. To\ndelete multiple files, retrieve the files from the bucket, extract\nthe  _id  field from the files you want to delete, and pass each  _id \nvalue in separate calls to the  delete()  method. You can use the  drop()  method to delete a bucket, which removes a bucket's\n files  and  chunks  collections. To delete the bucket, call  drop()  on\nyour bucket instance. The following example deletes a GridFS bucket: To learn more about any of the methods or types mentioned in this\nguide, see the following API documentation: gridfs_bucket() GridFsBucketOptions open_upload_stream() open_download_stream() FilesCollectionDocument rename() delete() drop()",
            "code": [
                {
                    "lang": "rust",
                    "value": "let bucket = my_db.gridfs_bucket(None);"
                },
                {
                    "lang": "rust",
                    "value": "let wc = WriteConcern::builder().w_timeout(Duration::new(5, 0)).build();\n\nlet opts = GridFsBucketOptions::builder()\n    .bucket_name(\"my_bucket\".to_string())\n    .write_concern(wc)\n    .build();\nlet bucket_with_opts = my_db.gridfs_bucket(opts);"
                },
                {
                    "lang": "rust",
                    "value": "use futures_util::io::AsyncWriteExt;"
                },
                {
                    "lang": "rust",
                    "value": "let bucket = my_db.gridfs_bucket(None);\nlet file_bytes = fs::read(\"example.txt\").await?;\n\nlet mut upload_stream = bucket.open_upload_stream(\"example\", None);\nupload_stream.write_all(&file_bytes[..]).await?;\n\nprintln!(\"Document uploaded with ID: {}\", upload_stream.id());\nupload_stream.close().await?;"
                },
                {
                    "lang": "rust",
                    "value": "use futures_util::io::AsyncReadExt;"
                },
                {
                    "lang": "rust",
                    "value": "let bucket = my_db.gridfs_bucket(None);\nlet id = ObjectId::from_str(\"3289\").expect(\"Could not convert to ObjectId\");\nlet mut buf = Vec::new();\n\nlet mut download_stream = bucket.open_download_stream(Bson::ObjectId(id)).await?;\nlet result = download_stream.read_to_end(&mut buf).await?;\n\nprintln!(\"{:?}\", result);"
                },
                {
                    "lang": "rust",
                    "value": "let bucket = my_db.gridfs_bucket(None);\nlet filter = doc! {};\nlet mut cursor = bucket.find(filter, None).await?;\n\nwhile let Some(result) = cursor.try_next().await? {\n    println!(\"File length: {}\\n\", result.length);\n};"
                },
                {
                    "lang": "rust",
                    "value": "let bucket = my_db.gridfs_bucket(None);\nlet id = ObjectId::from_str(\"3289\").expect(\"Could not convert to ObjectId\");\nlet new_name = \"new_file_name\";\n\nbucket.rename(Bson::ObjectId(id), &new_name).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let bucket = my_db.gridfs_bucket(None);\nlet id = ObjectId::from_str(\"3289\").expect(\"Could not convert to ObjectId\");\nbucket.delete(Bson::ObjectId(id)).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let bucket = my_db.gridfs_bucket(None);\nbucket.drop().await?;"
                }
            ],
            "preview": "In this guide, you can learn how to store and retrieve large files in\nMongoDB by using GridFS. GridFS is a specification that describes how\nto split files into chunks during storage and reassemble them during retrieval.\nThe Rust driver implementation of GridFS manages the operations and\norganization of the file storage.",
            "tags": "large files, storage, code example",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/crud/read-operations",
            "title": "Read Operations",
            "headings": [],
            "paragraphs": "Specify a Query Retrieve Data Access Data by Using a Cursor Open Change Streams Search Text",
            "code": [],
            "preview": null,
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/connections/tls",
            "title": "Enable and Configure TLS",
            "headings": [
                "Overview",
                "Enable TLS",
                "Configure Certificates",
                "Reference Certificates in a Client",
                "Example",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to use the  TLS protocol  to secure\nyour connection to a MongoDB deployment. TLS is a cryptographic protocol\nthat secures communication between your application and MongoDB. To\nconfigure your connection to use TLS, enable the TLS option and provide\nyour certificates for validation when creating a client. This guide includes the following sections: Enable TLS  describes ways to enable TLS on\nyour connection Configure Certificates \ndescribes the certificates required to configure TLS Reference Certificates in a Client \nprovides an example of how to create a  TlsOptions  struct to configure your\nTLS options Additional Information \nprovides links to resources and API documentation for types\nand methods mentioned in this guide To learn more about TLS, see the Wikipedia entry on\n Transport Layer Security . You can enable TLS on a connection to your MongoDB instance\nin one of the following ways: Select from the following  Connection String  and\n ClientOptions  tabs to see a corresponding code sample: For a full list of client options, see the\n Connection Options  guide. Setting the  tls  option to  true  in your connection string Setting the  tls  field of a  ClientOptions  instance to\nthe  Tls::Enabled  variant with an empty  TlsOptions  struct and\ninstantiating a  Client  with those options If your connection string uses a DNS SRV record by including\nthe  mongodb+srv  prefix, TLS is enabled on your connection by\ndefault. To successfully initiate a TLS request, your application must present\ncryptographic certificates to prove its identity. Your application's\ncertificates must be stored as Privacy Enhanced Mail (PEM) files to\nenable TLS when connecting to a MongoDB deployment. The PEM file format\nis a container format for cryptographic certificates. The following list describes the components that your client must\npresent to establish a TLS-enabled connection: For production use, we recommend that your MongoDB deployment use valid\ncertificates generated and signed by the same certificate authority.\nFor testing, your deployment can use self-signed certificates. TLS Component Description Certificate Authority (CA) One or more certificate authorities to\ntrust when making a TLS connection Client Certificate A digital certificate that allows the server to verify the identity\nof your application to establish an encrypted network connection Certificate Key The client certificate private key file, often\nincluded within the certificate file itself Passphrase The password to decrypt the private client key if it is encrypted You must reference your certificates in your  TlsOptions \nstruct so that the server can validate them before the client connects. You must first convert your certificate filepaths to\n PathBuf  types, so you must import this type from the  std::path \nmodule. Then, call the  TlsOptions  struct's builder functions\nto set the  ca_file_path  and  cert_key_file_path  fields to the\ncertificate filepaths. Within your  TlsOptions  instance, you can set optional\nfields to configure TLS on your connection. For  testing purposes ,\nyou can set the  allow_invalid_certificates  and\n allow_invalid_hostnames  fields. Setting the  allow_invalid_certificates  option to  true  disables\nhostname verification, and setting the\n allow_invalid_hostnames  to  true  disables certificate\nvalidation. Specifying either of these options in a production environment makes\nyour application insecure and potentially vulnerable to expired\ncertificates and to foreign processes posing as valid client\ninstances. This example performs the following actions to create a  TlsOptions \ninstance and a  Client  instance that is configured for TLS: Creates variables to reference the certificate filepaths in\n PathBuf  instances. Instantiates a  TlsOptions  struct and sets the  ca_file_path  and\n cert_key_file_path  fields to the relevant filepaths. Passes the  TlsOptions  instance to the  Enabled  variant of the\n Tls  enum. Sets the  tls  field of the  ClientOptions  struct to the\n Tls::Enabled  variant containing the  TlsOptions  instance. Creates a  Client  instance with these options. To learn more about enabling TLS on a connection, see the\nfollowing Server manual documentation: TLS/SSL (Transport Encryption) TLS/SSL Configuration for Clients To learn more about any of the methods or types mentioned in this\nguide, see the following API documentation: ClientOptions Client Tls TlsOptions PathBuf",
            "code": [
                {
                    "lang": "rust",
                    "value": "let uri = \"mongodb://<hostname>:<port>?tls=true\"\nlet client = Client::with_uri_str(uri).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let uri = \"<connection string>\"\nlet mut client_options = ClientOptions::parse_async(uri).await?;\n\nlet tls_opts = TlsOptions::builder().build();\nclient_options.tls = Some(Tls::Enabled(tls_opts));\n\nlet client = Client::with_options(client_options)?;"
                },
                {
                    "lang": "rust",
                    "value": "use std::path::PathBuf;\nuse mongodb::{ options::{ ClientOptions, TlsOptions, Tls }, Client };\n\n#[tokio::main]\nasync fn main() -> mongodb::error::Result<()> {\n    let uri = \"<connection string>\";\n\n    let mut client_options = ClientOptions::parse_async(uri).await?;\n\n    let ca_file = PathBuf::from(r\"<path to CA certificate>\");\n    let key_file = PathBuf::from(r\"<path to client certificate>\");\n\n    let tls_opts = TlsOptions::builder()\n        .ca_file_path(ca_file)\n        .cert_key_file_path(key_file)\n        .build();\n\n    client_options.tls = Some(Tls::Enabled(tls_opts));\n    let _client = Client::with_options(client_options)?;\n\n    Ok(())\n}\n"
                }
            ],
            "preview": "In this guide, you can learn how to use the TLS protocol to secure\nyour connection to a MongoDB deployment. TLS is a cryptographic protocol\nthat secures communication between your application and MongoDB. To\nconfigure your connection to use TLS, enable the TLS option and provide\nyour certificates for validation when creating a client.",
            "tags": "code example, security, connection options",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/crud/write-operations",
            "title": "Write Operations",
            "headings": [],
            "paragraphs": "Insert Documents Modify Documents Delete Documents",
            "code": [],
            "preview": null,
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/connections/connection-options",
            "title": "Connection Options",
            "headings": [
                "Overview"
            ],
            "paragraphs": "In this guide, you can learn about MongoDB connection and authentication\noptions. You can set connection options as parameters of your\nconnection string to specify how your  Client  instance behaves while\nconnected to the server. To see a full list of connection options, visit the\n Connection String Options section  of the\nServer manual entry on Connection Strings. Option Name Accepted Values Default Value Description appName String None authMechanism String None Specifies which authentication mechanism to use. If you do not\nspecify this option, the driver uses the default authentication\nmechanism. To learn more about authentication in the\nRust driver, see the guide on  Authentication Mechanisms . authMechanismProperties String None Specifies more properties for the authentication mechanism\nset in the  authMechanism  option. authSource String See description compressors A comma-separated list of strings None Specifies compressors that the  Client  instance uses in the specified order.\nTo learn more about network compression, see the  Network Compression  guide. connectTimeoutMS Non-negative integer 10000  (10 seconds) Specifies the connection timeout, in milliseconds, passed to each\nunderlying TCP stream when attempting to connect to the server. directConnection Boolean false Specifies whether the  Client  instance directly connects to a single host\ninstead of discovering and connecting to all servers in the cluster. heartbeatFrequencyMS Integer greater than or equal to 500 10000  (10 seconds) Specifies the amount of time in milliseconds that each\nmonitoring thread waits between performing server checks. journal Boolean false Requests acknowledgment that the operation propagated to the on-disk journal. localThresholdMS Non-negative integer 15 maxIdleTimeMS Non-negative integer 0 maxStalenessSeconds -1 , or any integer greater than or equal to  90 -1 maxPoolSize Non-negative integer 10 minPoolSize Non-negative integer 0 readConcernLevel String None Specifies the default read concern for operations performed on the  Client  instance.\nTo learn more, see  Read Concern  in the Server manual. readPreference String primary Specifies how the driver routes a read operation to members of a replica set.\nTo learn more, see  Read Preference  in the Server manual. readPreferenceTags A list of comma-separated key-value pairs None Specifies which replica set members are considered for operations.\nEach instance of this key is a separate tag set.\nThe driver checks each tag set until it finds one or more servers\nwith each tag in the set. replicaSet String None Specifies the name of the replica set that the  Client  instance connects to. retryReads Boolean true Specifies whether the client retries a read operation if the operation fails. serverSelectionTimeoutMS Non-negative integer 30000  (30 seconds) Specifies the amount of time in milliseconds that the\n Client  instance waits when attempting to select a server for an\noperation before timing out. tls Boolean false Specifies the TLS configuration for the  Client  instance to use in its connections with the server.\nBy default, TLS is off. tlsAllowInvalidCertificates Boolean false tlsCAFile String See description tlsCertificateKeyFile String None tlsInsecure Boolean false w Non-negative integer or string None wTimeoutMS Non-negative integer No timeout Specifies a time limit, in milliseconds, for the write concern.\nIf an operation has not propagated to the requested level within\nthe time limit, the driver raises an error. zlibCompressionLevel Integer between -1 and 9 (inclusive) -1",
            "code": [],
            "preview": "In this guide, you can learn about MongoDB connection and authentication\noptions. You can set connection options as parameters of your\nconnection string to specify how your Client instance behaves while\nconnected to the server.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/connections/network-compression",
            "title": "Network Compression",
            "headings": [
                "Overview",
                "Add Compression Feature Flags",
                "Enable Network Compression",
                "Connection String",
                "ClientOptions",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to configure  network compression  for\nyour connection to MongoDB by using the Rust driver. Network compression is a feature that allows you to compress and\ndecompress messages sent between your application and MongoDB, reducing\nthe total amount of data passed over the network. The driver supports the following compressors: This guide includes the following sections: Snappy : available in MongoDB 3.4 and later Zlib : available in MongoDB 3.6 and later Zstandard : available in MongoDB 4.2 and later If you specify multiple compressors to use on your connection, the\ndriver selects the first one that is supported by the MongoDB\ninstance that the driver is connected to. Add Compression Feature Flags  describes\nhow to add feature flags to your application for different compressors Enable Network Compression \ndescribes how to enable network compression on your  Client  instance Additional Information \nprovides links to resources and API documentation for types\nand methods mentioned in this guide To use a compressor, add the relevant feature flag to your\n mongodb  dependency's feature list in your project's  Cargo.toml \nfile. Select the tab for your preferred compressor to see how to add the\nnecessary feature flag to your  mongodb  dependency: To specify multiple compressors, you must add the feature flag for\neach compressor to your  mongodb  dependency. You can enable compression on your  Client  instance by specifying\ncompressors in the following ways: Adding the  compressors  parameter to your connection string. To see\nan example that enables compression this way, see the  Connection\nString  section. Setting the  compressors  field of a  ClientOptions  instance. You\ncan then pass the options to the  with_options()  method when\ninstantiating a  Client . To see an example that enables compression\nthis way, see the  ClientOptions  section. To enable compression by using a connection string, specify\nthe  compressors  parameter. You can specify one or more of the\nfollowing values for the  compressors  parameter: The following example shows how to specify Snappy, Zlib, and\nZstandard as the compressors for a connection: To learn more about setting client options, see the\nguide on  Connection Options . \"snappy\"  for Snappy compression \"zlib\"  for Zlib compression \"zstd\"  for Zstandard compression To enable compression within your  ClientOptions  instance, set\nthe  compressors  field, and then pass the options when creating a\nclient. The  compressors  field takes a value of\ntype  Vec<Compressor> . The  Compressor  type has the following\npossible values: For the compressors that have a  level  field, set the value to\n None  to indicate the default level. The following table describes the\ndefault and accepted compression levels for Zlib and Zstandard: A higher  level  value results in more compression, which is slower. The following example shows how to specify Snappy, Zlib, and\nZstandard as the compressors for a connection: Compressor::Snappy Compressor::Zstd { level: <integer> } Compressor::Zlib { level: <integer> } Compressor Default Level Accepted Levels Zlib 6 Integers from  0  to  9  or  None Zstandard 3 Integers from  1  to  22  or  None For more information about the concepts in this guide, see the following\ndocumentation: Connection Guide Connection String Compression Options  in the Server manual All Rust Driver Feature Flags To learn more about any of the methods or types mentioned in this\nguide, see the following API documentation: Client with_uri_str() parse() with_options() ClientOptions compressors Compressor",
            "code": [
                {
                    "lang": "none",
                    "value": "[dependencies.mongodb]\nversion = \"2.7.1\"\nfeatures = [\"snappy-compression\"]"
                },
                {
                    "lang": "none",
                    "value": "[dependencies.mongodb]\nversion = \"2.7.1\"\nfeatures = [\"zlib-compression\"]"
                },
                {
                    "lang": "none",
                    "value": "[dependencies.mongodb]\nversion = \"2.7.1\"\nfeatures = [\"zstd-compression\"]"
                },
                {
                    "lang": "rust",
                    "value": "let uri = \"mongodb+srv://<user>:<password>@<cluster-url>/?compressors=snappy,zlib,zstd\";\nlet client = Client::with_uri_str(uri).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let uri = \"<connection string>\";\nlet mut client_options = ClientOptions::parse_async(uri).await?;\n\nlet compressors = vec![\n    Compressor::Snappy,\n    Compressor::Zstd { level: Some(1) },\n    Compressor::Zlib { level: None }\n];\n\nclient_options.compressors = Some(compressors);\nlet client = Client::with_options(client_options)?;"
                }
            ],
            "preview": "In this guide, you can learn how to configure network compression for\nyour connection to MongoDB by using the Rust driver.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/crud/read-operations/cursor",
            "title": "Access Data by Using a Cursor",
            "headings": [
                "Overview",
                "Sample Data for Examples",
                "Retrieve Documents Individually",
                "Built-in Pattern",
                "Stream Implementation Pattern",
                "Retrieve Documents as an Array",
                "Specify Cursor Behavior",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to use the Rust driver to access\ndata returned from a read operation or aggregation by using a  cursor . A\ncursor is a mechanism that enables you to iterate through multiple documents\nwhile holding only a subset of them in memory at a given time. The driver offers the  Cursor  type to retrieve documents from a cursor.\nFor example, when you run a find operation that can return multiple\ndocuments, the driver returns a  Cursor  instance from which you can access\nthe matched documents. After you run a read operation or aggregation, the returned  Cursor  instance\ncontains the first batch of results from the operation. As you iterate through\nthe cursor, the server returns more individual results. If there are more\nmatching documents after you reach the end of a batch of results, the  Cursor \ninstance fetches the next batch of documents until all the results are returned. This guide includes the following sections: Sample Data for Examples  presents\nthe sample data that is used by the cursor examples Retrieve Documents Individually \ndescribes how to use iteration or a stream to access results one at a time Retrieve Documents as an Array \ndescribes how to access all results as a single array by collecting the\nreturned cursor results Specify Cursor Behavior  describes how\nto configure the cursor that a method returns Additional Information \nprovides links to resources and API documentation for types\nand methods mentioned in this guide The examples in this guide use the following data stored in a struct: The driver provides the following access patterns to iterate through\ndocuments returned by a  Cursor  instance: The following sections describe these access patterns and corresponding\nmethods in more detail. Built-in Pattern : advance the cursor,\nthen retrieve and deserialize the current document Stream Implementation Pattern : iterate over\nthe cursor and call methods provided by  Stream  to process single\nor multiple documents You can use the driver's built-in access pattern to retrieve and process\ndocuments one by one. The  Cursor  type includes the  advance()  and\n deserialize_current()  methods to iterate through a cursor and\naccess documents individually. The  advance()  method moves the cursor forward and sends a request to the\ndatabase for more results when the local buffer is exhausted, which occurs\nwhen the cursor reaches the end of a batch of results. Each time the cursor\nreaches the end of a batch of results, it requests the next batch. The cursor\nis exhausted when it has no more matching documents to return and is no longer\nusable. The  advance()  method returns a  true  result if new results are\nsuccessfully returned and a  false  result if the cursor is closed. The  deserialize_current()  method returns a reference to the current\nresult in the cursor and deserializes the result into the type\nassociated with the cursor. Unless you specify a type, the method uses the\nsame type that your collection is parameterized with. The following example shows how to implement this access pattern to\niterate through the results of a find operation on the  fruits \ncollection: You can call the  deserialize_current()  method only if the  advance() \nmethod returns a  true  result. The driver generates an error if you call\n deserialize_current()  on the cursor without a  true  result or\nwithout calling previously calling  advance() . You can access cursor results as a stream to retrieve individual documents\nor collect multiple documents at once. The  Cursor  type implements the  Stream  trait, so you can iterate\nthrough the cursor as a stream. This pattern may help you write more\nconcise code than the built-in pattern, because the  Stream  extension trait\n StreamExt  provides numerous functions to combine operations and\nconsolidate code. You can use the following methods to use the stream pattern: The following example shows how to implement the two stream methods to\niterate through the results of find operations on the  fruits \ncollection: next() : advances the cursor to the next result and returns an\n Option<Result<T>>  type try_next() : advances the cursor to the next result and returns\na  Result<Option<T>>  type To use the  next()  method, you must import the  StreamExt \ntrait. To use the  try_next()  method, you must import the\n TryStreamExt  trait. Because the  Cursor  type implements the  Stream  trait, you can\ncollect the results from a cursor into an array. You can use the following methods to retrieve documents as an array: collect() : collects results from a cursor into a\n Vec<Result<T>>  type try_collect() : collects results from a cursor into a\n Result<Vec<T>>  type To use the  collect()  method, you must import the  StreamExt \ntrait. To use the  try_collect()  method, you must import the\n TryStreamExt  trait. Avoid converting large sets of results to arrays. If the array exceeds\nthe size of available application memory, your application might crash.\nIf you expect a large result set, retrieve documents from the cursor individually.\nTo learn how to iterate through the cursor, see the  Retrieve Documents Individually  section of this guide. To modify the cursor that an operation returns, pass options to\nthe method that returns the  Cursor  instance. For example, you can\nspecify cursor-related options in a  FindOptions  type that you pass to the\n find()  method. The following table describes cursor-related options that you can set in\nan options instance: The following code shows how to construct a  FindOptions \ninstance and specify cursor-related settings: The Rust driver implements the Builder design pattern for the\ncreation of many different types, including  FindOptions . You can\nuse each type's  builder()  method to construct an options instance\nby chaining option builder functions one at a time. Setting Description batch_size cursor_type no_cursor_timeout Because the  Cursor  type implements the  Drop  trait, the\nserver closes a cursor when it goes out of scope. The server\nruns an asynchronous  killCursors  command to close the\ncursor. See  killCursors \nin the Server manual to learn more. To learn more about the operations in this guide, see the\nfollowing documentation: To learn more about converting between Rust types and BSON, see the\nguide on  Data Modeling and Serialization . Retrieve Data  guide Specify a Query  guide To learn more about the methods and types mentioned in this\nguide, see the following API documentation: Cursor advance() deserialize_current() next()  in the\n StreamExt  trait try_next()  in the\n TryStreamExt  trait collect()  in the\n StreamExt  trait try_collect()  in the\n TryStreamExt  trait find() FindOptions",
            "code": [
                {
                    "lang": "rust",
                    "value": "let docs = vec! [\n    Fruit { \n        name: \"strawberry\".to_string(), \n        color: \"red\".to_string() \n    },\n    Fruit { \n        name: \"banana\".to_string(), \n        color: \"yellow\".to_string() \n    },\n    Fruit { \n        name: \"pomegranate\".to_string(), \n        color: \"red\".to_string() \n    },\n    Fruit { \n        name: \"pineapple\".to_string(), \n        color: \"yellow\".to_string() \n    }\n];"
                },
                {
                    "lang": "rust",
                    "value": "let mut cursor = my_coll.find(doc! { \"color\": \"red\" }, None).await?;\nwhile cursor.advance().await? {\n    println!(\"{:?}\", cursor.deserialize_current()?);\n}"
                },
                {
                    "lang": "console",
                    "value": "Fruit { name: \"strawberry\", color: \"red\" }\nFruit { name: \"pomegranate\", color: \"red\" }"
                },
                {
                    "lang": "rust",
                    "value": "let mut cursor = my_coll.find(doc! { \"color\": \"red\" }, None).await?;\nprintln!(\"Output from next() iteration:\");\nwhile let Some(doc) = cursor.next().await {\n    println!(\"{:?}\", doc?);\n}\n\nprintln!();\nlet mut cursor = my_coll.find(doc! { \"color\": \"yellow\" }, None).await?;\nprintln!(\"Output from try_next() iteration:\");\nwhile let Some(doc) = cursor.try_next().await? {\n    println!(\"{:?}\", doc);\n}"
                },
                {
                    "lang": "console",
                    "value": "Output from next() iteration:\nFruit { name: \"strawberry\", color: \"red\" }\nFruit { name: \"pomegranate\", color: \"red\" }\n\nOutput from try_next() iteration:\nFruit { name: \"banana\", color: \"yellow\" }\nFruit { name: \"pineapple\", color: \"yellow\" }"
                },
                {
                    "lang": "rust",
                    "value": "let cursor = my_coll.find(doc! { \"color\": \"red\" }, None).await?;\nprintln!(\"Output from collect():\");\nlet v: Vec<Result<Fruit>> = cursor.collect().await;\nprintln!(\"{:?}\", v);\n\nprintln!();\nlet cursor = my_coll.find(doc! { \"color\": \"yellow\" }, None).await?;\nprintln!(\"Output from try_collect():\");\nlet v: Vec<Fruit> = cursor.try_collect().await?;\nprintln!(\"{:?}\", v);"
                },
                {
                    "lang": "console",
                    "value": "Output from collect():\n[Ok(Fruit { name: \"strawberry\", color: \"red\" }), Ok(Fruit { name: \"pomegranate\", color: \"red\" })]\n\nOutput from try_collect():\n[Fruit { name: \"banana\", color: \"yellow\" }, Fruit { name: \"pineapple\", color: \"yellow\" }]"
                },
                {
                    "lang": "rust",
                    "value": "let opts: FindOptions = FindOptions::builder()\n    .batch_size(5)\n    .cursor_type(CursorType::Tailable)\n    .no_cursor_timeout(true)\n    .build();"
                }
            ],
            "preview": "In this guide, you can learn how to use the Rust driver to access\ndata returned from a read operation or aggregation by using a cursor. A\ncursor is a mechanism that enables you to iterate through multiple documents\nwhile holding only a subset of them in memory at a given time.",
            "tags": "loop, retrieve, process, batch",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/crud/read-operations/change-streams",
            "title": "Open Change Streams",
            "headings": [
                "Overview",
                "Sample Data",
                "Open a Change Stream",
                "Example",
                "Apply Aggregation Operators to your Change Stream",
                "Example",
                "Include Pre-Images and Post-Images",
                "Create a Collection with Pre-Image and Post-Images Enabled",
                "Pre-Image Configuration Example",
                "Post-Image Configuration Example",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to use a  change stream  to monitor\nreal-time changes to your data. A change stream is a MongoDB Server feature\nthat allows your application to subscribe to data changes on a single\ncollection, database, or deployment. You can open a change stream to help perform the following actions: You can specify a set of aggregation operators to filter and transform the data\nthat your application receives. When connected to a MongoDB deployment v6.0 or later,\nyou can also configure the events to include the document data before and after the\nchange. To learn how to open and configure a change stream, navigate to the following\nsections: Enable devices to track and react to events, such as motion-detecting\ncameras Create an application that monitors changes in stock prices Generate a log of employee activity for specific job positions Sample Data Open a Change Stream Apply Aggregation Operators to your Change Stream Include Pre-Images and Post-Images Additional Information The examples in this guide monitor changes to the  directors  collection.\nAssume that this collection contains the following documents, which are modelled\nas structs: To learn how to insert documents into a collection, see the  Insert Documents \nguide. You can open a change stream to subscribe to specific types of data changes\nand produce change events in your application. To open a change stream, call the  watch()  method on a  Collection ,\n Database , or  Client  instance. The struct type on which you call the  watch()  method determines the scope of\nevents that the change stream listens for. The following table describes the\nbehavior of the  watch()  method based on its calling object: Standalone MongoDB deployments don't support change streams because\nthe feature requires a replica set oplog. To learn more about the oplog,\nsee the  Replica Set Oplog  page in the Server manual. Struct Type Behavior of  watch() Collection Database Client The following example opens a change stream on the  directors  collection.\nThe code prints the operation type and modified document of each change event by\naccessing the  operation_type  and  full_document  fields of each  ChangeStreamEvent \ninstance: If you insert a document into the  directors  collection in which the  name  value\nis  \"Wes Anderson\" , the preceding code produces the following output: For a full list of  ChangeStreamEvent  struct fields, see  ChangeStreamEvent  in the API documentation. You can pass an aggregation pipeline as a parameter to the  watch()  method\nto specify which change events the change stream receives. To learn which aggregation operators your MongoDB Server version supports, see\n Modify Change Stream Output  in the Server manual. The following example creates an aggregation pipeline to filter for update\noperations. Then, the code passes the pipeline to the  watch()  method,\nconfiguring the change stream to only receive and print change events for\nupdate operations: If you update the document in which the  name  value is  \"Todd Haynes\" \nby increasing the value of the  oscar_noms  field, the preceding code\nproduces the following output: To learn how to perform update operations, see the  Modify Documents \nguide. You can configure the change event to contain or omit the following data: To receive change stream events that include a pre-image or post-image, you\nmust perform the following actions: Pre-image : a document that represents the version of the\ndocument before the operation, if it exists Post-image : a document that represents the version of the\ndocument after the operation, if it exists You can enable pre- and post-images on collections only if your\ndeployment uses MongoDB v6.0 or later. Enable pre-images and post-images for the collection on your MongoDB\ndeployment. To learn how to enable pre- and post-images on your deployment, see\n Change Streams with Document Pre- and Post-Images \nin the Server manual. To learn how to instruct the driver to create a collection with pre-images\nand post-images enabled, see the  Create a Collection with Pre-Image and Post-Images Enabled \nsection of this page. Configure your change stream to retrieve either or both the pre-images and\npost-images. During this configuration, you can instruct the driver to require\npre- and post-images or to only include them when available. To configure your change stream to record the pre-image in change\nevents, see the  Pre-Image Configuration Example  on this page. To configure your change stream to record the post-image in change\nevents, see the  Post-Image Configuration Example  on this page. To create a collection with the pre-image and post-image documents enabled,\nconfigure this option in a  CreateCollectionOptions  struct instance. To begin\nbuilding a  CreateCollectionOptions  instance, call the  CreateCollectionOptions::builder() \nmethod. When configuring your  CreateCollectionOptions  instance, you must use the\n change_stream_pre_and_post_images()  builder method. The following example\nuses this builder method to specify collection options and creates a\ncollection for which pre- and post-images are available: You can change the pre-image and post-image option in an existing collection\nby running the  collMod  command from the MongoDB Shell or from your application.\nTo learn how to perform this operation, see the  Run a Command  guide\nand the entry on  collMod  in the Server manual. The Rust driver implements the Builder design pattern for the\ncreation of many different types, including  CreateCollectionOptions . You\ncan use the  builder()  method to construct an instance of each type\nby chaining option builder methods. If you enabled pre-images or post-images on a collection, modifying\nthese settings with  collMod  can cause existing change streams on\nthat collection to terminate. To configure a change stream that returns change events containing the pre-image,\nspecify a  ChangeStreamOptions  struct instance. To begin building a  ChangeStreamOptions \ninstance, call the  ChangeStreamOptions::builder()  method. When configuring your  ChangeStreamOptions  instance to return the pre-image document,\nyou must use the  full_document_before_change()  builder method. The following example\nspecifies change stream options and creates a change stream that returns pre-image\ndocuments: The preceding example passes a value of  FullDocumentBeforeChangeType::Required \nto the  full_document_before_change()  builder method. This option configures the change\nstream to require pre-images for replace, update, and delete change events. If the pre-image\nis not available, the driver raises an error. If you update a document in which the  name  value is  \"Jane Campion\" , the change event\nproduces the following output: To configure a change stream that returns change events containing the post-image,\nspecify a  ChangeStreamOptions  struct instance. To begin building a  ChangeStreamOptions \ninstance, call the  ChangeStreamOptions::builder()  method. When configuring your  ChangeStreamOptions  instance to return the post-image document,\nyou must use the  full_document()  builder method. The following example specifies change\nstream options and creates a change stream that returns post-image documents: The preceding example passes a value of  FullDocument::WhenAvailable  to the  full_document() \nbuilder method. This option configures the change stream to return post-images for replace, update,\nand delete change events if the post-image is available. If you delete the document in which the value of  name  is  \"Todd Haynes\" , the\nchange event produces the following output: To learn more about any of the methods or types mentioned in this\nguide, see the following API documentation: watch() CreateCollectionOptions ChangeStreamOptions FullDocumentBeforeChangeType FullDocumentType",
            "code": [
                {
                    "lang": "rust",
                    "value": "let docs = vec! [\n    Director {\n        name: \"Todd Haynes\".to_string(),\n        movies: vec! [\"Far From Heaven\".to_string(), \"Carol\".to_string()],\n        oscar_noms: 1,\n    },\n    Director {\n        name: \"Jane Campion\".to_string(),\n        movies: vec! [\"The Piano\".to_string(), \"Bright Star\".to_string()],\n        oscar_noms: 5,\n    }\n];"
                },
                {
                    "lang": null,
                    "value": "Operation performed: Insert\nDocument: Some(Director { name: \"Wes Anderson\", movies: [...], oscar_noms: 7 })"
                },
                {
                    "lang": "rust",
                    "value": "let mut change_stream = my_coll.watch(None, None).await?;\n\nwhile let Some(event) = change_stream.next().await.transpose()? {\n    println!(\"Operation performed: {:?}\", event.operation_type);\n    println!(\"Document: {:?}\", event.full_document);\n}"
                },
                {
                    "lang": null,
                    "value": "Update performed: Some(UpdateDescription { updated_fields: Document({\n\"oscar_noms\": Int64(2)}), removed_fields: [], truncated_arrays: Some([]) })"
                },
                {
                    "lang": "rust",
                    "value": "let pipeline = vec![\n    doc! { \"$match\" : doc! { \"operationType\" : \"update\" } }\n];\n\nlet mut update_change_stream = my_coll.watch(pipeline, None).await?;\nwhile let Some(event) = update_change_stream.next().await.transpose()? {\n    println!(\"Update performed: {:?}\", event.update_description);\n}"
                },
                {
                    "lang": "rust",
                    "value": "let enable = ChangeStreamPreAndPostImages::builder().enabled(true).build();\nlet opts = CreateCollectionOptions::builder()\n    .change_stream_pre_and_post_images(enable)\n    .build();\n\nlet result = my_db.create_collection(\"directors\", opts).await?;"
                },
                {
                    "lang": null,
                    "value": "Operation performed: Update\nPre-image: Some(Director { name: \"Jane Campion\", movies: [\"The Piano\",\n\"Bright Star\"], oscar_noms: 5 })"
                },
                {
                    "lang": "rust",
                    "value": "let pre_image = Some(FullDocumentBeforeChangeType::Required);\nlet opts = ChangeStreamOptions::builder()\n    .full_document_before_change(pre_image)\n    .build();\n\nlet mut change_stream = my_coll.watch(None, opts).await?;\nwhile let Some(event) = change_stream.next().await.transpose()? {\n    println!(\"Operation performed: {:?}\", event.operation_type);\n    println!(\"Pre-image: {:?}\", event.full_document_before_change);\n}"
                },
                {
                    "lang": null,
                    "value": "Operation performed: Delete\nPost-image: None"
                },
                {
                    "lang": "rust",
                    "value": "let post_image = Some(FullDocumentType::WhenAvailable);\nlet opts = ChangeStreamOptions::builder()\n    .full_document(post_image)\n    .build();\n\nlet mut change_stream = my_coll.watch(None, opts).await?;\nwhile let Some(event) = change_stream.next().await.transpose()? {\n    println!(\"Operation performed: {:?}\", event.operation_type);\n    println!(\"Post-image: {:?}\", event.full_document);\n}"
                }
            ],
            "preview": "In this guide, you can learn how to use a change stream to monitor\nreal-time changes to your data. A change stream is a MongoDB Server feature\nthat allows your application to subscribe to data changes on a single\ncollection, database, or deployment.",
            "tags": "monitor, delta, code example",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/crud/compound-operations",
            "title": "Compound Operations",
            "headings": [
                "Overview",
                "Sample Data for Examples",
                "Find and Delete a Document",
                "Modify Find and Delete Behavior",
                "Find and Delete Example",
                "Find and Update a Document",
                "Modify Find and Update Behavior",
                "Find and Update Example",
                "Find and Replace a Document",
                "Modify Find and Replace Behavior",
                "Find and Replace Example",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to use the Rust driver to perform\n compound operations . Compound operations combine the functionality of read and write\noperations into one  atomic  action. If you perform\na read operation and a write operation in sequence, someone might change\nyour target document between the operations, leading to unexpected\nresults. When you perform a compound operation, MongoDB prevents\nintermediate data changes by placing a write lock on the document you\nare modifying until the operation completes. You can perform the following compound operations with the driver: This guide includes the following sections: Find and delete one document Find and update one document Find and replace one document Sample Data for Examples  presents\nthe sample data that is used by the compound operation examples Find and Delete a Document  describes\nhow to find and delete a document in a single operation Find and Update a Document  describes\nhow to find and update a document in a single operation Find and Replace a Document  describes\nhow to find and replace a document in a single operation Additional Information \nprovides links to resources and API documentation for types\nand methods mentioned in this guide To learn how to perform atomic read and write operations on more than one\ndocument at a time, see the  Transactions  guide. The examples in this guide use the following sample documents. Each\ndocument represents a student and contains information about their age\nand the school that they attend: The  find_one_and_delete()  method finds and deletes the first document that\nmatches the specified query filter. If a document matches the filter\ncriteria, the method returns a  Some  type. If no documents match,\nit returns a  None  type. If you want to perform other operations between finding and deleting\na document, you can call the  find_one()  method followed by the\n delete_one()  method. You can optionally modify the behavior of the  find_one_and_delete() \nmethod by passing a  FineOneAndDeleteOptions  instance as a parameter.\nTo use default values for each setting, specify the value  None  for\nthe options parameter. The following table describes the options available in\n FineOneAndDeleteOptions : The Rust driver implements the Builder design pattern for the\ncreation of a  FindOneAndDeleteOptions  instance. You can use the\ntype's  builder()  method to construct an options instance by\nchaining option builder functions one at a time. The following code shows how to construct a  FindOneAndDeleteOptions \ninstance and pass it to the  find_one_and_delete()  method: Option Description max_time projection sort write_concern collation hint let_vars comment The following example uses the  find_one_and_delete()  method\nto match and delete the first document where the value of the  age \nfield is less than or equal to  10 : The  find_one_and_update()  method finds and updates the first\ndocument that matches the specified query filter. The operation updates\nthe document based on the specifications you provide in an update\ndocument. If a document matches the filter criteria, the method returns\na  Some  type. If no documents match, it returns a  None  type. If you want to perform other operations between finding and updating\na document, you can call the  find_one()  method followed by the\n update_one()  method. You can optionally modify the behavior of the  find_one_and_update() \nmethod by passing a  FindOneAndUpdateOptions  instance as a parameter.\nTo use default values for each setting, specify the value  None  for\nthe options parameter. The following table describes the options available in\n FineOneAndDeleteOptions : The Rust driver implements the Builder design pattern for the\ncreation of a  FindOneAndUpdateOptions  instance. You can use the\ntype's  builder()  method to construct an options instance by\nchaining option builder methods one at a time. The following code shows how to construct a  FindOneAndUpdateOptions \ninstance and pass it to the  find_one_and_update()  method: Option Description array_filters bypass_document_validation max_time projection return_document sort upsert write_concern collation hint let_vars comment This example shows how to call the  find_one_and_update()  method with the\nfollowing parameters: A query filter that matches a document where the value of  school \nis  \"Aurora High School\" An update document that sets the  school  field to  \"Durango High School\" \nand increments the  age  field by  1 A  FindOneAndUpdateOptions  instance that returns the document\n after  the update The  find_one_and_replace()  method finds and replaces the first\ndocument that matches the specified query filter. The operation replaces\nall the fields of the document except the  _id  field with fields\nand values that you provide. If a document matches the filter criteria,\nthe method returns a  Some  type. If no documents match, it returns a\n None  type. If you want to perform other operations between finding and replacing\na document, you can call the  find_one()  method followed by the\n replace_one()  method. You can optionally modify the behavior of the  find_one_and_replace() \nmethod by passing a  FindOneAndReplaceOptions  instance as a parameter.\nTo use default values for each setting, specify the value  None  for\nthe options parameter. The following table describes the options available in\n FindOneAndReplaceOptions : The Rust driver implements the Builder design pattern for the\ncreation of a  FindOneAndReplaceOptions  instance. You can use the\ntype's  builder()  method to construct an options instance by\nchaining option builder functions one at a time. The following code shows how to construct a  FindOneAndReplaceOptions \ninstance and pass it to the  find_one_and_replace()  method: Option Description bypass_document_validation max_time projection return_document sort upsert write_concern collation hint let_vars comment This example shows how to call the  find_one_and_replace()  method with the\nfollowing parameters: A query filter that matches a document where the value of  name \nincludes the string  \"Johnson\" A replacement document that describes a new student A  FindOneAndReplaceOptions  instance that returns the document\nafter replacement and projects only the  name  and  school  fields\nin the output To learn more about the operations in this guide, see the\nfollowing documentation: Retrieve Data Delete Documents Modify Documents To learn more about the methods and types mentioned in this\nguide, see the following API documentation: find_one_and_delete() FindOneAndDeleteOptions find_one_and_update() FindOneAndUpdateOptions ReturnDocument find_one_and_replace() FindOneAndReplaceOptions",
            "code": [
                {
                    "lang": "json",
                    "value": "{ \"name\": \"Alex Johnson\", \"age\": 8, \"school\": \"Lakeside Elementary\" },\n{ \"name\": \"Samara Khan\", \"age\": 11, \"school\": \"Rolling Hills Middle School\" },\n{ \"name\": \"Ben Joseph\", \"age\": 16, \"school\": \"Aurora High School\" },\n{ \"name\": \"Deanna Porowski\", \"age\": 10, \"school\": \"Lakeside Elementary\" }"
                },
                {
                    "lang": "rust",
                    "value": "let opts = FindOneAndDeleteOptions::builder().comment(bson!(\"hello\")).build();\nlet res = my_coll.find_one_and_delete(filter, opts).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"age\": doc! { \"$lte\": 10 } };\n\nlet res = my_coll.find_one_and_delete(filter, None).await?;\nprintln!(\"Deleted document:\\n{:?}\", res);"
                },
                {
                    "lang": "console",
                    "value": "Deleted document:\nSome(Document({\"_id\": ObjectId(\"...\"),\n\"name\": String(\"Deanna Porowski\"), \"age\": Int32(10), \"school\":\nString(\"Lakeside Elementary\")}))"
                },
                {
                    "lang": "rust",
                    "value": "let opts = FindOneAndUpdateOptions::builder().comment(bson!(\"hello\")).build();\nlet res = my_coll.find_one_and_update(filter, update, opts).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"school\": \"Aurora High School\" };\nlet update =\n    doc! { \"$set\": doc! { \"school\": \"Durango High School\" },\n           \"$inc\": doc! { \"age\": 1 } };\nlet opts = FindOneAndUpdateOptions::builder()\n    .return_document(Some(ReturnDocument::After))\n    .build();\n\nlet res = my_coll.find_one_and_update(filter, update, opts).await?;\nprintln!(\"Updated document:\\n{:?}\", res);"
                },
                {
                    "lang": "console",
                    "value": "Updated document:\nSome(Document({\"_id\": ObjectId(\"...\"),\n\"name\": String(\"Ben Joseph\"), \"age\": Int32(17), \"school\":\nString(\"Durango High School\")}))"
                },
                {
                    "lang": "rust",
                    "value": "let opts = FindOneAndReplaceOptions::builder().comment(bson!(\"hello\")).build();\nlet res = my_coll.find_one_and_replace(filter, replacement, opts).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"name\": doc! { \"$regex\": \"Johnson\" } };\nlet replacement =\n    doc! { \"name\": \"Toby Fletcher\", \n           \"age\": 14,\n           \"school\": \"Durango High School\" };\nlet opts = FindOneAndReplaceOptions::builder()\n    .return_document(Some(ReturnDocument::After))\n    .projection(doc! { \"name\": 1, \"school\": 1, \"_id\": 0 })\n    .build();\n\nlet res = my_coll.find_one_and_replace(filter, replacement, opts).await?;\nprintln!(\"Document after replacement:\\n{:?}\", res);"
                },
                {
                    "lang": "console",
                    "value": "Document after replacement:\nSome(Document({\"name\": String(\"Toby Fletcher\"), \"school\":\nString(\"Durango High School\")}))"
                }
            ],
            "preview": "In this guide, you can learn how to use the Rust driver to perform\ncompound operations.",
            "tags": "write lock, code example",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/crud/read-operations/retrieve",
            "title": "Retrieve Data",
            "headings": [
                "Overview",
                "Sample Data for Examples",
                "Find Operations",
                "Find All Matching Documents",
                "Find One Document",
                "Modify Find Behavior",
                "Examples",
                "find() Example",
                "find_one() Example",
                "Aggregation Operations",
                "Aggregate Document Data",
                "Modify Aggregation Behavior",
                "Example",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to retrieve data from your MongoDB\ncollections using  read operations . Read operations are commands that\nretrieve documents from the server. There are two types of read operations: This guide includes the following sections: Find operations, which allow you to retrieve documents from your collections Aggregation operations, which allow you to transform the data in your collections Sample Data for Examples  presents\nthe sample data that is used by the read operation examples Find Operations  describes how to use the\ndriver to execute find operations Aggregation Operations  describes how to use the\ndriver to execute aggregation operations Additional Information \nprovides links to resources and API documentation for types\nand methods mentioned in this guide The examples in this guide use the following sample documents. Each\ndocument represents an item in a store's inventory and contains\ninformation about its categorization and unit price: Use find operations to retrieve data from MongoDB. Find operations\nconsist of the  find()  and  find_one()  methods. To find  all the documents  that match your criteria, use the\n find()  method. This method takes a query filter as a parameter. A\nquery filter consists of the fields and values that form criteria for\ndocuments to match. The method returns a  Cursor  type that you can iterate through to\nretrieve any documents that match the filter criteria. To see an example that uses this method to retrieve data, see\nthe  find() example . To learn more about specifying a query, see the  Specify a Query  guide. To find  the first document  that matches your criteria, use the\n find_one()  method. This method takes a query filter as a parameter. A\nquery filter consists of the fields and values that form criteria for\ndocuments to match. If a document matches the filter criteria, the method returns a\n Result<Option<T>>  type with a value of  Some . If no documents\nmatch the filter criteria,  find_one()  returns a  Result<Option<T>> \ntype with a value of  None . To see an example that uses this method to retrieve data, see\nthe  find_one() example . You can modify the behavior of  find()  by passing\na  FindOptions  instance as a parameter, and you can modify the\nbehavior of  find_one()  by passing a  FindOneOptions  instance. To use default values for each setting, specify the value  None  as\nthe options parameter. The following table describes commonly used settings that you can specify in\n FindOptions  and  FindOneOptions : For a full list of settings you can specify for each type, see the API\ndocumentation for  FindOptions  and  FindOneOptions . Setting Description collation hint projection read_concern skip sort The Rust driver implements the Builder design pattern for the\ncreation of many different types, such as  FindOneOptions  or\n FindOptions . You can use each type's  builder()  method to\nconstruct an options instance by chaining option builder functions\none at a time. The following sections contain examples that use the  find()  and\n findOne()  methods to retrieve sample documents that match filter\ncriteria. This example shows how to call the  find()  method with the\nfollowing parameters: A query filter that matches documents where the value of  unit_price \nis less than  12.00  and the value of  category  is not  \"kitchen\" A  FindOptions  instance that sorts matched documents by\n unit_price  in descending order This example shows how to call the  find_one()  method with the\nfollowing parameters: A query filter that matches documents where the value of  unit_price \nis less than or equal to  20.00 A  FindOneOptions  instance that skips the first two matched documents Use aggregation operations to retrieve and transform data from your\ncollections. You can perform aggregation operations by using the  aggregate() \nmethod. The  aggregate()  method takes an  aggregation pipeline  as a\nparameter. An aggregation pipeline includes one or more  stages  that\nspecify how to transform data. A stage includes an aggregation operator\n(prefixed with a  $ ) and any required parameters for that operator. To learn more about aggregations and view aggregation examples, see the  Aggregation  guide. The method returns the resulting documents in a  Cursor  type. If\nyour aggregation pipeline does not contain a  $match  stage, the pipeline processes\nall the documents in the collection. You can modify the behavior of  aggregate()  by passing\nan  AggregateOptions  instance as an optional parameter. To use default values for each setting, specify the value  None  as\nthe options parameter. The following table describes commonly used settings that you can specify in\n AggregateOptions : For a full list of settings, see the API\ndocumentation for  AggregateOptions . Setting Description allow_disk_use batch_size collation hint read_concern write_concern This example shows how to call the  aggregate()  method with a\npipeline that contains the following stages: A  $group  stage to group documents by the  category  field and\ncalculate the average of the  unit_price  field by  category A  $sort  stage to by  avg_price  in ascending order For runnable examples of the find operations, see the following usage\nexamples: To learn more about the operations in this guide, see the\nfollowing documentation: Find a Document Find Multiple Documents Specify a Query  guide Access Data by Using a Cursor  guide Aggregation  guide To learn more about the methods and types mentioned in this\nguide, see the following API documentation: find_one() find() FindOptions FindOneOptions Cursor aggregate() AggregateOptions",
            "code": [
                {
                    "lang": "rust",
                    "value": "let docs = vec! [\n    Inventory {\n        item: \"candle\".to_string(),\n        category: \"decor\".to_string(),\n        unit_price: 2.89,\n    },\n    Inventory {\n        item: \"blender\".to_string(),\n        category: \"kitchen\".to_string(),\n        unit_price: 38.49,\n    },\n    Inventory {\n        item: \"placemat\".to_string(),\n        category: \"kitchen\".to_string(),\n        unit_price: 3.19,\n    },\n    Inventory {\n        item: \"watering can\".to_string(),\n        category: \"garden\".to_string(),\n        unit_price: 11.99,\n    }\n];"
                },
                {
                    "lang": "rust",
                    "value": "let opts = FindOptions::builder()\n    .sort(doc! { \"unit_price\": -1 })\n    .build();\n\nlet mut cursor = my_coll.find(\n    doc! { \"$and\": vec!\n        [\n            doc! { \"unit_price\": doc! { \"$lt\": 12.00 } },\n            doc! { \"category\": doc! { \"$ne\": \"kitchen\" } }\n        ] },\n    opts\n).await?;\n\nwhile let Some(result) = cursor.try_next().await? {\n    println!(\"{:?}\", result);\n};\n"
                },
                {
                    "lang": "console",
                    "value": "Inventory { item: \"watering can\", category: \"garden\", unit_price: 11.99 }\nInventory { item: \"candle\", category: \"decor\", unit_price: 2.89 }"
                },
                {
                    "lang": "rust",
                    "value": "let opts = FindOneOptions::builder().skip(2).build();\nlet result = my_coll.find_one(\n    doc! { \"unit_price\":\n        doc! { \"$lte\": 20.00 } },\n    opts\n).await?;\n\nprintln!(\"{:#?}\", result);"
                },
                {
                    "lang": "console",
                    "value": "Some(\n    Inventory {\n        item: \"watering can\",\n        category: \"garden\",\n        unit_price: 11.99,\n    },\n)"
                },
                {
                    "lang": "rust",
                    "value": "let pipeline = vec![\n    doc! { \"$group\": doc! { \"_id\" : doc! {\"category\": \"$category\"} ,\n                            \"avg_price\" : doc! { \"$avg\" : \"$unit_price\" } } },\n    doc! { \"$sort\": { \"_id.avg_price\" : 1 } }\n];\n\nlet mut cursor = my_coll.aggregate(pipeline, None).await?;\nwhile let Some(result) = cursor.try_next().await? {\n    println!(\"{:?}\", result);\n};"
                },
                {
                    "lang": "console",
                    "value": "Document({\"_id\": Document({\"category\": String(\"decor\")}), \"avg_price\": Double(2.890000104904175)})\nDocument({\"_id\": Document({\"category\": String(\"kitchen\")}), \"avg_price\": Double(20.840000867843628)})\nDocument({\"_id\": Document({\"category\": String(\"garden\")}), \"avg_price\": Double(11.989999771118164)})"
                }
            ],
            "preview": "In this guide, you can learn how to retrieve data from your MongoDB\ncollections using read operations. Read operations are commands that\nretrieve documents from the server.",
            "tags": "find one, find many, pipeline, code example",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/crud/read-operations/text-search",
            "title": "Search Text",
            "headings": [
                "Overview",
                "Sample Data for Examples",
                "Text Index",
                "Text Search",
                "Search for a Term",
                "Example",
                "Search for a Phrase",
                "Example",
                "Exclude Terms from Search",
                "Example",
                "Sort by Relevance",
                "Example",
                "Aggregation",
                "Match a Search Term",
                "Sort by Relevance",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to use the Rust driver to run a text search.\nA text search allows you to efficiently query fields with string values. This guide includes the following sections: MongoDB text search differs from the more powerful Atlas Search\nfeature. To learn more, see the  Atlas Search documentation . Sample Data for Examples  presents\nthe sample data that is used by the text search examples Text Index  describes how to create a text\nindex on a string-valued field Text Search  describes how to perform text\nsearches with different search criteria Aggregation  describes how to\nperform text searches by using aggregation pipelines Additional Information \nprovides links to resources and API documentation for types\nand methods mentioned in this guide The examples in this guide use the following  Dish  struct as a model\nfor documents in the  menu  collection: The examples use the following sample documents that describe\ndishes you can order at a restaurant: Before you perform a text search, you must create a  text index  on\nthe collection. A text index specifies the string or string array field\non which you can perform text searches. The examples in this guide perform text searches on the\n description  field of documents in the  menu  collection. To enable\ntext searches on the  description  field, create a text index as shown\nin the following code: A text search retrieves documents that contain a specified  term  or\n phrase  in the value of the indexed field. A term is a sequence of\ncharacters that excludes whitespace characters. A phrase is a sequence\nof terms with any number of whitespace characters. To perform a text search, include the  $text  evaluation query operator,\nfollowed by the  $search  field in your query filter. The  $text  operator\nspecifies that you are performing a text search on the text-indexed\nfields. The  $search  field specifies the term or phrase to search for\nin the text-indexed field or fields. Query filters for text searches use the following format: To search for a term, specify the term as a string in your query filter.\nTo search for multiple terms, separate each term with a space. When searching for multiple terms, the  find()  method returns any\ndocument in which the text-indexed field or fields contain at least\none of the terms. For example, if your search terms are  \"one two\nthree\" , MongoDB returns documents in which the indexed field\ncontains  \"one\" ,  \"two\" ,  \"three\" , or more than one of these terms. The following example performs a search for documents in which the\n description  field contains the term  \"herb\" : Even though the search term is  \"herb\" , the text search also matches\ndocuments in which the  description  field contains  \"herbs\" .\nThis is because a MongoDB text index uses suffix stemming to match\nsimilar words. To learn more about how MongoDB matches terms, see\n Index Entries  in the\nServer manual. To search for a phrase, specify the phrase with escaped quotes in your\nquery filter: If you don't add escaped quotes around the phrase, the\nsearch performs a  term search . The following example performs a search for documents in which the\n description  field contains the phrase  \"serves 2\" : To specify a term or phrase you want to exclude from your text search,\nprefix it with a minus sign in your query filter: You must search for at least one term or phrase to exclude\nother terms from your search. If you only exclude terms, the\nsearch doesn't return any documents. The following example performs a search for documents in which the\n description  field contains the term  \"vegan\" , but does not\ncontain the term  \"tofu\" : A text search assigns a numerical text score to indicate how closely\neach result matches the string in your query filter. A higher text score\nindicates that the result is more relevant to your query. To reveal the text\nscore in your output, use a projection to retrieve the  textScore \nfield from the metadata. You can sort the text score in descending order\nby specifying a sort on the  textScore  metadata field. This example performs the following actions: Performs a search for documents in which the  description  field contains the term  \"vegetarian\" Sorts the results in descending order on text score Includes only the  name  and  score  fields in the output You can include the  $text  evaluation query operator in a\n $match  aggregation\nstage to perform a text search in an aggregation pipeline. The following sections demonstrate how to perform text searches by using\naggregation pipelines instead of the  find()  method. The following example uses an aggregation to perform a search for\ndocuments in which the  description  field contains the term\n \"herb\" : This example uses an aggregation to perform the following actions: Performs a search for documents in which the  description  field contains the term  \"vegetarian\" Sorts the results in descending order on text score Includes only the  name  and  score  fields in the output For a runnable example that uses the  find()  method, see the\n Find Multiple Documents  usage example. To learn more about the operations in this guide, see the\nfollowing documentation: Specify a Query Retrieve Data Aggregation Indexes Text Indexes  in the Server manual $text  in the Server manual $meta  in the Server manual To learn more about the methods and types mentioned in this\nguide, see the following API documentation: find() FindOptions Cursor clone_with_type() aggregate()",
            "code": [
                {
                    "lang": "json",
                    "value": "{ \"name\": \"Shepherd\u2019s Pie\", \"description\": \"A vegetarian take on the classic dish that uses lentils as a base. Serves 2.\" },\n{ \"name\": \"Green Curry\", \"description\": \"A flavorful Thai curry, made vegetarian with tofu. Vegetarian and vegan friendly.\" },\n{ \"name\": \"Herbed Branzino\", \"description\": \"Grilled whole fish stuffed with herbs and pomegranate seeds. Serves 3-4.\" },\n{ \"name\": \"Kale Tabbouleh\", \"description\": \"A bright, herb-based salad. A perfect starter for vegetarians and vegans.\" },\n{ \"name\": \"Garlic Butter Trout\", \"description\": \"Baked trout seasoned with garlic, lemon, dill, and, of course, butter. Serves 2.\" }"
                },
                {
                    "lang": "rust",
                    "value": "#[derive(Serialize, Deserialize, Debug)]\nstruct Dish {\n    name: String,\n    description: String,\n}"
                },
                {
                    "lang": "rust",
                    "value": "let index = IndexModel::builder()\n    .keys(doc! { \"description\": \"text\" })\n    .build();\n\nlet idx_res = my_coll.create_index(index, None).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"$text\": { \"$search\": \"<search term or phrase>\" } };"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"$text\": { \"$search\": \"herb\" } };\n\nlet mut cursor = my_coll.find(filter, None).await?;\nwhile let Some(doc) = cursor.try_next().await? {\n    println!(\"{:?}\", doc);\n}"
                },
                {
                    "lang": "none",
                    "value": "Dish { name: \"Kale Tabbouleh\", description: \"A bright, herb-based salad. A perfect starter for vegetarians and vegans.\" }\nDish { name: \"Herbed Branzino\", description: \"Grilled whole fish stuffed with herbs and pomegranate seeds. Serves 3-4.\" }"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"$text\": { \"$search\": \"\\\"<some phrase>\\\"\" } };"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"$text\": { \"$search\": \"\\\"serves 2\\\"\" } };\n\nlet mut cursor = my_coll.find(filter, None).await?;\nwhile let Some(doc) = cursor.try_next().await? {\n    println!(\"{:?}\", doc);\n}"
                },
                {
                    "lang": "none",
                    "value": "Dish { name: \"Shepherd\u2019s Pie\", description: \"A vegetarian take on the classic dish that uses lentils as a base. Serves 2.\" }\nDish { name: \"Garlic Butter Trout\", description: \"Baked trout seasoned with garlic, lemon, dill, and, of course, butter. Serves 2.\" }"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"$text\": { \"$search\": \"<term> -<excluded term>\" } };"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"$text\": { \"$search\": \"vegan -tofu\" } };\n\nlet mut cursor = my_coll.find(filter, None).await?;\nwhile let Some(doc) = cursor.try_next().await? {\n    println!(\"{:?}\", doc);\n}"
                },
                {
                    "lang": "none",
                    "value": "Dish { name: \"Kale Tabbouleh\", description: \"A bright, herb-based salad. A perfect starter for vegetarians and vegans.\" }"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"$text\": { \"$search\": \"vegetarian\" } };\n\nlet sort = doc! { \"score\": { \"$meta\": \"textScore\" } };\nlet projection =\n    doc! { \n    \"_id\": 0, \n    \"name\": 1, \n    \"score\": { \"$meta\": \"textScore\" } \n};\nlet opts = FindOptions::builder().sort(sort).projection(projection).build();\n\nlet doc_coll: Collection<Document> = my_coll.clone_with_type();\nlet mut cursor = doc_coll.find(filter, opts).await?;\n\nwhile let Some(doc) = cursor.try_next().await? {\n    println!(\"{:?}\", doc);\n}"
                },
                {
                    "lang": "none",
                    "value": "Document({\"name\": String(\"Green Curry\"), \"score\": Double(0.9166666666666667)})\nDocument({\"name\": String(\"Kale Tabbouleh\"), \"score\": Double(0.5625)})\nDocument({\"name\": String(\"Shepherd\u2019s Pie\"), \"score\": Double(0.5555555555555556)})"
                },
                {
                    "lang": "rust",
                    "value": "let match_stage = doc! { \"$match\": { \"$text\": { \"$search\": \"herb\" } } };\n\nlet mut cursor = my_coll.aggregate([match_stage], None).await?;\nwhile let Some(doc) = cursor.try_next().await? {\n    println!(\"{:?}\", doc);\n}"
                },
                {
                    "lang": "none",
                    "value": "Document({\"_id\": ObjectId(\"...\"), \"name\": String(\"Kale Tabbouleh\"), \"description\": String(\"A bright, herb-based salad. A perfect starter for vegetarians and vegans.\")})\nDocument({\"_id\": ObjectId(\"...\"), \"name\": String(\"Herbed Branzino\"), \"description\": String(\"Grilled whole fish stuffed with herbs and pomegranate seeds. Serves 3-4.\")})"
                },
                {
                    "lang": "rust",
                    "value": "let match_stage = doc! { \"$match\": { \"$text\": { \"$search\": \"vegetarian\" } } };\nlet sort_stage = doc! { \"$sort\": { \"score\": { \"$meta\": \"textScore\" } } };\nlet proj_stage =\n    doc! { \"$project\": { \n    \"_id\": 0, \n    \"name\": 1, \n    \"score\": { \"$meta\": \"textScore\" } \n} };\n\nlet pipeline = [match_stage, sort_stage, proj_stage];\nlet mut cursor = my_coll.aggregate(pipeline, None).await?;\nwhile let Some(doc) = cursor.try_next().await? {\n    println!(\"{:?}\", doc);\n}"
                },
                {
                    "lang": "none",
                    "value": "Document({\"name\": String(\"Green Curry\"), \"score\": Double(0.9166666666666667)})\nDocument({\"name\": String(\"Kale Tabbouleh\"), \"score\": Double(0.5625)})\nDocument({\"name\": String(\"Shepherd\u2019s Pie\"), \"score\": Double(0.5555555555555556)})"
                }
            ],
            "preview": "In this guide, you can learn how to use the Rust driver to run a text search.\nA text search allows you to efficiently query fields with string values.",
            "tags": "code example, full text, string search",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/crud/read-operations/query",
            "title": "Specify a Query",
            "headings": [
                "Overview",
                "Sample Data",
                "Literal Values",
                "Comparison",
                "Example",
                "Logical",
                "Example",
                "Element",
                "Example",
                "Evaluation",
                "Example",
                "Bitwise",
                "Example",
                "Array",
                "Example",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to specify a query to match a subset\nof documents. To match a subset of documents, specify a  query filter  containing\nyour  match criteria . Match criteria consist of the fields and\nvalues you want documents to match. A query filter contains at least\none set of match criteria to determine which documents to return. If you\nuse an empty query filter in a find operation, the driver matches all\nthe documents in the collection. In a query filter, you can match fields with  literal values  or with query operators. Query operators allow\nyou to perform mathematical or logical operations to locate documents within a collection. To match documents by using literal values, use the following format: To create match criteria that include query operators, use the following\nformat: The examples in the following sections show how to specify queries by\nusing the  find()  method to match documents in a collection. This guide includes the following sections: Sample Data for Examples  presents\nthe sample data that is used by the query examples Literal Values  describes how to\nquery for data that exactly matches a value you provide in the query\nfilter Comparison  describes how to\nquery for data based on comparisons with values in a collection Logical  describes how to\nquery for data using logic applied to the results of field-level operators Element  describes how to\nquery based on the presence, absence, or type of field Evaluation  describes how\nto execute higher-level logic, like regex and text searches, when\nquerying for documents in a collection Bitwise  describes how to\nquery based on the equivalent bits set of a base-10 value Array  describes how to query\na collection based on data within an array-valued field Additional Information \nprovides links to resources and API documentation for types\nand methods mentioned in this guide The examples in this guide use the following sample documents. Each\ndocument represents a fruit in a store's inventory and contains\ninformation about its quantity. Some documents contain fields\nthat describe the fruit or its vendors. The examples in the following sections query a collection of documents described by\n Fruit  structs: Literal value query filters allow you to query for data that exactly matches\na value you provide in the query filter. The following operation uses a\nliteral query to search for documents containing a field called  name \nthat has the value of  \"pear\" : Literal value queries function identically to queries that use the\n $eq  comparison operator. For example, the following queries are\nequivalent: Comparison operators allow you to query for documents by comparing them\nto values in the query filter. Common comparison operators include\n $gt  for \"greater than\" comparisons,  $lt  for \"less than\" comparisons,\nand  $ne  for \"not equal to\" comparisons. The following operation uses the comparison operator  $gt  to match\ndocuments with a  quantity  value greater than  5 : For more information on comparison operators, see  Comparison\nQuery Operators  in the Server manual. Logical operators require at least two match criteria and can match\ndocuments that meet some, all, or none of these criteria. For example,\nyou can use the logical operator  $or  to query for documents that\nmatch either a  $gt  (greater than) comparison operator or a literal\nvalue query. The following operation uses the logical operator  $and  to match\ndocuments with a  quantity  value that is greater than  10  and\ndivisible by  3 : For a full list of logical operators, see  Logical\nQuery Operators  in the Server manual. If a query filter contains a literal value query with multiple field-value pairs,\nthe driver matches documents that meet all the criteria. For example, the following queries produce equivalent results: Element operators allow you to match documents based on the types of\nspecified fields or if they include specified fields. The following operation uses the element operator\n $exists  to search for documents containing the  description \nfield: For a full list of element operators, see  Element\nQuery Operators  in the Server manual. The  Fruit struct describing the documents  in this guide\nuses the  #[serde(skip_serializing_if = \"Option::is_none\")]  attribute on two of its\nfields. This attribute specifies that the field be ignored if its value is  None . This\nprevents a  description  value of  None  from being returned on an  $exists  query. See the  serialize_with  Serde\nattribute for more information. Evaluation operators analyze individual fields or a collection's documents to\ndetermine if they meet certain criteria. Each evaluation operator\nperforms a different function. For example, the  $mod  operator\nperforms a mathematical operation on a field value, and the  $where \noperator allows you to evaluate values against JavaScript expressions. The following operation uses the evaluation operator  $mod  to search\nfor documents with a  quantity  value that is divisible by 3: For a full list of evaluation operators, see  Evaluation\nQuery Operators  in the Server manual. Bitwise operators convert a numeric field from a base-10 (decimal)\nnumber into the corresponding base-2 (binary) number. They check whether\nthe value in a document has the same bits set as the value in your match\ncriteria. The following example matches documents where the  quantity  has the same\nbits set as  7 , which is equivalent to   00000111  in binary: For a full list of bitwise operators, see  Bitwise\nQuery Operators  in the Server manual. Array operators check the values or amount of elements in an array-valued field. The following example matches documents where the  vendor  array field\ncontains  \"C\" : For a full list of bitwise operators, see  Array\nQuery Operators  in the Server manual. To learn more about find operations, see the  Retrieve Data \nguide. To learn more about query operators, see  Query Selectors  in the Server manual. To learn more about the methods and types used in this\nguide, see the following API documentation: find() Cursor",
            "code": [
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"<field>\": \"<value>\" };"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"<field>\": doc! { \"<operator>\": \"<value>\" } };"
                },
                {
                    "lang": "rust",
                    "value": "#[derive(Serialize, Deserialize, Debug)]\nstruct Fruit {\n    _id: String,\n    name: String,\n    quantity: i32,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    description: Option<String>,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    vendors: Option<Vec<String>>\n}"
                },
                {
                    "lang": "rust",
                    "value": "let docs = vec! [\n    Fruit { \n        _id: 1.to_string(), \n        name: \"orange\".to_string(), \n        quantity: 7,\n        description: None,\n        vendors: None\n    },\n    Fruit { \n        _id: 2.to_string(), \n        name: \"apple\".to_string(), \n        quantity: 4,\n        description: Some(\"Granny Smith\".to_string()),\n        vendors: None\n    },\n    Fruit { \n        _id: 3.to_string(), \n        name: \"banana\".to_string(), \n        quantity: 36,\n        description: None,\n        vendors: None\n    },\n    Fruit { \n        _id: 4.to_string(), \n        name: \"pear\".to_string(), \n        quantity: 28,\n        description: None,\n        vendors: vec![\"A\".to_string(), \"C\".to_string() ].into()\n    },\n];"
                },
                {
                    "lang": "rust",
                    "value": "let query = doc! { \"name\": \"pear\" };\nlet mut cursor = my_coll.find(query, None).await?;\nwhile let Some(doc) = cursor.try_next().await? {\n    println!(\"{:?}\", doc);\n}"
                },
                {
                    "lang": "json",
                    "value": "Fruit { _id: \"4\", name: \"pear\", quantity: 28, description: None, vendors: Some([\"A\", \"C\"]) }"
                },
                {
                    "lang": "rust",
                    "value": "my_coll.find(doc! {\n   \"price\": doc! { \"$eq\": 5 }\n}).await?;"
                },
                {
                    "lang": "rust",
                    "value": "my_coll.find(doc! {\n   \"price\": 5\n}).await?;"
                },
                {
                    "lang": "rust",
                    "value": "// $gt means \"greater than\"\nlet query = doc! { \"quantity\": doc! { \"$gt\": 5 } };\nlet mut cursor = my_coll.find(query, None).await?;\nwhile let Some(doc) = cursor.try_next().await? {\n    println!(\"{:?}\", doc);\n}"
                },
                {
                    "lang": "json",
                    "value": "Fruit { _id: \"1\", name: \"orange\", quantity: 7, description: None, vendors: None }\nFruit { _id: \"3\", name: \"banana\", quantity: 36, description: None, vendors: None }\nFruit { _id: \"4\", name: \"pear\", quantity: 28, description: None, vendors: Some([\"A\", \"C\"]) }"
                },
                {
                    "lang": "rust",
                    "value": "let query =\n    doc! { \"$and\": [\n       doc! { \"quantity\": doc! { \"$gt\": 10 } },\n       doc! { \"quantity\": doc! { \"$mod\": [ 3, 0 ] } }\n   ]\n};\nlet mut cursor = my_coll.find(query, None).await?;\nwhile let Some(doc) = cursor.try_next().await? {\n    println!(\"{:?}\", doc);\n}"
                },
                {
                    "lang": "json",
                    "value": "Fruit { _id: \"3\", name: \"banana\", quantity: 36, description: None, vendors: None }"
                },
                {
                    "lang": "rust",
                    "value": "my_coll.find(doc! {\n   \"price\": doc! { \"$eq\": 5 },\n   \"quantity\": doc! { \"$gt\": 4 }\n});"
                },
                {
                    "lang": "rust",
                    "value": "my_coll.find(doc! {\n   $and: [\n      doc! { \"price\": { \"$eq\": 5 }},\n      doc! { \"quantity\": { \"$gt\": 4 }}\n   ]\n});"
                },
                {
                    "lang": "rust",
                    "value": "let query = doc! { \"description\": doc! { \"$exists\": true } };\nlet mut cursor = my_coll.find(query, None).await?;\nwhile let Some(doc) = cursor.try_next().await? {\n    println!(\"{:?}\", doc);\n}"
                },
                {
                    "lang": "json",
                    "value": "Fruit { _id: \"2\", name: \"apple\", quantity: 4, description: Some(\"Granny Smith\"),\nvendors: None }"
                },
                {
                    "lang": "rust",
                    "value": "// $mod means \"modulo\" and checks if the remainder is a specific value\nlet query = doc! { \"quantity\": doc! { \"$mod\": [ 3, 0 ] } };\nlet mut cursor = my_coll.find(query, None).await?;\nwhile let Some(doc) = cursor.try_next().await? {\n    println!(\"{:?}\", doc);\n}"
                },
                {
                    "lang": "json",
                    "value": "Fruit { _id: \"3\", name: \"banana\", quantity: 36, description: None, vendors: None }"
                },
                {
                    "lang": "rust",
                    "value": "let query = doc! { \"quantity\": doc! { \"$bitsAllSet\": 7 } };\nlet mut cursor = my_coll.find(query, None).await?;\nwhile let Some(doc) = cursor.try_next().await? {\n    println!(\"{:?}\", doc);\n}"
                },
                {
                    "lang": "json",
                    "value": "Fruit { _id: \"1\", name: \"orange\", quantity: 7, description: None, vendors: None }"
                },
                {
                    "lang": "rust",
                    "value": "let query = doc! { \"vendors\": doc! { \"$elemMatch\": { \"$eq\": \"C\" } } };\nlet mut cursor = my_coll.find(query, None).await?;\nwhile let Some(doc) = cursor.try_next().await? {\n    println!(\"{:?}\", doc);\n}"
                },
                {
                    "lang": "json",
                    "value": "Fruit { _id: \"4\", name: \"pear\", quantity: 28, description: None, vendors: Some([\"A\", \"C\"]) }"
                }
            ],
            "preview": "In this guide, you can learn how to specify a query to match a subset\nof documents.",
            "tags": "search, compare, code example",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/crud/write-operations/delete",
            "title": "Delete Documents",
            "headings": [
                "Overview",
                "Sample Data for Examples",
                "Delete Operations",
                "Parameters",
                "Return Value",
                "delete_many() Example",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to remove documents from your MongoDB\ncollections using  delete operations . This guide includes the following sections: Sample Data for Examples  presents\nthe sample data that is used by the delete operation example Delete Operations  describes how to use the\ndriver to execute delete operations Additional Information \nprovides links to resources and API documentation for types\nand methods mentioned in this guide The example in this guide uses the following sample documents. Each\ndocument represents an item in a store's inventory and contains\ninformation about its categorization and unit price: The Rust driver provides the  delete_one()  and  delete_many() \nmethods to perform delete operations. The  delete_one()  and  delete_many()  methods take a query filter\nas a parameter. A query filter consists of the fields and values that\nform criteria for documents to match. You can also optionally pass a  DeleteOptions  type as a parameter to\neither method. You can specify settings in a  DeleteOptions  instance\nto configure the delete operation. To use default values for each\nsetting, specify the value  None  as the options parameter. The following table describes settings that you can specify in a\n DeleteOptions  instance: The following code shows how to construct an  DeleteOptions \ninstance and pass it to the  delete_one()  method: The Rust driver implements the Builder design pattern for the\ncreation of many different types, including  DeleteOptions . You\ncan use each type's  builder()  method to construct an options\ninstance by chaining option builder functions one at a time. Option Description collation write_concern hint let_vars comment The  delete_one()  and  delete_many()  methods return a\n DeleteResult  type. This type contains the  deleted_count  property,\nwhich describes the number of documents deleted. If no documents match\nthe query filter you specified, the delete operation does\nnot remove any documents, and the value of  deleted_count  is  0 . This example shows how to call the  delete_many()  method with the\nfollowing parameters: A query filter that matches documents where the value of  category \nis  \"garden\" A  DeleteOptions  instance that uses the  _id_  index as the hint\nfor the delete operation If you use the  delete_one()  method instead of\n delete_many()  in the preceding code example, the driver deletes\nonly the first of the two documents that match the query filter. For runnable examples of the delete operations, see the following usage\nexamples: To learn more about the operations in this guide, see the\nfollowing documentation: Delete a Document Delete Multiple Documents Specify a Query  guide Collations  guide To learn more about the methods and types mentioned in this\nguide, see the following API documentation: delete_one() delete_many() DeleteOptions Hint DeleteResult",
            "code": [
                {
                    "lang": "json",
                    "value": "{ \"item\": \"trowel\", \"category\": \"garden\", \"unit_price\": 9.89 },\n{ \"item\": \"placemat\", \"category\": \"kitchen\", \"unit_price\": 3.19 },\n{ \"item\": \"watering can\", \"category\": \"garden\", \"unit_price\": 11.99 }"
                },
                {
                    "lang": "rust",
                    "value": "let opts: DeleteOptions = DeleteOptions::builder().comment(bson!(\"hello!\")).build();\nlet res = my_coll.delete_one(filter, opts).await?;"
                },
                {
                    "lang": "rust",
                    "value": "let filter = doc! { \"category\": \"garden\" };\nlet hint = Hint::Name(\"_id_\".to_string());\nlet opts: DeleteOptions = DeleteOptions::builder().hint(hint).build();\n\nlet res = my_coll.delete_many(filter, opts).await?;\nprintln!(\"Deleted documents: {}\", res.deleted_count);"
                },
                {
                    "lang": "console",
                    "value": "Deleted documents: 2"
                }
            ],
            "preview": "In this guide, you can learn how to remove documents from your MongoDB\ncollections using delete operations.",
            "tags": "set options, code example",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/monitoring/connection-monitoring",
            "title": "Connection Pool Monitoring",
            "headings": [
                "Overview",
                "Event Descriptions",
                "Event Subscription Example",
                "Example Event Documents",
                "PoolCreatedEvent",
                "PoolReadyEvent",
                "PoolClearedEvent",
                "PoolClosedEvent",
                "ConnectionCreatedEvent",
                "ConnectionReadyEvent",
                "ConnectionClosedEvent",
                "ConnectionCheckOutStartedEvent",
                "ConnectionCheckoutFailedEvent",
                "ConnectionCheckedOutEvent",
                "ConnectionCheckedInEvent",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "This guide shows you how to use the Rust driver to monitor the\ndriver's connection pool. A connection pool is a set of open\nTransmission Control Protocol (TCP) connections that your driver\nmaintains with a MongoDB instance. Connection pools help reduce the\nnumber of new connections your application needs to create,\nwhich might make your application run faster. You can use information about changes to your connection pool in your\napplication, or you can monitor the connection pool to learn more about\nhow the driver uses connections. This guide includes the following sections: Event Descriptions  describes\nthe connection pool events that the driver can generate Event Subscription Example \nprovides sample code that shows how to subscribe to a connection pool event Example Event Documents \nprovides samples of each connection pool event Additional Information \nprovides links to resources and API documentation for types\nand methods mentioned in this guide You can subscribe to one or more of the following connection pool\nmonitoring events: Event Name Description PoolCreatedEvent Created when a connection pool is created. PoolReadyEvent Created when a connection pool is ready. PoolClearedEvent Created when a connection pool is cleared. PoolClosedEvent Created when a connection pool is closed, before the destruction of\nthe server instance. ConnectionCreatedEvent Created when a connection is created, but not necessarily\nwhen it is used for an operation. ConnectionReadyEvent Created after a connection successfully completes a\nhandshake and is ready to be used for operations. ConnectionClosedEvent Created when a connection is closed. ConnectionCheckoutStartedEvent Created when an operation attempts to acquire a connection for\nexecution. ConnectionCheckoutFailedEvent Created when an operation cannot acquire a connection for\nexecution. ConnectionCheckedOutEvent Created when an operation successfully acquires a connection for\nexecution. ConnectionCheckedInEvent Created when a connection is checked back into the pool after an operation\nis executed. You can access one or more connection pool events by\nsubscribing to them in your application. The following example connects\nto a MongoDB deployment and subscribes to the  ConnectionCreatedEvent  event type: The following sections show sample output for each type of connection\npool monitoring event. To learn more about monitoring a MongoDB deployment, see the  How\nto Monitor MongoDB  article. To learn more about connecting to MongoDB, see the\n Connection Guide . To learn more about improving the performance of your application, see\nthe guide on  Performance Considerations . To learn more about the methods and types mentioned in this\nguide, see the following API documentation: CmapEventHandler ClientOptions Client::with_options()",
            "code": [
                {
                    "lang": "rust",
                    "value": "struct ConnectionCreatedHandler;\n\nimpl CmapEventHandler for ConnectionCreatedHandler {\n    fn handle_connection_created_event(&self, event: ConnectionCreatedEvent) {\n        eprintln!(\"Connection created: {:?}\", event);\n    }\n}\n\nlet handler: Arc<dyn CmapEventHandler> = Arc::new(ConnectionCreatedHandler);\nclient_options.cmap_event_handler = Some(handler);\n\nlet client = Client::with_options(client_options)?;\n\n// ... perform actions with the client to generate events\n"
                },
                {
                    "lang": "none",
                    "value": "PoolCreatedEvent {\n  address: ...,\n  options: {...}\n}"
                },
                {
                    "lang": "none",
                    "value": "PoolReadyEvent {\n  address: ...\n}"
                },
                {
                    "lang": "none",
                    "value": "PoolClearedEvent {\n  address: ...,\n  service_id: ...,\n}"
                },
                {
                    "lang": "none",
                    "value": "PoolClosedEvent {\n  address: ...\n}"
                },
                {
                    "lang": "none",
                    "value": "ConnectionCreatedEvent {\n  address: ...,\n  connection_id: 1\n}"
                },
                {
                    "lang": "none",
                    "value": "ConnectionReadyEvent {\n  address: ...,\n  connection_id: 1\n}"
                },
                {
                    "lang": "none",
                    "value": "ConnectionClosedEvent {\n  address: ...,\n  connection_id: 1,\n  reason: ...,\n  /* private fields */\n}"
                },
                {
                    "lang": "none",
                    "value": "ConnectionCheckOutStartedEvent {\n  address: ...,\n}"
                },
                {
                    "lang": "none",
                    "value": "ConnectionCheckOutFailedEvent {\n  address: ...,\n  reason: ...,\n  /* private fields */\n}"
                },
                {
                    "lang": "none",
                    "value": "ConnectionCheckedOutEvent {\n  address: ...,\n  connection_id: 1\n}"
                },
                {
                    "lang": "none",
                    "value": "ConnectionCheckedInEvent {\n  address: ...,\n  connection_id: 1\n}"
                }
            ],
            "preview": "This guide shows you how to use the Rust driver to monitor the\ndriver's connection pool. A connection pool is a set of open\nTransmission Control Protocol (TCP) connections that your driver\nmaintains with a MongoDB instance. Connection pools help reduce the\nnumber of new connections your application needs to create,\nwhich might make your application run faster.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/crud/write-operations/insert",
            "title": "Insert Documents",
            "headings": [
                "Overview",
                "The _id Field",
                "Insert a Document",
                "Example",
                "Modify insert_one Behavior",
                "Insert Multiple Documents",
                "Example",
                "Modify insert_many Behavior",
                "Ordered Behavior Example",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to  insert  documents into a MongoDB\ncollection. Before you can find, update, and delete any documents in MongoDB, you need\nto insert them. You can insert documents by using the following methods: This guide includes the following sections: insert_one()  to insert one document insert_many()  to insert one or more documents The _id Field  describes the  _id  field\nthat each document contains Insert a Document  describes how to use the\ndriver to insert a single document into a collection Insert Multiple Documents  describes how to use the\ndriver to insert multiple documents into a collection Additional Information \nprovides links to resources and API documentation for types\nand methods mentioned in this guide In MongoDB, each document  must  contain a unique  _id  field.\nMongoDB allows you to manage this field in the following ways: Unless you provide strong guarantees for uniqueness, we recommend that\nyou let the driver automatically generate  _id  values for your\ndocuments. To learn more about the  _id  field, see  Unique Indexes  in the Server manual. To learn more about document structure and rules, see\n Documents  in the Server manual. Manage this field yourself, ensuring that each  _id  value you set\nis unique. Let the driver automatically generate unique  ObjectId  values. The\ndriver generates a unique  ObjectId  value for each document if you do\nnot specify a value for the  _id  field when performing an insert. If you attempt to perform a write operation that includes duplicate  _id \nvalues, the duplicate values violate unique index constraints and cause\nthe write operation to fail. Use the  insert_one()  method to insert a single document into a\ncollection. Upon successful insertion, the method returns an\n InsertOneResult  instance that contains the  _id  of the inserted\ndocument. The following example uses the  insert_one()  method to insert a\ndocument into the  books  collection: If a database and collection don't exist when\nyou perform a write operation on them, the server automatically\ncreates them. You can modify the behavior of the  insert_one()  method by\nconstructing and passing an  InsertOneOptions  struct. The following table describes the options available in  InsertOneOptions : The following code shows how to construct an  InsertOneOptions \ninstance: The Rust driver implements the Builder design pattern for the\ncreation of many different types, including  InsertOneOptions .\nYou can use each type's  builder()  method to construct an options\ninstance by chaining option builder functions one at a time. Option Description bypass_document_validation write_concern comment Use the  insert_many()  method to insert multiple documents into a\ncollection. Upon successful insertion, the method returns an\n InsertManyResult  instance that contains the  _id  values of the\ninserted documents. The following example uses the  insert_many()  method to insert\nmultiple documents into the  books  collection: If a database and collection don't exist when\nyou perform a write operation on them, the server automatically\ncreates them. You can modify the behavior of the  insert_many()  method by\nconstructing and passing an  InsertManyOptions  struct. The\nfollowing table describes the options available in\n InsertManyOptions : The following code shows how to construct an  InsertManyOptions \ninstance: Option Description bypass_document_validation ordered write_concern comment Assume you want to insert the following documents into the  books \ncollection: When you attempt to insert these documents, the result depends on the\nvalue of the  ordered  option in your  InsertManyOptions : The following code shows how to perform an unordered write operation to\ninsert the preceding documents: Even though this operation results in a  BulkWriteError , you can\nstill find the non-error-producing documents in your collection: If  ordered  is  true  (the default value), the driver throws a\n BulkWriteError  when it attempts to insert the document with the\nduplicate  _id  value. However, the driver still inserts the\ndocuments before the error occurs. If you set  ordered  to  false , the driver still throws a\n BulkWriteError  when it attempts to insert the document with the\nduplicate  _id  value, but it inserts every other document. For runnable examples of the insert operations, see the following usage\nexamples: Insert a Document Insert Multiple Documents To learn more about the methods and types mentioned in this\nguide, see the following API documentation: insert_one() InsertOneResult InsertOneOptions insert_many() InsertManyResult InsertManyOptions BulkWriteError BulkWriteFailure",
            "code": [
                {
                    "lang": "rust",
                    "value": "let my_coll: Collection<Book> = client.database(\"db\").collection(\"books\");\nlet doc = Book { _id: 8, title: \"Atonement\".to_string(), author: \"Ian McEwan\".to_string() };\n\nlet insert_one_result = my_coll.insert_one(doc, None).await?;\nprintln!(\"Inserted document with _id: {}\", insert_one_result.inserted_id);"
                },
                {
                    "lang": "console",
                    "value": "Inserted document with _id: 8"
                },
                {
                    "lang": "rust",
                    "value": "let _opts = InsertOneOptions::builder()\n    .bypass_document_validation(true)\n    .build();"
                },
                {
                    "lang": "rust",
                    "value": "let docs = vec![\n    Book {\n        _id: 5,\n        title: \"Cat's Cradle\".to_string(),\n        author: \"Kurt Vonnegut Jr.\".to_string()\n    },\n    Book {\n        _id: 6,\n        title: \"In Memory of Memory\".to_string(),\n        author: \"Maria Stepanova\".to_string()\n    },\n    Book {\n        _id: 7,\n        title: \"Pride and Prejudice\".to_string(),\n        author: \"Jane Austen\".to_string()\n    }\n];\n\nlet insert_many_result = my_coll.insert_many(docs, None).await?;\nprintln!(\"Inserted documents with _ids:\");\nfor (_key, value) in &insert_many_result.inserted_ids {\n    println!(\"{:?}\", value);\n}"
                },
                {
                    "lang": "console",
                    "value": "Inserted documents with _ids:\nInt32(5)\nInt32(6)\nInt32(7)"
                },
                {
                    "lang": "rust",
                    "value": "let _opts = InsertManyOptions::builder()\n    .comment(Some(\"hello world\".into()))\n    .build();"
                },
                {
                    "lang": "json",
                    "value": "{ \"_id\": 1, \"title\": \"Where the Wild Things Are\" }\n{ \"_id\": 2, \"title\": \"The Very Hungry Caterpillar\" }\n{ \"_id\": 1, \"title\": \"Blueberries for Sal\" }\n{ \"_id\": 3, \"title\": \"Goodnight Moon\" }"
                },
                {
                    "lang": "json",
                    "value": "{ \"_id\": 1, \"title\": \"Where the Wild Things Are\" }\n{ \"_id\": 2, \"title\": \"The Very Hungry Caterpillar\" }\n{ \"_id\": 3, \"title\": \"Goodnight Moon\" }"
                },
                {
                    "lang": "rust",
                    "value": "let docs = vec![\n    Book { _id: 1, title: \"Where the Wild Things Are\".to_string(), author: \"\".to_string() },\n    Book { _id: 2, title: \"The Very Hungry Caterpillar\".to_string(), author: \"\".to_string() },\n    Book { _id: 4, title: \"Blueberries for Sal\".to_string(), author: \"\".to_string() },\n    Book { _id: 3, title: \"Goodnight Moon\".to_string(), author: \"\".to_string() }\n];\n\nlet opts = InsertManyOptions::builder().ordered(false).build();\nmy_coll.insert_many(docs, opts).await?;"
                }
            ],
            "preview": "In this guide, you can learn how to insert documents into a MongoDB\ncollection.",
            "tags": "set options, bulk write error, code example",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/monitoring/cluster-monitoring",
            "title": "Cluster Monitoring",
            "headings": [
                "Overview",
                "Event Descriptions",
                "Event Subscription Example",
                "Example Event Documents",
                "ServerDescriptionChangedEvent",
                "ServerOpeningEvent",
                "ServerClosedEvent",
                "TopologyDescriptionChangedEvent",
                "TopologyOpeningEvent",
                "TopologyClosedEvent",
                "ServerHeartbeatStartedEvent",
                "ServerHeartbeatSucceededEvent",
                "ServerHeartbeatFailedEvent",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "This guide shows you how to use the Rust driver to monitor topology\nevents in a MongoDB instance, replica set, or sharded cluster. The\ndriver creates topology events, also known as Server Discovery and\nMonitoring (SDAM) events, when there are any changes in the state of the\ninstance or cluster that you are connected to. You can use information about topology changes in your\napplication, or you can monitor cluster changes to learn more about\nhow they affect your application. This guide includes the following sections: Event Descriptions  describes\nthe SDAM events that the driver can generate Event Subscription Example \nprovides sample code that shows how to subscribe to an SDAM event Example Event Documents \nprovides samples of each SDAM event Additional Information \nprovides links to resources and API documentation for types\nand methods mentioned in this guide You can subscribe to one or more of the following SDAM events: Event Name Description ServerDescriptionChangedEvent Created when an instance state changes, such as when a replica set\nmember changes from a secondary to a primary. ServerOpeningEvent Created when a connection to an instance, such as a replica set member, opens. ServerClosedEvent Created when a connection to an instance, such as a replica set member, closes. TopologyDescriptionChangedEvent Created when the topology description changes, such as when there\nis an election of a new primary or when a  mongos  proxy disconnects. TopologyOpeningEvent Created before the driver attempts to connect to an instance. TopologyClosedEvent Created after all instance connections in the topology close. ServerHeartbeatStartedEvent Created before the driver issues a  hello  command to an instance. ServerHeartbeatSucceededEvent Created when the  hello  command returns successfully from a\nMongoDB instance. ServerHeartbeatFailedEvent Created when a  hello  command to a MongoDB instance does not\nreturn a successful response. You can access one or more SDAM events by\nsubscribing to them in your application. The following example connects\nto a MongoDB deployment and subscribes to the  ServerOpeningEvent  event type: The following sections show sample output for each type of SDAM event. To learn more about monitoring a MongoDB deployment, see the  How\nto Monitor MongoDB  article. To learn more about connecting to MongoDB, see the\n Connection Guide . To learn more about the methods and types mentioned in this\nguide, see the following API documentation: SdamEventHandler ClientOptions Client::with_options()",
            "code": [
                {
                    "lang": "rust",
                    "value": "struct ServerOpenHandler;\n\nimpl SdamEventHandler for ServerOpenHandler {\n    fn handle_server_opening_event(&self, event: ServerOpeningEvent) {\n        eprintln!(\"Server opening: {:?}\", event);\n    }\n}\n\nlet handler: Arc<dyn SdamEventHandler> = Arc::new(ServerOpenHandler);\nclient_options.sdam_event_handler = Some(handler);\n\nlet client = Client::with_options(client_options)?;\n\n// ... perform actions with the client to generate events\n"
                },
                {
                    "lang": "none",
                    "value": "ServerDescriptionChangedEvent {\n    address: ...,\n    topology_id: ...,\n    previous_description: ...,\n    new_description: ...,\n}"
                },
                {
                    "lang": "none",
                    "value": "ServerOpeningEvent {\n    address: ...,\n    topology_id: ...,\n}"
                },
                {
                    "lang": "none",
                    "value": "ServerClosedEvent {\n    address: ...,\n    topology_id: ...,\n}"
                },
                {
                    "lang": "none",
                    "value": "TopologyDescriptionChangedEvent {\n    topology_id: ...,\n    previous_description: ...,\n    new_description: ...,\n}"
                },
                {
                    "lang": "none",
                    "value": "TopologyOpeningEvent {\n    topology_id: ...,\n}"
                },
                {
                    "lang": "none",
                    "value": "TopologyClosedEvent {\n    topology_id: ...,\n}"
                },
                {
                    "lang": "none",
                    "value": "ServerHeartbeatStartedEvent {\n    server_address: ...,\n    awaited: false,\n    driver_connection_id: 12,\n    server_connection_id: ...,\n}"
                },
                {
                    "lang": "none",
                    "value": "ServerHeartbeatSucceededEvent {\n    duration: ...,\n    reply: ...,\n    server_address: ...,\n    awaited: false,\n    driver_connection_id: 12,\n    server_connection_id: ...,\n}"
                },
                {
                    "lang": "none",
                    "value": "ServerHeartbeatFailedEvent {\n    duration: ...,\n    failure: ...,\n    server_address: ...,\n    awaited: false,\n    driver_connection_id: 12,\n    server_connection_id: ...,\n}"
                }
            ],
            "preview": "This guide shows you how to use the Rust driver to monitor topology\nevents in a MongoDB instance, replica set, or sharded cluster. The\ndriver creates topology events, also known as Server Discovery and\nMonitoring (SDAM) events, when there are any changes in the state of the\ninstance or cluster that you are connected to.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/crud/write-operations/change",
            "title": "Modify Documents",
            "headings": [
                "Overview",
                "Update Document Pattern",
                "The _id Field",
                "Update Documents",
                "Parameters",
                "Return Value",
                "Update Example",
                "Update by ObjectId Example",
                "Replace a Document",
                "Parameters",
                "Return Values",
                "Replace Example",
                "Modify Update and Replace Behavior",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "In this guide, you can learn how to modify documents in MongoDB by using\n update  and  replace  operations. Update operations change the fields that you specify while leaving other\nfields and values unchanged. Replace operations remove all existing\nfields of a document except for the  _id  field and substitute the\nremoved fields with new fields and values. This guide includes the following sections: Update Documents  describes how to use the\ndriver to execute update operations Replace a Document  describes how to use the\ndriver to execute replace operations Modify Update and Replace Behavior \ndescribes how to modify the default behavior of the methods described\nin this guide Additional Information \nprovides links to resources and API documentation for types\nand methods mentioned in this guide In MongoDB, all methods to change documents follow the same pattern: These methods take the following parameters: The Rust driver provides the following methods to change documents: You can retrieve and modify data in one action by using compound\noperations. To learn more, see the guide on  Compound Operations . changeX()  is a placeholder and not a real method. A query filter to match one or more documents to change An update document that specifies the field and value changes (Optional)  An options type to modify the default behavior of the method update_one() update_many() replace_one() Each document in a MongoDB collection has a unique and immutable  _id \nfield. If you attempt to change the  _id  field through an update or\nreplace operation, the driver raises a  WriteError  and performs no\nupdates. You can perform update operations with the following methods: update_one() , which updates the first document that matches the\nsearch criteria update_many() , which updates all documents that match the search\ncriteria Each method takes a query filter and an  update document  that\nincludes at least one  update operator . The update operator\nspecifies the type of update to perform and includes the fields and\nvalues that describe the change. Update documents use the following format: To specify multiple updates in one update document, use the following\nformat: See the MongoDB server manual for a  complete list of update operators\nand descriptions . Update operations also take an  UpdateOptions  parameter. To learn\nabout modifying the behavior of the update methods, see the  Modify\nUpdate and Replace Behavior  section of this guide. If you are using MongoDB Server version 4.2 or later, you can use aggregation\npipelines in update operations. To learn more about the aggregation\nstages MongoDB supports in aggregation pipelines, see our tutorial on performing\n updates with aggregation pipelines . The  update_one()  and  update_many()  methods return an\n UpdateResult  type if the operation is successful. The\n UpdateResult  type contains the following properties that describe\nthe operation: If multiple documents match the query filter you pass to  UpdateOne() ,\nthe method selects and updates the first matched document. If no\ndocuments match the query filter, the update operation makes no\nchanges. Property Description matched_count The number of documents matched by the filter modified_count The number of documents modified by the operation upserted_id The  _id  of the upserted document, or empty if there is none The following documents describe employees of a company: This example performs an update operation with the  update_many()  method.\nThe  update_many()  method takes the following parameters: The following documents reflect the changes resulting from the preceding update operation: A query filter to match documents where the value of the\n department  field is  \"Marketing\" An update document that contains the following updates: A  $set  operator to change the value of  department  to\n \"Business Operations\"  and  role  to  \"Analytics Specialist\" An  $inc  operator to increase the value of  bonus  by  500 The following document describes an employee of a company: This example queries for the preceding document by specifying a query filter to match the\ndocument's unique  _id  value. Then, the code performs an update operation with the\n update_one()  method. The  update_one()  method takes the following parameters: The following document reflects the changes resulting from the preceding update operation: Query filter that matches a document in which the value of the  _id  field is\n ObjectId('4274') Update document that creates instructions to set the value of  name  to\n \"Jill Gillison\" To learn more about the  _id  field, see the  _id Field \nsection of this page or the  ObjectId() \nmethod documentation in the Server manual. You can perform a replace operation with the  replace_one()  method.\nThis method replaces all existing fields of a document except for the  _id \nfield with new fields and values that you specify. The  replace_one()  method takes a query filter and a  replacement\ndocument , which contains the fields and values that will replace an\nexisting document. Replacement documents use the following format: Replace operations also take an  UpdateOptions  parameter. To learn\nabout modifying the behavior of the  replace_one()  method, see the  Modify\nUpdate and Replace Behavior  section of this guide. The  replace_one  method returns an\n UpdateResult  type if the operation is successful. The\n UpdateResult  type contains the following properties that describe\nthe operation: If multiple documents match the query filter you pass to  replace_one() ,\nthe method selects and replaces the first matched document. If no\ndocuments match the query filter, the replace operation makes no\nchanges. Property Description matched_count The number of documents matched by the filter modified_count The number of documents modified by the operation upserted_id The  _id  of the upserted document, or empty if there is none The following document describes an employee of a company: This example uses the  replace_one()  method to replace\nthe preceding document with one that has the following fields: The replaced document contains the contents of the replacement document\nand the immutable  _id  field: A  name  value of  \"Susan Lee\" A  role  value of  \"Lead Consultant\" A  team_members  value of  [ \"Jill Gillison\" ] You can modify the behavior of the  update_one() ,  update_many ,\nand  replace_one()  methods by constructing and passing an\n UpdateOptions  struct as a parameter. The following table describes the options available in  UpdateOptions : The following code shows how to construct an  UpdateOptions \ninstance and pass it to the  update_one()  method: The Rust driver implements the Builder design pattern for the\ncreation of many different types, including  UpdateOptions . You\ncan use each type's  builder()  method to construct an options\ninstance by chaining option builder functions one at a time. Option Description array_filters bypass_document_validation upsert collation hint write_concern let_vars comment For more information about the concepts in this guide, see the following\ndocumentation: For runnable examples of the update and replace operations, see the\nfollowing usage examples: To learn more about the update operators, see  Update Operators  in the Server manual. Specify a Query  guide Compound Operations  guide Update a Document Update Multiple Documents Replace a Document To learn more about the methods and types mentioned in this\nguide, see the following API documentation: update_one() update_many() UpdateResult UpdateOptions replace_one() ReplaceOptions WriteError",
            "code": [
                {
                    "lang": "rust",
                    "value": "doc! { \"<update operator>\": doc! { \"<field>\": <value> } }"
                },
                {
                    "lang": "rust",
                    "value": "doc! {\n    \"<update operator>\": doc!{\"<field>\": <value>},\n    \"<update operator>\": doc!{\"<field>\": <value>},\n    ...\n}"
                },
                {
                    "lang": "json",
                    "value": "{\n  \"_id\": ObjectId('4337'),\n  \"name\": \"Shelley Olson\",\n  \"department\": \"Marketing\",\n  \"role\": \"Director\",\n  \"bonus\": 3000\n},\n{\n  \"_id\": ObjectId('4902'),\n  \"name\": \"Remi Ibrahim\",\n  \"department\": \"Marketing\",\n  \"role\": \"Consultant\",\n  \"bonus\": 1800\n}"
                },
                {
                    "lang": "json",
                    "value": "{\n  \"_id\": ObjectId('4337'),\n  \"name\": \"Shelley Olson\",\n  \"department\": \"Business Operations\",\n  \"role\": \"Analytics Specialist\",\n  \"bonus\": 3500\n},\n{\n  \"_id\": ObjectId('4902'),\n  \"name\": \"Remi Ibrahim\",\n  \"department\": \"Business Operations\",\n  \"role\": \"Analytics Specialist\",\n  \"bonus\": 2300\n}"
                },
                {
                    "lang": "rust",
                    "value": "let update_doc = doc! {\n        \"$set\": doc! { \"department\": \"Business Operations\",\n                      \"role\": \"Analytics Specialist\" },\n        \"$inc\": doc! { \"bonus\": 500 }\n};\n\nlet res = my_coll\n    .update_many(doc! { \"department\": \"Marketing\" }, update_doc, None)\n    .await?;\nprintln!(\"Modified documents: {}\", res.modified_count);"
                },
                {
                    "lang": "console",
                    "value": "Modified documents: 2"
                },
                {
                    "lang": "json",
                    "value": "{\n  \"_id\": ObjectId('4274'),\n  \"name\": \"Jill Millerton\",\n  \"department\": \"Marketing\",\n  \"role\": \"Consultant\"\n}"
                },
                {
                    "lang": "json",
                    "value": "{\n  \"_id\": ObjectId('4274'),\n  \"name\": \"Jill Gillison\",\n  \"department\": \"Marketing\",\n  \"role\": \"Consultant\"\n}"
                },
                {
                    "lang": "rust",
                    "value": "let id = ObjectId::from_str(\"4274\").expect(\"Could not convert to ObjectId\");\nlet filter_doc = doc! { \"_id\": id };\n\nlet update_doc = doc! {\n        \"$set\": doc! { \"name\": \"Jill Gillison\" }\n};\n\nlet res = my_coll\n    .update_one(filter_doc, update_doc, None)\n    .await?;\nprintln!(\"Modified documents: {}\", res.modified_count);"
                },
                {
                    "lang": "console",
                    "value": "Modified documents: 1"
                },
                {
                    "lang": "rust",
                    "value": "doc! { \"<field>\": <value>, \"<field>\": <value>, ... }"
                },
                {
                    "lang": "json",
                    "value": "{\n  \"_id\": ObjectId('4501'),\n  \"name\": \"Matt DeGuy\",\n  \"role\": \"Consultant\",\n  \"team_members\": [ \"Jill Gillison\", \"Susan Lee\" ]\n}"
                },
                {
                    "lang": "json",
                    "value": "{\n  \"_id\": ObjectId('4501'),\n  \"name\": \"Susan Lee\",\n  \"role\": \"Lead Consultant\",\n  \"team_members\": [ \"Jill Gillison\" ]\n}"
                },
                {
                    "lang": "rust",
                    "value": "let replace_doc = doc! {\n    \"name\": \"Susan Lee\",\n    \"role\": \"Lead Consultant\",\n    \"team_members\": vec! [ \"Jill Gillison\" ]\n};\n\nlet res = my_coll\n    .replace_one(doc! { \"name\": \"Matt DeGuy\" }, replace_doc, None)\n    .await?;\nprintln!(\n    \"Matched documents: {}\\nModified documents: {}\",\n    res.matched_count, res.modified_count\n);"
                },
                {
                    "lang": "console",
                    "value": "Matched documents: 1\nModified documents: 1"
                },
                {
                    "lang": "rust",
                    "value": "let opts: UpdateOptions = UpdateOptions::builder().upsert(true).build();\nlet res = my_coll.update_one(filter_doc, update_doc, opts).await?;"
                }
            ],
            "preview": "In this guide, you can learn how to modify documents in MongoDB by using\nupdate and replace operations.",
            "tags": "update one, update many, set options, code example",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "quick-start/create-a-connection-string",
            "title": "Create a Connection String",
            "headings": [
                "Find your MongoDB Atlas Connection String",
                "Copy your Connection String",
                "Update the Placeholders"
            ],
            "paragraphs": "You can connect to your MongoDB deployment by providing a\n connection URI , also called a  connection string , which\ninstructs the driver on how to connect to a MongoDB deployment\nand how to behave while connected. The connection string includes the hostname or IP address and\nport of your deployment, the authentication mechanism, user credentials\nwhen applicable, and connection options. To connect to an instance or deployment not hosted on Atlas, see\n Other Ways to Connect to MongoDB . After completing these steps, you have a connection string that\ncontains your database username and password. To retrieve your connection string for the deployment that\nyou created in the  previous step ,\nlog in to your Atlas account and navigate to the\n Database  section and click the  Connect  button\nfor your new deployment. Proceed to the  Connect your application  section and select\n\"Rust\" from the  Driver  selection menu and the version\nthat best matches the version you installed from the  Version \nselection menu. Select the  Password (SCRAM)  authentication mechanism. Deselect the  Include full driver code example  to view\nthe connection string. Click the button on the right of the connection string to copy it\nto your clipboard. Paste this connection string into a a file in your preferred text editor\nand replace the  <username>  and  <password>  placeholders with\nyour database user's username and password. Save this file to a safe location for use in the next step. If you run into issues on this step, ask for help in the\n MongoDB Community Forums \nor submit feedback by using the  Rate this page \ntab on the right or bottom right side of this page.",
            "code": [],
            "preview": "You can connect to your MongoDB deployment by providing a\nconnection URI, also called a connection string, which\ninstructs the driver on how to connect to a MongoDB deployment\nand how to behave while connected.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "quick-start/download-and-install",
            "title": "Download and Install",
            "headings": [
                "Install Rust and Cargo",
                "Create a Project Directory",
                "Install the Rust Driver"
            ],
            "paragraphs": "After you complete these steps, you have Rust and Cargo installed\nand a new Rust project with the necessary driver dependencies. Ensure you have Rust 1.60 or later, and Cargo, the\nRust package manager, installed in your development environment. For information about how to install Rust and Cargo, see\nthe official Rust guide on  downloading and installing Rust . In your shell, run the following command to create a\ndirectory called  rust_quickstart  for this project: When this command successfully completes, you have a  Cargo.toml \nfile and a  src  directory with a  main.rs  file in your\n rust_quickstart  directory. Run the following command to navigate into the project\ndirectory: Add the following crates to your project by including them in the\ndependencies list located in your project's  Cargo.toml  file: The driver supports both asynchronous and synchronous runtimes.\nTo see example dependency lists for each runtime, select\nfrom the following  Asynchronous API  and\n Synchronous API  tabs: To learn more about asynchronous and synchronous runtimes, see the  Asynchronous and Synchronous APIs \nguide. mongodb , the Rust driver crate serde , the serialization crate futures , an asynchronous runtime crate that provides core abstractions The  mongodb  crate resolves the  bson  crate, which is the primary\nMongoDB data representation crate. You can omit the  bson \ncrate in your dependencies list. The  tokio  asynchronous runtime is the driver's default runtime crate\nand does not require a feature flag. The preceding code example includes\nthe  \"tokio-runtime\"  feature flag to specify the  tokio  runtime, but\nthis flag is optional. If you run into issues on this step, ask for help in the\n MongoDB Community Forums \nor submit feedback by using the  Rate this page \ntab on the right or bottom right side of this page.",
            "code": [
                {
                    "lang": "bash",
                    "value": "cargo new rust_quickstart"
                },
                {
                    "lang": "bash",
                    "value": "cd rust_quickstart"
                },
                {
                    "lang": "bash",
                    "value": "[dependencies]\nserde = \"1.0.188\"\nfutures = \"0.3.28\"\ntokio = {version = \"1.32.0\", features = [\"full\"]}\n\n[dependencies.mongodb]\nversion = \"2.7.1\"\nfeatures = [\"tokio-runtime\"]"
                },
                {
                    "lang": "bash",
                    "value": "[dependencies]\nserde = \"1.0.188\"\n\n[dependencies.mongodb]\nversion = \"2.7.1\"\nfeatures = [\"tokio-sync\"]"
                }
            ],
            "preview": "After you complete these steps, you have Rust and Cargo installed\nand a new Rust project with the necessary driver dependencies.",
            "tags": "cargo.toml, code example",
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "quick-start/next-steps",
            "title": "Next Steps",
            "headings": [],
            "paragraphs": "Congratulations on completing the quick start tutorial! In this tutorial, you created a Rust application that\nconnects to a MongoDB deployment hosted on MongoDB Atlas\nand retrieves a document that matches a query. Learn more about the MongoDB Rust Driver from the following resources: Discover how to perform read and write operations in the\n CRUD Operations  section. See examples of frequently used operations in the  Usage Examples  section.",
            "code": [],
            "preview": "Congratulations on completing the quick start tutorial!",
            "tags": "learn more",
            "facets": {
                "genre": [
                    "reference"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "fundamentals/monitoring/command-monitoring",
            "title": "Command Monitoring",
            "headings": [
                "Overview",
                "Event Descriptions",
                "Event Subscription Example",
                "Example Event Documents",
                "CommandStartedEvent",
                "CommandSucceededEvent",
                "CommandFailedEvent",
                "Additional Information",
                "API Documentation"
            ],
            "paragraphs": "This guide shows you how to use the Rust driver to monitor the\noutcome of commands that the driver sends to your MongoDB deployment. You can use information about command events in your\napplication, or you can monitor commands to learn more about\nhow the driver executes them. This guide includes the following sections: Event Descriptions  describes\nthe command events that the driver can generate Event Subscription Example \nprovides sample code that shows how to subscribe to a command event Example Event Documents \nprovides samples of each command event Additional Information \nprovides links to resources and API documentation for types\nand methods mentioned in this guide You can subscribe to one or more of the following command monitoring\nevents: Event Name Description CommandStartedEvent Created when a command starts. CommandSucceededEvent Created when a command succeeds. CommandFailedEvent Created when a command does not succeed. You can access one or more command events by\nsubscribing to them in your application. The following example connects\nto a MongoDB deployment and subscribes to the  CommandStartedEvent  event type: The following sections show sample output for each type of command monitoring event. To learn more about monitoring a MongoDB deployment, see the  How\nto Monitor MongoDB  article. To learn more about performing MongoDB operations, see the\n CRUD Operations  guides. To learn more about the methods and types mentioned in this\nguide, see the following API documentation: CommandEventHandler ClientOptions Client::with_options()",
            "code": [
                {
                    "lang": "rust",
                    "value": "struct CommandStartHandler;\n\nimpl CommandEventHandler for CommandStartHandler {\n    fn handle_command_started_event(&self, event: CommandStartedEvent) {\n        eprintln!(\"Command started: {:?}\", event);\n    }\n}\n\nlet handler: Arc<dyn CommandEventHandler> = Arc::new(CommandStartHandler);\nclient_options.command_event_handler = Some(handler);\n\nlet client = Client::with_options(client_options)?;\n\n// ... perform actions with the client to generate events\n"
                },
                {
                    "lang": "none",
                    "value": "CommandStartedEvent {\n  request_id: 12,\n  db: \"testdb\",\n  command_name: \"find\",\n  connection: ...,\n  command: ...,\n  service_id: ...\n}"
                },
                {
                    "lang": "none",
                    "value": "CommandSucceededEvent {\n    duration: ...,\n    reply: ...,\n    command_name: \"find\",\n    request_id: 12,\n    connection: ...,\n    service_id: ...,\n}"
                },
                {
                    "lang": "none",
                    "value": "CommandFailedEvent {\n    duration: ...,\n    command_name: \"find\",\n    failure: ...,\n    request_id: 12,\n    connection: ...,\n    service_id: ...,\n}"
                }
            ],
            "preview": "This guide shows you how to use the Rust driver to monitor the\noutcome of commands that the driver sends to your MongoDB deployment.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "quick-start/create-a-deployment",
            "title": "Create a MongoDB Deployment",
            "headings": [
                "Create a Free MongoDB deployment on Atlas",
                "Save your Credentials"
            ],
            "paragraphs": "You can create a free tier MongoDB deployment on MongoDB Atlas\nto store and manage your data. MongoDB Atlas hosts and manages\nyour MongoDB database in the cloud. After you complete these steps, you have a new free tier MongoDB\ndeployment on Atlas, database user credentials, and sample data loaded\ninto your database. Complete the  Get Started with Atlas \nguide to set up a new Atlas account and load sample data into a new free\ntier MongoDB deployment. After you create your database user, save that user's\nusername and password to a safe location for use in an upcoming step. If you run into issues on this step, ask for help in the\n MongoDB Community Forums \nor submit feedback by using the  Rate this page \ntab on the right or bottom right side of this page.",
            "code": [],
            "preview": "You can create a free tier MongoDB deployment on MongoDB Atlas\nto store and manage your data. MongoDB Atlas hosts and manages\nyour MongoDB database in the cloud.",
            "tags": null,
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        },
        {
            "slug": "quick-start/connect-to-mongodb",
            "title": "Connect to MongoDB",
            "headings": [
                "Create your Rust Application",
                "Assign the Connection String",
                "Run your Rust Application"
            ],
            "paragraphs": "After you complete these steps, you have a working application that\nuses the driver to connect to your MongoDB deployment, runs a query on\nthe sample data, and prints out the result. Open the file called  main.rs  in your\n rust_quickstart/src  project directory.  In this file, you can\nbegin writing your application. Copy and paste the following code into the  main.rs  file: Replace the  <connection string>  placeholder with the\nconnection string that you copied from the  Create a Connection String \nstep of this guide. In your shell, run the following command to compile and run this application: The command line output contains details about the retrieved movie\ndocument: If you encounter an error or see no output, ensure that you specified the\nproper connection string in the  main.rs  file and that you loaded the\nsample data. If you run into issues on this step, ask for help in the\n MongoDB Community Forums \nor submit feedback by using the  Rate this page \ntab on the right or bottom right side of this page.",
            "code": [
                {
                    "lang": "rust",
                    "value": "use mongodb::{ \n\tbson::{Document, doc},\n\tClient,\n\tCollection \n};\n\n#[tokio::main]\nasync fn main() -> mongodb::error::Result<()> {\n    // Replace the placeholder with your Atlas connection string\n    let uri = \"<connection string>\";\n\n    // Create a new client and connect to the server\n    let client = Client::with_uri_str(uri).await?;\n\n    // Get a handle on the movies collection\n    let database = client.database(\"sample_mflix\");\n    let my_coll: Collection<Document> = database.collection(\"movies\");\n\n    // Find a movie based on the title value\n    let my_movie = my_coll.find_one(doc! { \"title\": \"The Perils of Pauline\" }, None).await?;\n\n    // Print the document\n    println!(\"Found a movie:\\n{:#?}\", my_movie);\n    Ok(())\n}\n"
                },
                {
                    "lang": "rust",
                    "value": "use mongodb::{ \n\tbson::{Document, doc},\n\tsync::{Client, Collection} \n};\n\nfn main() -> mongodb::error::Result<()> {\n    // Replace the placeholder with your Atlas connection string\n    let uri = \"<connection string>\";\n\n    // Create a new client and connect to the server\n    let client = Client::with_uri_str(uri)?;\n\n    // Get a handle on the movies collection\n    let database = client.database(\"sample_mflix\");\n    let my_coll: Collection<Document> = database.collection(\"movies\");\n\n    // Find a movie based on the title value\n    let my_movie = my_coll.find_one(doc! { \"title\": \"The Perils of Pauline\" }, None)?;\n\n    // Print the document\n    println!(\"Found a movie:\\n{:#?}\", my_movie);\n    Ok(())\n}\n"
                },
                {
                    "lang": "none",
                    "value": "cargo run"
                },
                {
                    "lang": "none",
                    "value": "Found a movie:\nSome(\n    Document({\n        \"_id\": ObjectId(...),\n        \"title\": String(\n            \"The Perils of Pauline\",\n        ),\n        \"plot\": String(\n            \"Young Pauline is left a lot of money ...\",\n        ),\n        \"runtime\": Int32(\n            199,\n        ),\n        \"cast\": Array([\n            String(\n                \"Pearl White\",\n            ),\n            String(\n                \"Crane Wilbur\",\n            ),\n            ...\n        ]),\n    }),\n)"
                }
            ],
            "preview": "After you complete these steps, you have a working application that\nuses the driver to connect to your MongoDB deployment, runs a query on\nthe sample data, and prints out the result.",
            "tags": "test connection, runnable, code example",
            "facets": {
                "genre": [
                    "tutorial"
                ],
                "target_product": [
                    "drivers"
                ],
                "programming_language": [
                    "rust"
                ]
            }
        }
    ]
}